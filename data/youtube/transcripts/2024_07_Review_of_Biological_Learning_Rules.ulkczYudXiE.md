Cool. So, yeah, I guess as you all saw on Slack, I'll be talking about, learning rules, in the brain today. and this is, I think what's going to be kind of part one of probably like a two part presentation. and unfortunately, Rami, the second part, I'll probably, first give in, kind of September or something. After our other researchers, Hoji and Scott join, but, but, yeah, I'm sure there'll be a chance where you can see it as well.

but, yeah, the general kind of aim is to cover the diversity of learning rules in the brain, but what I'm really going to focus on is kind of the computational details and what the kind of implications of these are. And, of course, the main motivation for this is to kind of explore the significance of these for Monty and hopefully kind of trigger some inspiration, or kind of ideas about how we might use these either now or in the future. And, yeah, obviously stop me if anyone has any questions.

Yeah, I guess what the presentation is not is kind of Yeah, I'm not gonna cover the full diversity of learning in the brain. And in particular, I'm not gonna be covering it at a particularly biological level. Fortunately, I kind of discovered this presentation from Jeremy Forrest before I had put together too many slides. and I thought that was a really nice summary of the all the kind of different learning rules from a kind of biological perspective. and so I would definitely urge everyone to watch that if you've not had a chance.

yeah, I mean, you could watch it after this as well. I'm a little confused if it's about learning in the brain, but you're not gonna focus on the biology. Is it really? I think it'll become clear, as in like that presentation was a lot about, you know, what are the biological, underpinnings of kind of reasons that weights change and things like that. Whereas this is more about. Okay, say you have spike time dependent plasticity, what does that mean in terms of what you can encode and how the dynamics of a network changes over time, things like that.

so yeah, and then I guess why I care about this. So yeah, as we all know, the driving belief really in Numenta is that there's, you know, unique advantages to these biological, learning rules, at least in certain cases. and we already kind of leveraged, I think, some of these in Monty and of course Numenta's prior work. but then, you know, there's scope to expand this, and then I probably won't talk about it today, but, because I think it's better after having discussed all the different types of learning rules. But, yeah, this kind of unlocks various benefits that, that we could realize in, in Monty.

and yeah, I think it's worth kind of saying. So learning currently in Monty is in a sense, Brain like in some respects, so I would argue that all the learning we're doing is local. So local when you talk about like brain, kind of learning rules is basically just that it's information that the pre synaptic neuron and the post synaptic neuron both have. That's all the information you need to determine what the kind of change is going to be. you don't need to transport information from some other, distant part of the network. yeah. In order to to kind of update, the values in the system, and that's that's something that Monty already does. and these changes are rapid associative changes were kind of strengthening or weakening connections between different parts of the network.

you know how we they're not necessarily represented as connections, but, in terms of like how we kind of associate a certain feature with a location in space. That's kind of a rapid rapid change that's made. and these associations are also sparse in some sense that, like, for example, when we learn an object, we're only storing the locations that we actually care about and the features that are associated with those locations. We're not storing information about any possible location on an object.

and I think, yeah, we can agree we want to keep these. So, you know, avoid, for example, introducing backprop in the system, which will start breaking some of these properties.

But I think the key thing that's kind of not present, which I do think, you know, could, bring significant benefits in the future. And this is something we've discussed before is high dimensional feature representations and the learning rules that would be associated with those. So the classic example would be SDRs. so this kind of unlocks using these kind of representations, unlocks a bunch of things around kind of more fuzzy matching. You have these representations encoding features or objects. but I'm not going to be talking about kind of what the specific benefits of SDRs are themselves, but rather kind of if you have, if you are representing things with a kind of, more neural population, what are the kind of biological learning rules that might function, in those kind of high dimensional populations. And I won't just be talking about SDRs. In fact, I won't get to SDRs and Numenta's learning rules today. I'm going to start with the kind of more, kind of classical firing rates and STVP, to give that as a context, for, for Numenta's, learning rules, next time.

Cool. any questions before I go on? No, this, this sounds great. Thanks. Cool. So, yeah, and I'd say the kind of, of course, when you say learning in the brain, you know, that could be at all kinds of levels that could be at the behavioral level. And, you know, of course there's biological processes. Changing the expression of DNA and all this kind of stuff that goes on, but I'm not going to be talking about those really. I'm going to be talking about processes that kind of happen at the level of individual neurons.

and I think it's worth kind of, I think everyone's probably fairly familiar with this, but just not assuming too much knowledge about, like, the kind of structure of, of neurons. So just that it's kind of highlighted in case these terms have come up. So a pyramidal cell is one of the most, common excitatory neurons in the brain, in the cortex. it has this kind of distinct structure of these, dendritic, branches with a long axon that projects and sends, spikes out to other cells, that receive them. And then the dendritic branches are where, the cell can receive inputs as well as on its soma, which is kind of the body. of the cell and, these dendritic branches, have the actual, kind of synapses on their, on these spines, these tiny fusions, and so you can see one here, for example, as like another axon will often kind of pass by, it may produce a small branch or just directly on it, it may produce the kind of synapse that then connects to the spine.

and the kind of knowledge of these, of this kind of structure is key to, for example, Numenta's representation of neurons where, you know, rather than having just like a weighted sum input to represent a neuron, you actually try and represent the structure in the, in the kind of the way neurons learn, where they have apical dendritic, segments, basal dendritic segments, and then the kind of feed forward input, At the Soma. and so these can essentially well, yeah, I'll get into this another time, but these essentially can buy at the cell and it's just worth mentioning. If you hear the term post segment. That's essentially referring to like a spatial cluster of synapses that are nearby each other, in space. Are you going to talk about the difference between apical and basal? I will eventually, yeah, not today. Okay, but that's pretty different. Yeah, because the apical stuff has a pretty different impact, I believe. Yeah. And then just a couple of high level points before we get a bit more into the details, So you could broadly categorize, kind of synaptic plasticity or kind of learning changes that happen at the neural level into what are called functional, you know, what you can think of as like weight changes, and structural, which you can kind of think of as wiring, changes. And so, you know, if you had these two neurons here that are kind of both projecting their axons to each other, then, what you call it, this weight here, that was increased such that If this blue neuron spikes, the impact on the green neuron is more significant, it's more likely to push the green neuron to then spike. That's kind of represented by the increase in this weight, various biological processes that can cause that. Or you can have more of a wiring change where, through, again, various mechanisms, a kind of synapse where one in effect wasn't before, now is. and in general, this is more the kind of flavor of pluses that, the new mentor, uses, yeah, partly because, I mean, yeah, Jeremy talks about a lot of this, which is why I'm not going too much into it, but, you know, there's evidence that the, fidelity of these weights isn't that, high. So, like, there is definitely evidence of this kind of weight persistency, but it might be, you know, the equivalent of having like, very close to zero weight. Very high weight and maybe two levels in between, if you think of it as kind of a form of, quantization. And I think even in like, in distal dendritic segments, the impact of the synapse is way lower in individual synapse. So there, it may, it may just be literally binary at that point. Yeah, right. Whether it impacts at all or not.

yeah, and then another high level point is just that, this is kind of a summary of what Jeremy talks about in case you haven't seen it. Right. The connection properties and how they evolve over time kind of fall on this large time scale. So if you imagine the kind of connection properties becoming stronger versus weaker, this can happen on the order of kind of milliseconds. The short term, that's just the all the way up to. Yeah, I mean, I haven't tried to have this super accurately, but kind of generally days. where you'd have kind of structural plasticity where you're actually growing new synaptic spines. But then in between that, you can modify things about the synapse that give you kind of a, kind of medium term potentiation. So increasing the strength of the weight or, decrease. And then, more kind of long term permanent potentiation. so this would be kind of a weight change. And then this would be a structural places, but sissy change where you can have kind of a, dendritic spine. That's sort of, synapses inactive. But then, through some fairly rapid changes can become, active without having to grow a new one.

and so you can kind of think of these two shorter ones as kind of traces that might serve some purpose, in kind of the short term versus more kind of persistent changes that would, you'd expect to last, kind of much longer.

And then a final caution. just because I think if you have a background in your science, this is often kind of taken as a given. You may not have come across this if not, but there's something kind of generally referred to as Dale's law, but basically neurons of a particular type of neurotransmitter. So an excitatory or an inhibitory neurotransmitter will generally only release that type of transmitter when they, kind of connect to other neurons. And so this means that, you know, neurons are either excitatory or inhibitory and Progressive changes to a weight is not, it will never kind of flip it from being positive to negative, vice versa.

It's worth pointing out, I don't know if you're going to do it yet, but the inhibitory synapses are quite different. They don't have spines, and they're generally not viewed as participating in learning. I'm sure there's some exceptions to that, but there are sort of more background computational things going on. Yeah. Okay. The rule you were just talking about spines and forming a new synapses generally do not are not believed to occur with inhibitory synapses and they don't have spines. Yeah. Yeah. Okay. Interesting. Yeah. I wasn't aware about the, the kind of spine, difference. That's, that's interesting. Yeah. Yeah. Another big difference is that it's, it's not, you know, excitatory synapses I think by and large are very similar, but inhibitory synapses is a huge diversity of different types of Inhibitory neurons and they have very different temporal dynamics and very different types of impact on the on the postsynaptic cell. And so this is like, I don't know, like five or 10 completely different types of. in between neurons in the, in the cortex. And what I've always used is when you, when you have some sort of algorithm that has to be operated or created in the, in the cortex, those algorithms are often highly, dependent on inhibitory neurons, you know, sparsity, synchronization, those, those are the, those are like the, the computational. background where the excitatory for mostly, you know, they are where memories are formed and where you learn things. Right, right, right. Yeah. That's how I view it too. Like the excited synapsis are like the memory of the system and the inhibitory neurons of the control system. It's like actually the CPU instructions, it's a very different view than deep learning. Yeah. Yeah. I feel like, I mean, yeah, maybe at some point that could be interesting to. A little bit more into the different types of inhibitory neurons and everything from the temporal dynamics and stuff, but maybe there's a recording. Yeah, there should be a recording of one or two, you know, videos we've done on that. It's the data on that is not as clear. There's all sorts of. things, but maybe now it's like, you know, six years later, it might be, there might be more. There's a lot of data that's even old about that. I think we said enough perhaps, but just something as simple as, you know, a cell body, the soma of the cell generally does not have any excitatory synapses on it, but it has inhibitory synapses on it. So the excitatory synapses are limited to the dendrites. Where the inhibitory synapses are on dendrites on the cell body and also on the axon. So it's a very different type of, Effect in the system. Right.

okay. Yeah. So then to get into the kind of broad category, then, I'm really going to be talking about Hebbian learning. and I mean, I guess everyone will have heard of this, but, you know, it's this classic rule, associative rule that, you know, cells that fire together, wire together. and this was proposed by Donahue in the 1940s, and I guess one of the kind of clearest demonstrations of this at the cellular level was, first done by, this Norwegian physiologist, in the 1970s, when he kind of showed this long term potentiation, when you, cause, neurons to kind of spike together.

And it's a kind of simple learning rule at face value. but it's worth kind of, your kind of immediate concerns that might spring to mind are probably well founded in that, you know, if this neuron is firing a lot and this neuron is firing a lot and then they keep increasing the weight between them, then, you know, where does that end? weights can grow kind of unbounded in a naive implementation and it becomes unstable.

and so what I think is maybe a useful perspective is that kind of any form of Hebbian learning. need some form of homeostasis to, kind of balance the system. And then some form of competition, which kind of connects to what, Jeff and super tight were mentioning earlier about inhibition, in order to be interesting.

and so I thought this kind of would be a, an interesting way to then examine kind of three forms of heavy and learning. which is kind of the classic firing rate neurons and then spike time dependent plasticity, and then nomenclature HTM neurons.

Where all of these, both of these things apply. And so the first two are really kind of more weight plasticity, whereas Numenta's HTM neurons are more, structural.

So, again, I'm sure this is familiar to, most people, but, you know, just a classic firing rate neuron, just to make sure that we're kind of, in agreement on the kind of variables. You know, you have, some output, which is dependent on a weighted sum of inputs. where these input neurons are spiking a certain number of times per second. That's their rate. And then typically you'd have some non linearity. which ultimately determines the output of the, firing this, this neuron, which, you know, could itself be expressed or kind of viewed as a, as a firing rate.

and in order for this kind of network to, to learn with a kind of Hebbian style plasticity, you would update the weight based on the kind of current value plus, change. This is the kind of Hebbian term. So basically the. Magnitude of the input and the output you want to remember. These are never going to be negative. They're always going to be either zero or positive. And then the learning rate, which is some kind of small factor that slows down that learning.

And so, yeah, this, you know, this is what I was talking about earlier, that if you could just kind of naively implement this and then had a bunch of input neurons and then an output neuron, and then you wired them up, this way, would likely continue just growing unbounded.

and so one kind of popular way that was proposed to kind of, deal with this is to kind of introduce this homeostatic term, which was called Oha's learning rule, where there is a negative effect on the weight that is both proportional to the size of the weight. And the size of the output neuron, squared. And, yeah, so the reason I'm kind of going through this is because I think it's interesting to understand kind of what a firing rate can learn to encode, before we get on to kind of more complex neurons. I mean, it's interesting, I'm not familiar with this rule, I've never heard it before, but, you know, I always felt it was like, okay, a synapse is just a physical structure, it doesn't get very big, it can only do some, release so many, synaptic vessels at once, so it's like physically limited, but this implies It's tied to the activity of the neuron, which is odd to me. I don't know why that term would be like that. Yeah. So there's a few ways you can. So yeah. This equation may reflect what we see in biology, but it's not, I think, what's actually going on in biology. Yeah. I mean, yeah. You can imagine like a hard, a hard balance and that's also somehow controlled by the rate of firing of the neuron. That's weird. So yeah. You can imagine a hard balance so that, as you say, like the science can only get so big. I see. You could. You can very easily just say, okay, weights cannot go above the value of 1. 0 or whatever. and, and that's a totally legitimate thing to do, but it doesn't solve all the problems. the other thing is like, yeah, in terms of what this homeostatic term might represent, I mean, the, the squared here is, you know, I, I, this wasn't a learning rule that was necessarily fit to biological data that, that wasn't its kind of providence, but, but you could imagine that, you know, every time a post synaptic neuron fires, maybe it releases some factor. that then, degrades, kind of synapses, like just kind of a decaying term. I, I guess from a biology point of view, I don't think, I've never heard any evidence for that. So, it is, again, it may be a useful rule, but I don't think it's reflecting biology as far as I can tell. It's just, you know, synapses are physical structures, they're limited, they have limited area, they can only release so many, synaptic vessels, vesicles, and they just hit that limit. That's all it is, you know. Okay. But, but I mean, yeah, I'd say most, I mean, even like, I think the, it's not the same, but the, the HTM neuron has like a negative, well, we had, we had a decay. Yeah, exactly. It decayed. Right. That's not the same as a limiting factor. It's. It's it's a decay and there's and there's lots of different ways, you know, but you know, I mean, it was bounded between zero and one, I guess, because it's it's naturally because it's it's binary. And then there's a decay that kind of, well, it's binary or it's it's just limited. So you could say zero 50. Who care? but, you know, the synapses come and go. And, you know, we do forget. And so there is a part of forgetting is just not, I'm not saying all of it, but a lot of part of forgetting is if synapses aren't used, they just sort of decay, you know, they just can't go with it, so you don't want to keep everything active, you know, every member, we, we, we forget things a lot, right, especially my age, but, yeah, so, but yeah, I guess I agree this is probably not, the most biologically plausible implementation of this, but I guess it's interesting because OHA was the first one to, person to kind of show that, yeah. What is the significance of this is that so in this network, we just have one output neuron that receives a bunch of input neurons X, you know, on through X. I, and if there's some, kind of statistical structure, basically to the activity of the input neurons. Then the alpha neuron is going to pick up on that. And in particular, so if you have the, if you imagine certain precept, pre synaptic neurons are firing together, i. e. they're correlated, that's going to, you know, with some random weight initialization, again, all weights here are positive. with some random weight initialization, that's going to cause the output neuron to fire, higher when those neurons are firing together. And so those will all experience an increase in their weights up to a limit.

on the other hand, if you had some other neuron, not shown here, that you can imagine that is poorly correlated with the others, then this homeostatic term is actually going to kind of negatively dominate. So, you know, the other neurons are driving the output neuron, so Y is high. But, X J in this case is actually low. and so, if it started randomly with a non zero weight, it's going to decrease. Yeah, there is, and it's fine. I don't want to pick apart this, but the basic way. I mean, basically, you don't want too many neurons. Firing and learning at the same time. And yeah, this is getting before before inhibition. I'll get to that. Right? Right. Right. Because this is really done by inhibitory neurons. wait. So, well, but this is kind of imagine for the moment. We just have a single output neuron. All right, right. Okay. But but okay, fine. I can imagine it, but it's not. Yeah. Right. And we do, we don't have that. We have, we have these very fast inhibitory basket cells that essentially enforce sparsity, but it's okay. I just want, I just don't want anyone to get confused, like, oh, this is what's really going on. It's like, well, it's a good way of expressing some stuff. Yeah. Well, so yeah, so just to recap, so yeah, so basically these are neurons that are correlated When they're firing, you know, firing together, they're going to experience, kind of weight growth to the output neuron, and then uncorrelated neurons are going to, their weights are going to decrease. And the end result of this is basically Y is going to learn to respond to the variation along the first principal component, if that means anything. So if you're familiar with principal component analysis, if you have this kind of, cloud of points, some higher dimensional space, you're There's some kind of lower dimensional structure to that. So this kind of axis of principle kind of largest variation. And basically, that is the dimension of which on which the kind of why neuron is going to be most sensitive to.

which is kind of an interesting, that's up to network. Yeah, I remember this was a really big deal in the early nineties when we were, you know, backpropagation had just come out and stuff like that. This was referred to a lot. This is a pretty big deal. Yeah. Yeah. And then, but then what, what makes it more interesting? So, so remember, this is kind of the homeostatic term. all you need is that, and then you can kind of get this, property. But then to Jeff's point, inhibition is very important. and so anti Hebbian learning is a term you may hear thrown around. And it basically just means, you know, as the name implies, the opposite of Hebbian learning. So cells that fire together, there's actually going to be a growth in a negative connection between them. So if you now imagine that we have multiple output neurons and multiple input neurons, then, any given output neuron, if it's highly active, it's going to inhibit the others. And per Dale's law, It wouldn't in the brain, it wouldn't do that directly. There would be some inhibitory neuron that connects to first, which is why inhibitory neurons are kind of called interneurons. it would connect to that neuron first. And then when that inhibitory interneuron spikes, it would then inhibit the others. And of course, this is a toy network where you get kind of one winner take all where one, excitatory neuron when it wins in this output layer, it's going to inhibit everything else.

and so this is interesting because at the moment, if you, without this inhibition, if you had a bunch of neurons in the output layer, they would all learn the same thing. They would all learn this first principle component.

but with this, competition, with this inhibition, then basically the first neuron is going to, or, you know, one of the neurons is basically going to learn, the first principle component. And so it will inhibit the other neurons. when, it's most active along that, component, but then the other neurons and then basically learn to represent, the orthogonal principal components.

and so, in this way, you can get an output. So let's say why the output layer is of lower dimension than the input layer. Then this is, you know, this way you can naturally take like a hundred dimensional input and compress it down into, you know, let's say a five dimensional and a PCA. Decomposition.

any, yeah, questions on that?

Roughly makes sense. Yeah, I think, you know, the spatial puller is sort of a variation on this idea, but instead of the, you know, each neuron being orthogonal to the others. you have an end winner take all, you know, and so it's, it's, it's not, it doesn't have to be, this is one cell wins and they all lose. It's, it's like a subset of the cells win. And then another one, another subset wins and so on. So, it's not, it's not like one cell wins. It's in the brain. I don't see that. Yeah. But it's the same basic idea, but, but it's more of a, an end winner. It takes a long, you know. Yeah. And I guess while we're on that topic, like in terms of encoding, like more continuous properties, like whether that's like how confident a neuron is that something's in the, in its receptive field or yeah, something like that, I guess. yeah. Is that something you, you guys ever kind of thought about whether it would be worth adding back in? Something like kind of firing rates or firing probabilities or we had, we didn't have firing rates, but we had, you know, the way we would, we would do continuous variables as we would have, you know, encoding, which was distributed and change slowly with the change in the, in the continuous variable up to that, up to some resolution. so we didn't have firing rates as such, but we did have that course coding, if you will. And finally, and you do see that in the brain, and we always, you know, I think we always felt the firing rates are just too slow to encode anything useful, because you need to integrate over hundreds of milliseconds to get any sort of, you know, to get a reasonable. scale of value from just a single neuron firing, but from a population coding, you can get in five milliseconds, you can get a pretty accurate core, you know, scale. Yeah, it's clear in the brain. There are parts of the brain that really are.

you know, firing rate dependent, that's a fact, you know that, and, there are parts of the cortex that are that way too, but, so it's not like this doesn't exist, it's just that when we talk about the kind of representations we, we form in the cortex, there's much less evidence for that. There's much more evidence for sparse and distributed representations, you know. You know, I mentioned before, like, a neuron that drives a muscle fiber to contract is a rate encoded neuron. I mean, the stronger you want to contract, the faster it spikes, and you slow it down and speed it up. the time frames make sense for that. It's, you know, and those neurons are coming, some of those firing rates are coming from the layer five cells. So there are firing rate dependent, but when we talk about encoding information in models and so on, it's, it's, the evidence is suggesting it's more, it's sparse and it's not firing rate dependent. Yeah. There's a bunch of experiments that, yeah, like V4 and stuff, you start to see. Right. Within like a hundred milliseconds, you can recognize an animal. Yeah, exactly. Or even less than a hundred milliseconds. If you think about, you know, the information coming to the retina, retina processing it through a couple of layers, through the thalamus, through V1, and then eventually to V And there just isn't time for any firing. I guess the only thing with that is, if you are sampling from like a large population, so like even if Each spike, even if each neuron only has time to give one spike, if those neurons kind of are emitting those spikes kind of randomly with some statistics or whatever. I think that as long as you sample from a large population, you could still kind of approximate kind of the firing rate input. But you might still be a population. That's still population coding. But yes, you could still do that. Yeah, I see what you're saying.

It's not like the same population is encoding completely different scalar values just by changing their probabilities, there's an actual shift. Yeah. Which ones. And you do, you definitely see that in the brain. Yeah. Right. Yeah. It's so confusing because in the literature people slide between, you know, someone will be studying a policy of the snail and there'll be showing this kind of, you know, these neurons that work this way. And the general assumption is like, oh, neurons throughout the cortex of the brain work this way, but it's not true. And so you have to be careful, you know, there's a lot of evidence for this kind of neuron firing, but the evidence in the cortex is quite different. Yeah, you really need to know which neurons they've been studying. Yeah, and what scenario. Were you going to say something, Vivien? I wanted to ask, Niels. Or really anyone is, is there a consensus on which side of the synapse learns as in do you learn by gaining more receptors or do you learn by gaining more vesicles that can emit neurotransmitters or, or both?

honestly, I'm not sure. I, I think it's a mixture of both, but, well, yeah, I mean, I guess it probably varies everywhere. Primarily the postsynaptic cell, but. A big part of it is the area of the synapse itself, how much, you know, like a synapse is just these two membranes that are next to each other at the tip of the, of the spine, and the, there are vesicles containing the neurotransmitters and they, they pass across that gap. And how many can pass across that gap at any moment in time is dependent on a bunch of things, but certainly the area is important. So a big, you know, well learned synapse will have more area, these are really tiny areas, of course, but, more area than a, than a skinny little synapse. so that's one thing. Another thing is, it's a very complicated area because when the vesicles go across and they release their neurotransmitter, they have to be replenished on the presynaptic side. And so, you know, there's not an infinite supply of them, so it's, you know, there's a synapse that fires, meaning it passes its It's neurotransmitter has a period of time where it can't do any more can't do much because it hasn't regenerated new vesicles on the other side. So how quickly it can replenish vesicles. So it's a complex equation, but. Mostly, it is viewed as learning is on the post synaptic side, that's the general rule. Synapses get bigger mostly on the post synaptic side, you can see the spine's getting bigger. And, and that's, you know, I would say most of the learning is generally viewed to be on that side, the post synaptic side. And I was just asking to sort of, like, cause with Rojas So did I get the rule name right, you know, it, it assumes information's flowing back to the synapse and that's going to be easier if it's post synaptic or re synaptic. Right. So all these, all of these rules, at least our rules, require in the HTM neuron, it requires that the, there is a back action potential, meaning once the cell fires, the spike goes down the axon, but there's another spike that goes back up the dendrites. And it reaches the point where the dendrite was active and was receiving information. And that's, that is the learning signal. It says, Hey, yeah, I did fire. Therefore, you know, this was useful. You guys should strengthen this. You've got a way to do coincidence detection at the synapse. Right? Otherwise you wouldn't know. It, it, these, these synapses are not at the soma, remember, they're not at the body. So, and then most of them are pretty far from the cell body. So they need to know if the cell spiked. and so there has to be this back action potential.

yeah, so I guess just kind of the final note on this is just that, yeah, I brought up Oha's learning rule because it's kind of a classic example of how to learn in these networks, but it's not the only way. So yeah, as mentioned, you could kind of have a hard bound on weight values, which you know, there's plenty of biological reasons that might exist, and this would be kind of clipping if you want to use kind of more machine learning terminology. And then, I think, you know, one other classic learning rule that's worth just mentioning is this BCM, learning rule, because, so the OHA's learning rule, I mentioned it learns the principal components, but actually, if you look at the kind of receptive field properties of neurons in V1, say, they're not actually, they don't correspond to the principal components of, natural images. Instead, they correspond to local feature detectors like oriented bars, or at least that's what it looks like when you kind of examine them. And this BCM learning rule actually learns more like these, and it's It's not that different from Oh, I was learning rule. It's just a bit more complicated, complex in terms of how it, how the weight changes are dependent on the firing properties of the post synaptic neuron.

yeah, then with that, I was then going to talk about spike time and fantasticity because, this is where you start to get into how kind of weight changes are actually happening in the brain. So before this is kind of a high level approximation of what we kind of seem to observe. This is much closer to kind of Mathematically how how synapse is actually changed in the brain over time.

and it gets its name because of this kind of relationship between. So if you have a priest and after you're on arriving at sending a spike writing at a post synaptic neuron. So this is the priest and epic spike and post synaptic spike. Basically, this one precedes that one. Then you will get this long term potentiation increase in the efficacy of that synaptic weight. And if the ordering is reversed, you'll get a decrease, but this depression in the efficacy of that synapse, but this only happens within a narrow window around, the kind of timing of the two spikes. and so essentially, yeah, the output neuron is then looking not just at whether, you know, I'm firing and you're firing. But really, it's more of a causal kind of learning rule, because the output neuron is kind of saying, is there evidence the presynaptic neuron was actually responsible for my spiking? Personally, I think it's a pretty cool thing that evolution kind of figured this out. It makes a lot of sense when you think about the amount of noise and kind of random spikes that are happening in the brain, that you would want this kind of sensitivity.

and. This is another way. This is another way that neuron activities get separated. You know, we talked about inhibition. basically, you know, you're going to say, Hey, you know, if, if you, if, if, if your input couldn't have possibly been responsible for my output, you know, then I'm going to tell you not, I'm going to tell you, forget that. And so it will separate out neuron representations, to this rule, as well. Yeah. Yeah. And I guess. Yeah, I mentioned that, you know, this is kind of actually how weights are being changed. So I just thought it was worth kind of showing some actual data from biological experiments where they're showing the percentage change in the efficacy of the synapse, as a function of kind of when the pre and post synaptic neurons, spiked and, and the kind of difference between those. And you see it forms this kind of curve that is so often shown, quite nicely.

and so this is kind of a essentially then a coincidence detection learning rule, kind of a temporal learning rule. and it means that you can have output neurons that are sensitive to the timing of input neurons. and in particular, kind of neurons that are all going to, have signals that arrive together, within a short period of time. And so this is a computational study, from, And one of the groups that's been most interested in this kind of computation in the brain.

and so what they're showing here is so along this y axis, you have the neuron IDs. So you're on 100, you're on number one. these are all kind of in the input layer. And then the blue dots are when they spike over time. and the, they're kind of spike times are approximately random, except for these, Pattern shown in red where they will fire with some kind of fixed, kind of within some short time window relative to one another.

and so what's kind of important to note is that if you look at the firing rate of the population, that's what's being shown here in this bottom box. So if you kind of some along the along this access, the population's firing rate never changes significantly, even when these patterns are being presented And similarly, if you look at the firing rate of this input neuron across the simulation, these aren't any different from the neurons that aren't part of the input pattern. And so basically, a neuron that is limited to, a kind of simple firing rate code and firing rate base changes to its weights. Is not going to become sensitive to, this input pattern.

but, but a neuron with spike time dependent plasticity does. And so, and so it just basically means that Repeat again, how they had identified the red neurons? Because sometimes it's like, it's just one of them. So it doesn't look like there was actually neuron 50, for example, in the, there's just one red dot. So I don't see like why there's a change in the firing pattern.

you're on 50. Yeah. I mean, like here. Sorry. Yeah. Wow. So the firing rate is taken across the entire period. Yeah. Like 600 milliseconds, but that's what's measured here. So like, okay. It's like this one is fired. We 1, 2, 3, 4, 5, 6, 7, I don't know, 8, 9 times or something. And then this firing rate is calculated by looking across the different neurons. and you're expecting at that point in time. Yeah, but what decides if it's red or blue? So they're, they're inserting these patterns. They're, they're just, they're coloring it red to show us that that pattern is there.

but it's basically, they're just saying these neurons are fine. Yeah, so they artificially increased the synchrony during those, right? Yeah, they basically artificially inserted this pattern so that, These neurons are kind of firing with some distinct pattern, like if you look, there's kind of even these like subtle details, like these three neurons firing with this offset and stuff like that. But the statistics of their firing, like if you just look at the, the firing rate, is, is, is the same. It's, it's not being changed during, the presentation of these, patterns. So it's, it's like, it's synthetic data basically questioning like, okay, if you look at the population and it looks like random noise. but secretly there's actually these temporal patterns happening. Would a neuron with STDP learn to respond to those patterns? Okay. So they know that at the red points, they artificially changed it. They know that, but the neuron doesn't know that. It's an unsupervised learning. Yeah. Okay.

Cool. Oh yeah. Good question. yeah. So I, I should say, yeah, everything I'm talking about is unsupervised learning, as well as yeah, local. Okay. Cool.

so, yeah, anyways, but so an STD, neuron, an output neuron, with STDP, learning rules does learn to, respond to these patterns. So that kind of, what that suggests is that if you equip neurons with these, this kind of more biologically plausible learning rule, it opens up the, kind of capacity of what kind of information, how information can be encoded, We're no longer limited to just firing rates, but you can respond to particular patterns in time as well.

are they saying that the neuron learns to respond to this within the red thing? If you were to just scramble the red? Patterns. It would, it would not respond anymore, so they don't know if they made that claim. And, I don't think that would work. So it's not really sensitive to the timing of the red. Yeah, I think you could. I think you could do both like it would. I think it would be fairly straightforward to set the like time constant so that you would be insensitive to their precise order so that you could have like quite a lot of jitter. And it's more that they're kind of synchronous within like, let's say 20 millisecond window. Yeah. Or you can have time constants so that they have to fire, you know, within three milliseconds of this prescribed pattern, each neuron.

I guess I'm just, like, suppose you did exactly what they did here. Yeah. And the claim is, okay, it's going to, it's sensitive to the timing of the input neurons. Yeah, but after this learning process, if you were to scramble a few of these red, the timing of a few of these red dots, I think it would still fire. It's not sensitive. I think that's what it really that's. Yeah, I think it does depend on the time constant. So, like.

yeah, like, especially in each synapse time constant, does each synapse have its own? But as in like, so if, yeah, if the time constant is fairly wide, then, then I agree like, you know, and, and sorry, I mean, yeah, I guess there's the STDP time constant, which is already fairly broad, but, but more I'm thinking the, like conductance and things like that, where basically like. The time over which the spikes can be integrated by the, the post synaptic spiking neuron. And, Yeah, but if it, I don't know if that's true here. because if you look at just those, you know, you pointed out that diagonal pattern here. If instead it went like this, I don't, I don't think it would make any difference to the output, regardless of. Yeah, not, not in this experiment, but I think there is a, a setting where that wouldn't, so we can maybe talk about this the next time with like, Right, you can construct, you can construct that, but I don't think STDP enforces that. I think the claim here is that STDP causes neurons to become sensitive to the timing, but that's not true. No, yeah, I, I would say that, that that's not true. Yeah, yeah, basically you'd need, like heterogeneous conduction delays. Yeah, you can do it. And basically, like, if you still need STTP, but, but, but, yeah, it has STTP is no longer like sufficient. Yeah, yeah, exactly. Yeah. Yeah. So, like, yeah, just for anyone else who's curious, I guess, yeah, I'll talk about this next time. But there's, this is kind of a form of synchrony. Although, yeah, they have kind of fixed the pattern, but there's another thing kind of called polychrony, where if, let's say, yeah, they're firing with this kind of specific pattern, right? Yeah. If you have asynchronous, or like heterogeneous conduction delays, all landing on your post snap neuron. depending on the values of those delays, these might all be arriving within a very narrow window. Like, you know, within a couple milliseconds of one another. And then, you can imagine, potentially, an output neuron that's then sensitive only to this pattern. And then if you reverse the order of these, and all these, and whatever, like, they all fire within this kind of time window. But in a different order, then that output neuron would not respond.

but that's a big if, because you need those delays to be correct.

but yeah, I think it's worth kind of tying it back to this kind of general principles of Hebbian learning. So although now things are kind of dependent on time, it's still fundamentally a Hebbian, kind of learning rule. So you still need some kind of form of homeostasis. So again, you can have this issue where. Weights will grow kind of unbounded. And so one of the first papers to kind of computationally study STVP, they basically had this kind of actor where inhibition slightly. Sorry, I should say. So this is kind of how much the weight is going to change, depending on the difference in the timing of the spikes. and basically, you know, you either have like the weight being increased, in which case there's this kind of positive learning rule, learning rate, or it's the weights are being decreased. and then this just is determining kind of the sign and the magnitude of that for these curves. But basically, they made the inhibitory kind of learning factor or the decrement learning factor, larger so that it kind of balanced learning in the network, and it didn't kind of runway again. It's not necessarily good biological evidence for that, but it's just an example of the kind of challenges and things to be aware of when kind of, I guess, working with, happy and networks.

and actually for like a real heavy network, that's still I mean, these are very, sorry, a real spike in your network. They're generally very challenging to get to learn, anything. and so, you know, in the study, it was still relatively simple stimuli. I'll show in a couple of slides, but they had a variety of kind of biologically motivated. So they were all local and everything like that. But. But it was like four different homeostatic factors that were all working in concert to get stable learning and so that the, they could basically have the learned representations maintain over, a kind of unbounded amount of time, even though there was kind of constant noise, being fed into the network.

and similarly, the competition is still important. So. This was a follow up study from the muscular group to the earlier one I showed. And here they're, with this first one, they were basically showing that a single spike neuron could learn this pattern. It could learn a single pattern, so kind of the equivalent of the single firing rate learn, firing rate neuron learning a single principal component. In this follow up study, they showed that multiple output spike neurons could learn multiple different input patterns and become sensitive to those.

Yeah, LIF just stands for leaky integrated fire, which is a type of, a simple mathematical model for a spiking neuron.

yeah, that's what these output neurons learn different patterns.

so yeah, I mean, in general, this seems pretty neat. And there was a lot of excitement about temporal code in the brain. I'd say particularly between 1996 and 2006. tons of papers about this, and kind of the biggest journals there are. but maybe around 2007 onwards, there was this kind of general shift in the zeitgeist where there was concerns about kind of plausibility in terms of kind of noise in the brain and things like that. And I also wonder to what degree maybe the success of artificial neural networks as models or, or the embracement of artificial neural networks as models of the brain. Kind of dampened enthusiasm, around kind of a temporal code, being significant. But I think what, yeah, you can definitely say it's temporal. The temporal sensitivity of STDP is a biological fact. and so the existence of temporal codes in the brain perhaps less clear, but I think kind of when Jeff alluded to this earlier, there's, you know, it's probably somewhere in between. So what's interesting, actually, about STDP is that, They themselves are kind of a hybrid. So, so this is the study I mentioned earlier that had like four different homeostatic factors. These were kind of stimuli. So if you imagine this is a 64 by 64 grid of neurons, the white neurons are firing with a higher rate and they will be showing these different inputs. and, but the spike times of those neurons are governed by a Poisson distribution, so they are kind of random in time. there's no kind of synchrony or anything like that going on. and this neuron that's receiving these inputs is a spiking neural network with STTP based learning. and it will learn to encode these different patterns.

and so, and in general, this connects to the fact that, essentially at low firing rates, STDP is in general more temporally sensitive, whereas at high firing rates, it starts to act more like standard firing rates, heavy and learning and part of the reason this emerges, I just thought of this, but to mention this, but I could have had a better graph, but you can imagine, You have this neuron spiking and then this neuron spiking, but now imagine that this pre synaptic neuron is firing so frequently that it fires at this time as well. So just after the other one that's firing just before and just after. and that's generally the kind of regime that starts happening when you have really high firing rates where, it's kind of symmetric. And we know in biology that in that kind of regime, like if we experimentally do the neurons, they tend to act more just like the simple heavy and weights.

but then, yeah, as mentioned at lower firing rates, these two are going to be very different whether the spike happens before or after. and so then you are going to see this more asymmetric, temporally sensitive, changes to the weights. You generally don't, I mean, there are neurons that fire, spike very rapidly, but you know, that's not typically, for example, pyramidal cells. they, you know, there tend to be more inhibitory cells. So it's, it's not clear that particular thing we're talking about actually occurs very often. you know, most neurons don't fire that fast, that, that, that role, this, this idea would come to play. Okay. Thanks. but, you know, some inhibitory neurons do, and in some places you see that, but it's, it's pretty rare in the cortex. You do see a, a bunch of neurons that they don't emit a single spike, but when they become active, they emit a, a, a train of spikes anywhere between three and five long, and those are very close together. It just complicates things. Right. Yeah, I was going to maybe try and talk about bursting next time. Right, right. I know that's something you guys account for. Right, because that, that, that can lead to what they call metabolic changes, which are changes in the chemistry or slower changes in the cell. Anyway, yeah, I don't know if I should keep interjecting my biases into this. It's a good presentation. No, no, no. I mean, I've always found that STTP was over, you know, you said it had its, its, its decade and then it kind of declined. It's a, there's a very, very simple explanation, which you've already given, is that, you know, there's a lot of time, there's a lot of time delays and uncertainty in the brain, and, and a lot of neurons have a background firing rate, which is pretty low, but they're, they're kind of firing a lot. I mean, they're firing all the time at some low rate. That's pretty common. And so there's a lot of random spikes that don't mean anything. And, and so this rule basically says, you know what, let's only pay attention to the ones that are truly causal, that this predicted this, you know, so if pre, pre synaptic neuron is a good predictor of the post synaptic neuron, well, we want to remember that, and it shouldn't be much of a delay because we're not trying to predict, we're not trying to look back in time, we're just like, right now, these neurons, this one happened before this one, you know. and, it just sort of cleans up the whole learning rule stuff and clearly if something happened after, if the pre synaptic neuron fires after the post synaptic neuron, it couldn't possibly have predicted it. so, forget that one. Yeah. There's very simple pedantic mechanics here that could say this is why the brain works like this, as opposed to it's a, this is an important part of how information is encoded. It's more like, hey, it's an important part of how synapses learn, but it's, I've always viewed it as sort of not really an information theoretic composite. Yeah, you're right. But as you point out, a lot of people wrote a lot of papers suggesting otherwise. Yeah, yeah, so, yeah, I guess it's also just kind of on this note of like, okay, maybe it's not like a black and white in the brain. I think it's also worth mentioning that there's some neurons that are at least more amenable to encoding information in more kind of temporal like activity. So, for example, like the, the spikes that arrive from dylamic neurons, like LGN, onto the cortex. tend to be more kind of driving inputs that have, where, you know, just a handful of spikes can be enough to cause a post synaptic, spike, whereas many other spikes in the brain, you might need hundreds to, to kind of, come together. And in general, like there's, you can kind of show that those, these kinds of small, like sparser high magnitude spikes, if there was kind of a temple code. It would, you would be using those kinds of, sign access to, kind of encoded and transfer that information. We proposed in our neuron paper an alternate explanation for that, which is that, the vast majority of synapses are pretty far from the soma, and they're on the dendrite branches, and any, any individual spike out there has very, very little effect on the, on the soma. So what typically a researcher will do, they'll measure the voltage inside the body of the cell, the soma, and they'll see what happens when, a presynaptic neuron fires, and, and they'll say, hey, This, this piece is not going to be neuron fried, but it has a soma, therefore we're going to need hundreds of them. And, and other ones will have a very large effect on the soma, since we only need a few. But we propose an alternate explanation, which is the ones that are far from the soma, you don't need hundreds to summate, you just need 15 or 20 near each other, and then they generate this dendritic spike, and then that dendritic spike has a large effect on the soma. And, and so the vast majority of the studies that people did in this area, they didn't account for that possibility. they just measured like, Oh, well, this synapse doesn't seem to have much of a fact. Therefore, we need a lot of them as opposed to, well, let's happen. What if we had 15 of them at the same time in the same segment of the dendrite, then you'd have a very different effect. So I just want to point that out that, yeah, that was a big, big part of what our neuron theory says. It explains that that difference, it gives a functional reason for it. Right. So, so yeah, just that. I guess we shouldn't discount at least the possibility that, binary temporal and kind of more sort of binary codes could be working together, but right, you know, I think the whole one of the temple codes that we talked about recently, is this idea of, you know, groups of neurons firing in, in sequence during a phase of a background frequency, like, like, you know, looking at the data frequency within the, Within the 100 milliseconds of the, or whatever it is of the, of that cycle, neurons go through a sequence of patterns. And, and that's a, that's a type of temporal code, which is obviously very important in the brain. but it's not the kind of temporal code that most people think about. It's, you know, most people think about, I believe what you're talking about, most people think about temporal code is like the exact timing of individual synapses, or individual cells, where clearly that's important in some parts, but it's much less evidence for that in the cortex.

Yeah. Maybe the way to put it is that everything you said in here is correct, but it's also very, very. Confusing.

Yeah, hopefully not too confusing. Well, you presented it clearly, but I think, you know, a lot of people, a lot of the research out there hasn't really incorporated the kind of the insights that we've had. And, and, and, you know, I don't, you know, sit there and say, Hey, why don't you guys are listening to us? I don't feel that way at all. But I do feel like we really understand some of this pretty well. And, the vast majority of researchers out there don't, don't think about it that way. They just don't even consider these possibilities. There's a lot of like, really detailed experiments on plasticity and, and have like very specific. Shows very specific, types of plasticity rules that we, I found correlate really well with what we did in the neuron paper. I have like this detailed list of, things just like that P minus that you pointed out, for example, that in that paper, there are experiments that validate that. Yeah, okay. And then what happens when a dendritic segment fires? And the postsynaptic cell does end up firing or it doesn't. What are the, what's the impact on the dendritic branch? There's like specific things that happen there, that correlate really well with, with our, our learning rules. and then there's some there that we haven't yet incorporated, I think, but there's a lot of like, really. Detail things that are quite important at the end of the day. Yeah, I feel like this level is interesting, but it's it's hard to know what to really make of it until you actually put it in an algorithm, actually put it in a network and have it do something real. Yeah, and that's the piece I feel like I don't know now, but at least a few years ago in the computational neuroscience community, they didn't do much of that at all. I don't know how you could combine all of these to recognize a cat, an image of a cat, for example, you know, they show, okay, like oriented bars emerge, you know, okay. Yeah. Yeah. And I guess on that note, so like, yeah, just kind of summarizing. So, yeah, the, these kinds of two Ebbian learning rules I talked about today. So the kind of firing rate based ones, you know, they can learn input features. The PCA of the data or more local features, which I didn't get into like kind of oriented bars and then SDP based kind of spiking of this. They can learn temporal spike patterns, but they can also learn what kind of firing rates neurons can, but, oh yeah, but, but to your point, super tight, they're extremely complex to set up and maintain and just get to be stable. like, yeah, I think in general it's, It's a great way to start pulling your hair out is trying to work with spiking neural networks. If I believe I, I think we shouldn't be tying heavy in with finding rates. I believe heavy head did not talk about the firing range. He just talked about, you know, firing together. And, yeah, so I didn't mean to imply that we use have been learning in our, in our neuron role. I mean. Yeah. Yeah. It's really interesting to read what he actually said. He did not say neurons that fire together, wire together, as an example. Right. He had a very specific sentence or two that's very telling. Right. Yeah. It's interesting to read that because it's, it's, you know, it's a lot more precise, I think. And if you don't mind, I'd like to make a comment back to the question Michael asked about earlier.

it's, there's a, think about a synapse, right? You have an axon and a dendrite and they might be near each other and they may not have a synapse at all, but they're near each other and it's sometimes referred to as a potential synapse. And so even in that situation where the, where the axon and the dendrite are near each other but not connected in any way, they, they will have been learning type of. rule, they will form a synapse. So, they will, they will grow a new synapse. The brain has the ability to do this. It says, you know, I know you're not touching, but, you know, you should be. And, and, it's, these, there's these other, neurons, or these other cells in the brain that facilitate this. and then, and then you start off with a very skinny little synapse. synaptic, spike, spine. It's really like a little more like a little thread and it works. And as you, as a, as a, as the, the synapse trains that it gets reinforced, the, that, that, spine gets, gets bigger. Now we talked earlier about like, oh, when it gets bigger, maybe more neurotransmitters get passed through, but there's a lot of evidence and, and some other people wrote about this and we adopted it. that once a neuron gets to a certain size, it doesn't really, and you still train it, it doesn't really pass any more neurotransmitters. That is, its weight value doesn't go up, but the spine gets bigger. So the spine continues to grow even though it's not transmitting any more synapses. And that, the idea behind that is that the spine is a, is a sort of permanence. It's like how, how hard is it to forget this synapse? Once you've built it and it's structurally there, it's a lot harder to get rid of than if it's just some skinny little thing and, and so we adopted that as a, we called it permanence. It's, it was a, it's a, it's a learning that is not about increasing efficiency. or transmission, but more about permanence of memory. And so things that have been reinforced a lot, even if you don't use them in a long, long time, you'll still remember them. where if something that you learned recently, and it's just as, it has just as much effect as the old synapse. But you might, you might forget it pretty quickly if you don't continue to, to reinforce it. So, it, there's, it, I just wanted to point out, that's a, back to what Michael asked earlier, learning is not just about increasing efficiency, it's also permanence of these memories.

Yeah, yeah, and so, yeah, the presentation from Jeremy, there's a lot of discussion around the kind of biology of that, and then, otherwise, the next presentation I give, I'll go into, I guess, yeah, it mentions actually algorithm for how the premise values change and things like that, and then what the significance of that is. Could you just, I mean, you had the link in the presentation to that. Yeah, I'll, I can share it on Slack. Slack someplace, I'd like to listen to it. Right, all the way to the start.

Yeah, it was two presentations from November 2021. Oh, yeah. But yeah, I'll send it on Slack. Jeremy Forest. I guess I could just look, but, yeah, I just wanted to kind of in summarizing just say that Yeah, just kind of the, the kind of one thing to just remember is that Yeah, at its core, like heian plasticity is kind of working in both these firing rate and these spiking networks. and so some homeostasis and some competition is needed. And actually when we talk about ensis algorithms, the, the same will still apply because it's, it's still, as you were saying, Jeff, fundamentally, Hebbian plasticity as well.

so, yeah, so that's what I'm going to focus on next time is this kind of structural plasticity and the role of the actions and the role of dendrites. But, but there's a few other things I'd like to just touch on briefly. I mentioned kind of mile or polycritic and how that might connect to myelin plasticity. I think kind of dopamine and serotonin is worth kind of referring to briefly. And then, yeah, some other things we've talked about recently, like contrastive learning, representational drift, objective coding, and then maybe local ish backdrop in the brain. I think it'd just be interesting to, to touch on.

but hopefully this was like a useful starting point. Yeah, thanks. That was great. Yeah, thanks, Nils. Yeah, then I've got these slides about kind of potential benefits, but I, I think they'll make more sense after we Talk about, talk about the other learning rules and, and those are all clear.