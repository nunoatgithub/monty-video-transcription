this is an interesting, it just shows, several things going on here. It shows ods, secs, which are green. it shows, when you think you're fixating, and, but you're, drifting that's in, in yellow, and then there's micro secs, which are red.

It's confusing. the point of this is that, your eyes are moving all the time. And I had a recent, even when you think they're fixed, so you think your fixation is in yellow here, and you could see the eyes are drifting during that fixation. And then there's, there's this, A micros odd. I'm not sure if that's the same as drift or jitter. There's, so they talk about this jitter. No, I think those are different. Yeah. Yeah. I think the drift is more smooth and less controlled. No, but then there's a jitter and a micros, so I'm not sure they also, the jittering here. Yeah, I think the jitter is like even smaller than the micros. And, that's yeah. what, Bruno also has just told me recently, I saw him a few weeks ago, he, he told me that even during the smallest of these movements, that the retinal ganglion cells that are getting activated are completely changing. That is, there's no stability in the, signal from the retina.

which is surprising. He also pointed out that, that we're able to determine, detail, which is cannot be captured by the resolution of the retinal ganglion cells.

so the brain is relying on integrating the, retina is relying on integrating, input, excuse me, of the, cones, the re photoreceptors. And so the retina is already doing some sort of time integration of information. So I don't have any conclusion of this, but it's just something to keep in mind that when we think the, sensorimotor is fixed, it really isn't, and it's moving and things are changing all the time. And these changes lead to changes in the, retinal output, and the cortical input. I don't, I'm just, I'm not making any assessment of this. I'm just pointing out that when we try to think about the problem of, oh, you have a, non-moving sensorimotor, at least it comes a vision, it doesn't really exist and it's constantly changing all the time. And that can impact the way I think about the problem a bit. but I just thought pass that on because it's not obvious that stuff, is happening all the time, but it wasn't obvious to me. Yeah. That drift is much bigger than I would've expected. Yeah, I thought so too. I maybe, I thought that, and I thought sometimes the cards are much larger, so maybe, but this says here, if you look on the bottom right of this image, it shows a little hour. It says one degree of viewing angle. this picture is, I wonder how long they were viewing it for. 'cause just from a quick Google, it sounds like you might have half a degree of, drift per second or something. So you'd have to be staring at a point for quite a few seconds. Drift that far? Yeah. I, I, don't know. That's interesting question. I, honestly didn't read this paper, I, I, let's not make any grand assumptions about it. all I'm just saying is that there's a lot of motion, going on, right? And even the jitter, in these micross are sufficient to change the output of the retina. And of course, it depends on how quickly they're cha, these things change. I didn't think, I didn't find anything which said, the eye movements well, I don't know. I have, I didn't do research on it. I, it wasn't the most important part of the, work I was doing, but it, I just was curious about it because in the end, what I concluded, not conclude, I didn't conclude anything during studying this problem. What I came to realize is that, there's no easy, I couldn't see an easy solution to this problem. And, and maybe somebody else does, but let, me just walk you through my thinking about it, if that's okay. Can I ask a quick question? Yeah. not about if anybody has seen like a trajectory when the eye is doing smooth pursuit movement, like how much kind of jitter, like not the eye went jitter, but how much variation there is if we're intentionally doing smooth pursuit, is it, less sporadic?

first of all, I, don't know that answer. It's a good question. I do know, I would be careful of the word intentional because you cannot intentionally in do smooth pursuit, okay. That it's, it is a, it's a, reflux type of thing, and you can't consciously make your eyes do smooth movements. but the eyes will do smooth movements to follow a moving object. Okay. That's my understanding. But it's still an interesting question as to, how accurate they are. I don't know. Yeah. Maybe they, I don't know either. I guess the only thing is I think it's thought that the micross are intentional, whereas jitter is potentially just like neural slash muscular noise. I When you think, I thought the, secs were intentional, but not the micros secs. Okay. I, maybe it's in the open question, but I, think there's at least a fair number of people who think have various purposes related to things like attention and Oh, they may not be, they may have purposes, but you're not aware that you're doing it. Oh, yeah, Sorry. Yeah, Sorry. Intentional as in intentional sort of from an evolutionary point of view. Whereas Jitter I think is just that's the resolution of that biology can do, right? so basically I imagine with Drift, sorry, with smooth pursuit, you'd still have, jitter and, maybe drift. But maybe you don't have micro sec cods given the nature of it. I don't know. But and I think that, I think they, the question about Drift was, is that just an, are you just correcting an error or are they functional as well? I think I've heard arguments in both cases anyway. I don't wanna spend too much time on that one, so I'm just gonna go some texts here if you don't mind, and we can talk about it. So first of all, and this is a summary of lots and lots of notes of confusion I had. So this is like boiling it down. So what is the problem? the problem is we can recognize objects that are briefly flashed on the screen, in theory without sensorimotor movement, but that's questionable if there's any sense of movement at all. But without sensorimotor movement, our learning modules, voting acts like a bag of features and therefore, presumably Monty with no movement can't do flash inference.

if, we allow even the small amount of movement, we're no longer a bag of features. And so it's not Monte's useless. in fact, in the, frameworks paper, we, showed how just a few movements can really make a big difference in it voting.

anyway, but if we assume no movements and, then it's like a bag of features and then you presumably couldn't do any of the things that you guys are just doing.

so therefore the relative poses of sense features must be used during flash inference. that's a logical conclusion I think, unless my logic is wrong. and this ability is missing in Monty. it's not clear how important this is. I guess just to clarify, so Monty does have that ability, but we just don't know how it might be done in the brain. Oh, I didn't know that. Yeah, so Monty has the ability, because what we give as input to learning modules, are locations in the common reference frames. So we can easily use those to have the relative poses between voting learning modules. But the question is if we wanted to change that to giving only movement, vectors only displacement as input instead of absolute locations, then well, how does, so how does that work? Alright. So then, a lot of my analysis, I'm thinking about the neuroscience here, and I wasn't, even aware of this. I'm sorry about this.

how, do you solve the problem that, there's end modules and therefore who updates who, what, how do you, I, really struggle with this issue is to like, okay, even if I know the location of each learning module and relative each other, how do you update the learning modules to, how do I take advantage of that? Again, I'm thinking all neuroscience, so maybe I'm completely off base here.

maybe can you explain that to me? Maybe Niels, it's worth pulling up the picture from the paper where we visualize that. So basically we calculate the relative displacement between the sensory input that goes into the two learning modules that are voting. And then the sending learning module basically says, I'm here. I think I'm here. So given our relative displacement, you should be here and then, but, if you have a hundred learning modules, how do you do that? I guess that, so, it is comp, it does computationally, like it does get expensive with, as you scale more learning modules and it's current form. But basically you can imagine each learning module that's receiving votes, let's say this learning module is receiving votes, it would do a different offset. There would be a different displacement for each set of votes coming in, depending on which learning module it was coming from. Which column? you have to go, you have to go, each learning module has to go through each other learning module one at a time. you could do it in parallel, but yeah. But they're done separately. So it's an n squared problem then, right? Yeah, yeah. And Monte you can, specify like a connectivity matrix of which learning module can vote with what other learning modules. So you can make that sparser or you could think of it in the future being like an intentional thing or whatever. But yeah, and also here, we send a lot of votes right now 'cause whatever, but You could make votes much sparser. You could imagine sending just, I don't know, three or four really important votes per learning module. So I might, my whole analysis might be off base here because I was thinking like, okay, I'm working with Tical columns and what the representations have and how would they do this problem? And I don't think they can do the way you've shown it here, because this requires a, serial processing going through a list of other columns and yeah, I don't know if it's necessarily the serial nature, the, because it can be done in parallel. I think the issue is more, you, can't, somehow, you need to do this center displacement. I guess it depends on how you're accounting for it. if you accounted for it before it came into the column, then you could do it in parallel. But that's the issue. Like with the lateral connectivity, it seems to go straight to like the, layer that's meant to be, explain this to me 'cause I'm confused about this. if I'm one of a hundred columns and, and therefore there's a other, there's 99 other columns out there, how would I process in parallel to accommodate all of their relative positions? Basically all of the a hundred columns would send out, I'm here and I have these hypotheses about where I am on the object. Yeah. And then all the receiving columns would take that kind of, I'm here signal and calculate the difference to where. The receiving column is, and that's the displacement. But you have to do that by column basis. You can do it all at the same time. Like you can update all of them in parallel because it's basically, they're just all sent their hypotheses out and they might send their hypotheses to all of the other learning modules. Yeah. But I'm one learning module. The learning I have, I'm one learning module, I can receive all these hypotheses. Yeah, But how would I'm trying to understand how the neural system would, process that. yeah, I think at least computationally it's definitely can be broken down as a parallel computation in terms of, but in terms of what neurons would do, I feel like, like an alternative would be more where as long as each column was voting on, more of a central location, this, would require basically that like different learning modules that know about different objects have a, similar sense of like the, not necessarily the center, but if, I'm communi, let's, sorry. Let's say I'm a learning module that knows about phones and I'm communicating to the next level, okay, this is where the phone is in space. If there's some sort of agreement between the other columns that are laterally connected about where this phone is in space and how to describe that, then they could vote directly on that. So as in, if they're all saying, oh, the phone is at this coordinate. Which kind of localizes to this thing, then they're all going to agree, if they're seeing the same thing. And then the displacement kind of happens. That calculation happens once within each learning module because they're basically taking their kind of object centric sense of rather than voting on where they are on the object, they're saying, where's the object in the environment in some egocentric corner. So they do that calculation internally, and then they project that. I'm still confused by this because no one, we don't know what the object is yet. Nobody even has a reasonable Yeah, this would be a hypothesis, but based on that hypothesis, they could calculate a location of the object. But imagine in a, real world, it's very unlikely any, in a single sensation, it's very unlikely any column would've any reasonable hypothesis of the object.

and so I have to assume, all I know is a feature, and I might, the system might know, okay, I know someone might know, a column in our current implementation, a learning module or column, at least in our current implementation, wouldn't know where it is in egocentric space. But we can imagine somebody does.

then, I just still don't understand how I could say, okay, we have a whole bunch of people in different points in space, relative to the body, let's say, in these different features. but I don't know what the, I don't know what the shape of this object is. I don't know what the object is. And how would, another way I looked at it was the following. I said, imagine I'm a column again, I was thinking political columns, not learning modules and the representation I have in a column. What could someone tell me that would let me change my hypothesis, make me more accurate? No, I couldn't figure out the answer to that question. I could say, yeah, someone could tell me what the object is, but that's the whole problem. but no one can tell me where I am on the object. How could they, they could tell me where I might know where I am in space and I could go thoroughly to other people one at a time knowing where they are in space. maybe someone could calculate a OID or something like that. But, I'm just confused by this. Maybe, I didn't, Can we, let's, what's the answer to that question? What could a, cortical column be told, have it, that would help it, infer rapidly? Yeah, I guess it, what we basically do in Monty right now is we tell it where it is on the object. So like in the object's reference frame, what location, but how, do you know the object's reference frame if you don't know what the object is? Yeah. So there's one assumption that I don't know if it's reasonable, which is that the object was learned. All of the columns at the same time in one specific location. So they all have learned the object in the same orientation. specific egocentric location like, relative, yeah, like the mark was on the table and all of your columns learned the mark at the same time while it was in that orientation. so that is that a reasonable assumption? I thought it was at the time, but I don't know. Maybe it's, it, feels yeah, we could accommodate it. Like right now it's, like a strict requirement, but, if it, yeah, like we talked about ways that you could accommodate in like an unsupervised way where Yeah, as long as that generally holds true and you resee, you see the object in many different instances. Like I, in the future you might be learning more about the mug in a different position, but the point is it's not like some of the columns are getting like one version of the mug in one location space and other columns are getting this version of the mug and this location space, like the mug is basically presented to all of them as like a single object. But, yes. But over time it could be, any instance it would be one place, but in other places it would, different place. Yeah. And, that's, I think that would be fine. I think that could be accommodated. I, guess I'm, not fine. I think it's only an issue if, you almost have a VR headset that's like projecting two different images to each eye or something. It's mostly an issue if it's like you learn it by looking at it and then, but not by touching it. And then you try to infer it with touch in a different orientation. But, I think that's general. Maybe not something we need to expect, but be able to do.

also, maybe I'm confused by this because I'm, when I think of reference names, I'm always thinking of grid cells and how they work. And, and there's no com there's no shared reference frames. It's not a shared reference. They all have their own reference frame. It's just, yeah. They don't even have to, they're like different spaces. The main thing is that the, as they're learned, they need to be aligned in the orientation so that if we then apply a displacement to both of the reference frames, it moves you through them in the same way.

I think I totally misunderstood this. so I apologize for that. I was, I was trying to imagine how this stuff would occur in the brain and, was not even, I guess I wasn't really cognizant of how Monty was doing it today. So I'm not sure how much my analysis would be very valuable. I'm still struggling with it because I, read some sort of conclusions thinking about the neuroscience, how difficult this would be to do.

but not knowing how you guys did it, using non, using non neurons. I should probably just get myself educated on that more and, see if I could, I saw as a fundamental problem as I couldn't resolve, I, felt like I should be able to resolve it, but I couldn't get it resolved. How, even if I had egocentric representations or columns are how I would, be able to, how they would help each other. how would I, how can a column be told where it is in some location space, based on all these, the hundred other columns when nobody knows what the object is.

yeah, because for what it's worth, I, would say that yeah, that part does work now that even if you just get one observation and then, so it's inherently ambiguous, it's just a surface normal and some curvature at one point, that could be anything on pretty much any object. when it's combined with all the other observations, through, through voting, it can disa, big disambiguate the object. I can, maybe I should read the K paper more carefully again. I just don't see, I, you can say that, but I couldn't see how it gets resolved. It's, yeah, I made some writeups and visualizations on this back some years ago when I implemented that. I can try and dig them up again and, send them in the, research channel. Yeah, maybe, it is, this is a, common problem I have is where I think about a problem one way and I reach some conclusions from it. Think about it the other way, that way. And other people think about it different way. And, then, and yet, I, but my co conclusions seem very solid to me and, in my language and my thinking. And, yet, when people describe it in other languages, they say, oh no, it's not a problem. Or something like that. And I'm like, I get, I just, I still feel like it is, like I, I haven't been, I have to somehow see where the failure of my logic was.

so did you come up with an alternative?

I came up with Do you wanna discuss or, I thought it was worth maybe discussing, and maybe this is just some of my observations. I'll go back to sharing my screen.

I thought there was, here's how I thought about the problem. I thought there was two classes of solutions to this one class of solution. I called the fully independent assumption. This assumes that sensorimotor patches can have arbitrary poses relative to each other. There's no restrictions on that, and therefore it requires a central method for columns to communicate the relative poses of their sensorimotor patches. It requires you have a central place where everybody's going to, and then that's communicated back out to all the columns. my as this is what I think you've implemented and this is what my walking in assumption was, and I had difficulty getting it to work, so I might just be missing something. probably, but there's an alternate one, which is the, I call it the partially independent assumption, which is that central patches rely on the relative position on the retina or on the skin. Skin. And this could, use local communication between the adjacent columns, that it wouldn't be a centralized, sort of communication proposition. this is not where I started, or, but I, but it I, and I didn't reach a conclusion, but I, this popped in and raised in relevance. Let just talk about it a little bit. these two classes a bit. 'cause I'll explain some of my thinking behind it. So on the fully appendant assumption, this is attractive because it's a universal solution, right? It says, oh, I can have any kind of centric patches and any orientation with each other. And no matter what it is, it's gonna work. So I immediately, when I started thinking about, cor common cortical algorithms and inferences where I went, I said, it is, what is the evidence for this? that there's a central repository. and so immediately I knew that when I talk to other neuroscientists about this, they would point out, these, the columns, the, columns aren't in, random. They're all arranged right in topological order on the retina. So they have this fixed relationships on the retina, which is consistent with the partially independent assumption.

and then I said, let's not talk about, this is my own thinking. Now, in the, past, I said, let's not talk about vision. Let's move it over to somato century input, because there, it's clear that sometimes at leaves that the skin, the, sensors on your skin are not, are not dependent each other. and then I, and I realize that's not even true of the skin on one hand. So if you notice, when I usually talk about this problem, I usually talk about two fingers on the two hands. because that, I can imagine moving those two fingers in, the tips of those two fingers in, one pa, one, one sensorimotor patch, or one finger and one sensorimotor patch on the other finger. At least those would seem to be independent moveable.

So I said, this is why I described, the problem with fingertips on both hands.

and even the fingertips on the hands are not completely independent. I cannot move my in fingers independently. So I to, prove that we had to, that there had to be a fully independent solution, meaning a solution that required they could work at any, set of poses, of essential patches. I had to, at least, I had to come up with an example that didn't require some relative positions, that it didn't have relative positions and the retina didn't fit that requirement, and most of the skin didn't fit that requirement either. so you following me so far in this? Yeah, I'm just, okay. I can't see you, so might as well just say yes or something. yeah, but I never felt totally comfortable with that either. ignore, ignore this next paragraph for the moment. don't read this one yet. Here's why. Because when I actually tried to do flash inference with my fingertips, it's hard to do, but it's an extension of the, Olympics you guys did. try to like, touch something with just to touch your fingers. don't get multiple center patches on, on your, finger. Just the, just one little tip. It's very hard to do. I couldn't, convince myself I could actually do it. but I do notice when I, if I wrap, if I grab a mug with my hands. my, my skin wraps around the mug. It's very easy, right? My, my fingers will wrap around, or the palm will be there. And in this case, I might be using the local connections between the columns. So I couldn't, I don't think I can, I completely could have a, an saleable example that shows that we actually do a fully independent solution. even though that's what I wanted to do, that's what I started out assuming. Then I said, what is the evidence for the partially independent assumption? This is, again, this is the idea that you're their local, the local connection between columns are helping here. The columns know that they're adjacent to each other. So I already mentioned this first one. touch inference works best when I wrap my fingers and hands around the object, contact the lung, continuous surfaces. My skin works much better than fingertips, but after that, I have mostly negative evidence.

and I mentioned this already, we do not have an unambiguous example of flash inference or all the central patches move independently. I don't think I have. I haven't proven that yet, so I, haven't, it still might be possible. The fully independent solution is an N squared problem, and I, and you told me you've solved this.

I, it's just not clear to me how it works, when you have this end, these end columns trying to help each other.

Maybe you may, but that, seems like a separate issue. isn't it n squared with normal voting, even if it's just on object ID as well. It's just who. Yeah, but the voting mechanism we have works for that because it's, tied to the next thing here. Voting. You can, if a column, if columns are inferring the same thing, you can vote on it. So you, can vote on object id. Even though in Monty there's a sort of a shared, I think, dictionary of object IDs and, the neuroscience, there isn't, each column defines its own SDR for an object, but you can do this associative memory pairing and it works for n number of problems. And we've shown that it works. It, doesn't, it's n square, but it's not, you don't have to go through it thoroughly. It just, all resolves instantaneously. So it's not n squared, like it's n squared, but it's not in the sense that, the voting mechanism is just a settling Yeah. Maybe one way of describing is that like the computation between any given two columns is a bit more kind of bespoke or Yeah, did, it make sense, Viv, what I was trying to describe earlier about if we just had a general location for the objects, like that could, I think be common to all the columns?

again, if they've learned in the object in similar, locations in the past and stuff, and then that feels closer to voting as it's currently formulated, where again, they're just like voting on one thing. It's not like each, and, it is kinda like before the column projects, like the, let's say one column is here and it, this is its hypothesis. So before it projects the location of the object, it works out okay, I'm here. I think this is where I'm on the object, so I'm gonna project the center of the phone to everyone else. And then another column is here and it's okay, I'm gonna calculate what the location is of the center of the object and project that to everyone. So in that sense, it's more of a bit like a common, id, it's kinda like a common location. I, think functionally it would be the same as, probably as what we do at the moment, but it would just be like a different way of calculating it.

I wasn't able to get my, your, screen up in front of me to watch, to see what you're saying. Oh, sorry. Let, lemme try that again. So one column thinks it's like here on the object. That's its hypothesis, but it's, right now in Monty we communicate that and then if it's voting with a column up here, it communicates that and calculates a, bespoke displacement for between these two columns. I'm, just saying instead of that, this column, it believes it's here. So it works out. It's. Where the center of the object is some kind of arbitrary, agreed upon location. So within the column it figures out, okay, this is the center of the object, that's what I'm gonna send to everyone else. And then this other column, it also says, okay, yeah, the center of the object is here. I'm gonna send that to everyone else. Yeah. And so in that sense, they're speaking a more common language, I guess that makes sense. Although we don't have a variable like that in our learning module, or at least in the cortical column. that would be, each cortical column would have to have a hypothesis about the center. yeah. So we, I guess what I was thinking I was trying to get earlier is it might be similar to the location of the object that you would want to send up the hierarchy, because let's say also you're representing where the phone is in the room or something like that, or where the phone is, on the table. You, you want some sort of location representation for that. So maybe over time columns generally agree, okay, if we're gonna talk about the location of this object we're talking about here, and that might be central mass, it might be something else. that's interesting. it's interesting because we, after years of struggling, we abandoned that idea because it didn't work for positionality and other things. And so I've, gone completely the opposite direction. I saying nobody, there is no center to an object. There's just points in an object and those points are aligned with other points in other objects. And that'd be a big, ask for me to abandon that and go back to the old way of thinking about it again, because it just didn't work. I couldn't, so I felt like such a relief when we came up with a composition idea, the column by column. it could be, I guess you could be voting on some sort of center of mass. I don't know. I don't, I'd have to think then we'd have to have some sort of, some cells in a, cortical column that are doing that.

but I don't even, I don't even know what, how, I don't know. I, have no idea how to begin thinking about that. yeah. I guess the only thought is it, feels like it would be a little bit similar to the L five projection in that before voting you'd want to convert it into an egocentric representation. 'cause ultimately that's the space that the voting's happening in, right? so, we can imagine we could, maybe a column has something it could change into an ecocentric book, location.

but yeah, but I agree with you. I also feel uncomfortable with the idea of a single location for each object un unless maybe it's like a fuzzy thing. So it's, I don't know. But then of course the fuzzier, you make it in space, then the less refined the voting's gonna be and yeah. it was funny. I had I, the paragraph I had earlier, I said, don't read it yet, which was the idea that. If I ho if I just hold my hands out in space in front of me, I'm not touching anything. I have a, sense of the volume they occupy. It's a pretty crude sense in sense. It's not like a detailed shape or anything like that, but it's like I, know where my hands are, which one's on the left or which one's on the right, how far apart they are. if, I were moving my hands together and all of a sudden they touch something, I have a, very good sense for the size of that object. So that's an observation that's in support of the independent hypothesis that says, yeah, there is knowledge, somewhere in the brain as to the volume that your sensors occupy right at the moment.

I, didn't, I assumed that wasn't in the allocentric, columns that we've been modeling so far that, it was, some sort of egocentric thing, but I couldn't figure out how to make that work. I said, that's evidence. It's there. I clearly know that. I know when I, touch something, I, have a sense for the volume of it and where his boundaries, at least some of the boundaries are.

but then I couldn't figure out how to get that back into ausable, I guess your idea, if I had like a central point, we could all be voting on that central point, then Yes. Then I could bring that back into a column That's right.

All these things just made me a bit uncomfortable instead of confused. So maybe I'll just not, again, I didn't reach any conclusion and maybe, my analysis is not very useful then I don't know. Lemme just finish going through it, if you don't mind. You can decide whether you find it useful or not.

this one, this paragraph here really, really, got me for a while. and you just partially answered it, what information could a column receive that would allow it to infer without movement? I don't think it can be told its location because its location's in the code that it's sharable that no one else knows anything about. Its codes of location. but as you pointed out, it could be given, something in a common egocentric value in terms somehow into a local centric value. I'm not clear how that would work. but but this, sorry, I said it can and called it can be totally the correct. I object id. That's what we do in voting. but that just pushes the problem elsewhere. and, and somehow, it seems like I need to somehow use the columns model, but, so I think you gave a partial salute answer to this question. I said I'm open to suggestions and you at least propose one. Yeah. Although one interesting thought just right now is Maybe part of the issue as well is standard voting kind of makes sense in neurons because even though they two columns don't know the same object id, they vote on, we've performed an associative connection between, these two SDRs. And so in another instance we see that object, this one can say, oh, I think you should predict this SDR even though I have no idea, but even though that SDR doesn't look like anything like my SDR, right? But, that seems harder to do for locations, even if it's egocentric because, you, can't just make like an associative connection. let's say it was in location, I don't know, 1.5, 0.12. and then, it was the same in the other one. They each have unique location codes. Even if you associate those, now they're in different locations. So how did they share that?

Oh, can I voting requires that they, that, you learned these associations from stable patterns. Yeah. Hojae, I think maybe a concept that, this discussion reminded me of this page in our documentation. I'm just gonna share the screen like real quick. Lemme Okay. Lemme stop sharing again. yeah, about the, difference between sensors and agents where, An agent can have multiple sensors, and right now we're showing like an eye agent and a finger agent. But if there's a human agent, then we will have sensors on, both eyes and touch, but one agent. And I feel like even if the sensorimotor, sorry, I'm, lost Hojae. What's the difference between agent and a sensorimotor again? Say that again. Oh, so a sensors in my head, the agent, something that a sensorimotor, something that moves maybe an agent. Yeah, an agent is the thing that's moving and then all those sensors attached to an agent are moving together. Okay, that makes sense. Yeah. So in, in, that description, we would technically describe a human as a hierarchy of agents, right? And so the lowest level agent is where the sensors are fixed relative to each other. like the partial correlation that, or, whatever that you were talking about, Jeff. Yeah. Yeah. So even if these sensors are, like, if the, sensors on the eye and sensors on the finger move independently, I feel like eventually the highest level agent, in this case, human, would know all the, would be able to consolidate the information about where the sensors are relative to each other, to like calculate, To, do the vote is I feel like the, human agent is like the, central location where all this information, this is confusing because if, the agent is just literally the thing that moves a bunch of sensors, then I wouldn't, in that definition, I don't think the human agent doesn't exist in my mind. Oh yeah. The fingertip that moves is one piece and the retina that moves is one piece, but as soon as you start having fingers and eyes and you have multiple agents. Yeah. So I wouldn't say there's a human agent, there's just multiple agents that are moving around and this definition, I mean in other definitions you can see, right? yeah. So I mean there might, so I guess I was thinking, one is that we have one agent where the sensors at very two different location, like groups of sensors at two different locations. Like one human agent that has both this sensors and those sensors, I think one knows, was talking about the hierarchy. He said there's two agents, there's a eyeball agent and a fingertip agent, and maybe like a orchestrating agent like human that controls both of those. So like eventually, I guess in my mind I was thinking about it as there's eventually like one, at least one agent that knows like everybody, all the sensorimotor positions. So I'm, not sure where the point you were gonna get with this, but it does go on, fly against the idea that the agent is just the thing that's moving the sensors. It's, or a fixed set of sensors. so what, so how does this relate to now I'm really confused. So how does this relate to what you were just talking about? Maybe I make things more confusing. No, it's, it's that, going back to the post fully independent or partially, I think if there's one agent that, eventually knows all the sensorimotor locations, then that means that we can always calculate the relative and positions of the sensors. Alright, listen, what does that mean, from a call point of view? That, like an agent, I think rather than talking about agents, it's useful to think about columns. 'cause I feel like an agent is like an abstraction almost that we've come up with mentally, but at the end of the day, it's columns communicating with columns everywhere.

and maybe there's like a mapping sometimes between columns and agents. But if it's, yeah, I feel like if it's possible to frame it in that way, I, feel like it'll be clear. Yeah, I guess I, it probably most along the higher order column, like Yeah, so you, you're saying a higher order column would know where the finger is relative to the eye and then it would project down to the finger in the I column telling them how their relative location is for them to vote with each other.

I think it could help for sure. Sorry, I got a very well develop. those are kind. Yeah. Those are kinda ideas like, I thought of similar ideas like, oh, is there some sort of hierarchy composition going on here that, like we described Hojae, but it's all too fuzzy for me. Yeah, I agree. Would the idea of a phantom limb or all those illusions help here because they seems to support that perhaps our egocentric coordinates are learned in the learning modules and not like innate in the neural wiring because where you can, people put a fake arm next to yours and then they slam it with a hammer and you just react to it. You like very rapidly learned that your arm is now over there and that, that, seems to be evidence against like hard wiring of lo egocentric locations and more about learning modules, having a model of egocentric locations. that only works like the, there's two things you were talking about there. one is like this idea that you can fool yourself to thinking that the hand is not, is your hand when it's a rubber hand, but your hand has to be pretty close to it. It doesn't have, it can't be often in the other direction. It's not to right next to it and you just can't see one. And so that, that's like a, that would still argue that, That's it reminds me of grid cells where you think you're in one location and then you've distorted the room and it's now distorting your location space or something like that. I'm not sure if that relates there. I think, fan, obviously it's a separate, my, it's clearly the brain knows where your limbs are, right? it's up to some accuracy. I guess maybe those, a lot of those, things have to, not the phantom limb, but the one where you, you feel, you fooled and thinking the rubber hand is yours. That's like within the accuracy range. So you can distort it because it's a slightly off and you can fool it by sensory input, but I don't think you can fool it by, if your hand's behind your back and you see this rubber hand in front of you, you're not gonna, it's not gonna happen.

they have to, really it's, that's a trickier problem. just one more little observation I had, which struck me once I thought maybe useful is often I'm like, I was imagining my finger going along an object and then occasionally it would, like if I was going along the rim of this cup and, and then it, as I'm going along, I, hit the, handle right? And maybe I didn't know it was gonna hit the handle. I'm just going around the rim and I hit the handle. That's basically an activation on the side of my finger. So the tip of my finger is following the rim, and then the side of my finger hits that, The handle piece and it feels very local. It feels like that. I guess this is Handwaving argument, but it felt like very local, not my brain feels like the side of my finger and the front of my finger are two separate things, and it has to figure out where they are in the world. It's this No, it sounds yeah, I know. It's right there. You're right next to this one. So it's like this set of sensorimotor patches on my digit of my finger seem to work together. They don't seem to be independent. They seem to be, they know exactly where they are relative to each other, and those things don't move on the digit of my finger. they're, I can move the digit, but I can't. Anyway, it's all handr arguments. it's not very good in that record. yeah, that one, feels like, I was gonna say, sorry, with that example, like that feels like hierarchy could help with that at least. But I don't know. You have, yeah, you have a column that's just this patch of skin and another column. This is this patch of skin, but you also have a column that's the sleeve of this finger or something like that. Maybe. But it doesn't feel, it doesn't feel that way. It feels more like I have a one on the side and one on the front. it feels to me like, I, a way of describing it just stepped outta in my head.

it's almost like this, finger of all these things around these central patches around it, and there's many central patches on your fingertip. They're working as a unit somehow. They are, a unit and they recognize certain patterns amongst themselves. That is, that they know when there's a feeling here and a feeling here or like this is the cup with the chip in it. when I get to the, gap with the chip is my fingertip feels both edges of the chip. It feels like that's something my fingertip knows. It's not like a bunch of sensorimotor packages know, and they have to communicate through some central communication mechanism. It feels like that's like the fingertip knows that. anyway, it's, not very strong arguments, but it's possible that both mechanisms are play, it's possible that there's a centralized mechanism and there's also local stuff going on too. Yeah. That could be approximate local stuff happening without external input. Like kind of localized lateral ODing, that's pretty much within retina topically neighboring area. Or, fingertip area. Yeah. But then if you have a more long range kind of lateral connection, like from one finger to the other or from the finger to the eye visual cortex to auditory cortex, that might have to be routed through something that does a reference frame, transform or use hierarchy, To take into account more of a model of where things are relative to each other in, on the body. So then I asked myself in vision, what if I had a similar mechanism like this going on in vision? Local patches of my retina, which are many, many sensory patches are like similar to my fingertip, right? What if they know certain things that they vote locally and they're all able to do this? how could you solve the flash inference problem under that assumption? Would there be enough information, that I could extract between local interactions so that would be sufficient to lead to the global solution?

and, I couldn't convince myself one way or the other on that one, but it still seems possible. It's in the sense, like as we showed in general with when we first did the first paper on a thousand Brains, we showed how just with few movements you could generally settle down on the right solution. and, and so that didn't have any centralized voting. And, of course with a few movements, you're no longer doing bag of features. you're, narrowing down very quickly. And so then it felt maybe there's these local voting on my skin and local voting on the retina would be sufficient to just essentially solve the problem. and I couldn't convince myself one way or the other about that. So that's, would that be biologically plausible if, like you said, to have both? Because one way. I'm asking for the biologically plausible way of local patches is, in, in, development, everything is connected. And those, the local patches, those are predictive of each other. So those connections would stay alive versus the things that don't predict each other would start getting pruned in development. So you'll get like these patches of where the local partial things work together versus the things that are not correlated, just are not required anymore. So that's, so in the brain, imagine you're in the brain now we're on the cortical sheet, right? And so you're, in some somatosensory area that's somatosensory area and next, and then another region, which might be a different modality starts, right? So you might have a, you might have a vision region touching up against the language region or something like that. presumably then those, the connections that are local connections would not be correlated and they'd be lost. But just like you're saying, and and the, we've talked about this before, but the hypo one hypothesis about, syn anesthesia is that those connections gets remain and they shouldn't be there. And therefore, you're making these, you're making these associations across modalities, which are incorrect, because they should have been forgotten. But between adjacent columns, here's a color column, here's a sound column. And they should have no connections between them. And yet if there is one, then your sound has a color.

so it's, yeah, I like this idea of, maybe it's a combination of both and it's just associative learning of what remains correlated and what doesn't.

but I guess it doesn't, it still raise the question of, how space is, taken into account? I feel like you still risk a bag of features, in a, even if it's local, maybe. I don't think so.

but, what, one thing that we could do is so let me, there's clear evidence in my mind the idea that I have a sense of the space my hands are occupying if they're not touching anything. That to me was like, there is a central idea of location, of an object somewhere. Can't deny that. And then this idea of my fingertips sort, recognizing little weird little nuances on a cup and so on. Also, it's pretty strong for me. And so, I could argue, there's probably, both of these things are going on somehow. we could decide to pursue them or not pursue them if we want. I didn't get, I didn't work on what would an actual mechanism for local voting be.

but I could think about that. but I think it's possible that you have multiple mechanisms going on, just like Viviane said. yeah, what we want, what we wanna do about this is, I don't know, Yeah. We don't understand either of the two, but, Both. But it sounds like you have a, you have a solution to money already, so why are we doing this? Yeah, the main motivation, I guess for us to question how we're doing it currently in Monty is because we were thinking about sending movements as input instead of locations and ego, in Yeah. Egocentric shared space. and if we only send movements, then we don't know where sensors are relative to each other anymore. 'cause we don't have the shared coordinate system. And that was where the question came from. is that also a issue for the output? Just thinking about it now, because at the moment when we send like a command, again, we need to move, convert from the kind of object centric space to ecocentric space. And that again, requires that column knows Yeah. where that object is. So even if we, yeah, I guess that could be a movement. yeah, that would be a movement too then, so it wouldn't matter in this case. Yeah. but yeah, also, just as a reminder, we're over an hour in, okay. So I don't, if you wanna keep, digging deeper on this topic or kind of, lemme see if there's anything else I wanted to, the only one other last observation I would say, there's, I wonder whether there's any evidence that even in visual flash inference, that even though we present it and it goes away quickly, that there's not a existing trace that somehow gets processed later. like you, you are able to attend to different parts of the flashed image even though the flashed image is no longer there. So I don't know if there's Yeah, I think they try and, who knows if, where it's, I think in, because often in psychological experiments, this idea of flash inference of a complex scene, I think it's called, the gist. can you, get the gist kind of, and, yeah. So things like, street singing or whatever. And often they follow it with masking, so they'll show it for 70 milliseconds or something, and then they'll show some wide noise. And then the idea is that the white noise should prevent you from doing recurrent processing, but no one knows for sure if it does. oh, so that's a did that experiment was inconclusive. as in like, how do we know that mask is actually having that effect? But, people can still recognize it, I think, with masking, but I think it is a bit harder. which I guess supports that it is doing something, the mask, if they did those kind of gist of flash inference experiments with showing things in unusual orientations. Yeah. no, I can't remember.

but, because yeah, even if we assume that they know their relative, locations, and that is a fixed relative arrangement. If we wanna recognize stuff in any orientation using F flash inference, it would still require always doing reference frame transformations between the different, sensorimotor set Bo or, column set boat with each other. But if we would assume that kind of canonical orientations work very well, but non canonical ones don't work well, then that could be just a more hardwired, associative connections. Yeah. And I think that does fit with at least some evidence that people are. If you give them less time, they're worse at atypical orientations. I think if I, did that little flash inference exercise in the beginning and those images were upside down or inverted, I bet you'd have a lot of problems with 'em. I did. I could do that experiment anyway. I hope this wasn't a waste of time.

not at all. No, definitely not. I don't know. I feel like I failed, no, I think it was interesting. I still, I, I don't understand Monte well enough. That's my failure. So if Monty gets more and more capable, I'm gonna be like behind, I feel like. Yeah. Maybe just briefly, one example that Scott has mentioned before that's maybe a problem to think about more after this, which I thought was an interesting one, is, the inverse of the moving the finger over the mug to recognize it, which is, someone drawing on your hand or your back or whatever. And then you recognizing that object. 'cause it's interesting. It's a little like flash inference, but it, requires integration over time. 'cause it's not it's not like something's pressed into the palm of your hand and it's seeing everything at once. It's, it's tracing it out.

so yeah, I don't think we should discuss it now, but I feel like it's just one to maybe think about.