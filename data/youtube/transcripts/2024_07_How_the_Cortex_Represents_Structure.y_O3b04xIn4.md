I find it often that just rephrasing a problem or trying to be explicit about what the problem is you're trying to solve. Is very helpful. And so when I get stuck, I usually go back and just Hey, what is the thing we're trying to solve here? What is the, maybe lemme look at it a different way and, and just bump up a level like, okay, we're getting lost in the weeds here. What's the bigger problem? So I, I don't have this written down to show it to you, so it's on my, it's on my ePad here, but not anything I could easily share. The way I'm doing this and you and what you're gonna present, what you can talk, your hap idea will fit into this scheme. Presumably we're dealing with, how the cortex represents structure in the world. And, and I see, we have a model for that in thousand Brain theory, but the model is short. It doesn't explain everything. We have, oh, we have these unique locations and we have these unique, these features that both represent uniquely in context and that's great, but it doesn't deal with a of two major classes of problems. it doesn't deal with the fact that we have. a sliding scale of objects. We have the cylinder that becomes a specific cylinder, and somehow we have to share some knowledge about the generic object with the specific object. That was one of our problems that we were dealing with. And some objects have no specific features, an egg shape or an oval or a circle or something like that. so we were struggling with this idea of okay, we have a solution for very specific objects with very specific features that seems to work, but we don't have this other scale or sliding or, moving from less specific to more specific. That's one. And we also call that class of objects. you could think the cylinder in the specific cylinder, maybe one's a class of the other, something like that. the other thing we haven't really been able to do with at all is object behaviors. and that is a big hole. and maybe we won't solve the first problem when we fi until we figure out how object behaviors work. And I think object behaviors have a similar sort of, dichotomy or spread. There are generic behaviors. There are specific behaviors. So I can take a generic behavior and apply it to a new object. I can take a like, oh, here's a procedure I do and I'm gonna apply it to this new object, which might work the same way. so somehow we're able to take, take knowledge from one object and apply it to another object. But just similar to perhaps the taking knowledge from one object's morphology and applying it to another's, it would be nice if those solutions were the same. I dunno if they would be. I, so I brought up, okay, we got this general problem of, representation, which we only have a partial solution, central motor representation, and then we defined two big holes in it there, classes of objects and object behaviors. and I'll just stop there for a moment and see if anyone has any thoughts about that because that's, it's the high scale phrasing of the problem.

I dunno if I've missed anything.

Yeah, with the classes of objects, I feel like we had two ways. We talked about it before. One was like, like you said, right now that it's like. The overall category of objects and then specific instances of them versus, having a morphological model and a feature model and you can mix and match different features onto, feature models onto the same morphology model. are those different? How is, are they fundamentally different in your mind? it seems One is hierarchical where you have the overall class and then the subcategories, and the other one is like a mix and match where you can also, you, can put like the Menta logo model onto a baseball cap and a coffee mug and a plate, like you can mix and match them. Like it's not this hierarchical relationship basically is what I'm saying. But does it become a specific instance once you start adding unique features? Like that, I think that was our assumption all along, right?

you had these unique features and then you say, oh, this is the specific coffee cup, and then we lose the, but yeah, I feel like the, yeah. Uncertainty for me is like you, you can have morphology can also be quite unique. can define a unique, object. Yeah, so I guess how I thought of it so far was like somewhere in the layer four, layer six connections. Then maybe layer five as well. We are learning like a, feature model, a morphology model, and a behavior model. And then the combinations of those three. Can make a, like a specific instance. Id in maybe layer two and maybe in layer three we only have the ID of the morphology or the ID of the, behavior or whatever. So like basically the models are separate in the lower layers and then in the upper layer, the combinations of which feature, which. Models are detected to find a specific instance like, oh, you're saying the banana that works like a person or, so you're saying, let me review what you just said. You said three types of model, a feature model, a nephrology model, and a behavior model. But in a hierarchy, you're saying the lower column would only be activating one of those at that time, and then that becomes, is that what you said?

this is just speculative and how I was thinking of it before was basically there would be three model IDs, the feature, morphology and behavior model. maybe in layer three, and then in layer two, which might be the object ca no, sorry, in layer two, which would be the object category, and then whatever is the specific object instance, ID would be like. A combination of those three models that define the specific object instance. By the way, if I would, if I were to guess, I'll take it back. I don't know. I was gonna say oh, behavior model. Where's that? And, It's confusing because at one point I would say, oh, that's gonna be layer five, those layer five A cells that the non intrinsically bursting ones and the ones that connect horizontally and, 'cause that's that's where behavior goes. But we're, that would be like a behavior of my body. So I'll take that back. That'd be more like I, I've learned behavior that I'm doing like signing my name or something like that. Whereas if we're talking about the behavior of an object that would be in the upper layers, like layer three. so I was confused by that.

yeah, I'm not sure how, it is an interesting idea that these three, but if I say there are three different models, are there three different representations of location?

that's a tricky one, right?

yeah. could you get away with one representational location and, and, then would it be unique? I'm. Yeah. I think they have to solve the sort of location and the feature thing at the same time. Yeah. I think if we would, if we assume that the locations are unique to each object, then they would have to be separate location representations, but it would have to be the same space. Like movement moves you through those. We have this idea that the, we're probably not gonna have two different path integrations mechanisms. Yeah. So the path integration mechanism has to work on all. Small models of space, can, I'll just, I, these are good ideas. I don't, I'm not sure they work out yet. You know what I'm saying? It's oh, how do you really get this to work?

and maybe if you have that in your head, you can present that, I'm still struggling, oh, which of these would be hierarchical, like between columns, which would be local to a particular column?

I'll just throw in one more thing to think about. So I was thinking about what are the different ways we've talked about representing space where we have this idea that we want this sort of a generic space and then there somehow you become, it becomes more specific. for particular, it's like how I have to predict the generic. Shape of the cylinder, but now that I know it has a particular ridge on it someplace, I have to predict that at that location. But I don't wanna have to relearn the whole model. that problem. And I thought there was three different ways I could think of, forming multiple representations with a single path integration. That's, the goal, right? that you have, you wanna have a single path integration and yet somehow form three different represent or two different representations of space. Something like that. So we just talked about that. one, is, you could just have two different sets of cells. I don't believe this is right. I mentioned it recently. I said, oh, what if the double bouquet cells are like the do the generic representation of space and the peral cells a specific representation space. So we have two different sets of cells and they'd both be doing path integration. 'cause path integration. Should work on both of those. and therefore we would, we could form a generic model with the double que cells. I just don't, I don't think the anatomy supports that very well. And it seems a little hooky. I don't know why. Just, I'm not a big fan of it, but it's possible. So two different sets of cells that are combined together, because the double case cell represents the many columns. Therefore, their, Path integration somehow like that. The second one is we've talked a lot about is you have a single set of cells represent location, but under various contexts it becomes more sparse. So it's not like you go to a completely different set of cells, you just become more sparse. So I could take one representation A, which is let's say, I don't know, 10 sparsity, and I could then form multiple unique representations. From that, that are each 2 sparsity, but they would be a subset of the larger ones. So you're basically taking a broader thing and narrowing it down by dropping out bits. so that's again, using the same set of cells but at different levels of sparsity.

and then the third one, which we really haven't talked about, but I threw it into my thinking, and maybe we've talked a little bit about it, is that somehow, perhaps. You could have the same set of cells, but use the phase of those cells, to form unique representations. Like one, you could have a class of objects and then a unique one would be you would take a subset of the cells and put 'em in phase. So you're not really changing which cells are active, but you're somehow changing which cells are in phase or not. and you could represent up to some number of objects that way at the same time, so you could cycle through. you could cycle through a more generic or less generic or something like that. for many, years we had no theories about how phase would play into, our theories. not that we didn't think they were important, we just didn't know how to do anything with it. And of course, grid cells told us, and place cells told us that, oh, phase really is important, and it didn they play a role in coding. and so at least we have a model to start thinking about that. So anyway, those are the three ideas I, I could think of. To deal with it. This, I'm just, this is not countering what you said, Vivian's. Just throwing in one more thing to think about. do you have two sets of cells, one set of cells for location that different sparsity levels or, one set of cells and somehow use phase to make things unique? I couldn't think of anything else.

and, the methods for doing this, that might work. so that's where I stopped with, yeah. Yeah. One thought on that is yeah. 'cause I remember we were discussing some similar stuff during by the bay and Yeah. One recent thought was just that, with the two populations, like the kind of dense one and more sparse, it feels harder to, do path integration over a reasonably large set of potential objects. let's assume we want to path integrate over K equals five. Top most likely objects, I feel like, unless those are all the same one. So like they're all the cylinder one and then that's the one that's being sparsed or something. like it feels easier to imagine how that would work with like phase where they're separated in time or, I don't know, if, and it's simplest like with kind of two populations. Like you don't only do two hypotheses in some ways, You wouldn't have two hypothesis. Unless, or, or they would have to have the same kind of parent or like base model. So like they would all have to be cylindrical objects and they can pass, integrate together, but then those we can prune down to which cylindrical object it is. I think that one it feels like with the phase, yeah. I mean it makes it, it, I just feel compared to what we're currently doing in Monte, it's potentially more limiting, whereas It's easier to imagine. We're currently doing in Monte where we explore a wider hypothesis space of, 'cause at the start, we don't have any idea really what the morphology is. And so we explore a lot of different options and that takes a lot of time. again, just at the risk that introspection isn't correct. Like I feel like if you fix a mystery object, and you're trying to, for what it is like at first, I think your ideas about it are evolving quite slowly. So maybe that's because you're through phase or something, you're cycling through, almost like in serial, a bunch of different hypotheses as opposed to in a massively parallel way exploring all of them at the same time.

I don't know. It's like it is serial of course.

but you can't.

Two, you have an update. you can't start eliminating hypotheses. So I don't, what's the state before you start eliminating anything? I'm not, I'm, I guess I'm struggling with that distinction between massively parallel and serial, it seems. Yeah, I guess I'm just worried 'cause I think you opened the discussion about all this stuff at by the Bay with we want to have like multiple grid cells, like codes simultaneously active or that was how it was. Described in the 2018 papers, and then those, like all path integrate independently. But it's not obvious how you would do that. no, I, and so I'm worried that issue still exists. I think it does. in fact, I'm surprised if I said something other than this. I said, we've never figured out how that path integration could work with multiple. Yeah, but it seems like a phase code is like the most straightforward way to solve that problem. I guess maybe it, it sounds like maybe it may straightforward way because I haven't worked out the detail to work out the details. It may not work at all. I was like, yeah, there's a new idea that could solve it. maybe I don't know what to think about it. yeah. I, first of all, we never got that to work. the idea that path integration over a union of hypothesis, it just didn't seem to be possible. At least not, we didn't know the mechanism, how it could be done. And I suppose that, phase even using different phases is also somewhat limiting.

Because if you think about different phases, you usually have a very short period of time to cycle through phases. if you think about grid cells and so on, there's, the theta phase and you can go through maybe eight different representations in half the theta phase or like that. but it might work out. Sure. we don't, know. I think, the other real thing to think about is like object behaviors.

what is going on in representation in object behaviors? It's It's a little bit like, a cylinder with a, and now it's cylinder has a logo on it. It's like saying, oh, here's an object and now I know it's in a different state and therefore I have to make different predictions.

it's it's the, the staple example, it's the same object. I don't confuse that. It's not, oh, here's a new object that's open staple blue versus closed staple blue. I see them as the same.

even though the features have changed and, and so how do I represent that, right? I have to represent that somewhere. I thought, yeah, this is still a stapler, but also this is a state of the stapler that leads to different predictions. and therefore I have to have some different representation of location if the location's gonna predict something. the location might not have to change. You could, imagine I have a location space and, and then that's projecting to some feature, like layer six to layer four. But then we could also add some context, another projection to layer four, which is saying this is the state of the object. Therefore the state of the object is like a different feature and it can lead to a different prediction. there's, you could still be like, the locations could be. The location space could be the same for stapler, open or closed, but you'd predict different features based on context and basically on, on the context of the, the, the behavioral state of the object. you would still predict the same features just at different locations, right? Yeah, but I bet you there's lots of examples where that isn't the case where. if I look at my cell phone screen, I see, I don't see the state of the cell phone, but I hold different features on the screen. So clearly sometimes we see features moving or features in different locations, but sometimes the features change. You just see different things. if you open up the stapler, now you'll see components of the fate staple you couldn't see before. Or maybe they change. I don't know. I, anyway, the cell phone's a good better example.

I always, I think my con or the thing that always worries me when going down the thoughts about how we do the stapler and stuff like that is just, coming up with a way that we don't have to store, a million points, Of a, or like a million different models to have a continuous or near continuous representation. And of course the stapler is very simple. It's, almost like a 1D behavior. Yeah, I think that's where like the separate behaviors from morphology models would Come in. 'cause we could learn this like hinge behavior once in however much detail we want. And then apply it to any object that has a hinge, like the stapler or a door or whatever. Yeah. I then, yeah, we then we need to wait. Sorry. Wanna remind you, I've talked about this before, but I, if you remember it, There's this, there, there's this trick about neurons in the, in our synapse model where if you wanna imagine you're learning a trajectory of something, it's moving through space. and this would apply even just your finger moving over an object. if, you say, okay, I'm, gonna divide that into 20 different points along this trajectory, or 20 different points on the object. And each time I have to store a set of synapses to represent that point. It's just too much memory, and what I was able to show is that as if you take an SDR and you, let's say you like it, it could be the movement of the stapler, but just imagine it's your finger moving across some object and you're going from point A to point B that you can, as you move from point A to point B, you don't have to store individual points along the way. You can store incremental synapses along the way very efficiently. And it, and you might think if we think about the mechanism of how I think this works, that it might be prone for errors, but it's one of those SDR tricks where, yes, it's prone for errors, but the errors are very small compared to the potential size of the space. Therefore, you will very rarely ever get any errors. So my point is there's a way of officially storing a whole set of a sequence of. It's important, it's a sequence. Anytime you have a sequence, whether you're moving your finger along the object or the staple is opening and close, there's a very efficient way of storing that sequence with very few synapses, and you don't have to have a lot of learning points. I know we've talked about this in the past, and you don't have to visit every point either. you could just, you could, you could pick, let's say you take 10 points between A and B, and, the next time you pick a different 10 points, it won't work. and it won't relearn and it does the right thing. So I think there's a solution to the efficiency problem when it comes to neurons, which is interesting in Monty if we're doing real number of things. I don't think we had a solution for that efficiency problem. Like we had to story all these points along the way. and then interpretate between them, if I recall.

Yeah, we would have to interpretate, but we wouldn't have to store, every possible point. Yeah. I think neurons do it nicely, very efficiently. and if you want, I could walk through that algorithm again sometime, but wouldn't the neurons also be interpolating in some sense? it, yeah, but the, there's a natural overlap between all the points as you move along in a sequence.

you, it's if I store 10 points between A and b. Those, I didn't really store 10 points. I, in some sense, by the synapses, I would learn, I'd store all the points between A and B, and it would be no distinction between, the 10 points I did stop at and the ones in between it, it's just, it's a continuous addition of synapses as you move through space. So there isn't like d unique points. It's like you would extend the synapsis on a dendrite and now that dendrite. Would represent all points equally between the two points.

and as you do this, of course, imagine I'm doing it with my finger and I'm touching an object. the feature will change too. And so different columns become active. So it is individual neuron only has to learn like during the time I'm active, my many column is active. I don't have to learn these numbers, synapses, but another neuron will have a different sort of span. So it's just very efficient. It really could just add like one synapse at a time. And it seems to, I think it all works out. I did the math one time anyway, so I, mentioned that because I don't think we have to worry about, I don't worry about the issue of oh, we have to store all these points of the stapler moving and closing. Oh, I think I have a solution happen. So it's really a matter of, what would be the representation, of object behavior. Yeah. But I also feel like. Yeah, it's easier when it's a 1D sequence, but I feel as the space grows in terms of where we could be, then it, becomes a lot harder. I, think it works for that too. that it doesn't require this to be one dimensional. It just, requires that, that you're following a trajectory, whether it's multidimensional or not. Somebody's doing something here. yeah, I just shared a whiteboard. Oh, a whiteboard. Because I was just trying to think through what you were saying and I just wanna make sure I understand it, correctly. So I guess if we have, if we have the computational approach or whatever we do in Monty, we would just lay down a series of points. Can you see what I'm drawing? yeah. There's a lot of other stuff on my screen too, which says like, all these, like Navigate the canvas, collaborate with others. these are like, clues is what I'm supposed to do. how do I get rid of all those?

the screen is cluttered with helpful hints.

I'm not sure. Think oh, I just, I click anywhere and they all went away. Okay. Okay. so yeah, basically if we're observing a line, We would just be laying down a couple of points on that line and then let me change the color basically next time. If we observe like a point here, for example, we would just interpolate and you're talking about the way Mar does it today? Yeah, that Monty does it. Yeah. Okay. We would just interpolate between these points or if we would observe a point. I don't know. Here. We would look at this point, and maybe a little bit at this point, I don't know, but eventually it would represent like a space like this around it. Yeah. Yeah. but we would explicitly store these points, and then the way I understand it, how it would be done with neurons is that we just def represent this space. We don't lay down these explicit points. We can like, recognize or deal with any point in this space.

It so then, yeah, then it seems like it's functionally equivalent. if we don't look at like taking. Out the fact that here we store explicit points, if we just look at the behavior of what it would return, if it, if we observe another. I think, you're right. I think it in theory, unless we, once you get into it, you might find there's some holes in there, but you are right. A basic idea is that it, you would end up with the same result supposedly, right? Yeah. I mean it's one of those things when you do it with SDRs and neurons, there might be some other benefits that we're not even anticipating right now. But as you've described the problem, I think they would be equivalent. I would, I think the neuron's way of doing it is some sense simpler. there's no decision as to, oh, how close is this point to a previous point? Or I need to store it. there's no discreetness to these points. Yeah. it's just It's like I, if I think of 15 synapses on a dendrite representing a point, I can just extend the number. I can just basically add new synapses along the same dendritic branch, as the sdr r morphs between one location another, and it'll automatically, represent the entire space. So that extended branch on the dendrite, which may now have 30 synapses or 40 synapses, something like that. and it's bigger than the integration zone, but that extended branch would represent all the points in between you and reliably. technically there could be errors. there could be, mix, mix and match errors and false, but it would unlikely happen. Yeah. So yeah, basically functionally in the sense that they can make predictions about any point in this space, they would be equivalent, but in the sense of what they store and how efficient it is to retrieve that information, the neural representation, might be better, might be more efficient. Yeah. And there are, there might be some other benefits too. I don't know. there might be some like, oh, what happens? When you give it a, I don't know, like a novel object or one that's slightly similar, where the two would behave differently in, in, situations where the points aren't exactly in the same line. You know what I'm saying? yeah. What would, I don't know. I can't say what that difference should be, but, SDRs have some, have properties that are surprising. but on the surface, yes, they would produce the same result. Okay. And, I feel, I felt like even though I didn't like the way we did it before, 'cause oh, that's not, that's complex. It seemed to me, I didn't see any problem with it. yeah. as long as you guys don't mind using CPU power to do that stuff, but, it could, and we talk about object behaviors, we might have similar problems. I, I don't know. but Right. But maybe we can divorce ourselves from the issue. But anyway, I just reacting again to Neil said earlier, oh, I, it'd be a lot of, I don't wanna store all the points between the rotating arm of the stapler. And I said, oh, I'm not worried about that.

There's ways of handling it.

I don't really have a good, I don't have to Go ahead. Sorry. I have a question. when we talk about object behaviors. are we also considering the temporal hierarchy of, these behaviors? Or do we believe that exists?

Maybe what's, what, how would you define temporal hierarchy? like when I'm pressing, when I'm the stapling action, for example, that would be, pressing and not pressing, and you could do the pressing on the stapler. Maybe for something else, that's probably not a good example, but no, that's a good example. No, I think it's exactly the same. it's just the inverse of inference, right? In inference, you have common set of sensations or movements that are represented uniquely in context. Now we wanna play back a sequence. We have a unique sequence, but in the end, it has to end up with, you have to do a series of common, behaviors. If you think about language, right? I have to be able to understand the words in context. And now in context, I have to be able to say and predict what next word should be said. that's gonna be unique representation of that word, but I have to turn it into me speaking that one sound. You know what I'm saying? So you go from a set of generic to unique in context, back to generic again. So in that sense, that's what you meant.

yeah. And that's not necessarily a hierarchy that's. That's just outta context, in context. But there could be a hierarchy too, right? In the sense that we have a hierarchy of object features.

like we were writing in the paper.

and so I imagine the behaviors would've a similar sort of hierarchy.

you're trying to do some complex behavior and what happens as you're going along with this complex behavior, things happen. You have to adjust. And then maybe try a different solution or something. I dunno. Yeah. Yeah. It feels there is a hierarchy of, even when you do action policies, there's a hierarchy of these action policies and, But, my general rule is that even if a hierarchy is required, you, can't do everything in a hierarchy. you still have to, the individual comms have to be able to do some of this.

but maybe not. that's the general way I've thought about it. alright. So yeah, the hierarchy behaviors, we still have to, that's just, I dunno if that makes it easier or harder to acknowledge that. it just, I think it, because when we do, positionality in, in space, we're all, we're always thinking that everything is, stationary. I feel that it might be that we need to think of everything as behaviors and stationary or space is just a, a sub problem of that. It might be, It could be, I'm not saying it is, but it could be that example, last time. we have some objects, but, maybe counters, that is the fact we have behaviors that can be applied to different objects.

I don't know.

Yeah. and some objects don't have behaviors. the coffee cup doesn't really have any behaviors. I can't, it doesn't, yeah. Yeah. I would say that's a, so that this is a sub problem. It could be a subset. that would be a nice, that would be a nice solution is if all behavior and this why I think it's right up there equal to object morphology or class of objects. I might learn my notes here. I they're really basic two problems that may be the same. And that's what you're suggesting. Yeah, object behaviors. Have a and object classes. And that's, and this is why I suggested if we saw maybe by, if we really solve the object behavior problem, it'll be, it'll inform us about the object classes. That may be the, you're right. So would be ideal if you're right Robbie, that they're, that these are, really the same problem and we've just been thinking about 'em as separate problems. the last time you, in the brainstorming session, you presented a paper where there's a bar in front of a, I think a monkey, or a rat, I don't remember, but it was a, bar that was moving, this way and there were some, neurons that are representing just this, movement. And, I think when the bar was not moving, there were, there was no representation. That makes sense. That makes sense. there's two places you see those cells. One is in the lower layers of the cortex, which makes a total bunch of sense about, okay, this is representing the animal's movement through space.

and then the upper ones in layer three, remember I presented that paper distinction between layer two and layer three? And they were showing that layer three cells. No. They were saying, oh, the layer C cells are motion insensitive or directional sensitivity. you gotta be really careful, and I mentioned it at the time because those are the layer three cells they were looking for. There's a lot of other layer three cells that don't behave that way at all. So yeah, you have to be really careful about that. but there, there clearly are layer three cells that are responding to motion and they were, remember if they had small, receptive fields and there some of 'em were end stopped, meaning that if the line got bigger, they started responding less. So that would imply that those cells are representing behaviors of the object. they're movement, local, individual field. They're not global movement where the layer six ones, which seem to be more global. So those are clearly, and, the odd thing was that in that paper that, layer three is classically viewed as the input to the next LE level on the cortex next region. Therefore, if that we just took on our face value, what we're sending to the next region of the cortex is not a, an object id. Purely an object id, but it's a motion related object id. But it's also, if those cells don't respond without motion, then it would imply that nothing's being passed in the next region of the cortex. If it wasn't, if it wasn't moving, which seems a bit difficult to accept.

Yeah, I think the, it has learned the object behavior. so because the, training data that they're giving to the monkey is that the bar is always moving. So it's trying to attend to the, movement of the, it's not attending to it, the, animal specifically not attending to it. The animal specifically fixated on a.in the center of the screen. And, and if the animal does not attend to that dot, doesn't get any reward. Literally the animal saying, don't move your eyes. Don't move your eyes. Just pay attention to this dot. Just don't move your eyes from this dot. And often the periphery, there's things flying around. They may be aware of it, but they're not attending to it. but these are out of context. Those movements don't relate to any objects in the real world. so it's a weird experiment. That's the best I can do. one, unfortunately Vivian and I have a meeting in 15 minutes. I was just thinking, would it be all right if I just quickly mentioned the, just 'cause it related to the last, yeah, sure. Last meeting. I right with that. Is that alright, Viv?

yeah. So it was just, 'cause we, yeah. I thought it was really interesting, the conversation about yeah, how you represent generic spaces and like the example came up of the song and stuff like that. And then we were talking about okay, what is L four?

if, the song is represented as a, kind of spatial reference frame, and then you're moving like through that, as the frequency changes and that gives you key in variance then, like what are the features coming in? And then I was, it just reminded me of the stuff we had looked at before where we were using displacement almost as features where, we talked for a while about how like maybe in certain contexts, for example, like when recognizing a face. There might be like specific placements which are more salient or more common and that we key off. And so it seemed it definitely doesn't solve all the problems, but if, if a particular frequency displacement is the, and that's more of a relative difference, then that's something that could maybe be stored in L four that would reignite all the songs that have. in their spatial reference frames, all the songs that have that relative displacement. and then you would start kind of path integrating through those, but wouldn't relative displacement, I think Vivian brought up this idea and, the idea is that the input, the layer six would've been, yeah, it would be a movement. So it would be both. It would be a relative movement. So it would be themselves. So we would be both. So you would, have the relative movement into L six, which would be like what you're path integrating. Then the displacement is just a specific, could be a feature that would, because basically you don't know which kind of graphs you should be even moving through, to begin with. And I guess the reason I thought it, it might work particularly well for songs and, certain reference frames is just, like firstly music is like lower dimensional. there's fewer. Dimensions, like we can move through. So there's a, like a more narrow space over which like over which you need to save displacement. And then I guess the other thing is I think humans are only sensitive to a semitone change in pitch or whatever. So like it, it we don't have that same issue we had sometimes with this, like continuous space of vision where, you know what happens if you do like a partial displacement and fall somewhere in between Displacement in music are almost more discreet. And, but I think there's other kind of reference frames that, it wouldn't be just a music thing, but my question to you is Yeah. If my assumption based on that idea was that the actual melody, which is a series of displacement Yeah. Would logically be learned in the lower layers. Yeah. five and six someplace. because that's independent of the actual features that are coming in. it's right. and so when you said you thought you'd learned that sequence of displacement in layer four, I was like puzzled by that because no. So I'm not disagreeing with that, that, so that would still be there. This is more like a way of, yeah, the relative movements are what's ultimately going through the whole song, but maybe there's, I don't know, just certain displacement that are, ones that we've actually memorized in a sense. So ra rather than relying more on path integration, it's like the actual frequency change is what we've memorized. and that's the feature recovering the specific, the specific, yeah. that was like, I went back to the idea that you have this memory, exact memory of, somebody famous artist first during the song, the key they're in, even though you don't think you know it, but you've memorized it. That's the general rule.

So there must be a memory of what the actual key was, which is like, where, was it On the co, when that occurred. Somehow that has to be stored. So my thinking like, oh, that somehow has to be in layer four maybe. 'cause that's layer four, specific thing.

But I what Neils is getting at, if I'm understanding it is that in music we don't really have path integration. We it the same, melody isn't the same forwards and backwards. We can't just play a song backwards in our head or I. skip five notes ahead without significant, thinking about it or like even just the A, B, C, we have to like sing it in our heads to say it backwards. So it, it seems like a different process there. I think, I, think, it, I guess it is, although it fits beautifully with the temple algorithm, right? The temple memory algorithm says, I'll learn the sequence. I can't go backwards with the sequence. so unless I hear it backwards, obviously I could learn to say the alphabet backwards, just like I learned to say it forward. so there's no problem with that, but it doesn't come automatically. I think that's your point, right? I don't, I can't just do path integration. Go backwards. Yeah. And I guess it's just that the displacement bring the kind of pitch, or sorry, key variance.

I, but I'm not sure if it's inconsistent with everything we've said so far. Like imagine layer six is representing, you're passing in the displacement and now you're, not really doing path integration. You're, basically just learning a sequence of those, the sequence of those things you just saying, oh, here's. I'm gonna learn this. This is the interval, and now, and here's it uniquely and here's it uniquely. So that wouldn't, in some sense, maybe Here's one way of thinking about it. Path integration doesn't work with a melody because we never go backwards. We never, ever, if I heard, learned it reverse. you it, it depends on what you mean by backwards. Like we, we go up and down in frequency. you're right. But yeah, and, I think it's nice that's an ordered thing. so again, I'm not trying to suggest we don't have an L six representation for the song. it, I guess maybe it helps if I go back to the problem, what I thought a problem was is that okay, that's really nice that we have, a more like a morphological model of the song or whatever. But let's say a note comes in. Do we know, like if we're, key in variant, how do we know which of all the endless songs we know we should start hypothesis testing and start path integrating over? You can't. first of all, you, have to have at least two nodes. Yes. So E exactly. So what I'm suggesting is those two notes give it displacement and that displacement is what you've learned in L four and you're detecting, and that's basically are getting all of the Okay, I let. I never could figure how L four could learn displacement and even represent, but I guess we, we said last time that maybe the inferior ulu, no. Did that obviously.

then Vivian suggested just calculate it externally. Don't calculate it in the cortex. Calculate externally, which is convenient if, lazy perhaps, but convenient.

and say, okay, that's, so L six is getting a displacement. But L four would not be getting a displacement. Presumably. L four has to get, there's something that's known. For example, there are first notes of some songs that are so unique that you know what song it is. it's very rare, but there are examples of that where the specific first note orchestration or voicing is so unique that then you say, oh yes, I know that song. so you don't have to get the interval. So my point was that seems like L four would get like the moment to moment details, but layer six under this theory would only get the displacement.

I think I didn't understand, your point the first time, Neil. So sorry about that. I hope I get it now because if I do, I think I really like the idea. so are you saying that, The displacement could actually go to layer four. And there we learn like a displacement model. So the displacement are essentially the features over time. So I guess we wouldn't even need layer six. We would just learn basically like the h temporal memory algorithm. We learn a sequence of displacement.

I know, but I, personally, I still like that we have the L six because. I think you can path integrate a sense into a song. Like I can, I know Bohemian Rly well enough that I can be like, okay, I wanna skip ahead to so and so bid or whatever. Or I'm just trying to think about how the, don't you have, how this relates to like, don't you actually have to go through all the notes in your head? it's long enough of a song that, yeah, maybe that's why it's, it feels like you can break it up into parts, but, but yeah, but just thinking about Another abstract example, like a family tree. Like it feels like seeing the movement, which is like parent, that's a displacement. So that tells you, okay, I'm on a family tree graph. And that, that, that's that's an a movement you can associate with a part of that graph, but it's still useful to have the overall graph and to be able to move flexibly through it rather than just being a one dimensional sequence that you have to follow from beginning to end without any deviation.

Yeah, it just feels like in some spaces, like a displacement is going to be more salient than in, for example, vision, where it's like we do a million displacement with our eyes. we cate all over the place except for some things like faces or something. There's probably not much of a pattern to it.

and yeah. yeah, whether or not we, wanna have L six or not for, this problem, I like the idea that in L four there's also a displacement model. Like instead of saying, okay, we just have a model of relative locations in frequency space in L six, and then we have specific features in L four, which is like the person who's singing it or the instrument that's playing it or whatever. But then. I can recognize it in a different instrument because I don't, think we actually said why, but I think having this just displacement model in L six would solve that in some sense. But also I was thinking could we have the same idea for object models like the general morphology models. That we have a displacement model in L six in addition to the feature models and stuff. but like the problem with the, like the, I feel like three D's general space is you can go between any two nodes via any direction. there's just like a combinatorial number of displacement to deal with. Yeah, it's a combinatorial problem, but. if we just want quick detection, like we talked before about like having some displacement model somewhere just for faster object recognition, like in addition to the actual path integrated model. maybe one way, because we're gonna run outta time here in a second. Maybe one way to think about this is that last week we talked about the idea that you could input a displacement into layer six, for music. And what I hear you're saying is you could also input a displacement into layer four. In my mind that would probably go to the mini column representation as opposed to the, being a feature. but you didn't say that, but that's what I'm thinking. So now the idea is we're just extending the idea of saying, what if displacement were passed into both layer four mini columns, let's say, and layer six. and they might serve different purposes. Is that, would that be a proper summary of that? Yeah. Yeah. I think this interesting idea. So we just one step further from layer six. Now add layer four.

it'd be interesting to look at the literature on audition. it's always been much poorer than vision. but by now there's probably a bunch of stuff on this. It's every time in the past, past being like 10, 15 years ago and earlier, when I read about representations in auditory cortex, it was very confusing and I felt like the data wasn't reliable. Maybe that's changed. We might be able to find something now that's seems to be better, but I like that idea. So as long as you're not throwing it away, from layer six. 'cause I think I don't, yeah. I also don't wanna get rid of Yeah. Layer six. and I think that was a nice idea that there's morphology. I had a similar odd observation before we leave here. I'm thinking like. If we do path integration in physical space, you always, if you end up back at the same point, like you can return to the same point and then, it's the same place. But in, in music, it's not the case. I could traverse through a series of intervals and come back to the, same interval, but it, won't be the same place in the song. it's just doesn't, it's a, but it's because you can sing to the, once you get given the key to the song. You can sing the right note even though it's a new key that you may have never heard it or sung it in. And that's path integrating through like the frequency domain to be like, okay, this is how I should be singing a or whatever. Maybe, but again, but perhaps, but in, in physical space, if I come back to the same location, I expect to see the same physical things. Yeah. I have the same representation location. In music, it's not, if I come back to the, the, if the song starts on a fifth and I come back to a fifth, or I go up and down, I don't, I have to think through it, but it just you don't end up at the, you never end up at the same spot again. You're moving through time and you never return. it's like you never come back to the same point where you say, oh, yeah. You can do that in like little sections of songs where you repeat 'em over and over again. So I don't know. Anyway. It's alright. maybe since you have to leave and it's 11 o'clock, that was a good idea that to, to leave on, we can digest to think about placements. Yeah. For what it's worth, like after last week's meeting when we were talking about the music stuff, I thought it could be an interesting one. Possibility is a first like abstract space to try and concretely solve or, I know it's not abstract, but sorry, rather not 3D. as a way of showing that what we're doing in Monte can generalize to other types of spaces. Yeah. If we can figure it out, but yeah. Yeah. And in, in audition you've got this weird thing. It's all, it's very much very critically tied to time and, we don't, grid cells represent 1D space very well. But unlike a melody, if you come around to the same point again, it's represented the same. And a melody, you can never come back to the beginning.

unless it's, a repeated little rift that goes over and over and over again, which we can also learn. All right, a lot of things to think about there. All right, maybe we'll have some more thoughts. Now, Wednesday, we're not gonna talk about this, so maybe the next time we talk about this again would be Monday then.