Yeah. I think what I was saying is we still want a pretty unique representation in layer four, like whether it's a cap or can, but then the location representation in layer six would be pretty very similar. What about region two or region one? either one. So in layer four that would be just a feature. Yeah. Okay. but it was just an idea like more motivated by this, I'm not sure. Yeah, I haven't thought it through in the context of, object similarity, like in the feature space, because what you said is, when we're, thinking about the, the location in the lower region, we're maybe the shared, cells and, the grid cells that would. The one that are reliable are just representing some sort of a cylinder, right? Yeah. So that kind of similarity needs to come from higher levels or No, because, I was thinking it's basically just encoded by in the grid cells and which are once turned, I guess it can be learned, through the connective, what I'm suggesting is maybe it is influenced by, merging these two objects or making them more overlap in the higher region. And that affects the six A in the higher region and then it, when it rejects back to six A in the lower region, it Yeah. Does have that effect because now they're closer in, in higher region. We assume that depolarized cells stay depolarized for a while after, yeah. 300 milliseconds or something like that. I think some can be longer.

we did, when we first came up with the temple memory algorithm, that was a key item. It has to say to long enough, Yeah. And, I think we convinced ourselves it goes long enough. I think there's some literature that said 300 milliseconds, and then there was other literature that said longer than that.

so there's enough ambiguity there that we felt, okay, it's gonna work. it wouldn't be super long, it's okay. Yeah. I don't know. What, do you think is necessary?

I, have this crazy idea, but, oh, what's okay idea? I don't wanna derail the conversation. No, it's all right. It's good. we're waiting, probably be better if I Okay, Yeah. Whatever you want be. It's up to you, Ron. No, I wanna share it, but I don't know if, just Don't want right in the corner up there. Okay. You don't wanna erase anything here? no.

we just assume that we, these columns, like we have multiple columns and these are all in region one. Yeah. We have, an object, these columns, minicolumns, the columns. Okay. We have an object and we have a, feature and we have location and object feature location. Yeah. and these are all connected together with associative links. Okay. Something like this.

Although it isn't clear that layer three connects the layer four. So that's minimal evidence. layer, Oh, I see here. Yeah. Yeah. It's generally not view, although there are some connections, people generally say this. Okay. But anyway, for the moment, whatever you want, to be able to. To recognize an object. All of these have to agree or, reach some sort of, I'm gonna use the term energy here, but, okay. Yeah. I don't like it. Yeah.

in a tractor sense. yeah, I know, but it's, I find people use the, sort of energy thinking is very, it just sticks to down long path. I, just, I call it agreement between all of these layers. and in that sense, I just think implications as Rami's doing a completely orthogonal idea while we were waiting for you to come back. Yeah. I was, yeah. Perhaps maybe we could revisit this at the end, but, I wanna say right up front, that's something Viviane said a moment ago. It has to work without multiple columns. It's gotta work with single column. Yeah. You can't rely on multiple columns is for speed and, a lot of other things, but it's, it, you gotta be able to, that's what I was going, forward with the, depolarization that stays on for a while. remember? Yeah. Neuro cannot transmit that signal if it doesn't spike. Yeah. But it could act as if, as a prior when later on, like if wrong, start asking how long ago Cell to stay. Depolarized you didn't explain why he was asking. he's trying to spend now. and I said, the, they're very clear for several hundred milliseconds, that 300 milliseconds, and there's some evidence that could be much longer than that, but a couple seconds. But you, were about to explain why it's important. Yeah, so we have a union of predictions and the features here, and there's union of predictions and, we choose one of them that union will still stay active, even after we choose, like the other ones that did not get chosen will still, stay active and, the be polarized, the Depolarized, oh, sorry, not active Depolarized. and, they have a high probability of getting, chosen later on if we, for example, in a different column or even here, get some evidence for, feature that, I guess what I'm trying to say is, over time this would be a way of ma reducing the, the possibilities, but it would just depend on the, on the ization of the cells. You don't really want to have depo cells last for very long because, if they did, then as you move around, if you, let's say it would be a multiple sensations like doing the saccades right, with your eyes, and if they lasted for like tens of saccades, then you would, then you've got this mishmash of depolarization that aren't meaningful. So my, the assumption's always been that they, and this could be wrong, that you, have a, you have an anticipation before sensory input, and then you got that sensory input. It matches or it doesn't match the prediction. You pick a set of cells and then at that point you have a very strong inhibition, which basically shuts down all the other cells. and, but what if they keep getting like every now and then some more evidence, that, the, but the polarization evidence, wouldn't be useful at that point. it's interesting, they talk about three oh milliseconds is typical, that's like a sec duration, right? it lasts long enough for you to do the next sensation, but not enough for do two sensations. Yeah. I'm thinking of these polarization as a, as the way Vivin is doing it with the evidences. they basically were basically accumulating, evidence as ization. And when we try to sample some of those to maybe simulate some, one of the possibilities and go with it. So if we, sample based on the ization here from the ones that are active, the ones that are depolarized, the highest ones are depolarized, they're going to drive some, projection to the object and the location, and then they're going to go across and, try to do something here, but then maybe it doesn't match and then it gets something here. again, I'm gonna force you to think about one column. Yeah.

I think also one thing because yeah, I remember we were talking about this at one point, like it's worth bearing in mind that like you could depolarize and predict a cell and you could, maybe have more depolarization to have it more bias or whatever. But to Ben benefit from that. You have to visit that SDR again, you have to visit those set of active cells, but if that's unique for a given location and you keep moving along the object that depolarization is never really gonna have any effect, even if it does last a while. unless you revisit a location. yeah. So you have to keep giving, more evidence or more, yeah. Or as in like, I can see how having like multiple depolarizations might like bias a particular SDR so that when you go back to it, you like, oh yeah, we're definitely at that location. Yeah. Because we've predicted that feature multiple times, whatever, but that kind of, it just requires looping back, which isn't maybe the norm when you're like, recognizing I'm actually getting that looking back from the object, not from the location. you're getting multiple features at some point, and then every now and then you get a feature that corresponds to more, you get an object, prediction there that responds to more, of those features. And you keep thinking, oh, maybe it's this, but. This is just an ortho thing, Alright, so let's go back to our, first conversation. Maybe we can just review with all the crazy things we've talked about. Yeah. I think particularly. Okay. Yeah. I was just gonna say, I particularly wanted to just recap the, joint grid cells slash graphs that we're talking about just before we took the bio. Okay. So just that the whole cylinder thing that like, Like I'm just, I don't think this is right the way I'm describing it, but just like at a high level, like intuitively we might imagine that, okay, when you put your finger on unknown object, but you're feeling it, it feels like a cylinder, let's say for the sake of argument that somehow grid cells have been pooled in a certain way. That you have just a set of grid cells that are active for kinda like cylinder objects. And so you're moving through that space and again, assuming this has happened somehow through learning, it is predicting features associated with objects that have cylinders. So we would be predicting both features associated with coffee mugs and features associated with cans. Who's predicting that? The, grid cells are predicting that. Okay. The grid cells that represent cylinder. Okay. So they don't know which kind of cylinder they're predicting Both. Yeah. And that would be related to this idea of transition structures that we talked about two years ago, where we have Like where grid cells can learn different trends, like we also talked about in the context of UV maps, like mapping different feature maps onto the same, morphology or structure. Yeah, Yes. We have a more, and, this would also help with the representational capacity thing because then like for this part of the object at least, you just need, what you call it, you just need the location for, for, cylinders. And then let's say then you move to the handle, then experimentally that would be the re-anchoring point because suddenly you have this very unique feature. Okay, now you know, you're just on the coffee cup. So now, the lo now the grid cells changed to the location, representation for coffee cup, but now we go back to the pixel and product. Yeah, it doesn't, and then what happens? I don't know. Yeah, that's, yeah, that's another issue is I think we are thinking of it right now as like different 3D object shapes, but I guess all the experiments are mice in a navigation task, right? Where it's probably like you could, if in this idea represented with the same type of location space. Yeah. It's much easier. yeah, I'm sorry. In the last sense involved in the previous one, so we're talking about mice as in, it's always just like a two, 2D Cartesian, like Yeah. Plane. Whereas if it's different 3D objects, then it's, it wouldn't really be necessary to have a Ritz, like a different Ritz space representation for, different like just the 2D navigation plan. you do have it though. Yeah. in this idea that, there no, there's no evidence that while the, rats stops looking at signpost here and it started moving over here, it hasn't looked at another sign post that there's, a, it doesn't, there's it doesn't go back to like generic room. Yeah. which would be our generic square room or something like that. Yeah. 'cause you could argue then like just following that earlier description, okay, now you move back to the cylinder or like the body of the gun and, but now you're in the uni unique coffee mug space. Yeah. But that doesn't seem very efficient because then you're basically having to relearn the object. I agree. But that seems to be what's going on. Yeah. at least from the rat in the room. it, doesn't, once you remap for all points in the room. and yeah. It doesn't go back to a, the evidence is that once the rat's in the room, it knows it's in the room. And that goes my observation too, that I don't go back to just representing similar because I know exactly when I'm supposed to predict it. Peeling the handle. and there's no ambiguity. Oh, back on a cylinder again. It's no, somehow we can do both. You don't wanna have to relearn all cylinders. Yeah. and then, yeah, in terms of then the like grid cell neurons being dropped, like another thing that maybe would fit with the literature is okay, again, you're on the cylinder. You, you started on the cylinder, so you're in that generic space and then you move on to the coffee cup and now it drops a neuron, I don't know. And some, and it's dropped basically the neuron that corresponded to the Coke can or whatever. and so, now it's single neuron. Yeah. Yeah. but then that's also maybe the problem is like, how would this have the representational capacity to be useful? Yeah. But then assuming somehow dropping a couple neurons is enough, it drops the couple neurons associated with the Coke can. And so now instead of predicting a union of, features in the, L four, it's predicting just the features associated with the coffee mug. Yeah. but then there's no re-anchoring, so then that doesn't fit with the fact that re-anchoring occurs. Do you know if there are any studies of, grid cells in relation to objects, like on monkeys or something? there probably are. I know there's, been ones with baths flying in three dimensional spaces. Yeah. Three dimensional spaces. good cells in primates. Yeah, like with objects, not like navigating our whole vision space, actually. Oh, really? Yeah. There's a cool one with, maca, where they're like looking at a, an image and and they basically have like good cells associated with that. Oh, that's good. Oh yeah, if you could share that one. Yeah, I think it was from like 2012 or something. Oh. Anyway, it's, it would be pretty big problem for us if it didn't work for, yeah. but it was still an interal cortex, but yeah. oh. all, there's also stuff with like prefrontal cortex, but like those, are the two main areas. the prefrontal cortex there was the stuff there related to like abstract optic, like even in humans, right? Abstract optics. Yeah. That with the birds, right? That was MRI. Yeah. the primary one I'm pretty sure was single cell, but I can double check.

and the, fm RI one is a sort of a crude measurement. you're not looking at individual cells, you're just looking at, collective cells and how they, if you recall how that works. If, you had imagined space that's tiled with grid cells, if you go in one direction, you're hitting the grid cells are becoming more active, over and over again. Then if you go a slight angle to it, they change slower. And so they can detect that. They can detect that there's less activity in the right pattern as you move in different directions. just strong evidence. Yeah. Not direct, but it's strong. I was just going, I would like to just, I'm, not sure if you covered the topic you wanted to cover, but, yeah, I think it, yeah, I just thought it was interesting to just revisit that because I think it's, I think the idea of merging the good self space firstly like addresses some of the issues around like representational capacity that we're worried about that. if we're trying to learn lots of objects and it also, yeah. And maybe addresses the point about like, how do you have multiple populations of active, and then the last point is just, it fits also with, I think we've been wanting to try and do in Monty, which is like start to merge the 3D models, right? So that at the moment we have unique, 3D models for the different mugs, my cup and C and all this stuff. And they're almost identical. Actually, we, have the hypothesis space to orient them together and basically say look, this is essentially the same graph. Yeah. And so we, could do something like that. Yeah. And that would even just be the same, exactly. Same graph, just different scale, but. And different colors. you can have the same graph and attempts a little modifier on the side. Say, oh, by the way, I don't want a coffee cop. The, for, I don't know. this is the paper by the way, Killian 2012. But, so they like the monkeys who, Nathaniel Killian. Oh, Elizabeth Buffalo? No. Okay. Killian was the guy worked at RI, but yeah, like you can see there's like a cell that's active at these locations when the these circadian around. I'll send, yeah, why don't we do the follow, there's another project we say, okay, we clearly don't wanna have to relearn all cylinders. that's wasteful. That doesn't make sense. Yeah. We clearly have very clear predictions when I know what object I'm on. when I'm expecting something different than a cylinder I'm expecting to handle that is, to my mind, that's like a absolute mean. I know if you ask me, oh, I'm only feeling this, but I know I'm on the cup, even if not filling a handle, I know that it's, there. It's not like I've lost any information. Yeah. So one way that you could do that, I'll see if I can come up the way to do that. you could have two spaces in some sense. You could have, we talked about this, touch on this earlier, like there could be, a generic space. I think there's some evidence for this in rats. I, I have to go check. I might be wrong with this, but if I recall. If you put a rat in a circle room, generic circle room, you get like one map, you put in a rectangular room, you get another map, you put in a square room, you get another map. These are not, but then you put objects in there, it gets unique. Yeah. or the rat can make unique. So there might be like two different, maybe you have some sort of base representation, which is, I hate to think like this, but you have push this way, which is a generic object. And, but you don't throw that away when you get the specific object. And maybe they, maybe somehow they both are continue to exist. there's one way to do that is you could have the same set of cells, in one phase become a different set at a different phase. And so when the, rat researchers are looking, they, I don't, maybe they're biased in how they look at this or something like that. Maybe this, maybe the second one is very sparse and the first one that's not so sparse. I'm just saying you could have the same set of cells could in different phases or different periods of time represent both the cylinder and then later the specific object. That's one possibility. you could have two sets of objects, two sets of good cells, two sets of things, and, both are being updated independently.

yeah, I like the way how you proposed to Neil said. There's the base object, the cylinder, and then once you get to the handle, you just drop off some of the neurons from that base object. And that makes it the specific, that was my hope when I saw the tank paper. Yeah. But I couldn't get it to work. When I tried to work through the details of dropping out things, there wasn't enough dropping out to make a unique code. Yeah, the code. But that's clearly evidence though. That's a really important piece of evidence. Like why would this particular grid cell stop activating at some point? But it would be nice because it would still keep the information that it is a cylindrical object. But it doesn't keep enough information about the specific version. if there are only so many cylindrical objects, it, I wouldn't be able to encode like hundreds of cylindrical unique objects. But, and the other, problem with that is, is that if I drop out a few of these cells, not all out of 'em, but a few of them, the, representation is still mostly cylinder. I have to somehow, I have to know that when these few cells are missing, how do I detect that these few cells are missing? Then it's no longer a cylinder, now it's a coffee cup. Go.

I did not do that. It was like, it just wasn't, where's the information? you guys, oh, I know this cell is missing and that cell's missing. How, and yeah, just to paraphrase what you were saying before, like one approach is like you re-anchor, but we also maintain that dropped out generic one and we just use the two different phases to, or I dunno if it's re anchored or as in like we have the dropout one at one phase that's active. and then we have the unique new re-anchor one and another phase. But, or, and that doesn't again, then like when we revisit the base, are we relearning? I don't know. But it's also it doesn't really stop being a cylinder. The information that it is a cy object is still very useful for us to make predictions of where the object is at all times. Like only very specific things change once we know that it is a cup. And maybe only those are the changes that are conveyed by the neurons that are dropped from the, I don't know how you convey information. The neurons that are dropped. It's, it's more when they, it wouldn't predict the other possible features anymore. When let's say you have, at a given moment in time, this is like all six and you have the majority of cells are like generic. The majority of the grid cells behaving on grid cells supposed to behave. Yeah, And, are as associated with both, what do you call it, the both cylinders, objects, and then you have a couple, grid cells that like, okay, this is associated with a coffee mug. This is associated with a Coke can, but it is dropping out or is it active At the moment they're both active because, because they're regular grid cells. So as far as we're concerned right now, they're regular grid cells because we haven't, recognized the object. And I appreciate this kind of sparsely whatever, it does not fit with how, the numbers normally work. But let's just say for the sake of argument that this is enough that we can predict, I mean in general, the features we're gonna be predicting are also gonna be overlapping because at this point, in a lot of locations until I get to a specific knowledge. Yeah. Yeah.

but then, once we then suddenly sense the handle, suddenly this one kind of drops out, or, this is gonna be a different grid cell, but like this kind of the, these very sparse handful of cells that represent the Coke can is gonna drop out, but this one's still gonna be active. So this one at this location is predicting handle. Whereas the, can, predict something else. We always need a distribution to predict anything one axon doesn't. Yeah, I know. And that's the issue. from a numbers point of view, it doesn't work. But if you assumed sufficient kind of capacity or something like in just for the sake of argument in Monty, we could quite easily do this. Yeah, you could, right? but no, can't do it. Yeah. again, that's the premise behind everything here, Monty, we may decide to do whatever's efficient for coding and yeah, whatever, but the way we're doing it now is not very efficient, right? So we'd have to change things. but it's nice to get a clue from neuroscience how this, yeah. How about the idea, remember earlier I talked about you, it's hard to, I can't imagine how you propagate two sets of grid cells simultaneously. That seems to be hard for me.

first one set, then another set all at the same time, yeah. unless they're completely different sets. One, one possibility, is that you have a sort of a denser, you have your sort of base like object, from the racks, like a round room or rectangular or square room type of thing. And, or we're talking about cylinders and, then you spars it, in phase, like, it goes through a, it goes through a set of phases where a lot of the cells just drop out quickly. Very sparse, sort active cells at one point in the phase, and then they all become active again. So, if by looking at any particular, any particular grid cell, most, when people look at grid cells, I don't know if they look at the phase of the grid cell, but if they look at the phases and coating something, but imagine, what happens is, I'm trying to go where I have one set of grid cells, they're all being propagated by the, I'm trying to do the dropout thing, but much, much more sparse than what tank showed, right? At least in the, excuse me, in the off phase, like maybe for the sake of language, if we say there's like an on phase in an off phase or something, right? Like that. So the on phase is they, and then off phase, very sparse. And, in those situations, typical research have di they don't even look for it and they don't see it. And it is because it's so sparse, it just, it's so sparse. It looks like a random spike. It doesn't fit in any of their, their, histograms. so it, it's easy to miss Right now the tank thing is a oddball where it's oh, why is this, you can cell, it doesn't look like a normal good cell at all. It just seems to be never an active, maybe that's an artifact of something else that's going on. We don't know.

it could be an artifact of the way, but that's for the moment. There's an enphase and an off phase and, so yeah, it looks like all these are real good cells and then in the off phase it's really sparse. no one notices that because we're talking about spike times, right? Exact spike times. So they have to be looking at multiple cells and seeing whether they're spiking, relatively tolerated, all difficult to do. So it is possible that kind of thing could be missed. so to me that feels like a better solution to me. It's I know I'm on the cylinder and now I'm, and I also know I'm on the copycat. You just look at the en phase in the office and those two things are there at the same time.

and so yeah, they still ahead.

so, what might happen is now I'm making a prediction. I have two predictions going up to layer four.

one would be, oh, if I look at the on phase, then I'm just a generic prediction, but it could be anything on the cylinder. If I'm looking the off phase, then it's very specific. and, I would know right away if it's right or wrong. by the way, the off phase could be prior to the on phase. We could start off with a specific prediction and then move to the generic one. it doesn't have to be in the other order.

you could say, I have a spec. If I have a specific prediction, I'm gonna project it up to later, four, if it matches, then I'm done. if it doesn't match, then I go onto the, on face and I have more of a generic prediction. So that's why if I'm moving on the Coke can, I may not have a specific prediction at a particular point, where, on the, whereas in the, on the coffee cup, I would have a specific prediction that was either met or wasn't met.

something like that fits the evidence better for me than anything else. Yeah. I guess the only thing is then, just going back to the experimental literature, like in that argument we're basically saying re-anchoring happens, but it's very sparse and precise in time. So it's not often observed. but then Oh, okay. But then re-anchoring is observed. You're right. What is the re-anchoring that is observed? Kering is observed. Shit, sorry. No, I like the idea that yeah, it's like this is happening, but it's just hard to record. the whole idea, the re yanking is occurring. It's like the evidence says that Yeah, but then we don't wanna have to learn everything. Yeah. Because it re-anchor.

when the rat, is in the room and it re-anchor, it's it is funny 'cause when the rat's in the room, imagine it's for the moment it's like it's in the dark. And I do, I've done say, permit myself to, in. And you don't really have much information at all. You're not really making any predictions until you get to some point. It's not like they'll be talking about moving your finger around the cylinder, oh, I have this constant prediction of what it's gonna feel like. obviously that feels correct, but, in other situations, if you're not, the rats, the room and it just feeling, it's whiskers. There's a long period of time where it makes no prediction of anything and then it says I should feel something.

it's not like learning every point. It's not like saying, I thought in the room, learn what I'm feeling, nothing or, and then, so it wouldn't be a lot of learning. But again, it's not, we have the problem if we're trying to learn a, some cylinder or something like that, but then we think, we feel like we have to learn the same thing. We have to learn all this learning about, I'm just, there's there's a difference there. A around the room doesn't have to learn every point until it senses something. Yet we're assuming we have to learn every point as, because we're sensing continuously.

why is that? That seems to, rat doesn't even have this problem as much, but even though it re anchors, it's not learning every point that could be use a useful piece to think about, for the point that. We don't wanna have a big union of predictions in the beginning when we are uncertain because maybe in the beginning we just don't have any predictions. We just wait until like we collect about some sensory information until we have enough information to make some educated guess. what shape of object you're on or how big the room is. Like you just walk in the dark room until you hit the wall and then you use the distance you walk to make a prediction of what size room you're in. Yeah. Like maybe in the beginning when you're, when you, it's hard, but in the beginning when we're touching something, I'm, it feels like we're getting information right away. oh, it's a curve.

you know what I'm saying? It's not like with the touch one, like on the object like this, it's hard to, it's not like the rat. it's like, it seems like I'm getting information right away immediately. yeah. But still if you put your, hand into a dark box and you're supposed to recognize an object, I feel like you still, you don't make a prediction on first contact. No. You still use your whole hand, try to judge the size of the object. Say one thing, but let's say one thing, you would still go over it once to get, get the size of the object at least, or the rough shape and then you start making more specific prediction. I feel the opposite. I feel like I, I would argue that if I touch an, I don't know what this is and that's, oh, there's a, it is got a curvy thing here and then, oh, there's a little hole here. I know that hole. that holds on my coffee cup. It's an oval hole. I know what it looks like. I didn't have to touch the whole thing, but as you touch the cup the first time, or even when you start moving, do you already make predictions like, oh, this could be a cup or a can or a spoon, or, I don't, somehow I'm able to, I'm able to infer Rapidly without touching the whole thing. Can I make a suggestion? I don't know if this has ever been done at you mentioned, but, we get a box. There's a box up here, and we each pick an item for someone else, and then put it in the box and we're each gonna put a hand in. I did that at the Exploratorium last year. Oh yeah. Yeah. And it was actually, it's not easy because I think, yeah. 'cause we use this example so often. I think it would be, you don't, you can't do it. you can do it, but that's, but just especially in the early stage, I think it is interesting to think about like how your hypothesis space is developing. I fun to try. We can take like in empty box. What did you learn? I think I, yeah, I think I've got a slightly bigger one. You have to be able to, or you can put a blindfold on. You don't have to put Yeah, that's true. Don't a box. Yeah. Put a blindfold on.

you have to make sure you just do one finger and then, I'd be fun to try. Yeah. That's his. Yeah. should we, wanna do it right now or do now, or it take a long time or, or after lunch, then we can have a bit time to find an object. Yeah, whenever, I would Wait. How are you around today? I'm all day. All day. I know super time. Wanted to talk to you. He wanted to talk me. So around 1130. I have to see, speak to him. I don't know how long, what you guys have planned for the rest of the day. We were timetable till 11, I think, today. Yeah. And I think Josh might bring by a link around 11. Oh, that'd be fun. So you can meet her if you like. Yeah. Yeah. Cool. I, have nothing else planned other than doing the research meeting right now, I can, you guys have to do something else. I can spend time thinking about this. see if I come up with any ideas. Yeah. yeah, we still wanna work a little bit on the hackathon project as well, but, since you're here, yeah, yeah, It's position. Great. Wonderful. I'll, wait till later. See what, nothing conceptual.

yeah. I would, prefer to keep going here. Personally, I prefer to keep thinking about these things right now. Yeah. Yeah. I think in the afternoon we can do a little fun. Yeah. I think I, I feel like it'd be interesting to just, roll out the implications a bit more of let's just assume okay, we have the generic, the generic space and then we, the more generic one and for cylinder optics, whatever, and we have the more unique one once we're on the coffee cup, and let's say maybe there's two phases, then they're both active and maybe they're. Maybe they're both very active and that's what the re-anchoring that people observe is. But, but just in terms of how catastrophic that is from a point of view of learning efficiency and stuff like that. 'cause like we were saying, that's not ideal because then like you, okay, you go back, now you're predicting with two different ones. But does that mean what does that mean for like, how we learn the object? Do we have to like, revisit every location twice? no, what we do, it would be, it was something along the lines of using the generic object that I learned, like cylinder or something. Yeah. it has a set of predictions and, but if I have a different input that comes in, then I'm gonna pair it with the sparser version of the grid cells.

I would say if I have an input, it doesn't match this. Like I'm on the, it seems like I'm on the cylinder, but now I get input that doesn't match it. then I would start, I wouldn't re anchor right away. I would, say, learn that new feature with the sparse version. So if I have a, so if the sparse version has a prediction, I'll predict it, but if the sparse version doesn't have a prediction, I'll just go with the generic one. So like the sparse version has priority, but yeah, to your point, like earlier I think you were saying like once, once you feel the handle and you go back on the mug, you're not like, oh, I'm back on the cylinder. Yeah, you're at that point. You're like, I am on a mug. Yeah. So it feels like the internal representation is, but maybe that's just 'cause that's, how do, that's the L three, that's the question. That's interest question. It could be L three, right? it could be L three says, oh, I'm this specific thing. Yeah. And let's say that somehow that worked and now well, layer three is projecting the layer six. It says if I know the specific thing, and, there was a, unique match for some location. I'll predict that unique match first.

But imagine you have the, maybe you have the unique prediction first and then I, it doesn't matter. Yes. Maybe it could be resolved by, let's leave it that way. Maybe it could be resolved by layer three.

so you would say that you go back to the cylinder representation once they're both active. but then, but yeah. But you're saying the, I guess the unique one doesn't get used that much because. or but I feel like it would make sense to stay with the unique one once you have it. Like, why would you go back once you know that you're on a copy? 'cause you want, because we don't wanna have to relearn all the things for cylinder. But you, if it's if it's the same SDR, you just drop some of them. You don't have to relearn. But I can't see how to get that to work. Dropping a few doesn't allow me to learn something unique. it's like noise. It's just, SDRs are very robust to dropping some things. They don't, they, still recognize the same pattern. For what it's worth. I'm just thinking like there's a potential advantage other than learning efficiency to re to going back to the cylinder, which is that let's say now later, we use these models for things like action planning. You can generalize much more because anything that applies to the body of the cylinder applies to any cylinder regardless of which object it is. So it's like a more, you reuse, it's a different face of the same problem. It it's the same problem, but it, applies to a different, we have the same problem, but not only do we infer objects without having to learn the entire object, we wanna be able to action plans without having to perform a unique action plan for every object. Yeah. But I was just thinking if I, get your point that it's difficult to do this with SDRs, but if it is just turning off some of the neurons, then it would make sense to not turn them back on. Because once you know that you're on a coffee cup, you wanna predict. All the things that you would see on a coffee mug like the mento logo or that it could be warm or something like that. And you don't want to go back to all the predictions that it would make for any solution. This is what I was saying. I saw, I was saying imagine you have the generic prediction and you have a specific prediction and, the specific prediction only comes into play if there's a specific prediction.

and so you, I'm reacting to something you just said. I don't forget the exact words of it. You, don't have to go back and forth. It's like the generic prediction works, but when I get to a location where I have a specific prediction, then that one dominates. It's so I know layer three knows I'm on a unique object. Layer six, is is representing generic objects, and to the point where I have learned a specific feature on take the generic object, I'm going a specific feature on it. At that point, the unique layer six activation becomes dominant. Otherwise it would, there's otherwise it is not gonna, otherwise you are the generic space. yeah. so if. If you have an SDR and you drop some of the neurons, and then the analogy that you, could have been on a generic object, but now you know you're on a specific one, you're just making less potential predictions. so the ones that you're still making from the cylinder could be like the curvature that you'll sense or aware and space the object will be, but then you drop some of the potential predictions, like the Coca-Cola logo is not predicted anymore as a potential feature, but I, the problem I get is it you just can't drop a few. Yeah. You have to drop almost all of 'em. And, it, you just, you can't represent something unique By taking a representation in and dropping a few bits that, that SDRs are robust to dropping a few bits, they'll still recognize it, the same thing. you have to basically go to a very spark representation that's unique.

I don't know if this, yeah, just on the neural side, if this is interesting, but I'm just thinking some sort of, if these are a little bit more like kind of grandmother type cells with some sort of inhibition, lateral inhibition or something. So it, so we still need the SDR, but basically once you drop this one out, then it's no longer inhibiting, some set of cells or whatever. I don't know. may maybe. I feel I, my feeling is that the dropping out of a few cells is more of, an artifact or a clue as to what actually is going on. It's not that, it's not the main event, like the key, it is not the main event. It is like a clue what the, why would that be happening. For example, if I, if we could explain the dropout at, with the two, two phases, for example, that'd be really cool.

I just, I can't get the rep. Maybe I'm, listening to you, but I can't see how you get the representational capacity by dropping out. Yeah, it's, I definitely see you point with that. I, was just, yeah. The general idea, so I really wanna do is you really wanna go to you've got a whole bunch of grid cells that are active. let's just look at this tank paper was, it was really key here. Go back to the tank paper. Oh, can you tell me my last sec?

man, I missed the, print, yeah, the, what? It's just so long since we've done a brainstorming session. Oh, I'd say I've missed it. Yeah. So this, was, this is like the really telling thing here. This figure here, this is a grid cell module. And, and the point of this paper is we try to figure out what these new morphology.

can zoom. Alright, that might be more helpful if you close this toolbar on the side. It might also close. There's a little X on the right next to all tools, no tools. Down a little there. This, oh, that guy. Oh, I'm sorry. Yeah.

this is a grid cell module and, these are actually grid cell modules here. This is what, there's six of 'em here. So this, these are cells, these cells, all rep or these cells are all tying in the space.

the colors are representing, if I recall, where these cells have become active in space. And so there, essentially there's six of these things in, and these are all the grid cells that are at some scale, right? This is another grid cell module. The grid cells, a set of grid cells are at a different scale. Remember, grid cells come in different scales. And so these are all the ones at a particular scale. And you can see there's six redundant sets of grid cells to represent tying of the space.

so there are multiple cells that represent the same location in a, space. If I find the other red cells here, these all representing the same location. In the space. So there's multiple grid cells active at that location. That's 'cause there's six of them here. Six of these sets. Now six is not a lot. originally we were thinking like, oh we have a lot of grid cell modules. So I'm sorry. I'll be clear. This is what we normally be considered a grid cell module. One of these little six things on these things here. I said, we have a lot of grid cell modules like we did in our first, paper about this. Then you could form a very, unique set of locations by a lot of grid cell modules. but there seems to be six. I asked Tank about, the way they do this. Was this, I think it might have been the two photon, microscope thing. I said he was looking at a particular plane. I said, could there be a lot of cells vertically that you're not showing here? And I believe he said yes, I'd have to, I'm not certain about. I believe he said yes. oh yeah, they, these only rep go down a depth of I know, 10 microns or 15 microns. there could be more cells deeper than that, right? So is it possible? Yeah. And so that there might be a lot of cells in here that are, 'cause I'm trying to get to a large number of good cells where you can drop, we could, you could then drop a whole bunch out and get a unique representation. so that was interesting. six didn't, six of these things didn't seem like enough, but ma maybe there's a lot more cells than he's showing here because there's many in the depth here. and so that's a possibility. and but to really form a, very unique representation, you'd have to drop out a lot of these cells. you can't just drop out a small percentage 'cause you drop out a small percentage. It's SDRs are just anyway, and this representation, by the way, is not very sparse, This, grid cells are not like they, they're gonna come on every, so many whatever distance you're going. so it's not a very sparse representation that even in any situation here, it only becomes sparse if you could drop out a bunch. so I think I even toyed around the idea that if there's a vertical stack of these, like he's only showing, like he's not showing the depth of it, right? There might be a lot of cells at that location in this particular module. that may be that, in that depth they become more sparse. I'm, trying to get to the sparsity thing. It's like somehow we gotta get to the sparse representation of space. And so maybe now it was coming back to me, I said, maybe some of these cells at one layer are the ones that they're measuring most often because those are the ones that they can reliably measure as grid cells. But there might be a lot of other cells further down that are very sparse and have grid grids, but you just, they don't capture 'em because they're sparser, they don't fire most of the time. And maybe the dropout that they observed was like, oh, that's right. No, it's coming back. maybe that dropout, like we said, some of these dropout, but very few, maybe you're just catching right at that transition. I. Where, where maybe like the cell right below the cell, right below this one, it starts to be sparse. And and he's, outta the border there and so he found like one cell, the cell that was dropping out. maybe if you go deeper, they all drop out or they, there's a lot of dropouts, something like that. so I was trying to come up with ways of getting sparsity out of this thing. yet preserving path integration for the whole thing. you want path integration work for everything, but I was trying to get to a representation that's standard denser representation and then you'd have a sparse version. So this should be consistent with anchoring on a particular, I don't know, anchoring on an environment and then spars ification for that particular environment for specific features or something like that. that, that would work. Let's see how that we go. yeah, because I guess if, yeah, this is, I like the idea that yeah, something about like the 3D space is what gives the drop outta the sparsity, but I'm just thinking Yeah, if this is gonna level at which experimentalists see a lot of activity, maybe 'cause it's like the generic with the generic models or representative or something, then You would still see like the re-anchoring at this level. okay, so re-anchoring actually, do they talk about re-anchoring at all in this paper? I don't remember. Because it would be interesting if there somehow there's Yeah, some like maybe under these experimental conditions reining never happened, but, or something like that. yeah, I don't know. it's a puzzle, isn't it? There's like a bunch of conflicting that's why I can never find the tank paper. 'cause Tank is the last author and I save it under goo. he was, he is I think the lead author. It's his lab. Yeah.

so this is a classic kind of problem we deal with here. You've got a bunch of sort of pieces of the data that are seemingly somewhat conflicting, but not a hundred percent. And we, have theoretical constraints we're trying to achieve. And then if you spend enough time thinking about it, you can come up with crazy ass solution. But then that crazy as solution has to be correct because it don't think that fits all the constraints. So it's and then you look for evidence, right? And you find it right. That's the threat.

in these situations, they only report the cells that are clearly that touch look, there's a lot of other cells that they, they're in here, they're not reporting at all because they don't seem to have the right properties. So the, it's in, these aren't all the cells. These are some subset of cells that they see that say, oh, these look like mid cells. We know there's a ton of conjunctive cells, which are combinations of different things. The cells that are very sparse, that have grittiness to them, all these things. So we're just looking at what a, a selected set of cells that seem that work, like generic grid cells and anything else, they wouldn't report. 'cause they don't know what it means.

someone share this paper in a group. Oh yeah. How, do you drop it into, slack drag dropage Drag it file on my desktop. I can drag it where? Drag it into what? Into into the message box, like where you type. Oh, really? Text. Yeah. Yeah. But I think you can also just, do the plus icon on and pick it as an attachment. Yeah. And just, or just share the link if it's, yeah, just, I don't have a link to the real paper. I just have a, I downloaded, it might have been, I think, oh, I remember was, I saw a presentation from Tank and he gave a talk someplace. I saw it. And this figure was in that, talk. And I immediately wrote to him saying, oh, I, I have all these questions about it. And he didn't respond for months until the paper was published. Daddy was willing to talk about it. It was really frustrating. It was like, I won't ask you about this. I wanna ask you about this. I only saw, it was briefly mentioned at the end of his talk. I was like, oh my God, that's a great figure. It was, something similar that happened with, so Edward Moser's group, they had a poster from like 2014 or something about rats in 3D cages. Yeah. And so I was really curious what the, like good cells were like for that. And then, yeah. And the, lead author basically, they published it recently and so she, but she was unwilling to like, talk about it until it was published. And then by the time it was published it became apparent. Okay. This ist relevant to us. I see. But I got really, yeah. Excited interest if they already have a poster, it feels like if you go up to the, at the conference or wherever it was presented you Yeah. Have, but I think it was new results and yeah, I don't know. I guess experiments are a lot more nervous about being scooped. Yeah. I'm not blaming em for it, I'm just saying it was frustrat for me. And the other thing here that's really interesting about these, the dimensionality of these things, the size of this, I was thinking like, is this equivalent, of course this is Cortex, but is this dimension here may be equivalent to a column. So would we see something like this in the column in the cortex where you might have six or 10 of these grid cell modules lined up to each other? Because these are, this is much smaller than column one. So again, I'm taking this as a sort of prototype, what a column would look like in the cortex, six of these things, but maybe there's a depth to them.

anyway, the beauty of that idea is that imagine these cells, I'm switching an idea here. Imagine each of these color cells is like a mini column. And so the minicolumns or your, or it's, because remember we were saying there might be some dense ones and some sparse ones, and then, but you wanna path integrate the whole mini column, right? You don't wanna path integrate individual cells. You don't wanna path integrate the whole minicolumns, but even the sparse ones, get path integrated, something like that.

because one, one of our problems is we wanna be able to do path integration, on, on, on sparse patterns, sparse, locations. And it's hard to manage how to do that. Yeah.

so we did, this is different than this, but the idea that you're doing path integration on, a set of cells, that might be vertically aligned.