so Q2. also it was fun putting these slides together 'cause you forget about all these things that you did and then you see them all again. but, so this is what we set out to do. three months ago, we wanted to pave the way for Monte to model compositional objects. We want to make money, easy to use in a variety of applications, increase our academic engagement and figure out how to model object behaviors. And so I'll just go through the sub goals that we set for each of those. So for paving the way for mild to Marty Monty to model compositional objects, one of the sub goals was that the accuracy on unsupervised inference benchmark is dramatically improved via hypothesis resampling. And I would say that's definitely checked off 'cause we went from 12 accuracy to 96 and from 6 to 94 accuracy. So I would say that's dramatically improved. and it's been done through hypothesis resampling. So great work Rami.

we had the speed of inference for distant age and dramatically improved via better policies. and this one has been deprioritized, which is why I made it gray. 'cause there was a lot of other stuff that came up and we had to work on like finalizing DMC paper and the hackathon wrap up.

Or, it was a whole quarter. But yeah, generally the hackathon work, as well took a lot of time. But, so we deprioritize this one, but still towards the end of last month, Scott, spent a lot of time on outlining how we wanna do this, and we have a really concrete idea now of how we wanna tackle that in the next quarter. then putting together a test bit for compositional objects, so Logos on Cups is available, and that's done, thanks to Scott's, work last week. And then the performance baseline quantified is not done yet. that will be a bigger project, figuring out how we actually want to measure performance on that, how we wanna learn how, we wanna do inference and so on.

and then also the motor system supports swapping out policies, which, thanks to Tristan. It, it does now.

then on making one easy to use. we had the motor system is disentangled from other classes that one, Tristan did a whole bunch of work on, but it's a, huge project, so it's still in progress, but there's been, lots of progress made on it. as you can see from all these merch, prs, Monty is not constrained to Python 3.0. again, it's, in progress. There. There is a draft PR that Jeremy, put here. and he put a lot of, work into kind of, making it unconstrained to Python, but we haven't merged it yet. And, Jeremy's currently exploring a different path because with the newest Habitat SIM versions, which is needed for a new Python version. That one for some reason requires GPUs. and then we have to add GPUs to all of our infrastructure just to run the simulator. And so right now, the different path, Jeremy's going down as adding a different simulator instead of, keeping reliance on habitats. And, we published tutorials on using Monty in novel applications and in robotics. So I put up these two tutorials on that and then, published several example projects. Those are the projects from the hackathons that we have. The, Lego, Asbury PI project and all its documentation. We have the ultrasound and all its documentation, and then also the drone project. And, hint around what people should, watch out for when building a robotics application plus the website once it's public.

Then yeah, for increasing academic engagement, the kind of university outreach and creating content for targeting universities, hasn't gotten as much attention as we planned this, the squatter, but still, will has created some of the, content pieces, like a short form two page, PDF, and then we'll also have the two papers to use, once they're published. everyone looked into conferences to go to and, I don't think all of them are booked yet, but at least everyone had looked into those. A lot of them are planned and booked. and yeah. Some, plans made for this year and then adding 500 academic context on Twitter, blue sky, I think on Blue Sky we have, more than 500 that we're following now that we'll add it. And then on Twitter, not as many, but we decided that Blue sky works better and more academics are there nowadays. anyways, but yeah, that's also still in progress. will it released, 36 hours of video? Exactly. For some reason? YouTube doesn't give you the statistic, it just tells you how many hours people have spent watching your videos, which is 1,362 hours. But I went in with the calculator and just added them up real quick and it actually added up to 36 hours. So I don't know if you planned this Will or but just, was a lucky coincidence, but just, Yeah, lots of, research meetings that will, process then transcribed and uploaded. And the most exciting thing is that we're almost caught up with the backlog of videos. So that's almost complete. That is very exciting because we have like over 200 videos in that backlog, I think.

and then, yeah, the one that really got the most attention the quarter, I, would say, especially from the research team, was, publishing or finalizing these two articles, especially the DMC paper. and so yeah, Niels uploaded them last night to archive and then, yeah, for the peer reviewed journal, that will take a couple more months to get the reviews and everything and address them.

then on the last one, figuring out how to model object behaviors. one of our goals was to have a concrete proposal for generalizing the stapler behavior to another object, including being able to predict observed features. And we do have a pretty concrete proposal for that, which is sending the kind of movement stored in the behavior model down to the child objects column and move through the child objects reference frame. And we also have kinda pre concrete proposal for solving a lot of the questions around the modeling object behaviors, for concrete proposal for how to model them in Monty. We do have some sections on that in the, disclosure document that Jeff and I wrote, and that we published, but not super concrete yet. So I put that to in progress. And then file provisional patent application or public disclosure. We decided to go with the public disclosure and, disclose this PDF plus a bunch of videos of us discussing, these new ideas.

and so although we didn't complete all of the sub things we set out for each of those, I decided to make all of these, green because we did spend a significant amount of time on each of these items, on each of these kind of broad items, and made a, lot of, progress on each of them. And overall, pretty much almost all of the things we did fell into one of these four categories and these tasks we set out, which I thought was really great. So there was a lot of good focus on those. There were a couple of things that I didn't mention yet, but we still spend a good amount of time on, so I thought I'll put those on some sites to just highlight as well. One is interacting with the community, which is an ongoing effort, but still takes a lot of time from people, in at least some, a lot of the instances when there are more detailed replies and questions. yeah, thanks to everyone who interacted on discourse and who posted, replies to people's questions and help them out. there. And also for people who, like Tristan, who reviewed p PRS on our GI repository from external contributors.

then also presented the project at several venues. So Tristan presented, the project.

then I, was on a podcast and Scott also presented, our project at the, Chen Institute. and both of those were two really nice new slide decks and new ways of presenting Monty. really good to have in the repertoire.

got a better idea of potential applications of Monty. Tristan visited some, the expo and some, other potential kind of, neck place in, the robotics space. I put together this presentation of, applications and how they tie into the capabilities of Monty. And then Niels and I spent a fair amount of time talking to ultrasound, both ultrasound vendors and people who worked with AI on ultrasound and people who worked with computer vision and implemented kind of ultrasound projects and had access to, clinics with, ultrasound, just to figure out what's out there in the space. And could Monty, could this be a first application for Monty and would someone be interested in building this?

so that also got a fair amount of attention. and then the hackathon, although it was just one week itself, demanded a significant amount of, preparation, both in terms of ordering all the parts for it, pre-training models, and also getting swag and prizes and stuff like that. and then also a significant, amount of post work. like documenting everything. Tristan collected a bunch of feedback from everyone on Montes usability and issues they encountered and started addressing some of that feedback and then also some debugging work.

and then there was also, a good amount of brainstorming, especially also the brainstorming focus week. And I already mentioned in the main Q2 priorities that we. do have a proposal for object behaviors applied on a stapler, but we also talked a lot about, additional problems like object distortions. We talked about, you feature or surface models. We talked about general generic and specific models. We talked about circles and ovals and interpolation in variance and equity variance and learning in lower and higher regions and like all these different topics. yeah, a lot of interesting, ideas and thoughts. and then there were a, bunch of code and infrastructure and style improvements that happened, throughout the month, just on a continual basis improving things, in little, ways.

so yeah, overall really great job. Everyone I thought was yeah, really nice. All the things we accomplished.

and then, yeah, I would hand it over to Niels for a quick recap on everything that happened to produce the DMC paper. Yeah. And I know there's been a lot of recap, already, so I'll make it quick, but I just thought it would be nice given that this was, a huge effort to get this out to just kinda revisit because, yeah, it, it's definitely been a big, milestone and, it's ended up being a, big project that we worked on for a long time. But I think also, everyone's really proud of, what we've put together and rightly because yeah, our ambitions grew as, this unfolded. and the original kind of motivation was to. Essentially establish Monte these capabilities, show that to the community and kind of communi communicate that to others and what the current state of the art of a thousand brain system is. and of course there's a variety of reasons, would want to do that. But amongst other things, one of the main kind of aims of the TBP is to get people excited about and using, a thousand brain systems in this approach. And of course, showing what it's actually capable of is a big part of that, especially the academic community. but along the way, I think it was just surprising how many kind of new things that came out. So new metrics, new understandings of what Monty's kind of actually capable of, that we hadn't act, really conceptualized when we kinda first decided to write this. and also just lots of kind of fixes and general improvements to, Monty's implementation. And, many of those were definitely not, trivial.

and so it's, been a huge team effort, everyone at The Thousand Brains Project. And also, like I said, on Wednesday, a lot of the groundwork for this even started at Menta, as been saying, although we've been working on the DMC paper for maybe eight months, really this started more than three years ago, with the actual kind of, initial work on the thousand, on, kinda Monty. but, definitely special shout out to Scott and Hojae for the, huge amount of effort they've put into this. I think when you guys joined, the idea was this was gonna be like a two, maybe three month project that would be a nice way of getting to familiar with Monty's, experiments and how to run those and things like that. And, thank you for, all the effort you've put in. despite it being a actually a much bigger, project we ended up doing.

and so yeah, To rewind back to when we kinda started on this, what we had at the time was, of course, Monty, certainly a similar version to what we have now, but, but with some, as I said, bugs and things like that, that we'd later discover. And we had some benchmarks gauging approximately things like accuracy, in the context of certain amounts of noise and things like that. And we had some, visualizations, but nothing particularly, glamorous. and so when we were doing initial scoping work, I said it started, fairly simple, but then eventually grew, quite a bit ambition, and I'm not gonna spend a long time on it, but just to put into a bit of context, of the amount of work that went into, some of these figures, we had these alii draw boards where this is just a version three where you can see there's, a huge amount of, variations and comments and all this kind of stuff, going on. and this was version four. And, I think it went all the way up to, version five. but we, what we ended up with was these six, I think, really beautiful, results figures that do a really nice job of just showing how diverse Monty's capabilities are. and that's, I think what's so exciting about this is that any one of these would be an impressive result. but the fact that all of these capabilities fall out almost automatically from developing sensorimotor ai, informed by the cortex is, pretty exciting. And I, a pretty, it feels like a pretty strong, kinda signal that, what we're doing is on the right track.

and, along the way, this resulted in two, new repositories, which, are providing comprehensive kinda support for anyone who wants to replicate these experiments. that's really important from the point of view of open science. and it should also really, build trust in, in what we've done and, increase the likelihood that people build off of this. And, but yeah, these, this was a huge amount of effort when 30,000 lines of code and experiment configurations for the kind of main paper repository and then this epic repository that, Hojae put together TPP floppy, which for the first time enabled us to quantify the amount of flops, that, the amount of compute essentially, that Monty, consumes and, enable us to benchmark that n bts. but, this doesn't capture all this other stuff as, was highlighting before. even just things like replicating the experiments, not to mention, running them in the first place and running them many times, I should say. Every time we'd realize some kind of change we should make to the figure or. some bug had been identified or whatever it happened to be that kind of led to a cascade of running all this again. So a huge amount of effort.

and just a quick kind of summary of some things in terms of new evaluations and metrics and things like that. We added, better visualizations of movement sequences for the first time we properly quantified symmetry. and found a way of verifying that we looked at adversarial color robustness. we looked at the kind of stepwise effects of the model-based policy. looked at scaling of voting for the first time, and figured out tie breaking, quantified learning efficiency. And also versus VIT, we had no comparisons before at all to deep learning architectures. And that was a huge, effort, particularly on ho j's effort to, get that. Also comparing flops and quantifying that versus the VIT also looking at qu continual learning and comparing that against the VIT. Plus, outside of that stuff, we got updated professional diagrams. we did a literature review on related approaches. had a whole bunch of improvements to the configs. Just simple things like specifying a voting, system in Monty where you have multiple learning modules in a grid, was not trivial at all before. Scott made lots of nice improvements to that. we have now a comprehensive mathematical description of how Monty works, which we didn't have at all before. and notation for that and then fixed a whole bunch of bugs, which yeah, I said none of these were, trivial things. Like when we started this voting only worked with, learning modules and sensorimotor modules basically aligned in a one dimensional grid, or, aligned. We, couldn't have kind of other arrangements. something with the X percent threshold. We fixed patch off object. that was getting a huge effort on Scott's part and then semantic sensorimotor. This was a thing that was leaking into our. experiments that we didn't want to. So I'm sure I've missed some stuff. so it was, a lot of, things. and of course, I think all these metrics and evaluations that we've now developed and the pipeline for visualizing them, all this stuff is, work that we can reuse, when Monty's capabilities grow and we want to communicate that again. so it's definitely not a one-off, use case. And of course now we have this 32 page paper that we can share with everyone, and talk about when they ask what can Monty actually do. so yeah. Thanks everyone for their hard work. Yeah. Kind of patience through this whole process.

Yeah. since highlight yourself, I just highlight that. It would not have been this really high quality, awesome paper with all these great results if it wasn't for you. And like you put this huge amount of effort into it. and especially over the past months, really pulling everything together, coordinating everything, making sure all the experiments are up to high quality standards, writing really nice texts that is like really fun to read. and yeah, up to last night, figuring out last issues, looking into last little numbers, whether they're actually correct and yeah, it, would not have been this great high quality paper if it, wasn't for you. Great work, Niels everybody. Thank you everybody. Awesome. I don't know what this paper was gonna be like when first started on, but it turned out much, better. Imagine. And it's very great, results. So it's really, really impressive. Thank you. Yeah. Yeah. Thanks to everyone. So Q3 is, has already started last week. and Neil Tristan Will and I put together a couple of, priorities again, oh, I forgot to change this header. It should say three here. But, I liked how they aligned last time with our TBP mission, so I tried to align them again, this time. And some of them are similar to last and or extensions of last, quarters, priorities. So first one, this one is an extension of first one from last month. Last month we were lining things up, for Monte to be able to model composition objects in this quarter, we really want to, and have Monty actually model composition objects and assess its accuracy and demonstrate that with hierarchy we can model compositional objects in Monty, accurately and efficiently.

Then second, we want to make Monty easy to use, improve, and contribute to both for the TVP team and for external people. And again, I'll break down each of those into a couple of actionable items that, that we're planning to do for those. third, we wanna increase external interest and awareness of our approach. And fourth, figure out how to model object behaviors, finally completely.

and so what do those concretely mean? enabling multi to model composition objects accurately and efficiently. First of all, we wanna set up a data set training and inference protocol and evaluation measures to evaluate Monte's composition modeling abilities. And that's not. Trivial. So we have this data set that Scott put together, but now we need to figure out how do we actually train Monte on that? How do we give a supervisory signal for what's the child object? What's the parent output? What, how do we, evaluate what's the correct classification since different learning modules have different objects that they recognize. and so we'll have to set up a couple of new evaluation measures and think through how training and evaluation should look like in this composition object setting.

Then we wanna improve hypothesis resampling, based on different signals. So last quarter, Rami implemented the this way to Resample hypothesis. and then now we have a bunch of, signals that we wanna use to inform that, such as prediction, error, out of reference frame movement, salient features and confidence. And that should manifest itself as improved or comparable accuracy on the composition data set with reduced computational overhead. So kinda being faster and more accurate because we don't have to test a whole bunch of hypotheses.

and then sate policies to improve accuracy and enable sparse some models, which basically, means we, we move more principled. Like right now we do random walk on the object, but that kind of ties into these model free policies to. Sate to salient features, and, or make sure to stay on an object until it is recognized. And then lastly, adding and testing this, idea of a 2D Surface sensorimotor module. that basically extracts 2D movements and features to learn things like the logo that can, that's a 2D representation that can wrap around 3D objects.

then on making much easy to use, improve, and contribute to, we have a continuation of the motor system refactor, so disentangling the motor system from other classes.

we have, Monte not being constrained to Python 3.8 anymore, which also ties into the support for Muco simulator.

adding an interactive and UpToDate overview of where people can contribute so that hopefully the amount of external people who contribute significantly increases even further because we make it easier for them to see where they could contribute. And then also adding more documentation on how to do that and how to customize Monte for specific applications. Again, making it as easy as possible for people who wanna contribute or who wanna use Monty to actually be able to do that.

increasing external interest in awareness. We have, publishing material around the hierarchy and DMC paper, so Will has already a bunch of stuff lined up for that. And there's also more, to put together. videos, presentations, plain language, explainers, posts and so on. presenting Monty and BRS theory at several conferences and speaker series. Part of that is also reaching out to some universities and presenting at their symposium speaker series. organ and organizing an online workshop slash symposium about Monte. Again, similar to what we did in December.

and this might not actually happen in the next quarter, but to at least organize it and plan it.

and then figuring out how to model object behaviors. again, we made a lot of progress on that already in the past half year, but, hoping that in the next three months we can kinda have a theoretical proposal for all the open questions we currently still have around, especially object deformations and, hopefully also how actions turn into the, play into that, how actions change the state of objects. and then a concrete writeup or even a prototype of how, object behaviors could be modeled in Monty. So actually, I'm hoping actually a little code prototype of that, but, it depends a bit on how complex that solution we come up with will be. and so yeah, that's, the two, two parts here. and then again, there's a Google doc in our drive that I can also share in the team channel later that has more details. So those were just the high level company priorities, but there are also, there's also more detailed breakdown, especially of the research objectives that, Niels can go over, later in the research meeting.

and also the engineering and community objectives are a bit more detailed, broken down there.