so I was dealing with this basic issue we've had where you have, layer four and, layer six A. That was the basic idea. And you have these, bidirectional connections. And this is a, location on the object. It's unique. We assume this is a, this is a, sensory, if you will, sensory input in, in context. it's already been in it, it would already been spar sparsed to say, yeah, is this input in this particular context or in a different particular context? And so you, you represent the association between these two. and, one of the things we said, oh, if you don't really know where you are, you may have an input and you don't, know the context yet. You might not know that. And or you, therefore you wouldn't be able to predict or accurate what your location is. So we always said if you have some sort of un in-context input comes in, it would lead to a union of, of, locations, and then we propagate the union and then we come up and get another input and we narrow it down. I never thought that would work, because I don't, I never, we can never figure how you would propagate a union by sense by a motor input. You have motor input comes in here and the mechanisms that, that we know about for grid cells, it's not clear. it, it would, it is not at all obvious how you would propagate a union based on a motor output. You get the next set of unions, a set of locations, and so maybe it works. but we never, we, I can never figure out how it would work. Yeah. unless they're all oriented somehow in the same way. if your movement is just the same movement through all of these spaces, then it doesn't matter. but in reality, there's nothing to constrain the spaces to be. In the same way. Yeah. That issue I was thinking of ion issue, the diff the, dis. The other issue is if you think about how grid cells are supposed to work, and we could go into that and go into the details of that theory. You're essentially assuming that there's a subset of cells that are in phases, and those are the ones that represent something. And and, then you, I guess you'd be propagating all the cells. We should walk through that. Yeah. Anyway, so, what I wrote here was, so the way we've always assumed this worked is you have some sort of, you have some sort of columns, minicolumns. These are minicolumns, right? And you've got a bunch of cells in each mini column. And this is the temple memory algorithm. So the you sensory input comes in, it runs to the spatial, to the spatial pooler. You select, some set of minicolumns that represent that sensory input. and then you would randomly select one cell in each mini column. so the, all the active cells are, in each column represents the columns themselves represent the sensory input. But then the unique combination of, individual cells would be in, in context. And if you, we've done a lot of math on this saying how many minicolumns would typically be on a real column, and there seems to be enough. It seems to be a good number. Like you could get a, high enough unique representation here. if you take maybe, 200 minicolumns or something like that, and of I think that maybe, 50 or active or, so, or more active, something like that.

but this has always been a random thing. And the, I, the assumption is if you had it out of context, all these cells would fire, at once, and therefore, all the things that were associated with all the different possible features and all the different parts of the world would, be protected down here at once. And then, this also has minicolumns down here. They're, physically the same, but there's a lot of evidence that they're actually, logically separate from these. and that, the mini column active here doesn't necessarily mean it's minicolumn active down here. under very constrained context. It looks like that, the context being, anesthetized animal looking at gradings or something like that out of context. but what are the minicolumns down here represent?

first of all, in layer six A, there's lots of different types of cells. So we're not just talking about any, there's multiple types of cells down there, so we have to be careful about that. But one of the things about grid cells, and I don't remember how much we've discussed grid cells here, but a grid cell of course, becomes active, at multiple locations on an object, right? And the question is how do they, what generates, how does a grid cell become active? and their basic idea here is there's two signals. there's two sort of sign waves coming in and when they have the same peak, the cell become active. And one of these is a, a voltage, control oscillator and the voltage related to the speed of movement in a particular direction. So if you're moving in a particular duration, the, os oscillation frequency of this one will change and therefore this cell will become out of phase for a while and then it becomes in phase again later on. And to make this work, you actually have to have a whole set of cells that all share the same, movement, vector. And they all seem the same frequency, but they're out of phase. So they have different phases. All these have different phases going down here. This is not, this is not something we made up. This is been in the literature. and it's a bit speculative 'cause not everyone writes about it, but I can't see other way of doing it. It's not speculative, I guess most people just don't write about it much. They just talk about how a cell comes about. But if you wanna have a whole set of good cell raves. A whole set grid cells then, each of these saying you have to have a, for each direction, you have to have a set of cells that all seem to respond to the same movement and the same frequency would be out of phase. And then, and at any point in time you have a set of these guys and different meaning, I'm gonna assume those are minicolumns, because they all seem to have the same response, which out to field, right? Which is what and then at any point in time you have some one, some of these cells are in sync and that performs your, that becomes your unique input for what, where your location is. So if I were to look at all these cells and read out from 'em, and I say at any point in time, some are actually in phase, then that is a unique location of a, of an, of a movement in a particular direction. How far along am I that in where I, where am I in that particular direction?

and so I, I've always, been under the assumption, speculation that's what these minicolumns are doing because, they, 'cause they seem to have the same basic response properties. You do see voltage, you do see, speed moderated frequencies down here. the, and so os the oscillation frequencies. So that's been my assumption. That, and this, by the way, these aren't grid cells. These don't fit the definition of grid cells. A grid cell would be reading these out, right? But this is what you need to generate location. so let's stop there for a moment if that's clear so far. So this part, the oscillation part, this is for learning the grid cells, not for, just using them. It, is for using 'em. Just for using them, it for both.

essentially if I just have movement, if I have, if imagine I have, these are, all, each of these minicolumns is slightly different, direction of movement. Okay.

okay. I know there's a lot. So I don't know if there's a, base frequency that I don't know how to describe that. Base frequency and then, which is like coming from the Almas, that doesn't, change, that's spec our speculation. That's how you, change it to change the scale of something. But there's a base frequency and then each of these guys share that base frequency all. And, but if you're moving in a particular direction, the cells in the minicolumn that match that direction, they also oscillate. but they oscillate at a slightly, variation of that frequency based on how fast you're moving in that direction.

I'm making this clearable. I wanna get to the problem. We're trying to Yeah. Adjust that moment here. So even in the independent of what, anything else going on? If I just assume there's one cell active in each of these, in the minicolumns that are active right now. So there's only a set of minicolumns that are active 'cause set. They represent, anything, like, we're moving north, north mini column and slightly less than north the side. These are all active with different amounts, right? But the north one would be most active, right? Higher. and the others would be, the frequency would be less, right? Of the frequency shift would be less. So the, so basically if you just looked at, the, oscillation, the phase of all these cells that they're depending on if this column is moving faster than this column because this is north and this is northeast and I'm moving north, the phase on these will shift slower and the phase of these will shift faster. They're all still oscillating, but it's just a phase shift that matters. and when I say phase shift, it's a slightly different frequency, which means the peak phase is different than it was a moment ago. Does that make sense? Yeah. Does that make sense? Yeah. Okay. so this is the premise of which, and you would have to do this during learning because you'd have to, you'd have to, you just, you would randomly associate sign a like up here. We, we randomly associated the active cell here. We assumed, like randomly associated the active cell here, meaning one that's in phase. The active cell, the one that's in phase and with in phase with the base frequency. And then as you move, then, the, one that's in phase with the base frequency would shift in some direction. So essentially these would act like one dimensional grid cells. It would say I have maybe 20 cells here or 15 cells and I have 15 locations I can represent in a particular direction by which, which is in phase with the base frequency. And so as I keep moving, I'll cycle through 'em again. 'cause, 360 degrees, that's what I got. And but the combination of these cells would be unique. So it's like a one dimensional grid cell. If you look at the phase relative to the base frequency, which ones is in phase, that sort of look tells you your location along one dimension and and that will cycle back around again and again. So it's not unique, but yeah. And I guess the one thing, and maybe this is distraction, but yeah, it's clear to me that it's like a one dimensional grid cell in that it, has like path integration in one dimension, and will like loop back around. Yes. But I guess it is not obvious that it would have path integr, in multiple dimensions. So if you took a new path around the object and got back to the same location, you're not guaranteed to have the same, cells in phase.

I, we could like, let's see if, let's think about that. if we just did a really, let's say maybe this is like a, this is going left and then this is going up, or something like that. And then this is going right and down. I think the, problem, I think maybe the problem you have, if, let's say a minicolumn means that's going up and I have another minicolumn that's going down. Yeah. you are right because this one would be active going one way. This would be active going the other way. Yeah. And, that is a problem, this theory. And so what, which I guess we, you're saying like grid cells are almost like what read off of this and then they have the path integration in the higher dimension. I don't know if they, I, we've never resolved this, right? I'm not sure. I don't see any other way to do path. This is the way to do path integration. This is the only proposal that really makes any sense there is the, the can, the continuous, whatever track network. I don't think that works. and I've talked to scientists about this, they don't think it really works either. it takes too many cells. So to me, the only viable method of doing path integration is the one that was laid out. this is, again, not our idea, that you have a set of cells. Each is, representing a different phase. And as far as I know, that's the only way that anyone's proposed path integration can work and have all the right attributes. 'cause you have this phase shift, what do you call it? The one, when a location comes after, before the camera, but, and then afterwards. phase possession, I think it's called. Okay, so this is a problem. So there's another question. So goods, these aren't really grid cells because for the reason you said, Grid cells always is active in the same place. So it, feels in some sense, like there's another set of cells that reads these things out that we would call grid cells. Yeah.

And, grid cells have these really weird things because for, the life of us, we couldn't figure out how you could get a unique representational location using grid cells into the literature. there aren't enough grid cells, there aren't enough, variation in grid cells, but this would get it to you. And so somehow it almost feels and other people have written about this too, so it's not completely made off that this is the, the, way you generate path integration. Then it gets, converted into grid cells, which are actually have a form of the, the continuous attraction network. There was a paper called, there's a paper about how, grid cell, you need both. You need the, you need a continuous attracting network and you also need the, oscillate oscillatory interference method to make this stuff work. So somehow it's like you go over here, you activate the grid cells. these are persistent activation, and then they can read and state the right things here. So you can do the path ation. We, no one, as far as I know, no one understands how this works, but these are pieces that seem to make sense. So these, the idea that you have these kind cells, you have a continuous active, the can, which is actually the grid cells themselves. these are things that people propose, even if they're not generally agreed upon, in the grid cells literature. But they still, and so the unique location code would be in the vector cells rather than the grid cells, right? this is the only place I could figure out how you get a unique location code. And, so I, don't know how you deal with the path integration through multiple dimensions. 'cause this problem, I, don't, quite, I've never figured that out. I haven't worked on it through, but, alright, so this is all preamble, to the problem of, yeah. so let's talk about what your idea was.

and, I'll see if I can paraphrase it, but it's been a while since I thought about it. we've always assumed that, that when, if you look at our temporal memory algorithm, we would, when the input came in into layer four, we assumed that all the cells and all the minicolumns become in the, active minicolumns would become active. So you'd have, this is the input outta context and then a moment later it would, inhibit, these cells would get inhibited. You pick, you randomly pick an act, an active one. If the cells were depolarized, meaning you had a prediction coming in from let's say layer six, and you said, I'm predicting these cells, then only those cells would fire and you would never have this burst. and then a unique activation.

and there are issues with that. I can't remember them all right now, maybe I can remember. But that was the basic way we thought about this and we always thought that the selections of these cells, would be random. And we also felt that, now, right now it's coming back to me if I have a union of predictions, so I have multiple cells in these minicolumns that are active, we would, we always said, okay, you, activate all of them. You propagate that down here as a union. And, I think what you were proposing Ron mean was, that, if I have a union of cells here, we always expect that the same representation will occur in the right context. So imagine I come in, I, have a. we only, let's say if a union and I select a bunch of cells here and I narrow it down, we always under the assumption, as we narrow it down, we narrow it down to the unique one that was up there before. Yeah. And you're suggesting perhaps that No, it's maybe not the unique one we had before. We have a union here, and, we may not narrow it down, so we probably get the union fa, but maybe, and maybe after I do that union and I propag, I propagate, maybe I select a different set of cells for the momentary. Okay, now we're getting into the, heart of the matter, right? 'cause we, always assume there was a, an input comes in, you activate the minicolumns and, if it's, unique, you know exactly what it is. But if, the prediction is not unique or you don't have a prediction, then you get a set, set of cells active. But when you activate that set of cells, you may reset what the actual representation is. Is that, I think that's what you're saying. Yeah. So if I had cell, A, B, and C where the correct cells for that representation. But I have a, I have a, union coming in. I, and so I activate, I activate 20 cells.

maybe then, and then those 20 cells I narrow down to three. 'cause I do the same algorithm, which is always you burst and then then you pick a winner. I might not pick A, B, C, I may pick something else. I may, the three winners I pick would be D, E, and F, or depending on how much their overlap. If it's a big union that could pick random ones. If it was, a lot of overlap, I'd maybe just pick a few. but then you're essentially resetting what the, what this representation is in this context. Alright. That was a long way of getting something very difficult to think about. that's how I interpreted what you were suggesting. Yeah. The representation that we're mapping to is going to change to go more towards the other predicted. it, could be random. I yeah. I feel like you're suggesting that you just start with a totally new one.

I, would pick from the ones that were in the union of predictions. Yeah. So it's not totally random. Yeah. and if I didn't have a union predictions, I'd pick the same ones. It's, if I have a perfect match, then, then there's no drift. if I predicted exactly one thing Yeah. And an input comes in and I only had one prediction, no drift. But if I had multiple predictions, like what's, I have two, predictions. And so now I have, those, the, only place I would get drift is if I, you have a common mini column, right? So the two inputs have to have a common mini column. And, and now I had two predicted cells in that mini column. one of 'em is the right one and one of 'em is a different one. But one of, at that point in time, after you depolarize both of those, you just randomly pick one at that moment in time. so it wouldn't, all the cells wouldn't, wouldn't drift because owning a, you are only gonna exhibit the drift in a mini column where there was multiple cells predicted. If I had another mini column over here, we only had one prediction, I wouldn't get a drift. So I think about how much of a you that basically says you'd have more drift with more uncertainty. I dunno if that fits the literature or not, but that's what that would imply. so I guess the, whole point of this exercise was I was taking what you suggested and trying to map it into mini column, temple memory theory, and then, walk through the implications of that. So I'm not sure if there's an advantage to this.

I don't know what this advantage to this, but it would basically say if I have a bunch of predictions, alright, I'm sorry I took the long way to get here, but I have multiple predictions coming in. That means I got multiple cells, multiple, SDRs active, some of the minicolumns. I could randomly pick the wrong cell for the new representation and I start learning that.

and, and so for those, minicolumns, I would exhibit drift. and then of course once I picked the unique ones here, I would now have a unique representation to pass down here. Not a, union. See, I, still don't know how to deal with the union down here. maybe it works, maybe it doesn't work.

So the next thing to do is to figure out what if I just, okay. So I was supposed to do SDRA, and now I have, because I had a union, I have SDRA, prime, which is slightly modified from a, that's a drift from a, and then I passing that down here and, and now I'm associating the drifted, the slightly modified SDR up here with the location down here. But that's slightly modified. SDR is going to be more consistent over time. Is it? I don't know. it's supposed to, we have a union of features at layer four. And we're basically every time we're, I'm not sure about randomly choosing, from the union of predictions, but if we basically over time pull them towards some sort of an average or a, sample from, these unions into just a single representation and basically both features are going to be the same then, I don't How would you do that?

do you wanna explain that?

Is that also what you were thinking of Niels? Yeah. We, I don't understand.

Wouldn't helpful so far? Yeah. Yeah. I think it was good to take the detour as well. Okay. Yeah. Yeah.

Okay.

Can I, erase? Yeah, sure. Maybe we just take a quick photo. We have, but, the high resolution photo, great.

Erase everything just this way.

All, I guess it was the big two rectangles.

So the idea was if, that we, if we have, a union of predictions, then we would have multiple, so they don't have to be in the same column. So it, is only sometimes it happens in the same column, but sometimes also, you get a prediction here and you get a prediction there, and maybe SDRV only has this column in it, and SDRV only has this column in it. But, when you, make a union of predictions, you could have. This one and that one. you only have different columns. If the sensorimotor, the input to layer four, the sensory input to layer four was different. You have the same sensory, have the same minicolumns. Are we, just to clarify, are we talking about the example right now where we are like on a food bowl and it could be an apple or a banana? No. Or this is, this is the, extension of that where, Jeff is trying to apply to, just between, in, in a single cortical column between the u, between the location and the, oh, why wouldn't that be applied if apples orange? No, it would apply. The original idea was that I'd only use it for the hierarchical, but for generalizing that for, as a In our conversation is coming back to that, our conversation, I was more interested, you were thinking about hierarchical stuff and I'm thinking like, oh, this, could be occurring right here in layer four. I think maybe even said, I don't know, but layer four could be doing this. And then I asked myself, could this be, could this method be working on all parts of the cortex where the units are formed? Yeah. Personally, I think it would be easier to almost abstract away whether it's layer 4, 6, 3, whatever. And you just describe it as it's helpful for me to have that concrete. Okay. Yeah, a little bit. because in this case, yeah, mommy said, oh, I might have different mini column doctor, but that means I have a different sensory input. Yeah. So that's why I'm asking about if this the case. So if it's like an, banana and orange, it could definitely be the case that totally different features came in. So different minicolumns are active. But if it's like we, we have the same. You have feature input that's consistent with two objects. I think it's really important because they have completely different features. The way I just described it, there would be no drift because they normally columns have shared, or almost only have shared. Yeah. so that's the example where we have a can and a cup, and so far we haven't reached a handle yet. So it's consistent with both of them. So this would only occur when you have similarities between the charges, which is nice because that could, it suggested that maybe has something to do with classification and forming more general representations, right? Yeah. Yeah. So observing a banana and a can not, there's no drift going on. But if I have a can and a something else cup, then I might start having Drift because there's some common features that locations, but I think it'll, yeah, I think it'll, it could happen both with overlap in the features, but also overlap in their structural representation. Because the same thing would happen, assume you've learned two different objects and they're relatively similar, like at a structural level, I don't know. You have two different types of coffee cups yet now you're sensing one of them. You're going to have this union active here, which is initially unique, but you're gonna have the union active here, which is initially unique. No, I could never forget you used the word down. Remember that? Yeah. Okay. But if we did, if we had two different location, representations, active.

The same thing is gonna happen that, these are gonna be feeding back here. And you have this kind of overlap in okay, some cells are going to receive input from both of these and that could bias those cells to be more active. And so that could again, push these, the kind of, these two locations to be more similar.

or to rather just sub-select a union. I'm not fine. So I feel like it, it is just it's just basic heavy. And if, as long as you have some sort of sparsely constraint, if you have, like two different location representations. So the one in black and the one in green, yeah. and these are for two different objects that are similar. So there's gonna be some cells that get, green inputs. Yeah. There's gonna be some cells that get black inputs and there's gonna be, there's gonna be some overlap in those receptive fields. and so these cells that have inputs from both, but there wouldn't typically be many. If I have two SDRs, which similar Aspar, the overlap would be very low in terms of those upper cells. you just, the, it just would be very few cells would be input from most, if, they're spars. If the two inputs are spars, then mathematically there's very little, overlap between, any particular cell. Therefore, but there, there will be cells like maybe not the ones that were originally active. there, there's gonna be a significant number of cells that get inputs from each. No, I think that's not true. That's why I'm arguing if it's sparse, that won't be true.

you could use, what's the overlap between two, 2 representations? Yeah, it's very low. there'll be some, but not many. I think the learning rule here is that, what I'm trying to get at is that those representations will try to be, will try to have more overlap over time. We don't want it to be exactly the same, but they're just gonna have more overlap. Which, two representations. So these, union of predictions, the, that, union is going to be, much less, many less people or sales are going to be, happening over time. because they're always choosing from that sub sample. They're always converging to, more and more similar. I see. So along what Niels is saying it, but essentially, the problem I have with that is because if I think about this layer four, you don't want to think about it, you wanna abstract it, but I'm thinking about it. Layer four. On a particular input. I'm, specifying which minicolumns are active. That's it. I can't pick a different set of minicolumns, that's sensory driven. True. And I can't pick a different set. So all you do is pick from themselves within those minicolumns. but the thalamus is sending, like what, chooses, which layers here get active over time, is really which, Minicolumns get active. Yeah. First of all, our assumption is you take these bits from like the retina, for example. And, you run into a spatial pooler and you, essentially say, okay, I have so many minicolumns, I'm now gonna activate, 30 over 20 of 'em. And the spatial pooler determines that. It's just like the, you take a, there's all these possible inputs and you narrow it down to a, rep, not a very sparse, distributor, but not very sparse, sparse, but not very sparse representation of minicolumns. It is, the spatial pooler is trained, also learns to do that. And you have to assume that spatial pooler doesn't change very quickly. It essentially say, okay, I've seen the world, I've seen all the sensory inputs from the world, from my patch of the sensorimotor, and I've learned to represent 'em using a set of minicolumns via the spatial pooler. And that becomes your basis of which all learning occurs. If that spatial pooler changes, everything, everything gets outta whack, it would be, you could, it could learn differently. But my assumption so far is that the spatial pooler is not changing. Yeah, we slowly drift the spatial pooler. if the world changed and you no longer have lines, and now all of a sudden you have little curves everywhere, the spatial pooler would change. The other thing is, I'm just thinking to a certain degree, maybe this, it's a, this drift could be a bit of a feedback, recurrent thing that pushes it more and more in that okay, yeah, maybe there's not that much overlap initially. And so there's only a few cells that have enough input from each that they kind of form this, new subset. But then that helps. Again, you're gonna have these cove, so that's gonna push these, unique location cells, and you overlap there. Those are cells are gonna be more active. And just over time, if you're activating the same cells here, then by definition there's gonna be some set of cells up here that receive that input. and if deactivate the same cells, then I, had a thought while you're talking, maybe what you're saying, but I, lost your train of your thoughts, so if you wanna do it again, or I can Yeah, just that, it's, it is a bit of a, recurrent, feedback loop where I get, I see what you're saying now. Okay. There's only gonna be a very small number of cells that if these patterns are two totally different, SDRs are going to receive in info input from both. But let's say there's a few of those cells, so they now, these are more likely to be active when you see those objects for either of those objects. So these cells are always active in the context when you're looking at either of these objects. So there's gonna be some, let's say, new location cells that receive, input from these Yeah. That are more likely to become active. And then there's gonna be some new cell up here that receives input from these Yeah. That's more likely to be active. Yeah. And so over time, yeah. It might drift to more. Okay. I'll take, I'll throw that. let me, I, that's a good idea. So I'm not gonna, I'm not rejecting that. I'm gonna add something to it. So one of the things, about grid cells, they don't seem to forearm units as far as we can tell. And if an animal or rats in an environment, there's, a grid cell represents, is, active in a certain location, in that environment. And if, the rat is confused, doesn't know where it is, you don't see a union of grid cells, one grid cell active, and then when the rat, it says, oh, I know where I'm in, then it shifts to a different grid cell. So there's no evidence of viewings of grid cells. It, there's more of an evidence, like I have a representation for generic space, and then now I'll, oh no, I know where I am. And you throw away all the old grid cells and you now locked into a new set. So yeah. I'm curious, do you know like a specific paper about this? Because I remember when I was working with Marx's stuff that I was trying to find a paper about, what are grid cells doing when arise? Confused. there are a lot, because I'm curious how much it fit with, I, don't have papers. I can't remember. You should know this by now. this is not a rare finding. Yeah. I don't believe in that question. In the past I said that and then turned out to be rare.

this, is, a general way. I, there's been a lot of papers that talk about, when a rat doesn't know where it is and then it doesn't know where it's right and it locks it. and I believe, oh, just like the re-anchoring re it's a re-anchoring, but it's not like a union. And then you narrow it down. yeah. It's not oh, these are all the possible places I can be. it's no, I'm in, the generic space. Yeah. And, because I'm in the room, I have no idea where I am until I start seeing landmarks. and then I start narrowing it. And then, and when I do that, the grid cells change, but they're not like a union being narrowed down. There's that. I think, I believe that's the strong evidence for that. So I, it is one of the reasons I reject the whole union of vocations thing, because grid cells don't represent, union implications. Now, grid cells aren't the things I'm talking about here. The minicolumns, that's the derivative of minicolumns. but the same could apply between L three and L four. any of these things could apply between L. I'm not sure what the, how to parse that statement, but Yes. okay. Yeah. I'm just thinking. Okay. Yeah. I think it could, but let's take, because grid cells might be unique too. Locations could be unique. It's a, different mechanism. Where I was coming with this is, and we, I'm, trying to avoid using a union of locations. I'm trying to, I'd rather stick to say Hey, I have a, set of assumptions about where I am right now. It may be, a generic, like I'm in the unknown space. and Dan, when I start narrowing down, I jump to a different set of locations. like I, I lock into the correct set of grid cells. so you're saying that the representation that gets activated is, is some random subset of, the union of predictions and we will not have I would, no, I would, all I was saying is I'm trying to avoid having a union of, location position that I'm trying to avoid having the green and the black lines going up simultaneously. Yeah. that's really interesting. But that feels like a radical shift in terms of like how we update the hypothesis space, because it does, the whole basis for knowing which, features to reactivate based on which reference frame you're in is based on the, location cells being active. So I, I'm, not challenging it. I'm just interested or I, in, I'm interested now where this goes. I found this right for I, as I started off this today, I said one of the problems I've always had, I can't imagine how unions of locations work. Yeah. It doesn't fit the literature, it doesn't fit my models, it doesn't fit other people's models. it's difficult to imagine. I never felt it worked. And when we said, oh, we're gonna propagate this prediction of locations, I like, ah, that's gonna happen.

it doesn't seem possible. So anyway, maybe it is possible. So I've never felt comfortable with it. So now in this conversation when this came up, I said, maybe this is the way of revisiting all this. And it is a radical shift in some sense. He said, I'm not saying that union prediction doesn't occur anywhere. I'm just saying right now I'm talking about the location cells. Yeah. And how we know the location cells work. I was, I'm enticed with the idea of okay, maybe we can get away from the idea that you have a union of locations. and somehow this, this, drift works with the fact that, if I'm gonna understand the drift in layer four, between layer and layer six A, I have to somehow accommodate the fact that layer six A is not doing a unit. it, it may be like shifting completely from one space, the location space to a different location space. Could, that mean that we might need to question the assumption if like objects have unique locations associated with them? 'cause if we have a generic location space that lets us move through the feature space of different objects, that might mean that we don't need unique location representation for each object. other than the fact that when an animal actually does recognize where they are, yeah. The set of SDR of the set of grid cells that are active become unique to that space. Like you, obviously any particular grid cell will become active in many different places, right? Yeah. But then before that happens, it must have still been somehow been possible to move through the feature space in a correct way to recognize the object, right? It, I, don't, I think you're posing the problem more than Yeah. The solution. Yeah. More like saying maybe we need to question that assumption if it's always unique locations for, I don't know about that. It could, it, it is possible, right? It, could be that, I'm not sure why I need to throw away that assumption yet. it looks like grid cells, one, the animals in your environment, the set of grid cells are active, tend to be, tend to be unique. obviously any individual grid cells can't be unique, right? I just say grid cells can't only fire in some environment. it has to fire in lots of all environments practically. But the set of 'em has to be unique. and it seems that's what it looks like, right? When you look at the set of good cells, they anchor rean may be a wrong assumption. Maybe I'm extending it beyond the data. I don't know. so I, I'm, I don't, I'm not willing to throw it. I don't know if I want to throw away the nucleation yet. Is, there an advantage of throwing it away yet?

yeah. I dunno if this is a cop out, but it feels And I don't know what to what degree, it's just like a cell population question. Like almost there's something a bit more like place cells or something like that here. I don't mind place cell. I, I, but, and then, but that's supported by the grid cell population, which is, or whatever vector cell population, which isn't unique.

I don't have how we work in play cells into this. I've always wondered if the layer of four cells are the equivalent to play cells. yeah. And and the layer of six A cells are to, there's, a grid cell population down there along with these minicolumns, which are, the basis of itself. but yeah, I, guess we just start with what are some assumptions that we feel are necessary to be able to reference frame based object recognition? Yeah. And then we can think about, okay, what are the cell populations that might enable that? Because for example, I feel like we have to, during uncertainty, we have to be able to move through multiple reference frames to test hypotheses. okay. I'm not sure. Maybe, not in the same moment in time, like maybe it would cycle serially through them, but there has to be some way to test multiple hypotheses, otherwise how would you ever, narrow it down to the correct one? Okay. It just, as long as you use the word test multiple hypotheses very loosely. You may not believe in them, surly, there may be different ways of doing that. Yeah. obviously you have to somehow settle on the correct one, right? Yeah. Whether you're testing 'em, testing is a loaded word, but, it is. So it is really odd the way, you know how the grid cells rehan and they do it really quick, right? They just fall, they re anchor as soon as the animal knows where it is, there's a, from layer three to layer six A, right? I don't remember that. There might be, I forget. No, I saw it in a couple of figures there. Yeah. Objection. So it's fine. You can find all those predictions from any cells. Yeah. The, so one, if, we're assuming that there's voting and there's associative connections between all the columns, once a group of columns agrees on something or has more consensus or something that is there, is going to force the layer three of the column talking about to, to have a specific, object representation that's going to very quickly drive. That would be a good way of doing that. if from voting, yeah. So it seems I have multiple columns, active and Yeah. I'm ambiguous. I don't, my input's ambiguous or I don't have any input obscured whatever. And all the other columns, oh, we're looking at a banana. Then I get layer three banana and if that layer six, you're right, there's a layer, I think there is a layer three to layer six direction. Yeah. Check exactly what it was. Then you'd be able to say, oh yeah, I've associated banana with, but you won't associate Banana with a particular location. You have to associate banana with somehow anchoring the layer six A cells. because Banana doesn't tell what location, right? it just says, I don't, but, a banana and a feature, both of them are going to set the location, right? So by I had the feature, right? I would a good observation. So layer force says, Hey, I know the feature, so it's gonna be one of these, set of cells, they need minicolumns. And layer three says, I know it's a banana.

and so if I have an ambiguous feature, or if it's just an edge and I don't know what the edge is, but I know it's a banana, then I could really help me figure out where it is. I, I would almost mean that each column is just testing one hypothesis and then well, once they reach a consensus, I feel like this only works for the voting scenario. Yeah, I'd like to solve it without the voting scenario. Yeah. I think that's pretty important. I added a second one. I don't know. We agree with that, just that a location and reference frame should recall the correct feature. I haven't said a unique feature. 'cause if we're throwing out assumptions. Then maybe, I don't, I guess really the question is it a unique location, which I've always assumed, I've always wanted it to be a unique location. Yeah. But okay. I haven't written, I dunno, I just thought these are the computational requirements. But what do we, mean by location? Is it unique to the object? If it's unique, then it would, it, it should, recall the unique, the correct feature, right? Yeah. should predict the correct feature. Yeah. I guess this is, this is unique in the sense that it's a location in a reference frame. Okay, great. Yeah. Okay. it's not ambiguous which reference frame it's in.

I think that's correct.

so yeah, maybe is it worth just thinking a bit about the serial one a bit like this could almost relate to kind of frequency things and things like that. Where like at a particular frequency, one hypothesis being tested frequency. I, that's exactly where I was going with the same thinking there when you said, testing it, I'm thinking of that exact idea that you have, at a moment in time you have one set of grid cells that are in phase, and the next moment, the different set are slightly in phase, but they're not in phase as much. Yeah. It's this is like the phase progression in grid cells. They, become active early, not as strongly, and then they, everyone knows face possession, Very well. Yeah. The idea is you look at an individual grid cell.

and it says, okay, I'm active at this location in the room. that good self starts to become, it, starts to become active. it is active before and after that location. It's, and it's, it, in the phase of which it becomes active, it changes. remember there's a base frequency, whatever, I always forget again, whatever. There's a base frequency and that cell becomes active. Its, its activity is peak activity at the in phase at this location. But if you move a little bit this way and a little bit this way, it's still overlapping. the two peaks of the waves are not perfectly aligned, but they're slightly off. So the cell still becomes active here and still becomes active here. And the way it works is you're approaching, I forget, I think was you're approaching the further one becomes active first and then, and so the, if you look at, if you look at the grid cells as you're approaching its point of maximum representation, it starts becoming, act. The, position that would be active here becomes active. Then the, then it gets, so the, position that's represented by the grid cells moves in phase space from here to here, with maximum activity here. So it's almost At different points in the phase, different sets of SDRs would be active here. lemme try. Wasn't phase possession in place cells. it's in place cells and in grid cells. Okay. It was in marked.

so here you have a location in the space and the, this way over here you have SDR one, and, then here you have SDR two.

we're talking, individual cells at this point. I guess we're talking, so this cell, this cell starts bec as you're moving, like this, it, and there's a, there's an underlying, oscillatory, frequency. this cell starts firing fir it starts firing for all these locations. But I, but when it fires it, first, it starts firing here. When it is overlapping, I don't know. I'm trying to remember exactly how this works. but there's a, the phase possession is that the cell actually becomes active over multiple, locations with the maximum activity at, its direct activity. But that's not phase possession. I don't think I, that's just the fade and good cells phase possession is when it fires earlier or later relative to the timing of the spike.

that was like a yes. Yes. But I don't think that's inconsistent here. But The timing of the spike is, this is like a face, the face shift. You have, a, you have an underlying, so maybe this is the, so this is the upper one. This is, the base and this is the cell. So they're aligned here. That's perfect. And now this one's spiking here and this one's spiking here. And the, it's this, different. Isn't that what you just said there? I think it's because yeah, I think, at least when I think about this, it's more like each grid cell has like a, preferred, receptive field, almost like when it's on its exact location than it's maximum firing rate. And then it tails off as you, move away from that location and then eventually goes back up again as you get into the phase of that grid cell. And the reason that is, is because the input to the grid, okay, so I'm confusing things here. These, are the inputs to the grid cell. There's a base and there was, it is, this is the, these cells here that, it's these, I'm, getting confused here when you, I'm sorry, but No, it's, you've got, the grid cell is the grid cells is firing at a frequency, which is slightly different than the base frequency. I'm, I, the grid cell is, that cell anyway.

and, so when they're, you get the maximum firing rate when they're, aligned, when they're slightly off, you get a less firing rate. It's a lower firing rate. So because the cell is, not Okay. yeah. from this input. I see what you're saying. Yeah. it's it's a lower firing rate. Yeah. So this would be these cells here, but anyway, what is that the, it starts firing.

yeah, I get, but I guess the, going back to can we test different hypotheses at different phases? Ultimately, that's the question.

there is, it's, is it, as you're moving through space, it's saying, oh, you might be here a little bit more likely here, more like here. Really like to hear less likely to here, less it's like there's a distribution of where you might be. so it would, anyway, that's what it is. yeah. let's, go back to your two points here. I, the thing I would focus on is how do we make this work without a union of predictions coming up here? How would we make it then? Then I, think, should we just focus on the L three L four case? Why? because then we're not talking about locations, but I wanna understand how it works. okay. I guess maybe this is wrong, but I, feel like the, drift and pooling SDRs is orthogonal to this issue. All right. It didn't, but maybe that's wrong. It didn't feel that way to me. It felt it felt like they're related somehow. okay. This is this be to walk through the, drift thing, I deal a little bit more.

this lemme review the drift idea. You have two inputs to this layer that if, they're if they're very different and therefore they don't have to share any minicolumns, the current thinking is that in my head that there'd be no drift. it is only when the two inputs are similar or identical, then you can have drift because then you have multiple cells, you have the ability, you might pick multiple, you might pick a different cell active in that column and that would only occur if the prediction from here, led to multiple activities here.

multiple predictions here.

I'm trying to, I'm trying to figure out how it is that the drift idea works with the idea that you are re-anchoring down here as opposed to representing a union down here. that's what I'm trying to figure out. what would it mean re to re anchor and maybe I'm stuck at that point. If you wanna talk about layer screening layer four, that's fine. We can do that.

I still wanna stop the other problem, but maybe I don't have enough ideas about it yet. How would you face the problem between until later? So if we assume that we have drift, that would mean that over time we would represent similar objects with similar SDRs. So let's say we have the cup and the can, the only difference is that the cup has a handle over time. We would, they would have similar SDRs. So let's say we are, that sounds good, but can you tell me how that would happen because of the representational drift? So let's say we're on the cup and we're moving only on the outside of the cup. We haven't sensed the handle yet. So do I, what's going implication to have, are you, do I have any unique, yeah, so that's what I'm getting at. Okay. with the re-anchoring. So let's say we would think we are on the can and we are in the, we are testing the can hypothesis. We are in the location space of the can. And then once we sense the handle, it would quickly re-anchor on the bottom to the cups location space. And then what happens? How does it, where does the drift come in at that point? the drift would just mean that is actually possible because, while we're not sensing the handle yet, the SDRs at the top would be the same. and would work like even if we're in the, hang on.

so I think on the cup, I think I'm on the can I have a unique space for the can. Yeah. Yeah. Then now I've come along and now I have a feature which doesn't fit the can.

so I, it is gonna mis I a mis prediction, right? A feature that doesn't fit the can I'm, and therefore my prediction from the location space is, wrong. And now that has to somehow re-anchor the, let's, it's possible that one new feature, I know I'm on, a cup now or whatever. Yeah. That has to reor the grid cells saying, oh, I'm not on the can, I'm on the cup. But ideally you wouldn't have thrown away, if you, if that actually happened to you, I feel like you'd still have a sense, okay, the cup is oriented like this in space. 'cause I just felt its body, which I thought was a can at the time, but if, up until that point you'd only been testing the canned location space, then when you feel the handle, all you will know about the location of the cup is that you're on the, that you're on the handle.

so I throw everything away. yeah. I feel like we still would want to be testing maybe because if they, multiple locations, if they share an SDR up to that point, like the SDRs are the same up to that point, maybe that would inform it to then test the cup hypothesis. Yeah. In the locations. I mean as in but then we still need to, ultimately we still need to somehow be testing the, movements to the location space. But yeah, I didn't think that whether you could have Because we talked a bit about how do we wanna merge graphs as well? So let's say you have a graph for a cylinder or something, and then until, whether it's a can or a cup, you're you're moving through the graph or the cylinder graph and that's updating both. Yeah, I think what I was saying, it doesn't work with the idea that they have unique location representations.

but yeah, if they would share a location representation like the cylinder that could be, and then you, okay, maybe this won't be helpful. Again, going back to the grid cell literature, when you look at grid cells, we don't see these SDRs, right? We just, we don't see, all is some sort of grid cells are active and and then they reang it.

and but what I'm really saying is there doesn't seem to be enough grid cells to have form a unique representation, right? So I, it is it's two things at once. Once it, it does re-anchor when you go to the new object, but it doesn't look like there's enough cells to do the unique representation. there're not sparse enough. It's like a every, a, grid cells, okay, so imagine have a set of grid cells and you're seeing when one becomes active and they, for the most part, what they see is that the grid cells will always become active in every representation at just different locations. It's like you don't see ones that, for the most part, you don't see ones that are not active at those locations. If you had a real sparse representation, you'd see a grid cell that wouldn't become active at some location where it might have otherwise. You follow what I'm saying about that? Yeah. Now there actually is evidence for that. I can show you that I have a paper on my laptop where they say, Hey, we expect this grid cell to become active. once you, once a grid cell becomes active and you know its direction, it's supposed to, it's supposed to be co here, Then people have observed that it may not become active at this location reliably on a particular object. It's like this cell does not, this grid cell should become active here, but it doesn't, on this object, on a different object, it would be a different good cell. It's not active, but it's not like I see, not like I see like most of the points are, not active. It's like one drops out. I can show you this paper one drops out reliably. So if I'm looking at the can and moving along the can I, this grid cell should be active here. It doesn't become active. If I'm looking at something else, it does become active and another cell may come in. No. Like it never becomes active or just not as reliable on that? On that? No, it just totally blank. I can show the paper it and I talked to the research about it. Okay. it's very reliable and multiple people have seen this. They don't report it very much because they think it's like they don't understand it. Yeah. The common literature grid cells is they should be happy to go every location and, so it's not like it's just less likely to connect? No, it's reliably. I talk to the researcher about it. It's reliably inactive. Yeah. the majority of the cells are, active and majority of the cells are reliable. Then the, this is the annoying thing about it. 'cause the majority of the cells are correct. yeah, I show, I, I have a picture of here.

this is one of my favorite papers. And and we're talking in grid cells. and then that phase of the grid cell is never active or it's not active at a particular location. it is, it's not active. It just, the grid cells just doesn't become active at that location at all.

I think it's at the end of the paper. Oh, it's the tank paper? Yeah, the tank paper.

oh yeah. Where is it? Oh this, oh, this is supplement information. Not in the supple. It's somewhere else. It's the end of the paper. Little supplementary. Supplementary. Okay. see there's a figure that represented. Lemme see. I can find that.

I've got a great set of notes, that I wrote about tank paper. It just says tank paper Plus. Plus as it like to write more notes about the tank paper. Oh, here it is. Now I'm entering the main part of the paper. Yeah, I wanna read it again. I remember It's, yeah, it's one of these things. it's in here someplace. Yeah.

let's see here. C maybe, what does it say? C Mis field patterns. Mis field patterns are highlighted field and B and six cells. So what is that?

one by one significant.

okay. It's in here someplace. what is this one? Missed patterns? or I have to read this carefully. It's in here and I think I wrote the tank about it and I asked him.

I, can't remember exactly where it represented here, but Alright. I have to read it more carefully again, it's in here someplace. It's in this figure somehow for these two figures.

I think, what is that? Help you All right. unless you wanna sit here and read the paper, which should take an hour.

Missed field pattern on the, on of the field in each cell.

so this is a missed field. So, the cells should be active throughout the entire Correct. Throughout the entire run somehow. And, yet there are places where it reliably was inactive. It should have been active, but it was reliably inactive. Yeah. So this would be, and this is, the actual data that's almost half of the, I, thought it wasn't a lot, but maybe I'm misinterpreting it now. I can't remember. Maybe I got that wrong. so I just wanna make sure I understand it. So it was more about the misfield we're saying that the, when we change the, the environment that they're running in, some of the, some of the cells should become active and they're not.

so there's almost two conflicting things here. One is oh, the animal doesn't where it is. So you get one set of grid cells, then the animal doesn't, what it is, it re-anchor. the cells anchor at different locations, they're still active. And now you'd expect, once they re-anchor it, now they say, oh, it's now it's gonna be here, not here. So it's in a, it is an array of activity, a grid of activity that was here, and now it's shifted someplace else. But in that scenario, it doesn't reliably become active in every location that, that it should become. And, but it's reliably inactive. It's like for this object that lo when you're at this location in the object, it's never active. That would like, that's like the spars ification of a grid cell pattern, Saying, yo great, I'm, I now have a, set of unique, a set of grid cells that all should be active in some place. That's, not enough to create unique representations for all objects.

but, now you can, you start dropping 'em out and it says, no, this, so now the, these cells somehow become, I don't become sparser. yeah. And this was a, piece of data that no one don't, they don't have any explanation for.

it's, it wasn't, experimental missing or cell was misbehaving. It's like a reliable behavior, reliable thing. Anyway, see, these are multiple things that are I'm throwing into the mix here. yeah. That will be a useful mechanism if we want unique location or reputation. My recollection, it doesn't do it enough. Yeah. To make to, to the unique SDR. but so when I first started this, oh, this is great. Now we have an SDR formed with grid cells.

but it could be a clue to this thing. It's, it could be like there's a base. I think it gets very much to this generalization. There's a base, maybe there's a base. How about this? There's a base anchoring for, cylinder objects. Individual cylinder objects, you can drop out different, you can do a set of, not a very, large set, but a set of cylinder objects by dropping out somehow different, good cells at different locations.

yeah. And then you're predicting a sparse or pattern of features as well. like before you drop them out, you're predicting all of the But again, potential features, if it's not a lot of dropout, what it means is that you'd have an, you'd have a, set of grid cells that are active and then, on a particular location, it's a subset of them and they're generally predicting the same features. there, there's a lot of overlap. It's not like I went to a totally unique, it's like I don't have a unique representation of that location. On the object. On the object. I have a partially unique, some of the things dropped out and some are still there. I, would've almost thought of it and on a different level, that basically the unique, like the ification of the grid cells tells you what kind of object structure you're on, like cylinder, sphere, square, but then which specific cylindrical object it is depends on what the features are in L four then, because if you wanna encode unique locations for all of the objects. Say it again, I'm, losing it. Say again. You thought just sort that paragraph over here. Yeah. That basically the specification of the grid cells tells you what rough shape of object you're on instead of what specific object with that rough shape. so that the location representation for two cylindrical objects is the same in L six A, but then which specific cylinder cylindrical object it is, determined by the active cells in layer four. But, I guess I, okay, but how, but then I can't predict the specific from layer six. No. Yeah, you wouldn't be able to. I it is more than just generic You're saying on a cylinder. Yeah.

as opposed to some other shape object. Yeah. And that way it wouldn't be that big of a deal that it's not as sparse. 'cause we only need to encode like a limited amount of, but then now I move, I have to make a specific prediction. you predict a union.

if I know I'm on the, if I know I'm on the coffee cup, you're on the cylinder. I'm touching a cylinder, but I know I'm on the coffee cup. The moment I'm not touching anything about related to the coffee cup, I'm just touching the cylinder. But if I know I'm on the coffee cup, then when I move, I'm gonna make a very specific prediction. I'm gonna say oh, it is not just a cylinder. This is the, I should feel the handle. it's not like I'm gonna be surprised that the handle's there. I know I, at this point I'm on the cylinder. I know that I'm on the coffee cup. I, let's say I, I do. But let's say I touched the, handle. I moved away. Now I know I'm on the coffee cup. I have to make very specific predictions for every, could that be biased from L three connections to L four? It could be. If you can come up way of doing it. I need to. It could, But there, I don't think, there aren't many of L three that live four connections. It's, that's a sports. I think there are some, but there's some, but it's a lot.

My bag, what you're saying is when we have the hierarchy and we have the layer three to layer four connections, I'll be right back. And then we do the, generalization stuff, the mapping stuff, then the two representations of the, cup and one with a handle and one without are gonna be very similar. And then the location in six a in the, higher region are also going to be, become more similar because the, representation of those in the higher region are similar. So when that feeds back to six A in the lower region, they become more similar. It represents a cylinder more than an actual object in the high region.