I'll just jump in real quick. I don't mind any in-depth discussions or if you want to get this over with quickly. Definitely feel free to interrupt if you have questions.

Basically, I tried to make some visualization of what I took away from last week's research meeting about representing time. It's a mix of what's happening in the brain and in Monty. Hopefully it works, and maybe you can let me know if you took away the same broad concepts or other things.

As a first example, I took a melody. Let me explain this figure. Can you see my cursor? This is what's being experienced. There's time, and I'm going to move this gray bar to the right as it goes through the melody. Up here is the kind of shot clock or stopwatch mechanism we talked about. I'll refer to it as a stopwatch mechanism now because I visualize it like a stopwatch: you start it, this arrow moves through it, and then you can reset the stopwatch—lap to lap or reset—and the arrow goes back to the top and starts moving around again. You can reset it again, and it goes back up and moves again, and so on. Whichever point the arrow is currently pointing at is the input to layer one. That represents the timing since the last event. This clock gets reset with every significant event that was sensed.

For example, in the melody, each of those notes is a significant event. Whenever it hears any note, it resets this clock. As soon as it resets, it starts moving again clockwise. Where it points is the neural or context representation that goes into layer one.

Is it a circular representation of time? That would imply that if enough time passes, it goes back to zero. But I'm assuming it's more like it just trails off and you get slower and slower time cells. In this example, I avoided the issue of what happens if there's no event by the time it gets back to the top. One thing we talked about last week was that as it moves forward in time, the threshold for a significant event gets lower and lower, so maybe something minor gets detected as an event and resets the clock. Or if it gets to the end, it just resets the clock. It's not really circular in the sense that once it gets here, it starts over again. To get back to zero, this is a reset. If it gets back to zero, it shouldn't really get to zero from this last point.

Let me step through the example. We hear the first note, and which note it is is the feature input to layer four. The timing since the last event is just the very first one, since this is our first event. I added this other thing down here, which is which element in the sequence we're currently in. Right now, we're in the first element. We associate the time since the last event and the feature at that first element. We move forward, no note detected yet. This is currently the input to layer one. Move to the next note, shortly before the note, this is the input to layer one. Then we hear the note, the clock gets reset, we get the feature input again, and this reset signal triggers that we move to the next element in the sequence. Now we're at the second element in the sequence. We associate the timing representation we got just before that event happened and the feature with that element in the sequence.

Again, we move in time, move forward, this is the input to layer one, move forward, now this is the input to layer one, move forward, we hear the note, reset signal, move one more forward in the sequence, associate the last temporal input we got and the feature with that element in the sequence. Same thing happens with the next note. In this case, we are sensing a different feature and associating that different feature with the same element in the sequence.

This one is the only other interesting case because it's still the same mechanism, but we're moving a bit further down the stopwatch. As time passes, the input representation to layer one changes—it gets brighter. It's a bit hard to see because I wanted to make it look aesthetically pleasing, but it's not the best to distinguish. It changes at every step until we get to the next event, which is sensing this note, which triggers a reset. We move one further in the sequence and associate the feature we get as input and the time since the last event with that element in the sequence, and that goes on.

Does that make sense? Is that how you were thinking of it last week as well?

Yeah, it's a nice animation. I think that generally fits. I think it's still an open question in my head how we associate exactly what is being associated—that time thing with the feature. This is also the most intuitive to me, but I don't know if this is what Jeff had in mind, especially if we start speeding it up or slowing it down.

So, speeding it up and slowing it down is basically this blue arrow. I shouldn't have made it blue because it's not really real time. This one can turn at different speeds on the clock, but it still goes through the same sequence of neural activations. Whatever was active at this point predicts that feature in the sequence. You can speed up or slow down this blue arrow on the clock, but it doesn't change anything in the representation here. It just changes when each of these purple features is active in layer one.

Yeah, that makes sense.

So just to make sure I'm clear on this scheme, the clock gets reset at every note touch, right?

Yeah.

At every significant event. I have another example with the stapler that covers a few more cases, which might help with understanding in a moment. Do you want to ask some questions first? Do we send back the tempo to the thalamus to do something, or does this system figure out how to predict by inferring the pace or tempo and predicting when the next step will come? Does it send something back to the thalamus so the next prediction doesn't have to be inferred every time? I'm a little confused about the template.

The idea is that this happens in the matrix cells in the thalamus, which project to layer one. The column would recognize if it gets a feature input—basically, the next feature it expects in the sequence. If that appears slightly before or after the expected neural representation, it tells whether it needs to be slowed down or sped up. If we think of these as SDRs, it would be possible to tell whether it was before or after, and that signal gets sent back to the matrix cells to adjust the clock, making it go faster or slower. This is a global clock, so it changes the neural input representation to layer one of all the other columns it projects through. It's enough for one of them to signal to be faster, slower, or reset, and that changes the global signal everywhere, synchronizing everyone. For example, detecting a significant event could be anywhere. With the stapler example, the sound of the stapler stapling can be an event. That's not represented in the morphological model of the stapler at all, but it could be detected somewhere else and still reset the global clock.

Another question: is the element in sequence a 1D grid cell? I was thinking of this as basically 1D space, and you move through that space in one direction—always forward in time. The displacement that moves you forward is the reset signal from the clock, like getting the first in sequence again. That would be the movement.

That would basically be one movement. With time, that's straightforward, but if we have actions, you might be able to move in two directions through the sequence, though I haven't thought through that much yet.

It's really hard to try to do a melody backwards in your mind or move through it. Here we don't have actions, but if you have a hinge, you can imagine opening and closing it in both directions, and maybe it's like a double sequence. You need to learn both directions, or you can go through it in those directions—I'm not sure.

For things we learn as discrete sequences, if they're long and complex, it's really hard to do them backwards. Opening and closing a stapler is extremely simple—it's just doing that. Saying the alphabet backwards is really hard, or cooking lasagna backwards would be strange. You'd have to think forward and then do it backwards step by step. It might be that you can only move through this in one direction. One thing to note is that it's also discrete, not a continuous 1D string—it's discrete elements in the sequence. Within each interval, you can have different temporal representations that tile that interval space. I'll move to the stapler example now because that shows this better.

This is an object behavior with events and continuous changes between those events. Before, there was no feature change between events—every feature corresponded to a discrete event. With moving objects, there's often a lot of continuous change, and I think this mechanism can deal with that. As I made this animation, I realized that using different shades of purple wasn't very useful, so I added colored rings around the first ones so you can distinguish them better as the current input to layer one. 

Here's a stapler, and the red-yellow circle represents the sensorimotor patch where it is currently sensing in the world. It shows where it thinks it is in the object's reference frame. This is the morphological model it has learned—where the stapler exists and what features exist at those locations, corresponding to the layer 6A locations. At the first time step, we get the first representation as input and detect a flow pattern in this direction, associating that change with the time since the last event at this element in the sequence at this location. 

Then the stapler moves a bit, we detect this change, and have a different time since the last event. We haven't detected a significant event, so no time reset yet, but since there's a different representation up here, we can still make a new association with this slightly different flow pattern. We move further, it moves down again, and again we have a different representation in layer one, so we can associate that different change pattern with this location in the behavior model. 

Then we staple, which makes a click, we detect a significant event, and it resets the clock. This reset clock signal moves us one element further in the sequence, so now we have a new reference frame at that element in the sequence—a new state. Everything can be at different locations again, and we assume we stay in the same location within that reference frame. It's still the same reference frame; it's just conditioning what features we would expect at the locations, which can change. 

The stapler opens, time passes, we get the orange representation, and the flow pattern is moving upwards. We associate that upwards pattern with this location at this time. Time passes again, and we associate this with this location in the stapler's reference frame.

That would be basically it. That's the general idea. The learned model for this kind of behavior would be that there are two states or intervals. One state has three different durations since the last event associated with it: at the event, a short duration afterwards, and a longer duration afterwards. Those are the representations in layer one that continue to change as time passes, and each has a different flow pattern associated with that location in space. Then, at a significant event, we're in a new state, and that one again has two different features associated with it, both with slightly different durations since the last event.

During inference, in addition to testing different orientations of the object, we would test different states. We would start with hypotheses of being in different states and then try to match which of those fit the features we're currently sensing. We don't have to test the different durations since the last event, since those are externally provided by the global clock. The global clock also ticks during inference, so we already get this kind of red, orange, yellow signal. It tells us which one we should expect right now—do we just do inference on these discrete intervals or states?

Is there a reason the arrows are shown superimposed rather than at different positions in the reference frame? It's all still at the same location, so the sensorimotor hasn't moved.

It's always at the same location in the reference frame. It's just that at that location, we're observing different changes at different times.

So the sensor is staying totally still? If the sensorimotor moved down here, then this yellow one would move down here, and we would associate the changes detected there with this location in the reference frame. I was thinking, because sometimes we talked about smooth pursuit, that it would create a path, but to get the input feature to change in that case—I've tried to leave smooth pursuit out of this example because last week we said we wouldn't start with that. It's complicated because there, the sensorimotor is moving and the feature is static, but we want to interpret it as the feature moving and the sensorimotor not. I thought this was the simplest example to illustrate, because it shows how at the same location you can associate different changes at different times.

One thought is just whether—I'm just trying to see what my eye is doing. Maybe when you're not doing smooth pursuit, what you probably do is a bunch of saccades that are very short, so you'd be moving and then pausing at each one, catching a glimpse of movement, and then moving again. It's not that important or relevant to the time aspect. I'm just thinking through how we represent the behavior reference frame.

Basically, if I implement this now, I wouldn't change anything about how we represent space or the reference frame here. It's still like you're at a location in the stapler's reference frame and associating changes at that location. Now there's just an additional conditioning on what changes you expect there based on the time since the last event and where in the sequence you are. If we were to do supervised learning, for example, we could move the sensorimotor as much as we want and just tell it what is currently the element in the sequence and the time since the last event. It would learn it correctly. It just gets complicated once you don't tell it that, and for it to consistently infer, but it shouldn't be that hard—it just needs to be able to detect the significant events somehow, or someone needs to detect them.

I'm trying to think of what really makes a significant feature. The way you described it here is like the sound of the click. I've been thinking about pendulums, and in that case, a significant event is when it goes to the edge and there's a moment where it's still, and then it goes into motion again. I guess this is the same kind of deal, where not only is there a point where it's at rest, but then it also reverses direction. Maybe it's the fact that you have some sort of expected motion, but then you hit a limit and have to reverse direction. Is that something we could use to qualify something as a significant state?

I was thinking about saying that the significant event is just the change of direction, but then I thought it's maybe a more interesting example if the event is detected somewhere else, just to illustrate that this clock is global and can be reset by a bunch of things. The sensorimotor itself doesn't even necessarily need to observe that event.

I like the idea of the smoothness of the prediction. It doesn't necessarily need to be reversing direction; it could be that suddenly it gets hard, or the nature of change is just different, and you can't predict based on low-level, first-order information. Then you would chunk it and say, "Okay, this is now a different kind of sequence of behavior." I think Ramy was going to say something else.

No, I was going to say I noticed the same thing as Scott—that maybe it's the key frame where the object is just staying stable, not moving. I was thinking whether that key frame is basically feeding into the behavior, like when the morphology model of the stapler recognizes the closed state. I think a bunch of things like that could be significant events. For example, if the clock moves much farther and we decrease the threshold for significant events, I could imagine events like the orientation aligning in a straight or 90-degree orientation as significant. If you see an object smoothly spinning, you might artificially set events when it's upright or sideways. These could be minor things that define events at some point. The important thing is that they're consistent events you see every time you observe that behavior, and that can then reset the clock. I also like what Neil said about the prediction error being a change—a boundary—between moving to the next element in the sequence.

It seems very plausible.

It does seem like, to the other point, when humans see any kind of repetitive behavior, you develop a pulsing representation of it, where it doesn't feel truly continuous. If it were truly continuous, you wouldn't perceive it as repeating; you'd perceive it as constantly changing. But it's the fact that you notice it's cycling, and the beat of that cycling naturally emerges in your head. It's like with a thought that spins on a circle—when it laps, you know when it starts repeating again. If you look at a fire or the ocean, there isn't really a point where you say, "Now it starts over again," unless you watch one of those YouTube videos with smooth jazz in the background. Fire is a good example of something that doesn't feel cyclical at all.

Going back to the time cell idea, when I was thinking about the pendulum during this last presentation, if we imagine the ball starts at one end, you start the clock and it goes like this. Let's forget the right side for now. The time cell is clicking down, and eventually, when we get back to the beginning, if this system had learned the association with that early time cell, the state is now saying, "I was already associated with the time cell at the beginning of the sequence." Now we can restart the sequence because I've developed an association between what the time cell is and what this morphological state is. That time cell was an early sequence time cell. That's what I was thinking about for detecting cyclical patterns.

That's a really great point. If this cell down here sees a free feature at the beginning of the interval, it changes, and then it sees the same feature again—that's the signal that it's back at the beginning, right? That's your reset, like a cyclical reset signal. I like that. That might be the easiest mechanism, actually.

Is that, events signal, reset a vote?

No. I don't think voting would play too much into this because this is a global clock, already broadcasting widely everywhere. We wouldn't need voting anymore for significant event detection. We would still do voting on which object we're sensing or maybe where we are in the sequence, but we wouldn't vote about whether the event has reset or not.

When we see a sequence like A, B, C, D, A, D, or Abhi—like a sequence that has a repetition of A, but it's not really cyclic, it doesn't repeat the same thing—the second A should not be bound to the first element in the sequence. It needs to recognize that the sequence is A, B, C, D, A, D, not A, B, C, D, A, B, C, D, A, B, C, D. It's a higher order. In that case, each letter would be one of the elements in the sequence. The reset I was thinking of was what triggers moving one forward in the sequence. In your example, each letter would trigger moving one forward, but it doesn't solve knowing when the whole sequence restarts. It just solves, if we only have continuous change within one of those intervals, how do we know when that starts over? The event stuff plays into this quite a lot.

If we have a continuous stream of A, B, C, A, D, F, or whatever—a higher order sequence—with no rest period in between, it's quite hard to learn that higher order sequence. But if there was A, B, C, A, D, F, break, A, B, C, A, D, F, then that break gives us an indication that the first A is the beginning of an order sequence. It's a significant event. So that second A, when we come across it, maybe we would associate it with a—eh, I feel like it helps somehow, but I'm not sure. Even with music, you often play the first note a bit louder, with more attack, or you have a beat in the background that tells you the four-by-four rhythm starts over again.

I could imagine a threshold—like you were saying, Viviane, earlier—maybe that gets lower as the sequence gets longer, but you have some threshold for saying, "Okay, the sequence is repeated." With a challenging sequence like that, it might be a bit of trial and error where you're trying to predict what's happening and you might not initially know where that repetition happens.

I can almost imagine this—if you were reading a genetic sequence, you might not initially reset at all, but at certain points, you might question if there's a reset, update your hypothesis about where that reset point is, and continue. You could tune that point to align with the data, similar to watching a pendulum swing: at first, you don't know when it will stop and change direction, but as you observe, you adjust your understanding. HTM solved the higher-order sequence problem, so it could correctly handle sequences like A, B, C, A, D, F, but I don't think it treats the second A as the same as the first A because of context. It doesn't resolve how to unsupervisedly detect the start of a sequence versus the continuation of a longer sequence. We could augment that logic—rather than treating them as completely independent identities, there's an SDR for the first A and an SDR for the second A. They may be similar, but when resetting a clock, the similarity is tricky. Representing the same feature differently is solved by having the reference frame down here and moving through the sequence, so although the same letter A might appear, it would be in a different element of the sequence and predict a different next element. But as Neil said, it doesn't solve figuring out whether the A is in the middle or restarting.

Revisiting the warning paper from last week, in lab studies with sequences like A, B, C, D separated by a gray screen versus running without a gray screen, it's actually quite hard for mice to show the kind of prediction errors you get without the gray screen. Having a reset teaching signal or a clear event indicating the beginning has a large impact on whether prediction error signals emerge. That fits perfectly with this idea. Let me find the paper.

By the way, the time cells Scott mentioned last week had finer resolution at shorter intervals, which could be integrated here by putting more neurons at the beginning and fewer towards the end. There wouldn't need to be any change in the learning module—just higher resolution at the start, changing more frequently, to represent more detailed differences.

Let me put this in the chat. If you go to figure two, it shows—if you want to share your screen, I stopped sharing.

So, this one: oddball evoked responses. B1. Oh, look who the first author is. Here's one showing with and without gray. You have A, B, C, D, A, C, D, A, B, C, D with gray, A, B, C with gray. These are comparisons of the responses. You don't have to worry about OSG or RPG, the different stimulus types, but the deviations from the 2014 warning paper are quite different when you don't have intermediate gray screens to indicate stimulus or sequence onset. This matches what Niels has been saying about prediction error—every time there's gray, you're always learning the prediction from D to A or D to gray to A. It's not about prediction error per se. Does the gray period change, or is it always the same, like a second? With the gray, there's better prediction; they understand the sequence better. Without the gray period, it's like Markov chain learning—just learning transition probabilities between sequences, which is harder to do automatically than if you have something to set the clock at the beginning. That's why, when going over the clock, it feels like the clock is set at the first note, then we tick along and learn the notes until there's a rest period to reset the event clock. I wonder if it could be both—both are useful. In the same way we have different spaces for objects, we might have different time starts. This is interesting because the issue is that the animal needs to infer that D is the end of the sequence, but it has very little signal for that.

But, sorry. Blue, just to interpret it—blue is high firing rate because of a high prediction error in the continuous case we're talking about here? I'm just trying to see, of the traces, what's compared with what, or what should I be looking at? Different days. There's a five-day learning regime, so we're not looking at prediction here; we're looking at the amount of adaptation over days in this particular case. When we say "day" in the continuous case, blue-green is day one, blue is day five. It is saying that there isn't much difference across days when you don't get a teaching signal on the gray. But when you do get a gray signal in between, the day one responses are small, but they grow quite significantly after multiple days of exposure. It's thought that this kind of adaptation, the kind of learning you get from having this gray signal, is what helps drive the dictionary signals you see in the 2014 paper. They just don't seem to emerge as robustly when you don't have that gray signal, when you try to learn four days of non-continuous sequences.

That's cool. That's really fitting.

I have to remember what went into this. There's a lot of timing-related stuff in this paper as well, if you're interested in that kind of thing. That was everything.