Jeff Hawkins: I'm going to talk about two things. First, I'll discuss our mission again. Vivian covered this a bit, but I'll give you my perspective. Then, I want to provide a high-level overview of our goals. You've heard a lot of details in these presentations and about the amazing work happening in the system, but sometimes it's helpful to step back and look at the big picture.

Let's start with the Thousand Brains Project's mission. It all begins here. Vivian mentioned this: it can be summed up in one sentence—we're creating machine intelligence technology based on neocortical principles. There's a lot in that sentence, and I want to unpack it. I prefer the term "machine intelligence" over "artificial intelligence." To me, today's AI isn't truly intelligent. That doesn't mean it's not useful or impressive, but it's not the real thing. We're trying to create the real thing here, something we can all agree on. We're building machines that work the same way biological intelligence works.

We're really focused on building technology, not applications or businesses. It reminds me of the 1940s, when the pioneers of computing established the technology framework for computing, which has lasted for decades and continues today. I think we're doing something similar—building the fundamental technology and theory behind intelligent systems. We're using neocortical principles, and we're only able to do this because we've spent decades understanding how the brain works. That's our goal and our mission.

I'll remind you of the top principles involved. My top three principles are that these systems are sensorimotor. They have sensors that sense the world; we're not feeding them abstract data. The sensors move through the world, so motion is involved. Sensorimotor integration is used for learning, inference, and problem-solving. It's not an add-on; every learning module has a motor output. The whole system is sensorimotor.

One thing people often don't appreciate is that when you learn this way, you have structured models. You heard about reference frames. Everything processed in the brain and in Monty is not only what it is, but where it is—meaning pose, location, and orientation. That's how knowledge is structured in your brain and in Monty. This provides amazing abilities to manipulate knowledge, rotate things, and navigate through reference frames or structured spaces to solve problems. This is key to the system's strength.

It's a highly distributed architecture, and the learning module is very powerful. The systems become powerful because the same learning modules can be applied to different modalities and parts of the hierarchy, allowing us to build systems with different sensory modalities, embodiments, and capabilities. It's an incredibly modular system that nature discovered, and we're trying to replicate it.

You've heard about some of these attributes, like continuous learning, which is extremely important. To solve real-world problems, a system must learn moment to moment what the current reality is—where things are, what's happening, who is present, and what has changed recently. The system must be able to do these things, and it also features super low power and minimal training.

Our goals for 2026 are broad, and you've heard about all of them today. These are also our goals for 2025. First, we need to expand our community. We're eight people full-time, which is very small. What we're building will be much larger than any one company or organization can manage. We need more people involved and excited. Will gave a good introduction on how to get involved. If nothing else, tell people about the Thousand Brains Project—we think that's important.

You heard from Tristan about the need to build a platform, which is essential. I spend most of my time, and some of the research team does too, adding capabilities. I used to say "research," but now I say "add capabilities" because the number of things we need to research is decreasing. There aren't many big things left to figure out, and we're moving more into implementation.

We've done a lot of work on compositional models—how objects are structured from other objects. We understand that and are implementing it, and it should be fully integrated into Monty this year. Last year, we learned how the same learning modules can learn the behavioral dynamics of the world—how things change. The world isn't static, but fortunately, we didn't need new algorithms for that. It was a simple switch in the inputs to the learning modules. Now we have models of behaviors and how things are expected to change over time.

Once you have those two things—the static structure of the world and the dynamic structure—you can start approaching goal-oriented behaviors, like using behaviors to manipulate the world to reach various states. This is all coming together. I don't expect we'll have all of this implemented this year, but by the end of the year, our goal is to have a solid theory of goal-oriented behaviors and understand causality. Perhaps in 2027, we'll complete the whole thing.

I want to emphasize that there aren't many major things left to do. The beginning of this project was slow for years, but now things are moving quickly because we have the pieces in place. Now it's about reconfiguring components and adding new things. It's an exciting time for this endeavor.And with that, I want to thank those listening live today, those listening online later, and everyone who has contributed to the project so far. We talk about you all the time and truly appreciate your efforts. Now, I'll leave it here, and we'll move on to the Q&A, which I believe Will is going to moderate.