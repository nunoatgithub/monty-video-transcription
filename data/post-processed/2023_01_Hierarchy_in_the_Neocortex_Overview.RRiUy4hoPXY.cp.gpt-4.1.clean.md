As interactive as we can make it, the better. I'm going to talk about this from a biological point of view—the neuroarchitecture—and how that can inform decisions. I'm not going to discuss it from a Monty perspective specifically, but I think it might be helpful for people to see or at least understand some of the concepts if they're not obvious or you haven't been exposed to them before.

I'm not sure where everyone's mindset is about hierarchy, so let me just jump right into it. I'll do this verbally, and please interrupt me if you have any questions. That would be much better than me just talking. When we talk about hierarchy in the neocortex, this comes from two basic techniques or endeavors. One is anatomical evidence—how neurons are connected, what connects to what, the physical structure of the brain. Those connections define a hierarchy. The other way is from a physiological point of view—how the cells respond. You show an image or a sound, and you can look at different cells in the brain and see that they're not responding the same way. How they respond and the types of responses they make is also evidence of hierarchy. Anatomy and physiology together are the basic means by which we understand the hierarchical structure of cortex. There are very few theories about how this actually works in detail, and I think we have some of the best.

There's a lot of data—huge amounts of empirical data on anatomy and physiology. I've said this many times: you would be blown away by how many papers there are, the details, and how hard they are to read. But there's so much data. Maybe we can start off with the idea that hierarchy really got kicked into gear with the famous 1992 paper by Felleman and Van Essen, which we talk about a lot. Maybe I could show you that paper unless there are any questions before we get into that.

Okay, I need to share my screen. I'll do that by hitting the share screen button. I want to add something to what you said. First, I echo how difficult it is to really understand hierarchy in depth, but also, in parallel, it's surprising how many people have a very narrow view of hierarchy in the literature. They think it's just one thing, often based on the Felleman and Van Essen paper, and they don't consider all the other evidence that's out there. It's quite remarkable how much, and almost no one seems to understand these few really important things about it that 90% of people don't consider. 

From a computational viewpoint, the idea of hierarchy for object recognition—work from Jim DiCarlo and my group—is very dominant and focused on just recognizing objects. All that results in is, for example, cat versus dog, and that's the extent of your representation and how not rich it is. There's very little thought about what the dog looks like or any richer understanding of what a dog is. You just separate them in a high-dimensional space, and that's what it's for. He and others also have lots of actual empirical data, so any other view has to be somewhat compatible with that data and also explain it.

This is the Felleman and Van Essen paper, which is very famous. It's quite long and contains a lot of data. What they did was collect a whole bunch of studies, mostly about the macaque monkey. These were primarily anatomical studies, where, for example, they would inject a dye in one part of the neocortex to see where that part projects. An anterograde dye would show where it projects to, while a retrograde dye would show what parts of the cortex project to it. There are many different techniques for this, and I'm not going to go through them all. The data in this paper comes from different monkeys of various ages, using different techniques, preparations, and methods. They're trying to bring together a lot of disparate information.

This is a picture of a monkey's neocortex, flattened out. These are all different regions in the cortex. These regions are not obvious just by looking at the cortex; they are determined through various anatomical and physiological techniques. For example, this is V1, which is the primary visual cortex, and so on. They identified all these regions and then asked how to determine how they're connected. There is a lot of data about these studies that we won't go into, but here's the basic technique: these are cartoon images of a piece of cortex, showing upper, middle, and lower layers. They look at two regions and see how they're connected—specifically, which cells in one region connect to which cells in another. It's different for each connection; it's not all the same. This asymmetry defines what is going up the hierarchy and what is going down. This is how they built their map.

For example, some cells in the middle layers of one region project forward to lower and upper regions. Other cells in another region, in the upper and lower layers, project differently. These connections are not all identical. They can say that a certain set of connections are ascending, meaning they go forward in processing. Some connections are lateral, meaning they don't seem to be forward or backward; in these cases, the same cells project to the same cells, so there's no asymmetry. Some connections between regions are descending, with a different connectivity profile than the ascending or lateral ones. It's a very difficult study to do, but this is the basic method by which they determine if something is hierarchically higher or lower than another region, based on these types of connections. For example, V1 and V2 are connected in both directions, but projections from V1 to V2, considered ascending, look different from projections from V2 to V1, which are descending. In some cases, projections are similar both ways, and those are called lateral projections. That's the basic method. Are there any questions about that?

Okay, we'll move on. The conclusion of all this, jumping to the bottom, is that all the studies and data resulted in this famous diagram.

This diagram shows just the visual parts of the monkey. At the very bottom is the retina, with retinal ganglion cells. Then comes the LGN, which we'll discuss in a minute. Then it goes to V1, V2, and so on. The point of this diagram is to show the hierarchy, but many of the boxes are just white for some reason. There are regions like LIP and 7A, and several dozen others. They tried to figure out which regions are hierarchically above or below others, resulting in different layers of the hierarchy. There's one layer here, another layer above, and so on. At the very top, it projects to the entorhinal cortex in the hippocampus, where grid cells and momentary memory are studied.

As we've pointed out before, this is just a wiring diagram, and there are many surprising things about it. First, it's highly connected—many regions connect to many others. It's not a simple flow chart. Many regions at the same level connect to each other or don't, but they're still at the same level. About 40% of all connectivity between regions exists in this picture, making it complicated. It doesn't look like a strict hierarchy; information is flowing all over the place. The idea that information is processed step by step through a series of regions is true if you look at those specific series, but there are also many connections that skip steps. V1 doesn't just project to V2; it also projects to V4, MT, and other regions. So, I never quite believed in a strict hierarchical processing model. It's much messier than that. Different animals have different sets of regions and arrangements, and it all seems to work.

If you remove or damage one of these regions, the animal might have some deficit, but the whole system doesn't fall apart. They can still do various things. This was just seen as a hierarchy, like a flow chart, and it became dogma. But it's interesting because even in their abstract, they state that about 40% of all possible connections actually exist, which really contradicts the idea of a strict feedforward hierarchy.

As Neil pointed out, this analysis is almost always done in vision. Most of the physiology is vision-based, especially in monkeys, and the studies rarely consider motor behavior. Many early studies were conducted with anesthetized animals that couldn't move their eyes or think, and were shown abstract patterns that weren't meaningful to them, even if they were awake. Researchers then tried to figure out how cells responded in different regions. While research has progressed since then, there's a long history of focusing on image recognition—like distinguishing a dog from a cat—rather than real vision, where eyes and bodies move in the world.

Let me contrast this with an alternate view. We've been fans of two scientists, Murray Sherman and Ray Guillery. Guillery died a few years ago, but for many years, they promoted two big ideas about cortical organization that are missing from the Felleman and Van Essen model. Speaking personally to Murray Sherman, he found it frustrating that his ideas were never widely adopted, though many people know them. It's clear to me that they're onto something important.

Let's look at a diagram we've used before. It's still about hierarchy, but it's a slightly different view. Sherman and Guillery don't deny the existence of a hierarchy, but they propose two major differences. At the top of the diagram, there are three blue boxes representing cortical regions, like V1, V2, and V4. The classic view shows information flowing from the retina through the optic nerve, then through the thalamus—specifically the lateral geniculate nucleus (LGN)—and then to the first cortical region, V1. From there, it projects to the next blue region, and so on, as shown by Felleman and Van Essen.

I pointed out that from the retina, the signal goes to the thalamus, to relay cells, and then is processed in the cortex. Sherman and Guillery argued for an alternate pathway between cortical regions, which they believe exists everywhere. This is shown in the diagram as pink circles—other regions of the thalamus, labeled as first order and higher order. These thalamic regions also have relay cells, but unlike the first order relay cells, they don't get direct input from the eye. Instead, they receive input from a cortical region. For example, a cell in layer five projects down to a thalamic relay cell, which then projects up to another cortical region. This region also has a layer five cell that projects to another thalamic relay cell, which then projects to the next cortical region. This forms an indirect pathway: cortical-thalamic-cortical-thalamic-cortical.

These higher order relay cells look very similar to the first order relay cells. Sherman and Guillery argued that this alternate pathway is not only present but is the dominant and most important pathway. The most important connections are not the direct cortex-to-cortex ones, but those that go from cortex to thalamus to cortex. These cells are larger, and the pathway from the retina projects to layer four, similar to how the higher order relay projects to the next region.

Their first major proposal is that there is at least one alternate pathway in the cortex defining the hierarchy, which wasn't mentioned in the Felleman and Van Essen paper. They argue this pathway is more important than the direct cortical connections. I think I now understand why, after much consideration and discussion. If there's a coordinate or orientation transform—say, an input from the retina, like a movement vector or a sensory pattern—it must be rotated to match the object in the cortex. The cortex tells the thalamic region what transformation to perform. The output of this region goes to another region, which must do the same thing. For example, if an edge comes from the eye and now we have the rim of a cup, the rim must be oriented to the body of the cup.

This is the first major proposal: an alternate, major pathway exists everywhere in the cortex and should be considered when defining the hierarchy. The thalamus is essential to the hierarchical structure of the cortex, not just an add-on. In our view, the thalamus could be involved in voting among cortical projections. If these regions are all looking at the same object, it turns out they're not just processing sub-objects.We're looking at the same objects and proceeding with the same option. You want to be able to vote on them, which is important. If there were a hierarchical structure—such as one region looking at a letter and another at a word—you would want to run through this pathway and encode or handle the orientation difference between these two sub-objects and pose. I know that's a lot to absorb at once, but that's the idea.

I'll move on to the second topic they discussed. When you say that with the hierarchical connection, it should probably go through the thalamic connection, could it be that the cortical connection still transmits feature information and only the pose information goes through the thalamus? Yes, it could be.

It could be.

In fact, I think that's—well, the pose has to—the feature has to be changed to match the pose. If I'm building a model in these blue boxes, I have to take the current pose of the feature and turn it into the form of the object itself. I think it's a good question, Vivian. We don't really know. This is where theory can really help us. We're not going to get answers to questions like that from the neuroscience literature. Where we can get answers is by defining very clear problems that we know the cortex has to solve, like hierarchical modeling or compositional structure, and then asking what the absolute requirements are to do that, and where those things could occur. It's a good question, and I think theory can help us answer it. When you say pose, does that include scale? No one will talk about any of those things in this literature. That's a question for Vivian. I think scale is handled differently, but maybe other people think differently.

Again, in neuroscience, we can address this independently of the neuroscience or by dipping back into the neurosciences. When I say I think the thalamus could be doing this or not, you might have a better image in your mind of what I'm talking about.

One of the arguments they make is that this pathway from the relay cell into cortex is much stronger than the cortico-cortical pathway. What you're saying is true. We have to have a model that says feature information can be more like context or weaker than the actual pose information. Right now, the matching is such that we can recognize the morphology independently. Features can just add evidence, like color just adds evidence, but it doesn't subtract evidence. Morphology is crucial. That's a good insight. Another question I have is that here they make the distinction between first order and higher order thalamus. Is there also a distinction in functionality?

If you look at the anatomy and physiology of the cells, there isn't a distinction; it's very similar. Of course, what the cells respond to is different. This same organization exists for somatosensory or touch and hearing. There are a lot of thalamic relay centers, and a lot of those higher order centers. The cells in them are going to respond to different types of sensory input, and higher up, the more conceptual or object-like responses you get in these cells. They won't have the exact same cell responses, but they're basically doing the same thing. It's hard to imagine that these high order relay centers are not performing the same function, just on different data.

Is there evidence on how localized the projections are? The thalamus is a fairly small structure compared to the cortex, and if you have all these relay cells, presumably you don't have enough of them to have a one-to-one mapping. Is there a possibility that these connections are more coarse, broad-spectrum influence? Actually, it's just the opposite.

The projections to the thalamus and the projections back from the thalamus are very constrained. They don't spread broadly at all, and that's why they're called relay cells. Imagine this is the optic nerve, this green line here. There's about a million fibers on the optic nerve and about a million relay cells leaving the thalamus. It looks as if a single spike coming on one of these axons from the eye produces a spike on one of the relay cells leaving. This gets to your point that these are constrained numbers. You may think a million is a lot, but there are a lot more cells up here. This connection from layer six back to the thalamus is about 10 million cells. In this particular case, it's roughly 10 to one. This is more diffuse, encoding some sort of more complex signal, which I'm arguing is like a pose signal, whereas the other is just relaying it through. The numbers work out so that even though these thalamic relay centers are small, they're large enough to handle all the cells projecting to and from layer five. Every one of these layer five cells—there are two types, but the ones we're talking about here—projects down to a relay cell, and then that projects up to the next one, and so on. These are very precise connections. It's not a diffuse thing, and you don't see any mixing. You don't see the first order thalamus projecting elsewhere.

It gets more nuanced than this. Even though there's a one-to-one correspondence going through, if you look at the cells from the retina—this is true for other sensory systems as well, like touch and hearing—there seems to be a single cell that responds, that relay cell. But this axon doesn't make connections to just one relay cell; it makes connections to a bunch of them, not a huge number—maybe 15 to 30, somewhere in that range. The connections made from a single axon to these 20 or 30 relay cells look identical. There's a special type of synapse; it looks very unique. It's as if this axon is connecting to 20 relay cells, but only one relay cell is doing anything and the others are silent.

Clearly, the connection is there for them to affect those others. I found a paper on that. What's going on here? It's doing a relay function, but somehow it seems like it could be doing it to any 20 or 30 cells. This researcher, Carmen—Carmen Ella, I think—

We concluded that each of these cells could act as a multiplexer—the signal coming back from the cortex could indicate which relay cell this input should be routed to. It doesn't; one gets active, and when you do studies with anesthetized animals, that will never change. Only one will be active, and the other connections will be inactive, but it looks like the other connections could be inactive as well. We propose that this is doing routing, taking this input and routing it to different outputs, which would allow you to map a pattern to another pattern, as with an orientation change.

These are very strong axons. They make important synapses on the layer four cells where they project, and the other cells they project to. In contrast, the direct cortical connections seem weaker. There are a lot of them, but they're clearly encoding some spatial code, like the sparse distributed representation. Sherman and Guillery call these "drivers." These axons are strong and will make cells fire here. The connections between cortical regions directly don't seem strong enough to make things fire; they're weaker. That would be perfect for a voting mechanism or any kind of prediction where you're depolarizing cells. Their argument is that this is the strong connection.

If you believe in the canonical circuit from Vernon Mountcastle—that all cortical columns are the same—then the Sherman and Guillery view makes a lot of sense. The cortex, with its regional cortex and associated thalamic relay cells, is the unit. If you're going to do it on the first input to the brain, why wouldn't you do it on the next input, and the next, and the next? The actual cortical column, in some sense, would incorporate both of these things as part of its circuitry. Now you have a parallel architecture all the way around, everywhere in the cortex. It looks like this everywhere they've looked.

The other big thing here, which is puzzling at first, is that these cells in layer five that do the feedforward also split. You see the split right here—they divide in two, and the other half goes down and generates the motor behavior. In the visual system, this would be the part of the old brain called the superior colliculus, which actually moves the eyes.

Other parts of the cortex always project to something else that would move or change the input to this region. In some sense, each cortical region has a motor output, which changes what it receives.

Are those two separate neuron populations? Is it the same signal that goes to the thalamus? It's exactly the same. It's the same cell. Imagine this: one cell has an axon that splits into two parts, with one part going here and one part going there. It's the exact same signal. People refer to this as a corollary discharge or efference copy—it's literally that.

When the eye is sending information to the cortex, it's sending two types of signals: the pattern it's seeing, like a patch of retina, and a signal representing how the retina is moving, which is detected by the retina. There are two things passing through here, and they're separated. There are multiple sets of relay cells associated with this first-order relay; some represent parts of the retina detecting motion, and some represent parts detecting features. Both motion and features go through this, and both have to be converted to the proper orientation so you know how it's moving relative to the object.

If there's a motion signal going through the thalamus, the same thing will happen here. If this region is outputting, don't think of it as just a motor output—it's going back and has to tell the next region up how it's planning on moving the world, or the retina. This is the motion signal. It needs to tell the next region, "I'm moving the retina to the left by four degrees," for example. It has to tell the motor system to do that and also inform the next region up that it's about to move the motor system by four degrees.

There's something else going on that's not shown in this picture. This is the part of the brain that moves the eyes, and it gets direct input from the eyes themselves. The ganglion cell axon from the retina splits—one branch goes up to the thalamus, whether it's representing sensation or movement, and the other branch goes over here. This is the part that actually moves the eye; the cells here make the eyes move. It's possible that input from the eyes themselves can make your eyes move. If there's a flash of light in the corner of your eye, your eyes will automatically move over to it. You don't have to think about it; it just happens.

Now, what's not shown in this picture is that the cells that actually generate the motor behavior here also split. They show it right here—you see the split right here, and they show it going up here. But it happens everywhere. So it actually would come out; this is the actual motor behavior that's being generated. This is the actual behavior. This is like a request for behavior; this is the actual behavior. These split and go to each of these thalamic relay cells. If I were to look at what's coming into the thalamus here, the LGN, the first-order thalamus provision, I've got two types of signals from the eye: what's sensed and how the eye is moving, detected by the sensor. But I also get the efference copy directly from the superior colliculus, which comes over here and also goes to this first thalamus. So there are two sources of movement behavior. One is coming from what's detected by the eye—the eye says, "I'm moving, things are flowing across the retina." The other says, "I'm about to move the eye; I'm sending a command to move the eye." You get that earlier than the actual detection of the movement. But these are all segregated and kept separate as they move through the relay, and then they're all processed in the same way.

The idea here is that you could have a motor command generated by the motor system, or by some other cortex, or detected by the sensory system. There are different ways the brain can know how the eyes are moving or about to move, but in all cases, they go through these thalamic relay cells. My point is that it's true for these relay cells as well: it's not just this cell coming down into it now, it's also getting input from the motor system, which is also going to the higher-order thalamic relay. So there's either an internally generated motor command or one coming from the motor system itself, all being passed through separate relay cells, all converted through this feedback from the cortex.

This does not explain a bit of a mystery: is there a sensory feature being passed through the thalamus here, the higher-order thalamus? Remember, if I detect an edge in my retina, that's going to go through this first sort of thalamus. There's not a clear pathway for how that would get down to here and back up. So it's possible that maybe just the motor command has to be transferred through this, and the direct connections are representing features, like this detected handle, and this is the coffee cup that goes directly. But maybe the motor behavior, which represents some orientation—I don't really understand all of it. I have more clarity on it, but not completely.

The diagram we think about when we consider hierarchy in the cortex from an anatomy and functional point of view—from a Monty perspective, we can walk away with a couple of things. Every region, every learning module, has to be processing sensory data and motor data. The motor data could come from different sources, whether it's coming from a motor system, a sensory system, or some internally generated motor behavior. This layer, this cell here, could be telling this region what it's planning on moving. That's something that has to occur. There's clearly some sort of transform going on between learning modules. In this case, the learning module is doing some sort of transform on the sensation and the movement command, and it's doing them separately—meaning they're separate cells, even though they're all getting the same command. It's like saying, "I'm going to change the orientation of the movement, and I'm going to change the orientation of my sensation," or something like that. We have to be aware of that.

When we think about hierarchy, there's a mystery we have to resolve: how does motor behavior operate in a hierarchy? Maybe some of you have already thought about that, but it's not clear to me what's going on from here to here, and from here to here. How does that make sense from a hierarchical point of view? The one that says we're about to move is pretty critical because it allows you to predict what you're going to see and then go on from there. That's how I think everyone viewed that. It was a significant realization for me about five years ago that the retina itself is also telling you how it actually is moving, which is not as good. The reason you pointed out is that's after the fact—the retina says, "Hey, I moved," as opposed to this signal that tells you you're about to move. As you point out, with this one you can predict, and with the other, it's "whoops, you moved." The reason is that this is ground truth—the eye can tell you how it's actually moving.

These cells here, which may actually move the eye and project up to this region of the cortex—how is this region of cortex supposed to know how to interpret these movements? It's just a bunch of fibers coming in. All these things change over your lifetime; they're learning, changing, and modifying. There isn't a genetically determined motor plan that says these cells mean X, Y, and Z. This region is getting these motor signals, but it doesn't necessarily know how to interpret them. I think what's going on is that the input from the retina says, "The retina has just moved; it's moving at this speed to the right." That's being projected up here, as well as the actual motor signal that generated the movement, also projected up here. Now you have a training signal, so the cortex can say, "I know how to interpret this signal now. This is the ground truth; this is the thing that generated the ground truth. Now I can learn how to interpret this signal coming from here." I'm pretty certain that's what's going on. I bet we might even be able to find some papers, hidden in the archives, that talk about the physiology of the cells and how they might do that. But that's how I think it's going on.

Is that motor output going to the next higher-order area, or does it go back into the same region that generated it? That's a great question. I don't know the answer to that. That's probably available somewhere. The question is, here you've got these cells—this is not just a blob of cells in the thalamus; it also has a laminar structure and different parts project to different parts of the cortex.

I was under the impression, though I might be mistaken, that it just projects back to here, but it's possible it could project forward as well. How is that synchronized? Is it sequential or parallel? The classic view is that it's all sequential: information comes in here, then goes to the next region, and so on. However, there are some real holes in that view. Not shown on this diagram, another confusion is that some cells from the retina go directly to higher-order regions, skipping intermediate steps. They may go to both, but there are direct connections from the retina to multiple regions, possibly three or four in a row. So, it's not true that the retina only projects to V1.

Another point is that sometimes the response in the second blue region can occur before the response in the first blue region. They can even get that response when the first region is frozen and can't operate. This shows that the sequential view is not accurate; there is parallel processing to some extent. These upper regions can respond quicker than the lower regions under certain conditions. The Thousand Brains Theory addresses this by proposing that each blue region can learn objects, but at different scales. For example, a patch of V1 receives input from a small part of the retina, V2 from a larger area, and V4 from an even larger area. These regions could be modeling similar objects at different scales. V1 looks at a tiny part of the visual field, V2 at a larger part, and so on. There are also connections from higher to lower regions, such as from V4 to V2 to V1, often projecting to the upper layer. The general belief is that these backward projections bias the lower region, suggesting what should be seen there. For example, the upper region might indicate that, given the current input, a handle or logo should be present. Recognition can occur in multiple regions at once, and sometimes upper regions respond before lower ones.

If I were looking at a large object, like a big picture of a coffee cup, V1 might not be very helpful because it only sees fine detail, which isn't useful for larger objects. Object recognition could occur primarily in higher regions.

You mentioned that direct connections between cortical regions might be involved in voting. Would it make sense for different hierarchical regions to vote, or is it more logical for similar regions to vote? There are multiple cell populations projecting forward and backward, and voting could make sense. For example, if an object is recognizable by both V1 and V2 because it's small enough for both, they could vote. There are connections, not shown here, that go from layer two to layer two and layer three to layer three, which could support voting.

This would make sense if they're perceiving the same object, which is often the case when there's only one thing to look at. Other connections are more hierarchical, such as layer three cells projecting to layer four, as described in the Feldman and Senn paper. That's a hierarchical connection, while layer two to layer two is not. Layer two to layer two could be voting, and layer three to layer four would be more about hierarchical composition, like identifying a logo on a coffee cup. All these processes can occur simultaneously or in combination.

The way I approach this is by considering what a region or learning module must do to learn, and then reasoning about how to explain the different types of connections. Layer two to layer two could be explained by voting, and layer three to layer four by hierarchical composition. But I always start with the need to learn objects, their behaviors, and their composition.

I know this isn't concise or easy, but this figure is actually very helpful. There's nothing in it that contradicts what we're doing. It's a nice overview. I didn't discuss the physiology much here, but it's worth mentioning that as you probe cells higher in the hierarchy, you find cells that respond to more conceptual objects.

They don't find cells that respond to coffee cups down here. They only find cells that respond to edges, but they might find a cell somewhere four levels up that responds to coffee cups. Whatever you detect here is going to be on a very local area of the retina, and what you detect higher up tends to be over much larger areas of the retina. You might argue this goes against the Thousand Brains Theory, but the theory says that what this lower region is recognizing is not just an edge at some location on the retina—it's doing sensorimotor integration. It's tracking the movement of the retina over time, and because it can track it over time, it can learn an object representation down here, composed of edges at different locations. The way they do the physiology and test these cells, they would never see that. They just wouldn't see it; they would miss it completely. When they look at the cells in these regions, they can only make sense of about 40% of them. About 60% of the cells, they have no clue what they're doing. They can't get them to respond in a way that makes sense, so they just ignore them. It's very clear to me that even a low-level region like this could be learning a more complex object. The reason you might find a face cell or a cup cell in a higher region is that the output of the lower region has already recognized an object like a cup, and that is now the input to the next region. It's not that the next region is recognizing the cup; the next region is getting an input that is a cup. So they say, "Hey, look, there are cup cells up here." That's because a cup has already been recognized in a lower region. You wouldn't find a cup cell here; you'd find a sparse distributed representation in V1 that represents cups, but not a single cell that seems to be a cup. You could look at a sparse pattern and decode it as a cup. Once you start moving and feed that sparse distributed representation into layer four, you start getting representations of things like cells that do represent cups because of the spatial pool that turns them into that. There's a lot of physiology where people argue that V1 could never recognize an object because they don't see any cells that do that, but it's because they don't know how to look for them. They're missing it. There's a lot of physiology as you go up the hierarchy; you find more and more complex objects over larger parts of the receptive field, but none of that's inconsistent with what we're doing or the Thousand Brains Theory as far as I'm concerned.

I'm just curious about that motor output box. Is there also hierarchy in that box, or is it a many-to-one mapping to this one motor output region? I don't know if there's any hierarchy. If you look at the pre-calculus, which I've read the most papers on, it has a very specific architecture. There are cells arranged in a layer that represent how far the eye will move if you innervate that cell. If you innervate one cell, the eye might move 30 degrees in one direction; if you innervate another cell, it might move 20 degrees in a different direction. There's order and structure in it, there are layers, but I don't think the layers are hierarchical. I might be wrong about that; I'd have to check, but there's certainly nothing like the hierarchy you see in the cortex. It's a fairly small organ.

There are equivalent ones for different sensory modalities, but I don't believe there's a clear hierarchical organization to it. There is a lot of organization; it's not just a blob. There are many papers on it, and we could probably search quickly and find out if there's any sort of hierarchical representation. I'm not sure.

That's good to know. As a follow-up, the eye is a relatively simple thing to move. Do we know anything about how the structure of that motor box changes when it's moving a multi-joint thing? We, in the royal sense, do. Me, as Jeff, no. I started reading a book that Vernon Mountcastle wrote about the hand. I started reading it yesterday. It's a big book, about a thousand pages, and I was searching through it for information on that very topic. It's really complicated. I gave up, and my arm was hurting, so I stopped. There are answers to that. If we want to know, we can dig in and find lots of papers that talk about what happens in the somatic sensory system when these layer five cells project down to some part of the spinal cord or whatever.

I don't know the answer to that question. It's a really good question. Obviously, the eyes all move at once; you can't move part of the eye. You have two eyes, so you can move them somewhat separately, but you can't move part of the retina separately from another part, whereas you can do that with your fingers. That's a good observation and something we have to be aware of. I always think of it as a layer five cell trying to say, "Here's how I want my patch to move." It doesn't know about anybody else's; it's just saying, "My input, this is how I want my input to move."

From a computational point of view, you could argue it's hierarchical. There's evidence that if you stimulate a certain part of the motor cortex, you can initiate a complex movement, which seems to be a series of similar movements. You might just get a simple movement, but I'm not sure how that maps onto anatomy. I think you're making the theoretical argument that, especially in the somatomotor system where limbs and fingers can move independently, there must be some sort of hierarchical representation that's subcortical. I believe there are studies showing that if you stimulate a particular part of a monkey's brain, it will make a grasping motion, and if you stimulate a different part, you'll get a finger twitch. You can break that down into a hierarchy of complexity.

There's another part of the brain called the cerebellum, which has the most neurons of any part of the brain. It's not as big as the cortex, but it has more cells. The cerebellum is related to fine motor commands and has a lot to do with executing fine motor skills. If you lose your cerebellum or it's damaged, you lose a lot of fine motor skills; things become awkward and jerky. Maybe Neil's point is that there's a very complex motor system underlying the somatosensory system, which is certainly true, whereas it doesn't appear to be as complex underlying the visual motor system. The superior colliculus seems to have pretty direct control of the muscles of the eye, so it's a simpler system. For us, from the point of view of Monty, we don't need to worry too much about that complexity. Because of the simplicity of the camera moving, we just need to say, "Okay, camera, move here." We don't need a complex path-planning algorithm to move the eye; we don't have to plan how to move the head, body, torso, and legs to move the eye.

We have three pieces of cortex in blue here, and each one with that motor output is saying, "I want to move my patch of the retina here." If there are conflicting motor outputs, how do different motor signals from the cortex get resolved by that motor output box? I have no idea unless someone else does. This gets back to the question of hierarchy: is there a hierarchical preference for these? Is someone more important than someone else? Do they work together?

I'm sure there are papers on that question, but I don't want to just volunteer to look them up because it's a slow process. If we really need to know what's going on in the brain, we can dig into that, and I'm almost certain we'd find some papers that describe those questions. I don't know how they coordinate. What if one region says move this way and another says move that way? What happens?

From lower regions, that doesn't necessarily have to be like this patch of skin appearing now. Sherman said every region has these layer five cells that project subcortically, sometimes to motor areas. In many regions, that projection could be to the basal ganglia, which is a set of subcortical regions with really complex functions and probably hierarchical organization. That may generate all kinds of behaviors and effective behaviors. It's not going to be as simple as just outputting a command to move a muscle. It could be a desired movement that tells a very complex subcortical system, which might have a whole bunch of sub-behaviors.

The visual system is the simplest one in that regard.

I should mention one other interesting thing. There are two sources of movement behavior for the visual system: one from the eyes and one from the superior colliculus. There's actually a third source I forgot to mention, which comes from your inner ear—the balance system, the semicircular canals. What's the name of that sensory system? The vestibular system. The vestibular system also projects to these thalamic relays because it provides movement commands, telling you how your head is moving.

That also feeds into the thalamic relay cells. It's complex, but we don't have to deal with all that complexity. We can take a very simple system with a simple movement and try to get it to work.

That was a complex way to get started. I'll stop sharing my screen. That was useful.

Now we have to pretend we didn't know all that and go back to decide what we're going to do. I feel like that actually fit pretty well with how I've been thinking about adding hierarchy. It was nice to see that. Are you going to continue with your questions? What's your plan?

I made a slide with open questions, and maybe we can go through them and see if there are other questions. We need to set a framework for what we need to answer in the next week.

Basically, everything on the bottom part of this diagram has been implemented, and now the main part we need to resolve is the connectivity to the next layer and what's actually happening.

I can go through these questions I've come up with so far, and then we can see if there are any others. One main question we need to answer is what problems we want to solve with hierarchy, because that will inform everything else. How should we implement hierarchy, including the communication protocol? What is the input and output format of lower-level learning modules to higher-level learning modules? What's the connectivity—does one learning module connect to one other, or is there many-to-one or many-to-many connectivity, with some kind of pooling?

Related to that, what's the information routing? Is there some kind of attention mechanism to decide which information gets routed to which higher-level learning module?

Another question is the temporal sequence of information processing. Do we update the lower-level learning modules and then send it to the next one and update those, or does everything happen at once and take several steps for information to propagate?

How do we represent object ID to a higher-level learning module? This relates to what we talked about before—maybe creating an SDR representation of the object ID that expresses similarity between related objects.

Which models are learned at what level? Does the lower level of the hierarchy learn more detailed models, or does it learn coarse models that get composed together in the higher levels? This raises the question of oppositional versus decompositional or associative hierarchy.

Do we supervise this process somehow? How do we tell the system what it is supposed to learn? When we see input, how do we tell a learning module, "You're a lower-level module, you should learn the basic shape," and "You're a higher-level module, you should learn the composition of those shapes"? Does this happen naturally, or do we need a supervising signal or learning speed?

It's hard to write representation because we're skipping layers and going back and forth. I like the associative hierarchy idea—just associating information between different learning modules. It's not necessarily one level after another; some learning modules associate with others, and one on the top row might get input from a sensor. What does it mean to be a higher team? Partly, this comes from what we want the different models to represent in different parts. Language gives us an implicit understanding of hierarchy when we think about an object, and that's what we're trying to map onto this.

From the point of view of representational complexity, it might be higher up, even though that doesn't map exactly to the communication protocol. So, what communication needs to exist to solve hierarchical representations? Maybe it's very parallel and not a strict hierarchy. The hierarchy might be artificially introduced by saying there were a lot of stages before, but there are also connections that go almost directly from the first layers. In their paper, there were many options for how to order these regions in the diagram. It's not a crazy thought to ask what problems we want to solve with multi-level processing, rather than with hierarchy, since hierarchy is a loaded term. Thinking about it as multilevel processing acknowledges that it's not easily separated.

I haven't been able to hear everything, but the associative hierarchy—it's really two reasons that are associated with each other, isn't it? For example, a learning module getting vision and another getting touch could be voting with each other, trying to agree on what they're doing, or two vision modules next to each other. Is that what associative means in that case? The voting is more like learning modules with models of the same object talking with each other about whether it is the object they both know, like a pencil. In hierarchy, the module that gets input is a compositional model of the output from the lower object. It doesn't have the model of the pen, but it has a model of something else.

There's a soft version where there are a lot of skip connections, and it's not clear that something on level five of the hierarchy has gone through five learning modules—it might have gone through one. But we're still talking about compositional structure. Sometimes, compositional is more about statistically regular associations, while instantaneous few-shot stuff is more associative. A logo on a coffee cup would be a more associative representation, whereas a handle on a coffee cup is more compositional. Not all coffee cups have a logo, so it's statistically more likely to have a handle. There's some substructure that's a location on a larger structure. Compositional objects are when we keep seeing something like a cup with a handle, so we develop a compositional representation for a coffee cup.

Binding kind of representation would be, "Oh, this is a Menta coffee cup." It's basically just incorporating frequency information. When I see something that looks like a coffee cup, with high probability, I expect there to be a handle. I can't say with high probability there's going to be a Menta logo because there could be some other logo, or maybe no logo. That's all just probabilities. I could live in a world where there are more logos and fewer handles. There doesn't seem to be anything fundamentally different about the two problems; it's the statistical regularity of them. I feel one more defines the object identity, and one is more an association. Maybe a better example would be a cat's face. A cat's face has ears—sure, there are cats that don't have ears if they've been removed, but the presence of the ears informs the identity of a cat's face. That's compositional. Associated is like, "Oh, this cat is wearing a hat." It just happens to be associated at this point in time, but it informs. I feel like it's still the same process, just on a different scale. It might be a similar process, like short-term memories. There could be cats that always have hats, and maybe then we'd find a name for that, like horses that always have something, and then you develop a new term. I see it as a spectrum—a spectrum of probabilities. I'd rather treat it that way as opposed to something totally unique.

But what is decompositional hierarchy? I'm not sure. I don't understand what that means. Basically, the idea would be at the lowest level of the hierarchy, you have basic shapes, and then higher levels of hierarchy specify details at different locations on this object. The difference is just where in the hierarchy the story is. I've never thought of that as a possibility. Is that a real possibility, or are you just including it for completeness? In this terrible drawing, it's like a tree on one side, and on each location we have features associated with it, like the color or the structure of the leaf or the tree trunk. The difference between compositional or decompositional would be whether the left side is the top level or the right side is the top level. Are there any thoughts that the right side could be the top level?

I feel like this is an issue, but I think it'd be really cool if we could get both. From what we've discussed about this decomposition, the example you gave—a blurry photo of a tree—was a nice one. You don't recognize leaves or anything like that; the features are extremely impoverished, but you still recognize it's a tree. It's almost like the gestalt way of representing something, where you first get a core shape and then get more detail. Sometimes the higher level of the anatomy is responding before the lower, maybe because both of these things are happening in parallel. The evidence suggests strongly that if you go higher in the hierarchy, you get more complex, bigger objects, but you can do decomposition by flowing down the hierarchy. It can be represented both ways. I could have something at the highest level and say, "I don't have the details, but I'm going to predict them and try to look for them." I'd view that as just two different directions of flow on a hierarchical structure, going up and going down. It might still be IT cortex rather than V1 that's representing this coarse tree model, but then there's a lot of information flow doing the decompositional hierarchy you're talking about, but anatomically it just happens to be starting at the top.

Thinking of hierarchy as multi-processing input is a good way to approach it. You don't necessarily need to recognize all the leaves before you can recognize the tree. For example, you could get a skip connection to V2 or V4 with a large receptive field, recognize the coarse outline of the tree, and then the detailed features don't matter too much. It could be a tree with snow, but it should go both ways. Imagine two levels: the first recognizes leaves, the second recognizes trees. If I see leaves, I can suggest there should be a tree. If I see a tree, I can project backwards and suggest there should be leaves. It seems like the same structure, and the hierarchy could do both.

Am I missing something there?

No, I've tried drawing some early sketches to think about where the analogy breaks or where it's less clear how these two would interact. There are cases where you can lay out the decompositional and compositional and they just work together. Like you said, it's just information flow the other way. There are examples of representations that might appear in a certain type of processing where it's not obvious. In general, in the middle, they seem to mesh easily, but at the extremes—either very core shapes or very detailed features—it's less clear how those fit into the two. Maybe having some drawings would help.

As I was suggesting earlier, the anatomy suggests that when you go from V1 to V2 or V2 back to V1, there are connections that are really associative, like voting connections, and others that are more hierarchical. We know that a high-level object could be learned and you could learn a copy in both of those. There has to be a way in the brain for these learning modules to flow seamlessly between these extremes.

Whether they're representing the same thing or compositional things, it's not obvious, but at least you answered my question. I know what you meant by it.

By what you meant by decom, I think. Yes. Maybe in another session we can draw some more. I think once we decide on some of the earlier questions, like the communication protocol, things will become clearer. I feel like all three of those can become equivalent very easily; it's just a question of perspective. Especially if we're saying we don't have this strict sequential processing of one level of hierarchy and then the next. To be honest, my take is that compositional, decompositional, and associative all associate with my definition of compositional. That's what I keep hearing. Maybe it would be simpler to tame this by just thinking about compositionality and then different types of connections, like from higher levels back to lower levels or lateral connections.

Or different timescales, like we discussed earlier, but everything still seems fundamentally compositional as far as I can see.

So, back to the questions.

Are there any other questions you would add here?

Anything you feel needs more attention? I don't know if we'll have time, but how do we represent objects? A high-level question related to this is also how do we learn that representation? That was something we talked about. If we are going to use SDRs, then that raises questions about exactly how we let those SDRs do a couple of different things. That could be a subpoint, but how do we learn those? I feel like that's a sub-question that could lead to a lot of different possibilities. We might agree on how we want to represent it, but still be unsure about the best way to achieve those representations. It's basically time versus learning time, right? Exactly.

Do you want to try to list out the different types of problems you might want to solve with the hierarchy? The first question, basically. I can only think of one, but I'm curious what the other ones are. I always have a few slides of my own snapshots at these questions. One would be the fast association that Neil was talking about, like the logo on the cup, without requiring relearning the whole coffee cup or the whole logo—being able to quickly associate this. Secondly, representing higher-level object-product relationships, like letters. You still have those three bars, but they could be further away, longer, shorter, or tilted. It's a form of robustness to invariance. You respond regardless of particulars; you recognize that as an "A" or whatever, or a Korean character.

Do you see those as fundamentally different or as on a spectrum?

Again, probably just on a different timescale. Just to play devil's advocate, it could be that there is something different. Looking at the evidence from psychology, there is a fair amount of evidence that path associations are a very serial process that people do well only if they can devote attention to it. Whereas these kinds of more familiar associations that you've been exposed to many times can be processed in parallel and without the need for attention. That doesn't necessarily mean they're completely different processes—maybe attention is helping or something like that—but I do feel there's some evidence that there is still a difference. It reminds me of the very fast memory you can form in the hippocampus versus the slow memories that take time in the cortex. There's the question of what it takes to recognize an object. There's the graph, which is: these are the features at these locations. But that by itself is not a representation. That's not a momentary representation of the object. I can't say what's the name of that object. I can say, "I know all these pieces are in this arrangement," but I don't have a singular name for them. If you ask me to identify it or describe it, I feel like you could learn a melody without having a name for the melody, or you could learn an arrangement of furniture in a room without having a name for that type of room.

This is what the Temporal Pooler did. It essentially says, "We take all these different points on the graph and associate them with a common representation, a common ID." Therefore, if I know what graph I'm on, then I know what the ID is, and I have a label for it. The problem is that it takes a lot of memory to do that. The Temporal Pooler requires pooling a whole bunch of unique, changing patterns onto a single pattern. It takes a lot of memory to do that. It's not easy. I always felt that it's really easy to learn a new graph—these things are arranged relative to each other, just add them onto the graph quickly. But learning the temporal pooling name of a thing could take a lot longer. I'm wondering if that's the only distinction you're making: that we don't come up with labels for everything we learn. It's just too expensive, but we can learn the relationships between lots of things without having a label for them. Does that sound like the same thing you were just talking about?

I'm more interested in how you identify something regardless of whether you have a name for it. How do you identify an object when its defining features are statistically regular—something you've seen many times—versus something you've only seen once? That seems related to the difference in the brain where we have inactive synapses in the hippocampus, allowing rapid, even instantaneous learning, while most of the brain requires repeated exposure for synapses to grow. That difference seems relevant here.

For example, in a search task where you have a bunch of objects on the screen and are asked to identify a particular object—say, a bunch of letters with many Bs and one A—you might be asked, "Is the letter A here?" Sometimes the A isn't present. The speed of people's responses depends on the number of letters. If you're looking for a diagonal green bar among vertical and diagonal bars that are either red or green, finding the diagonal green bar requires scanning each object until you find it. In contrast, distinguishing Ts from Ls, even if they're slightly skewed, can be done almost instantaneously.

How does that relate to hierarchy? A T or an L is a compositional object formed from vertical and horizontal bars, and you could argue that a diagonal or vertical green line is also a compositional object. However, the T and L are defined by statistically regular associations, while the green vertical feature is a fast association that hasn't yet become its own model. The bottleneck seems to be in how we process these associations.

You can have an association without having learned an object category. For the letters, you've learned the category for L or T, which becomes its own model, but the fast association is just detecting two things together. As you develop a different representation that captures regularity, you may also form an ID label. As Jeffrey mentioned, you could form the label and later be told, "This is the name of the song," but that's more of a language thing. If you have the same name for different instances, you need a category for it. If you call multiple things "A," those differences matter.

In the search paradigm, if you say a green vertical bar is called "A," it doesn't necessarily help people to factor that in. But if you repeat the exercise, you would get better at it. There used to be a belief that color was special, that color had to be bound with shape, but evidence shows that a yellow banana is identified more quickly than a blue banana. Where there's regularity in the association, identification is faster. It's likely a spectrum, not a hard boundary—the speed of imprint is related to frequency and familiarity. If you rotate the T and L to make them less familiar, you become slower at recognizing them.

I want to focus on learning compositional models, and the associative property emerges naturally. If we see an association often enough, we build a new model and can recognize it. If I understood you correctly, I agree with that.

There was also something about ranking the most likely objects based on sensory input. You might start by guessing the most likely object, and if that's correct, you identify it instantly. If not, you search and reshuffle the order, which takes longer. I'm wondering if this phenomenon is already present in the implementation.

If we don't have a model of the logo plus coffee cup, we would switch to the most likely hypothesis. If there's a lot of noise or you switch from one object to another, the hypothesis changes.

The more important question is whether object frequency is encoded in your implementation. If you've seen the mug ten times more than the chair, does the mug come to the front of the queue faster? Not yet. Right now, every object is equally likely, so you could have a prior for more associated items.

That helps explain why it makes sense that you haven't incorporated that yet.

Because it sounds like it would basically just be based on the number of episodes. If I did five episodes with the mug and one episode with the chair, only then would that matter.

I think the current setup doesn't, because we just test objects. It makes sense to have some context, to have a prior for what you expect to see—faces, outlets, or whatever. Coming back to this question, for the problems we want to solve, would you all agree that those three things are the problems we want to solve with composition? That is, object categories and being able to model structurally complex objects more efficiently. For example, we could have a model of a complex airplane in one module, which would require many data points and wouldn't be as robust as having separate models for the different parts of an airplane, then composing them together in the overall airplane model.

I think efficiency is important.

There are the top two bullet points, and then the next three bullet points.

If we're going away with a short list of the problems we want to solve, the first two are more like examples, and the next three are the general capabilities. The first two would both be related to categories and composition, and then the efficient way is just a practical reason.

This might be off in the woods, but one question I have is whether the notion of object state only exists for certain objects. For example, a door with a handle that can spin and then open—those are actions you can apply to a door, changing its state. Maybe these lower-level modules only see small parts of the door, so when you change the object state, the lower-level modules don't know what they're going to see. But the higher-level modules, which have the notion of the door and the handle simultaneously, might. My first take on that would be not to do it that way. I would ask, can a single learning module solve that problem, even if it can't do it for a very complex or structurally complex object? I've always resisted trying to use hierarchy to solve fundamental problems that have to occur everywhere. My bias is to ask if we could solve that problem within a learning module itself. Maybe we can't, but at first glance, I would say it's not obvious that you can't do that yet. Object states are something we don't really deal with yet, so that could be something we add later. For a large object, we need to recognize more global state, and it would be difficult to do with one learning module, or at least it would be much more inefficient.

A structurally complex object suggests you need multiple modules, but for basic behaviors, it's not clear to me. Behaviors are almost like object categories with behavioral linkages between them. If we want to achieve categorization with hierarchy, the way we define categories is also not really clear. So far, we think of it as similarity, but it could also be behavioral similarity—like a chair is something you sit on, but the morphology can be very different.

We have to think about that as well. That could be a parallel classification system that we add later. It would also be related to the SDR representation or object ID—what is the similarity there?

Just in terms of these problems, I think it would help if we wrote out exactly what kind of problem it is.

For example, object categories—describing object categories as a problem. Is that too broad? Or just understanding why something is in a particular category. For me, something that is clear is that we want to solve the problem of being able to robustly recognize compositional objects. For example, the letter. It's a problem because it varies.

And so then hierarchy might resolve that. Object categories—how do we represent object categories of different granularity? Maybe it's pedantic, but I would like to have a clear sense of what I'm trying to achieve later down the line. I've always found it helpful, almost essential, to pick a specific problem that you can use to answer those questions. You can easily pick a bad problem, so that's a challenge, but sometimes it's helpful to have a very specific task, even though I've used the logo and the cup as examples. That can help enumerate the specific details of the challenge. I'm suggesting that you can do that. I feel like that would help me as well—a specific example for each one.

Categories come out of composition and representing structurally complex objects efficiently, because basically an object category is a definition of a composition of features, and it's always the same, even if features vary. For example, a cat is always two eyes, one nose, three ears, but the relative displacement between them can vary, and the color of the eyes and everything can be different. It's a set of similar compositional objects summarized into a category. I feel like there are multiple problems there. There's the problem of consistently recognizing a cat despite changing displacement, and then how to represent distinctions like cat versus tabby cat versus tiger. Both of those are important.

I'm wondering if it would be helpful to explore what the specific potential problems are, because they may have different solutions. For example, having invariance to the features of a cat's face—could we have the same solution through hierarchy as we do for representing different granularities of cat labels? What you define as a category also depends on your interaction with it. I don't speak Chinese, so I represent all Chinese characters as one category—"this character is Chinese"—but if I could read Chinese, each would be its own category. It's a bit arbitrary where we draw the line for categories.

Should we just make a new slide and write down some of these ideas? Maybe it's quicker to type. I think it's a great idea. I need to excuse myself right now.

I'm a little uncomfortable, and I also have to do something with my granddaughter, but I'll be there tomorrow.