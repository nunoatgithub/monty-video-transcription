Hojae Lee: My name is Hojae. I'll be giving a short presentation on how to run Monty and how to configure it so you can run your own experiments. I'll jump right into it. Our code is available at github.com/thousandbrainsproject/tbp.monty. Our documentation is at thousandbrainsproject.readme.io. After you get the code from GitHub, I highly recommend visiting the documentation site. It has additional information on setting up a conda environment or a programming environment where you can run Monty. It also has a link to download the YCB dataset. The YCB dataset consists of household objects you've seen in previous presentations from Scott and Niels, like the mug, bowl, bananas, etc. Finally, it also has a link to download some pre-trained Monty models, so you can immediately start experimenting with Monty. I highly recommend these two websites to get started. With that said, I'm going to switch over to a different window to show you what a Monty run looks like and what you can expect when you run an experiment.

Hopefully, you're looking at my code editor. On the left is a YAML-based configuration file that specifies the parameters of an experiment, and I'll explain what that experiment is. On the right is my integrated terminal, where I'll type commands to run a monty-experiment, the experiment specified here. This will be a quick experiment doing object recognition. It will evaluate a pre-trained Monty model to identify two objects from the YCB dataset. I specified a bowl and a mug. The goal of Monty is to move around the object, gather features at different locations, and try to determine which object it is sensing. This pre-trained Monty model has already learned up to 77 objects. Here, we'll present two, and Monty has to infer what they are. One last thing before I type the command: the configuration for experiments is divided into two parts. One is called defaults, which means importing configurations from other files to provide default values for any parameters not specified under config. If you're familiar with Python, these are like import statements, importing configurations from different files. Under config are overrides for specific parameters unique to that experiment. I know that's a lot, but I'll move on to running the experiment. Let me activate the Conda environment first: tbp.monty. To run the monty experiment, you have to specify which experiment to run. That's the only required argument, so you just specify experiment equals and the name of the experimental file, in this case, demo. You don't need to specify the file extension. Press enter. This will print out a long list of configs, the full configuration listed out.

Soon, it should start the evaluation.

Let's wait a couple of seconds for that to pop up. There we go. You can see a crude visualization of Monty moving around, looking at the bowl. It thinks the most likely hypothesis, MLH, is a bowl with a certain amount of evidence. It will move on to the mug, move around the mug, and explore different parts. It thinks the most likely hypothesis is the mug. That was a quick experiment. If we have time at the end, maybe we can come back to this. The experiment will run until Monty detects a match or times out.

For object recognition or inference experiments, we usually save some summary statistics of how Monty performed. You can find this in the output directory. In my output directory, you should see a folder named with the run name. The run name doesn't need to be the same as the file name; it can be different or the same. The most important file here is eval_stats.csv. If I double-click and open this, you can see it contains statistics for each object or episode Monty encountered. In the first episode, it encountered the ground-truth object, bowl, and thought the most likely object was bowl. There are also other columns calculating the rotation error, how long Monty took to reach this conclusion, etc. This is how we measure Monty's performance, and these are the metrics you'll see on our benchmark pages. This is what you can expect when you run Monty. I'll go back to the slides.

Previous presentations have alluded to this, but this is another view of the high-level classes in Monty. Monty is composed of one or more sensor modules, one or more learning modules, and a single motor system. It can be placed in a simulated or real environment to run an experiment. You just saw an experiment for object recognition to identify YCB objects. All these components are designed to be modular, so you can easily swap them in or out. You don't need to just change arguments or parameter values; you can write whole new classes for data you want to experiment with in Monty.

As an example, this is my own configuration for a project I'm working on. You won't see this in the documentation yet because the project isn't finished, but hopefully it will be soon. I've written a custom sensor module class in Python and specified it in the sensor module class key. I have some custom arguments as well. In the config, I'm mostly importing defaults, analogous to importing from this control experiment, but for this experiment, I'm overriding the sensor module class.

This is a tip for setting up experiments: if you want to compare two different experiments, like a control and an experimental, you can do so without accidentally changing other irrelevant parameters. The configuration is written in YAML so you can read and understand the major classes, even if you don't know Python. It's designed to be composable and modular, allowing you to easily plug in your own sensor module or custom classes, such as the sensor module, learning module, or environment.

That's it for my presentation. If you didn't get everything, that's okay—most of what I covered is written up in the "Running Your First Experiment" tutorial. This is one of many tutorials available, and I highly recommend starting there. There are also more advanced tutorials if you want to go deeper. If you get stuck or have questions, please post on Discourse or GitHub Issues. Even if you don't have questions, come say hi—we love meeting new community members and interacting with you. For those who are advanced and want to use Monty immediately for your own application, check out the project showcase page for inspiration.

With that, I'll hand it over to Ramy, who will show you some interactive visualization tools. This will give you a good sense of how Monty's brain works. Thank you.