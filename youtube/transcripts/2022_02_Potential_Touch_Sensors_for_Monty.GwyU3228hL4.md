So maybe related to this or not, but talk about like tight sensors and there are different kind of tight sensors like, like real sensors. They use pressure or they use, what I'm talking about is one I use, a vision touch sensorimotor. A vision type sensorimotor. That seems like an right. What's a, so basically it's a oh Is it like Yeah. Your fingers like a little camera. Yeah. They have a camera. They have a, surface that gets the form and have a camera that just reg register the DEF formation. So here's what it looks like, basically. So they have these, these rubber thingy. It's like a ter. And they have lenses and they have some LEDs. They put around those lenses and have a ca a camera at the end. Okay. That will capture. And all the information, for example. That's clever. Yeah. So they get a very high resolution, using, cell phone cameras. These are cell phone cameras. Yeah. That's nice. So Todd, do you remember, at interval they had something like this where they were capturing the surface of a drum? It was being deformed? no, but okay. Yeah, but it sounds plausible. So one of the trick thing is to get this, rubber thing, and there was this company that came out of MIT called Gel Site, and they came up with this other summit. That's very high resolution that we can get, very good, resolution. Someone makes this whole thing, right? Yeah. So that's what the, what it looks like, for example, the output of the sensorimotor. So this is like our little form. This is Velcro is what? Velcro, that's what they're touching. Yeah. This is the Velcro. This is the output of touching and Velcro. Touching some, I dunno, that is foam styrofoam. Yeah. And he is like a, circuit board and there's like a t Euros, I think. Tencent, those euroes. that's, that clearly is more resolution in my finger. I think you can't read the numbers on a, dime, it's or coin, I think, for example, file. File, yeah. Yeah. It's or maybe training. if you, they have pretty good sensorimotor.

Yeah. Not even that. that's pretty, every little.here, right? I mean my, how big is that tip face about the size of your fingertip? That's, yeah, so that's, what it looks like. That's the size of fingertip. It's clearly higher resolution than our skin. there's no question in my mind, it's much, much higher resolution than our skin. That's interesting. So this one is, the, is being developed by, Facebook created. This one is open source. You can just, buy out as well. Off the shelf goes. Do they have simulators? Is this you could use? That's the next slide. Oh, so here the simulator, like a habitat simulator or what? That is not, but like it's, but we can integrate into Habitat. It's also by Facebook research simulator. The Sensorimotor buy Facebook as well, the physical sensorimotor and buy from Facebook. What you buy the physical sensorimotor from Facebook? No, it's from, the, gel site company. you have to build that. I guess the design is open source, the design. Oh, you can, you buy the whole thing or you have to build your own? You, so that's what I'm saying. They, will, they'll, they will assemble for you for three day will gel site Okay. And, but we can buy all the elements and, build there. There's a bill of material if one, but I think it's d printable. You can print the whole thing. Its, yeah, so that's what it looks like the sensorimotor in a simulator. So here's a different one with the hand and they have multiple sensors in this hand. So each finger has one and and this is just putting a marble on the sensorimotor, but here's an example. They put like a different, there's like a, there's a corner there, so that corner, yeah. It's a little different than the surface. That's the surface. Yeah. So that's the example. Just more be like, this would be more like multiple columns on your skin, detecting it at the same time. Yeah. So those are two fingers there. Yeah. You probably detect the normal to the surface too. That's correct. Exactly what you can do. Because that's, that's a very high risk as the pressure there. the intensity is basically the pressure of that, tip that, gel that they have in there. So that creates this. Yeah, you get a very high resolution point. Cloud basically. Yeah. Interesting. So this is, also open source, this the simulator and the sensorimotor. So we can just integrate that into if you want, or, I'm assuming you can just even go to upstream because it's the same company.

And they just did it in November. So this is, so it's, they just released that November.

I was thinking about integrating into money initially before you do any manipulation. You just need these things and you just tap different places where you have multiple, Yeah. So that was the, but not even the need to manipulate the object yet. Starters. Object the thing. It's like a better thing. This one. Just have this guy up. Yeah. Better thing.

Yeah. This would be the thing. This will be the thing. Yeah.

Anyone using this stuff commercially? Or is this just like a research file? This is a commercial company that's selling this. Yeah. But commercial, they have a diff this specific sensorimotor, not use commercial, but they bought it for vr. They bought a company that did that. Yeah. Because of vr. Who? Facebook. Facebook bought, but not, the company was building Hands. Yeah. Ing the Sensorimotor. Oh, they handle Sensorimotor. The Sensorimotor. Yeah. But they, have already seen the prototype, like last year Rib, they show using the VR.

How would they use this in the vr? Because you don't really need a physical sensorimotor in the vr.

Dunno how they're gonna take, I dunno, press point something physical. It's not virtual. Yeah. So I know how well if you're wearing a Glo that iParts the same sense on your fingertips. That is in a virtual world. Yeah. But this doesn't, get fingers. No, But you need to know how to deform your glove. If you feel something in the virtual world, you need to transmit that. So they can use this as a training module for the virtual reality stimulator. this would tell use someone actually shows a physical object and then they figure out what they have to put on your fingers to make feel like, yeah, it wouldn't be training. You'd need it all. But if I'm touching something in the virtual world. I need to know exactly what that shape is in order to transmit that feeling here. Yeah. but when you're in the virtual world, you're not actually touching anything. So this wouldn't be useful. You would be touching in the, this is a simulation. Yeah. But, Yeah. But, this is actually a physical sensorimotor. It only gives your input if you touch something, right? No, this one's a virtual sensorimotor. There's no physical thing whatsoever. But it's still detecting, it's still based on this guy.

It's still, an input. it's a virtual 3D input, but it won't make you feel something. Yeah, I know that. But in order to make you feel something, you need to know what detailed sensation to transmit. Yes. This will give you that detailed. Yeah. but in the end result, am I using the virtual reality world? I wouldn't have this, right? Yeah, you would. Why would you need this? Why would you need the camera? No, not the physical one, the other one. I'm about the simulation. I don't need the simulation one. You would Oh, I see. You're saying for how would you in the Oh, I see. How would you know what that virtual puppet feels like otherwise, I see. So a direct connection to, haptics in your vir in your virtual reality. Yeah. It's a, this is a haptic sensorimotor. Alright. So yeah. but you would, the thing you would wear on your hand would not, would be totally different. Totally different, yeah. Have a virtual one that's touching the virtual objects. Exactly. So that, no, because you are asking why would you need a virtual one? Virtual. That's why I, was thinking why did you need a physical one? I didn't realize that. Maybe a physical one. For physical robots, it's really hard to do subtle manipulations. No, you can, I got it. I got, yeah, so they have a videos put, they have video. This robot. Grabbing an egg. Exactly. You said, they bought a company making these, and I'm saying, why said that? Oh, I said that. Said, why did they make the company making these for the virtual reality? Because you don't need the physical one for the virtual reality, the simulator one, you need to buy anything. I don't know. It's and they have something and it create something. They create something called I Touch.

We'll have models and data sets. They'll have models and data sets for this.

Right now it doesn't have anything right now, isn't it in, that animation you were showing when they, they, pressed the virtual ball against the, top figure. I kept noticing that the top joint was actually displacing not just the surface of the yeah. You could see it pushing back. Yeah. Yeah. Oh, so I'm just wondering why are they, what are they simulating there? The fact that the, whole thing is spring loaded. in this one they run the simulator inside, Ross. I think it's a Ross visualizer. So it's, truly articulated, but I, the you, should don't focus on the movement or the finger, just focus on the right side. Yeah. It's a focus. Yeah, I understand. Yeah. But it, was just that degree of they, they had to make that happen some way. one of the other things I realized that you, you might not, depending upon how this thing displaces, it's not only sensing texture, but also, pressure. Correct. So you get both of those, with, this one sensorimotor, on the right side, like when you have the intensity, it turns brighter. It goes brighter. once the, high changes. See, the high changing, see, according the mound castle, which you could be wrong about this, a single column wouldn't be able to possibly get information like this because a single column, the signals going into in some sense, mix. You don't really have spatial, you couldn't. I've mentioned this many times, you don't get further spatial resolution. And here you can actually see where the ball is moving around. Multiple sensors, multiple column here, which is fine. It's pretty cool.

Wow. Okay. That's cool. Thanks.

Minutes.

Okay. So probably next step would be to see how to integrate this. Yeah, that would be great. And it could be like, a single finger exploring your object.

So what would we use this for as a touch sensorimotor? To do what Instead of going, right now, we're going we, we're bypassing out the sensorimotor. We go directly to that, but this would be to train the vision module. The me be could be yours to try model.

I suggest that we work on two mod at once, as a way of two reasons for that. One is to keep us honest and not, get pulled into one direction. Like vision has its own problems. We don't realize there's other issues. And the other is that ultimately we do wanna do manipulation of objects.

it just felt I, we don't have to, but I thought we should probably, keep vision and touch going simultaneously. So learning modules can be generic and the system, we, they have different issues, not exactly know, so just keep us honest about the whole system.