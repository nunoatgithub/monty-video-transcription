I have some slides I can go through on, object behaviors and ideas around that. And then, yeah, Viviane, you mentioned if there was time, then, Get some stuff, maybe. yeah, just very short, but, no worries if we don't have time.

I don't have any slides, but I've been working on object behaviors a lot, so I have a lot of interesting observations, Oh, okay, nice. I don't know if I should interrupt and say, hey, I was thinking about this and that, or just let you go through it, but, Yeah, no, I think interrupt as much as possible, and then I guess we can always, Sometimes you do brainstorming. It's too slow. Sometimes it's it's brainstorming and sometimes you don't even want to get some material out. Anyway. Yeah, so I guess this is just an attempt at bringing together some different thoughts about graphs and sequences and how this relates to object behaviors. It's nothing really new. It's more just trying to like summarize a lot of the things Stuff we've discussed, and reframe it in a way that's hopefully useful, and in particular, how are we going to actually represent behaviors, in Monty or how they're represented in the brain, and part of this will touch on kind of, yeah, maybe just like how far we can get with, sequences and how universal they might be. So I guess, Yeah, after, for example, what you shared, Jeff, about how we can attend to changes, it feels like things like how we learn the object behaviors is a bit clear, but the sort of substrate that's actually representing object states is something we still need to clarify.

And in discussing this, I'm also going to touch on how we represent kind of reference frames, morphology, the path integration space, whatever you want to call it, that also have, so, you have the series of, states, the, behavior, at any given time, there's some kind of morphology that you are able to predict what you're going to see if you move somewhere on the object, and so how that might tie in with this as well.

and yeah, as alluded to before, I guess it's just a start of thinking about how kind of sequences might be useful, for a lot of different parts of this. Thanks. Can you, are you going to explain that? Yeah, by double, triple roles, I just mean like lots of different things. Yeah, you're going to walk through, you're going to walk through a bunch of things, but, okay. And then one other kind of related goal, is just there's lots of different, interesting work out there on how you represent, structures, everything from graph networks to hierarchical temporal memory and for sequences and all these kinds of different things and You don't need to have come across all these terms, whatever, but I just thought if these are things you've come across, at least I found it confusing, like, how do these all relate to each other? and so I'm just trying to maybe put a bit of structure, to that. and in particular, really look at the big ideas of kind of graphs and sequences, how these are related to one another, and then how these relate to representing states and representing space. Thanks.

That was a kind of preamble.

and yeah, hopefully I've not assumed too much that like part of the issue is like we've done kind of similar brainstorming sessions, many times over the years. And so I may assume, that you are fairly familiar with hierarchical temporal memory or, some of these other things. So definitely stop me if, if I can clarify anything.

so in terms of like how we might represent object behavior, I think, one way you could frame it is this sort of graph view where we have a more logical model of an object, which is a series of nodes. and are, those, nodes? The, are locations and yeah. So those are our locations, yeah. Okay. Because they're not like features. It's a, continuous space. So it's not like the three nodes or something. it's. Yeah, although, we don't represent it in a totally continuous space, and we've also talked about how, as we get more hierarchy, we would expect this to be more, sparse. Maybe, but it's the space itself that's continuous. That it's embedded in, is in continuous. There's a space in which we have, we've located features at different locations in that space and other points in that space, so we don't, we don't see anything. Yeah. Yeah. Okay. Yeah.

and then, if you wanted to encode behavior with a graph, you could lay down edges that, connect nodes, not necessarily all the nodes. so that's just showing an example here where there's edges between these and edges between these.

and then the behavior of the system could then follow this where, the state of a given node, a given location, at a time point is going to depend on a series of things can be summarized as the, state of the connected nodes. Based on incoming edges, so that's information from neighbors that's transformed by an edge affecting this node, some like local actions. So this is additional influence in the system. So for example, someone pushing and then, and oh, and I should say for the edges that includes like a self edge, and then it's not necessary, but it's potential that you could have some global state, like maybe some pooled state, that's describing the object. maybe it's hot, maybe it's cold, whatever, and that kind of influences, at a more kind of global level, all of the, nodes.

I'm not claiming that this is the way we should do it, I'm just trying to describe, like, how, one way you could frame it. is A represent a node? is it? It's like a, yeah, it's the top of the stapler. Okay, but so it's not a location. It's a, this is what I was getting back to earlier. I kind of view like, a model of an object is a bunch of space, and then we assign features at different locations in that space. and so you could, I could say, oh, the point in space is a node, but that's not what it is. You're saying the point, in this case, the A is like a feature. That is located at some space, location, but that feature can move, so it's I've always had trouble, trying to think about the brain as it's these, graphs like this, because they have, there's language that we use for graphs, That, that don't, it's hard to fit on top of this idea of location spaces and features that location. So I'm just confused what a is. I can understand what a note and a graph is, right? but it, that's why my first question was, is it a location, is it a feature, or is it a note on a graph? Yeah. so I, would say it's, it's a feature that's currently associated with a location, but that location can change. Okay, so that to me is, we can call that a node, but it's really, but if it's a feature, I wouldn't normally typically think of that as a node. I typically think of a node as a point in some sort of node. A space, right? Yeah, it's all the things associated with that point. So it's not just like a feature. but if it's moving, then all those things move together. Yeah. Again, the language of nodes and graphs is, it's just hard. Like maybe, one way, I don't know if this helps is thinking about it is it's almost like a place cell. So it's bound a bunch of information to it, but the mapping between the place cell and the grid cell. maybe that could change so that where the play cell actually is changes. But we don't see that, right? We don't see that. play cells represent a location, in a space. grid cells, but they're different, but it does represent a location. So you don't, you typically don't see a place they'll move. It's, it can represent, an individual cell can be far in different locations, but but it doesn't. It can remap though, can it? Yeah, not, it remaps. I'm not sure about that. Does it remap in the same environment? I think. I'm not aware of that. that's the thing, if we're changing the environment, that's what's happening. Yeah, the individual cells. So the question is what's happening when we change the state of an object? is that like changing the environment? Because I think there's things like, if you, start moving the, walls of the environment and things like that. on this case. Touch on this a little bit, but then, definitely the grid cells, and I think the place cells also, like distort and things like that. So I've argued earlier that, That, when the stapler moves, it's the same object and therefore it is the same, space. if it, if the, if we switch to a new space, then all the learning about the, stapler would, be forgotten. And so if you have an object and a little model of the object, and then some part of the model changes. I have to be able to represent that change, but I don't want to forget everything else. Yeah, I agree. It's yeah, I don't look at it and go, oh, that's not a stapler anymore. It's it's just changed. Yeah, no, I definitely agree. Yeah, and I guess I'll talk later about, The kind of the space element, and maybe that'll help in terms of I just, I do see there's a, in my mind, it just could be I'm stupid, but in my mind, there's a fundamental sort of impedance mismatch between talking about models based on locations and features and models based on nodes and edges. And I don't know how to, I don't know how to bridge those two. Yeah, I feel, it feels to me like part of the issue is just. it was easier to use the language of features at locations because we were always talking about static objects.

whereas it feels like, yeah, maybe, It almost needs some new language now that, I think we've Maybe. That's right, because I take the opposite approach. To me, is, it's okay, that language is great. It really works super well. How do I, explain behaviors within that language? And that's how I'm approaching it. I'm making, I think I'm making good progress on it. I'm open to other ideas, but it's going to be hard for me to, going different directions here and are thinking at the moment, but I'll, maybe I'll shut up for a while. Let you keep going. See when you can pick it up. That's right. I'm just, trying to really understand, okay, what is A and B exactly, I understand notes in the graph. Hopefully that clarified it a little bit, at least. Not really. Yeah, I understand it's hard to map, okay. It'd be hard to map onto the real science, but. It didn't really clarify it. Okay, do you mind if I give an explanation if that's, I'm just trying to find, the zoom. Whatever I can draw, to explain it, but where's the zoom controls? I'm sorry. I think if you hover above the top, at least I have an annotate. I don't know if you see one. Yeah. Nice. Okay. Oh, thank you, Will. Hi. Oh, you want to, draw something? I see. Yeah. Yeah. so let's say instead of a stapler, we have image like a, grid. Okay. so like a, let's say a 10 by 10 image, and we can think about this as a graph where each pixel is a node, right? Can you think of image as like a So is, this is not an object, this is just, a pixel, a pixelated display? Is that what you're saying? yeah, instead of a stapler object, I have an image object, a picture, let's say a picture. Okay, I'm trying to say, is that, is the object this grid or is the grid represent where I represent the object?

are we actually recognizing a grid or does the grid represent a pixelated yeah. The, latter. Yeah. I think for what it's worth, like I think Jeff, as he was say, like he, he understands the concept of the graph and, what a node and a graph is and things like that. I think it's more, it is this tricky thing of like, how do you, map that onto Yeah. I'm trying to get there. I haven't got, okay. I just wanted Hoja. I just wanted to clarify 'cause you said we have, okay, so let's say we have a, like a physical picture, like from a four paper. And I cut them up into little pieces, and so each, piece is a node, so does that, make sense, for now, can we imagine that? Do you want to define it that way? Sure. Sure, okay, so then each pixel, can have each of those little cuts, let's say we cut it very small enough, so that node, that small piece of paper after we cut up the, picture, we can think about it as a, as like a set or vector that contains the RGB value, for example, because it's coming from a picture, and also the XY location from where that came from, and that is representing that node. Yeah, but that, that, that's just a purely, there's, that's just describing, an image array. It's, it, there's no object there, there's no learning there, there's no model there. Thank you.

there, we need, these things that we're, that are moving on the stapler are not just pixels, they're objects, they're like, there's, features that, there's a model of the stapler, and, it's not just an image, and so Yeah, node A, when we learn features at locations, we do learn some kind of color, HSV, principle. Yeah, but I think, I I'm assuming that Neil's presenting a is not just some un undescribed pixel block. It's the top of the stapler. This would be associated with an, yeah, this would be associated with an object in, the lower level. I think the thing that, yeah, that you're stuck on, Jeff, which I think is a reasonable concern or like thing we, need to understand is. Yeah, we've always described like features at locations, which assumes or frames it as like the location is in some sense, like static. and then here it's there's the reference frame. At least what I'm, the way I'm thinking about this is there's the, this graph that's embedded in the reference frame. but where the kind of, elements of the graph are relative to one another, takes a change. It's a stretchy graph, right? It's a stretchy graph. Yeah, exactly. It's a stretchy graph. The problem here, there's two ways. Either the graph could stretch, Four things could be nudged around in it as a function of some, time or, so there's two ways you could do this, right? You could, modify the reference frame. And every time I thought about that, it's and I know in grid cells, they do get distorted. They're not really, but not, a lot. It doesn't explain this. That's this mechanism stuff. but the problem is, as soon as you start modifying the reference frame, It's very, difficult to do path integration. It's difficult to, do metrics, between two locations, two arbitrary locations. And I just, think it's the wrong place to go. You just, You just gotta assume the reference frame is a reference frame, that's why it's called a reference frame, it's not a flexible, graph, it's but we can consider this possibility, but I've always, I've taken a sort of baseline that the reference frame is a reference frame and it can't get distorted, because then you lose these desirable properties. And somehow we have to Yeah, I think that's why Yeah, it'll be interesting discussing. 'cause one of the things that I'm, I think it might connect to is with abstract spaces, by definition, generally they're distorted. like they're generally not gonna just follow kind of CLE space. And so like maybe these distortions are maybe continuum, maybe I, that's a good hypothesis, but I don't, I'm not willing to say that yet. I'm, I say I don't under, I'm, what I'm willing to say is I don't understand AppSec basis well enough to make any conclusions about it yet. and I am saying, look, I do know that it's very likely the neural mechanism is going to be the same. So if I'm dealing with physical objects and I have a fixed reference frame, I'm going to start with that assumption for abstract spaces, I just don't know yet. I just don't have a good sense yet for abstract stuff to make a conclusion. my intuition might say, Oh, yeah, things are moving around. But I don't trust them. I don't trust that.

Intuition is not really any kind of evidence for that. so I'm not, I don't want to, I don't want to reach that conclusion. but you could, No, that's fair. I think, you said there are two options, and then I think you didn't go into the second one, but I think the second one is actually how a lot of the graph neural networks work. would model things where, basically, we're not distorting the reference frame itself, like locations are still in a Euclidean space relative to a common point, but instead, depending on the state of the entire graph, you would expect each node to be in a different location in that reference frame. then, a node is a feature of the object, and then basically I can say the features of the object can move. In fact, I was typing it up just before we got here, this, the things that can, I've said this before, but I'll say it again. All, every single possible object behavior can be expressed as features moving locations, features changing orientation, features changing ID, and or, and this can happen at one or more locations independently or simultaneously, causally related. And that explains everything. every, kind of transition I can possibly imagine, even ones that aren't continuous, even ones with whole object changes, but all of them basically say that, the, that you're remapping the model. And those are the things that typically, like in the stapler, the features are moving. And they're moving locations and changing orientation, where something with a light, for example, the light turns on and off, that's a feature changing, it's a feature changing but it's not moving. anyway, so all possible behaviors can be represented by the idea that the graph elements, the features, move, change, and change orientation. Yeah. That's how I can think about it. I have a quick Okay, because that would actually be my preferred way of doing this, but I thought there was some concern around the feature, but Will, you go ahead first. Yeah, it was just, there was one thing that confused me, Jeff. You said that a feature can change its ID. I didn't, understand that. What does that mean? for example, It's, let's see if I can make a good example. I can make up a fanciful example. I'm trying to get a real world one. if you have Would it help if you said the node can change the ID associated with it? Here we go. Let's take, for example, I have, I'm looking at a screen and there's a letter on the screen, and then I push a button and the letter changes to a different letter. Same location, same orientation. It's now instead of A, it's B. The feature has changed from an A to a B. It hasn't changed location, orientation, or scale. or I could push a button and the letter A could move to the right, or I could push a button and the letter A could rotate. I can push a button and a bunch of things happen simultaneously, or one at a time independently. that's what I, that's an example of a, very simple example of a feature changing its ID. So yeah, I guess I feel like that's why the, I mean it doesn't have to be the word node, but I feel like some sort of terminology to capture the idea that there's a binding element, something that's gathering information, and that can both move, and the attributes associated with it, like feature ID can change. that's why I just, that's why my very first question to you is A feature? If A is a feature, then I'm with you. Okay, but, I think that was what is confusing as you, if what you're saying, or like asking about Will is if, that feature can change, is it the same feature? So I guess the, it's like, it's the same node. Even if the feature changes. now you switched the node to mean location. So but what if both are happening? what if you had, almost like a button that displays a letter on it, and that button can move around, but the letter that's on the button can change? As I said earlier, You take, let's say you have a model, you've learned a model in our classic way with a reference frame and features. each feature has an ID, each feature has an orientation and a location. And that defines a model, right? Any one of those components can change, and I can come up with examples, for each one or any combination. So it's possible that the feature can move and change orientation. It's possible the feature can move and change orientation and change ID.

or any combination of those things. It's basically Yeah I think that's pretty consistent with this, graph terminology, at least how it's used in that. Yeah. Is that a, like the node A can both change the features associated with it, but it can also move in space? Like without distorting the reference frame, it can just have a new location? I think that's what makes it, why, what, why is it a node? what makes a node, what's a node in that case? I guess it's a collection of information, how it's connected by edges to other nodes. you can say, in this case, this tape is a staple, you can say, oh, yeah, they're all connected to the hinge at B. But I came up with lots of examples where there's, no obvious connections at all.

it doesn't have to be a physical connection. It can also be a causal connection. but in this case, it's not clear that, the A and the B, it's, really, it looks very physical in this case. but, there doesn't even have to be a causal connection. I could just have a feature that changes on its own, just, whatever it wants to. maybe I have an object that randomly changes its color from, at some location from green to red. And, it's not moving, it's changing. I, I just, I think there's so much language associated with nodes, maybe it's just me, but, that we start using that language, all, you just slide into this thinking about graphs, and I'm trying to say, okay, given I have a reference frame and features, where is the graph you're talking about? A could be a feature. Yeah, I think it's, Like a proposed new language, from my view, it seems to fit pretty well what you're describing, but, I haven't heard that yet. I want to believe that, right? I do. I can say it's a feature, but you're not willing to say that. what if we say it's an object? So the ID of the object can change, the location of the object can change, the name of the sub object, which we do often call a feature. Can I try one definition?

What about defining a node as its feature at location that has edges? to other nodes. it seems to me that node is defined because of edges, because edges exist. If you don't have edges, you don't need nodes. You just have features at locations. So what makes it a node is, and there's, these features at locations have edges. all right, you could say that, but what, I'm in trouble with that too, because what does the edge represent? I could say there's two things that change that are causally related. I get that. That's good. if I just said the edge is a causal relationship, then I can see that maybe A and B are changing, and they're changing in a causal way. But I could still have a node A, which is just a feature at some location, and it has no edges. It's just basically, it's at the edges, it's location. That's what it is. it's located relative to everything else based on where it is in the reference frame. Yeah, maybe feature is a sufficient description. I think it's just, it maybe is confusing to others in terms of Or at least to me, in that, sometimes when you say feature, that just makes you think of, oh, it's just, the colors that are there. No, to me, a feature is whatever, I have a cortical column, and whatever bit pattern that's coming in that's going to layer four, I have no idea what it means. It's just, someone's telling me this thing exists at whatever location you're at.

and that thing could be an entire object. It could be, an edge on V1. It might be just a simple thing on the retina. but it could be an entire feature, that, that was represented hierarchically. But I guess the reason To move from feature to node is because now we want this thing to actually also be able to change location. So it's not just a feature, it's like a feature and location which can change. So if I have a pendulum, whatever is on the bottom of the pendulum is, it's a feature, but it's that can change location and the node that's connected to the top of the pendulum and okay so so the language i'm using exploits all those things but it doesn't assume there's a physical connection to anything there might be but it doesn't assume it I mean, the language I've said is that you have a reference frame and features, and those features can change, they can move, they can change orientation, they can come, they can disappear, a new one can appear, that explains, that describes every single possible object behavior you can imagine. And there is, there's nothing, it's complete, it's a complete basis of object behaviors, you can't, there's nothing else that could happen to an object. So I like that, from that point of view, I don't make any assumptions about anything else? just to clarify, so you would suggest instead of calling it a node, you would call it a feature? But I don't mind calling, I don't mind any language, but typically the word node means something else. and so it leads to lots of confusion. To me, a feature is nothing, I can't, don't try to picture what it is. it's just whatever is located at some location, and, it could be an entire object, it could be, it could be anything, it's just, in our models we have locations and, things at those locations, we've decided to call the things at those locations features. that's all it is, there's nothing else to it. Yeah, all right, maybe I'll, is it all right if I move on and then, yeah, I just, I just know, I think it's going to happen. it's, I'm just going to get lost on this and I'm not going to, it's not going to be meaningful to me, but I'll try. Yeah, let's keep going on.

yeah, we can maybe come back if it's, yeah, an issue, but yeah, so I guess one of the, the key kind of challenge to representing behaviors, is learning the properties of edges, for example, like a kind of rigid relation or, something more. Interesting. for example, with a hinge joint, I think that, some through kind of serial attention and knowledge of, what the close stapler would look like and attending to kind of movement at A, it would be reasonable to argue that, you're observing a single learning module is observing movement at A. It had some expectation about where B is. And because of the movement of A, there's now, a fixed distance, but a change in orientation relative to B. whereas versus C, it's, just moving, it's just, the displacement is continuing to grow. I'm not saying this is some sufficient or elegant way to learn it, but, hopefully this kind of captures just the, kind of basic idea that just, through the information that we're observing at a node and what we know about other nodes, or what we believe we know about other nodes, You might be able to infer some kind of relations or some of those edges, basically.

and I guess just, yeah. Oh, sorry, go ahead.

Bringing back what we, I think, discussed like two years ago. Yeah. The thing about this is that it, allows very fast generalization. if we learned an edge type before we can apply it to all kinds of other objects, where that type of edge exists, like a rigid relationships or a spring relationship, something like that. Yeah. Yeah. I think there's another way to do that. Same learning. but, I'll leave that for another day. Yeah, no, sounds exciting. but yeah, if it's necessary, just like another example with, like a hinge joint with a spring that's constantly trying to close the stapler, and again, A is moving, but this time on its own, and so there's a rigid relation still with B, but also some kind of closing relation, whatever's learning this doesn't need, whether it's a child or whatever, doesn't need to have some concept of spring. They just see that this kind of behavior happens again and again where the kind of hinges is closing itself.

yeah, okay, let me clarify this. Yeah, deforms is a function of, or, yeah, features, nodes move in the, which I'll get back to in a minute. But I just wanted to quickly contrast this with, oh yeah, and then one last kind of thing on like language that people may have come across. yeah. so in the sort of like graph networks, graph neural networks, literature, you'd often talk about message passing, and that's the dependence of one node at a time on the states of its neighbors from a previous time step. and you can iteratively pass these messages and see how the state of the network evolves. And then I think, an interesting thing just to think about is, hypernetwork, So a hypernetwork is a network that generates weights for another network. But so you can imagine how, as Viviane was just saying Weights, weights being what? Weights being like weights in a normal network? if, yeah, so if you assume that, what you call it, the way that this edge is encoded, like the way this, the influence of this, And the last feature, on this feature, takes place is via some weights. Those might not be A neural network. A neural network. Yeah, like a neural network. Okay. Those might not be always the same. they might change. And one way to change them in a deep learning setting is to generate a set of weights. But I'll touch on later how this, might connect to more SDR style HTML. weights.

and then, but yeah, but just contrasting this kind of graph view with a kind of global sequence view of behavior, which, if, I think we've discounted now, but that isn't to say that sequences aren't going to be, useful, and I'll come back to that, but so I think this is how we sometimes would talk about, behavior before, where you have a storage sequence of full object morphologies. So you have a morphology of time equals t, zero, and then, a hundred others or whatever, and then time equals t, but, that's lots of information to store that the amount explodes with the degrees of freedom of, the behavior, and it's, I think, to the points you had raised on Slack recently, Jeff, it's hard if, because the single LM generally only observes part of an object at a point in time, I also felt that objects have, don't have a global, state. Yeah, or at least not one that Constraints that is so specific, like this one is it's a, fully defined state with all the features and everything. I agree, even this one was not fully defined, it's a poor example, but I talked about the deflection plate at the bottom there, and there's a state of that deflection plate, it can be, in one of two positions, or it can be in the process of rotating between those positions, and that deflection plate, It's completely independent, it's behavior is completely independent of the stapler top. There's also typically a staple, have a way of removing the staples, which is, it's sometimes it's a spring at the back, sometimes it's in the top, but that's also somewhat independent.

and I can come up with lots of examples where objects have lots of independent parts moving in a car. The doors are open, the hood's open, the windows are down. these are all. The car has like a zillion possible objects and parts of it that are in different states. So there is no global state for a car, or state. So that tells you, you have to have the state for individual features or components. and it has to be on a location by location basis.

Yeah. Yeah. And yeah, I definitely also would agree that a state like this isn't, what we want. but yeah, okay. So that was brief discussion of behavior, sequence of states. What about space?

and so one way we can think about kind of reference frames and how morphology is represented is what I'm going to tentatively call an embedded graph. So features at locations in a reference frame, where this is embedded in, some defined space like Cartesian space or grid cells. and this is what we're currently doing with features at locations.

And, but yeah, as discussed earlier, you could have the features change as a function of time or, someone pushing in or whatever, their location in this, embedding.

and, yeah, this is the advantage that, you can generalize to novel displacements. So it's You don't have to do the exact same displacement as you've done before, if you just type out certain things. I don't understand that, generally, it's a novel displacement, what is, with the position of the, what do you mean by displacement? So now I'm just talking about, if you forget about behavior for a moment, just thinking about how you path integrate over the object. Okay, what's the word displacement referring to in this case? So you can take a movement of. a larger or smaller amount, for example, than you have previously. Is this displacement the angle of the top? Is that what displacement is representing? No, the displacement is the movement of the sensor. Oh, okay. That's what I mean. This is now nothing to do with behavior. This is now a sensor moving over the object. Okay. All right. All right. you're showing the state plane. okay. the general advantage of grid cells is they pass, integrate, and you can do that in novel directions, novel displacements. Yeah. Okay. Adis. Yeah, sorry, I did think about changing the object to something that didn't have a clear behavior, since we're just talking about path integration here, but then, anyways. I just, I don't often use the word displacement, so I'll just say, movements, path integration movements. Yeah, okay.

Question? But, yeah, sure. And we're still talking about space reference frame per object, right? So it's not luminiferous ether out there that everything is in, it's Cartesian space per object, it's grid cell space reference frame per object, yes?

So yeah, so I guess for us, we're currently representing, I guess it's, yeah, it's a unique Cartesian space per object. In the brain, you'd the grid cells would, encode multiple objects in their kind of distributed code. this stuff probably would work. Be careful because It, we've done the same thing in two different ways here. the way we've done it, if I understand it in our code today, is we've just picked different places in a very infinite space, and we've said, oh, over here is where we're going to represent staplers, and then over here is going to represent something else. And so these, they're in some sense in the same universal space, but they're so far apart that there's no interaction between them, right? So if I know my location, I know what object I'm on. And grid cells achieve the same result, but in a very different way. and if you don't know it, I'm not going to be able to describe it right now, but you have the same set of cells, but, but the combinations are that once you've locked onto an object, the patterns you'll see in those cells are unique for that object and you won't see the same pattern on any other object.

So it achieves the same result in a different way. But they're both achieving, essentially saying you have a, in some sense, a universal way of representing space, it's a finite set of resources to represent space, but when you actually represent an object. You've, locked into a particular part of that large space that, that, only exists for that particular object in both grid cells. Yeah, was your question, Do you have a concern, Tristan, or, No, just checking, just wondering. Okay, yeah, It's very different than what we typically think of Cartesian. This is really a really important point, Tristan, so I want to make sure everyone gets it. It's not oh, here's, we have some three dimensional space, and we're going to represent an object in one moment and another object in that space, another moment. It's like the objects are so far apart, and that you'll never get between them. it's technically you could, but it's infinite almost, you can't.

so they're like completely different spaces.

I hope that makes sense. Yeah, I guess just in case, to match it exactly with the code, it's not like in the code we move them at like far away distances in the same space. The objects are actually all represented around like a 0, 0, 0 location. I thought, you told me, I'm sorry, I thought you told me that, I thought you said no, the points are totally unique. We could do it that way. It's like mathematically equivalent. Each of them are basically their own space. So it's basically like that reference frame has a unique prefix and you would only index that reference frame if you're looking at this object. So like we could ever move like a large distance and accidentally get into a different objects area. I see. I see. That's not as powerful as I thought it was. You're basically using the object idea as an index. to, say, okay, now this reference space is representing object A, is that what you're doing?

if I understand you yes, but it, it, would be pretty much equivalent to putting them at very far distances. Like we couldn't put them at very far distances. It's basically, we have these different hypotheses of where we could be, and either we put the hypothesis of being like at very far away distances in the same space, or say, we could be. at this location, in this reference frame, or at that location, in this reference frame.

so if I want to predict what feature I should expect to see, I just can't look at the location. Is that right? Yeah, you could. it's How? Basically, if you would imagine, each of the locations Having a unique prefix depending on what object it is. So you're basically using an object ID to, say what, how do I interpret this space? Okay, I get it. That's not what I thought you were doing. But it's almost like a fourth dimension that we move along, or I don't know. I, it's not. But yeah, it does feel like it would be equivalent, except for the slight risk of interference that we don't. No, I'm not sure it is, maybe it isn't, but one of the things that neurons do is they, I mean in some sense you need to know that prefix to do anything, and that prefix is, I assume, a hard coded prefix, it means that you have a prefix that represents cups and a prefix that represents staplers. Is that correct? But you don't need to know it, you can test different ones at the same time. Yeah. I thought it would be equivalent because if we place them very far apart, we could do it exactly with a prefix, like adding whatever large number in front of it. Maybe, This, and I don't understand the neurons well enough in this case, but. when we're trying to do inference, it might make a difference under certain circumstances. I, didn't catch, I see what you're saying, Viviane, how you think of prefixes just like more bits in space. it's not clear to me whether that's equivalent or not. I'm not going to accept that yet. Okay, I'll let that go.

so yeah, so just the last thing to say with these kind of embedded graphs is. like this works really well with kind of 3D Euclidean space, but it's a bit more confusing how we would, embed abstract or arbitrary, spaces into this, like a family tree or whatever, if this is substrate that we're, using, like, how do you understand that certain parts of space connect you to other parts in space, but others don't?

and yeah, I won't go into this too much, but yeah, just that there's some evidence that these grid cells can distort, but I think it's a fair point, Jeff, that this is generally not, very significant. I do think a better way of, doing what we were talking about before is just having that, features basically can move in this, kind of space.

but then the other kind of way of, conceptualizing space is graphs as sequences. and this is actually quite related to what we tried for a bit, in Monty in before many people joined, in fact, before I joined, which was, features of displacements, where you learn space as a sequence and build a graph, from that, and this has the kind of advantage that you can, like in, in, normal kind of 3D space in the real world, generally those, displacements or kind of movements are very simple and follow, the same behavior you'd expect here, but you can imagine in some more complex or more abstract spaces, sometimes you can move between, points and sometimes you can't, and so that will those displacements will carve out the space. this potentially, yeah, abstract graph like structure, and it's important to note here the, these kind of green arrows, these aren't the same kind of edges that were in the earlier plot, like the earlier edges were about how one feature at a point in time influences other features, neighboring features at a point in time, so that's like a causal relation. This is a, connection in movement, like this is the fact that you can move between one of these to the other by following. this displacement, but what we found with the, when we tried to do this with the features of displacements learning modules was that this kind of, this tends to struggle with, novel displacements, in the sense that you, end up trying to match these movements exactly, which is fine if you're operating in a discrete grid world where you're always going like up one, right one, whatever, but you can imagine if you move only. One centimetre or 1. 5 centimetres instead of the three or two centimetres you did when learning. it can be hard to, match these.

yeah, I've been trying to think about some sort of like hybrid stuff that might address a bit of this. But, but yeah, I didn't make as much progress as I wanted. So I'll talk about that another time.

This could be, this could be very confusing for people who haven't been here in the past. Basically, we were trying to represent models. And there's two ways, basic ways, you can do it. You can say these features are at some location in some reference frame, or you could say these features are at some displacement from each other. Of course, if you're trying to figure out, physical displacement, like Niels was saying, some direction, distance, and there's a real power in doing physical displacements, but there's a combinatorial problem of, obviously if you have a lot of features, the trying to represent the displacements between all of them is impossible to learn. It takes too much memory. And so there was a, we were struggling, what is the basic representation of an object?

yeah, these are the two options we were looking at. Yeah, and this was actually the very first learning module that was implemented in Monty. And it had some really nice properties, doing it this way, we can actually represent displacements in a rotation invariant way, We could recognize objects in any rotation without test, specifically testing rotation hypotheses and like going through the different options. there were some nice properties of it, but yeah, like Niels and Jeff said, the issue was it's not really integratable. We couldn't take new movements that weren't stored in the graph.

Yeah. And that, I guess for what it's worth, if you are operating in a discrete kind of grid world where, you know, something like this, where You can only move up by one, left by one, so forth. That, those kind of issues go away. and so this, kind of approach has been used a lot, for example, in Duleek George's work, this close, oh, I was about to say, clone, structured cognitive graphs, and the Tolman Eckenbaum machine, which are ways of showing that, if you visit all of these edges, Even if it's a kind of complex graph, you, can build this representation and, then you can path integrate on this and, you can follow, not even though you visited every edge, you can follow an entirely novel path.

but the, for example, in this one, the way it's being learned is actually with this kind of, sequence memory that's definitely has similarities to, hierarchical temporal memory in that, although it's, this doesn't look like a sequence, If you basically follow a sequence, you can build up all of these edges and that forms like a graphical structure.

then going back to behavior, and trying to bring this together. now if we're looking at this, model again where, okay, now the edges are representing more causal relations doing these features, the kind of local states associated with a feature, or a node are gonna follow a sequence like this. Over time, and that's going to depend on, as things we talked about earlier, like the local actions, incoming states and edges, and then I do think it, it still makes sense that there's some global states that's pooled from all of the local states. So it has some information, but it's, not like a one to one mapping between yeah, this base plate or whatever. What's your argument for that? Why do you think there's a global I guess the main thing is to pass that information up the hierarchy. Because in the same way that this state is, the state of the learning module lower down in the hierarchy, so to summarize that the stapler is closed is useful information when I'm looking at my office desk. Although, as I said before, this is problematic because there isn't a global state. And I can imagine an object that has multiple different types of states. And in one context, one of those states is important to pass up. In another context, a different state is important to pass up.

and, I don't have a solution to that, but there isn't a global state.

I guess I feel like it's like object ID. So I put together a slide for this point, which, you know, just in terms of you can have changes, subtle changes in morphology and, but the, kind of object is still going to be the same object. it's still a mug. and so forth, and knowing it's a mug does not tell you exactly where every feature is on, in space, in the same way that knowing the, global pooled state doesn't tell you the state of every local element, Yeah, I think the answer to this question is the, whole trick for compositional structure was that even though we do, we, we can pass up, an idea of the feature, this is a, there's a, logo at this location on the cup, but, but it's actually the pairing is done by location basis. So on the back path, the downward path, we associate the location of the parent object with a specific location on the child object. Therefore we'd be associating, in this case, we'd have to be associating a specific state, a lo, a state of a particular location on the child object. So it's, not clear to me. I have to pass up, the state of the object to the parent, and maybe I do, but it's, but it by passing, by pairing the location on the parent with the location on the child. I, now basically can specify the local state of the child, object. I can follow that. actually, I think that's useful. again, in the same way that it's useful with the object ID and morphology, like it's useful to know the overall object ID and it's useful to know where you are on the object. Not just useful, it's essential. If I'm going to make a prediction about something, it's, if I'm going to make a prediction, I have to do that. Yeah, that was a whole compositional object struggle. But yeah, I guess to me, it's still, it feels like, yeah, that providing that information like L2, L3 or something so that Like it is just, yeah. I important for, oh, I, I think, the answer's gonna be different. yeah. I think the answer's gonna be, 'cause this is what the surprise of the composition structure was, is, that I don't pass up the state to the parent, but the parent associates its location with the state of the child.

the, I'm not, I can't say of certain yet, but that would be the, yeah, my guess that's what's gonna happen. Yeah, I guess it'll be clear when we get back to the, motor policy. Just remember the state, again, if you accept the fact that there are different states for the state, but they're not all tied together, and many objects have lots of states, a car, I can, and, the parent object can't know what those states mean. That's the whole point of it. The parent object can't, if I'm, a car, if I'm representing a car, I, can't represent The window at the same time, and whether the window is up or down, or whether the door is open or closed. You might represent, the car's on, or there are things that I would know about the car, but I can't accept all the individual states of the features of the car. I have no way of interpreting them. I don't want to store them. The whole point is I can't store everything everywhere. So I think No, I agree with that. I was started where you were in Neil. I was originally think, oh, we have to pass up the state. I'm not so certain of that now. And, yeah, and I, think I, I'm actually working on the assumption I don't have pass up the state. so if we have a. more global state. How would like more, broader state information spread? So for example, if I touch an object and I recognize its temperature, like I have a coffee cup and I notice it's warm just from touching a small part of it, I immediately know that the whole circumference of the cup will be warm. let's, take a more, I think that's a little bit more, it's an example of one that's, I can come up with a simple example that has the same problem. How do I associate?

of some observed feature or change in feature, let's, say with, a change in, a feature in another modality or on another part of the object, it gets back to the lamp, right? I press a button on the lamp, how do I associate that with the light turning on? They're in different locations. In fact, I might press a button and the light turns on in the next room.

I have to be able to associate these, these changes, and I can do it across modalities.

I think that's a broad, I'm trying to, I think that's the same question you're, it's actually the answer is the same, I'd say, what you were suggesting, Viviane. which is I touch it, warm, how do I know it's warm everywhere, type of thing.

we have to learn these things.

anyway, that's what I'm working on right now, and I think you can put some parameters on it. So I think, you know what, imagine a, whole bunch of columns and some of them are observing changes at this moment in time. Things are changing, what they're observing and some are not.

let's say, we have a voting mechanism. It's not, a, voting's not the right word. We have a, long distance connections. And if two columns, no matter where they are, if their state is changing, at the same time or in close proximity in time, we would, we might want to just associate the two. Let's say, hey, when this, these two changes occur at the same time, and, and they could be in the same modality, in different modalities, one could proceed, the other could follow, there could be a slight delay between them, if there's a bigger delay then you wouldn't catch it, you wouldn't catch the causality there. I think there's a general question is, if a column observes a change, how is it associated with other changes in other columns, whether they're nearby or far away? And that's a pretty simple mechanism to do. I'm working on that hypothesis right now. And then you can learn sequences of those as well, using the sequence memory we have. So I could say A follows B follows C and so on, in different locations or in different modalities.

it's a very different language than you're talking about here with graphs and so on. Just, at least I think about it. Yeah. Yeah, unless you wanted to ask more about that, Viviane, I've just got a few more slides I can just finish. Yeah, go ahead. I don't know if we were talking about the same thing or not. yeah, anyways, global states may or may not exist, but anyways, if they do exist, they could follow some sort of sequence over time. And then, yeah, the morphology, as said, or how, a movement is going to map onto where, what you're going to observe, is going to be influenced by It is going to change as a function of the local state, so as in, as this moves, if you're on B and you move up here, you're going to predict something different versus if this hasn't moved. and maybe that's changes in or to the graph space, or maybe that's related to changes in the sequence describing the space, like this kind of, this more kind of view of space.

so it just felt like thinking through this that, a lot of things, in bold here can potentially just come down to sequences. and I guess this was interesting for me because often when I was thinking about this kind of more graphical representation of object behavior, I was still thinking a lot of it about in the, kind of sense of nodes interacting and, that sort of thing. Like in a graph neural network, I wasn't really thinking about it as sequences, but it feels like it could generally all be framed as sequences, but it's just important that there's local sequences and these sequences are dependent on one another. If, by sequence we mean, time based, one follows the other, Is that what you mean by sequence? Yeah, but also conditional on other things. So, the sequence transition. Yeah, couldn't be conditioned on an action. I conditioned the state of neighbors. there's lots of ways, yes, but so the way I've been working on this and thinking about it is that sequences sometimes occur, and temporal sequences occur, and we have to be able to learn them, but often, state changes, are not temporal sequences. Things can happen simultaneously and change all at once, and that's it. There's no sequence. There's no time involved. The features of an object can change, and then it stops. And, but sometimes those things Yeah, so I guess it's not always like time, but, something has to change. but it could, but it, there's basically causality in space and causality in time. And both of those can occur in any combination.

several things can change all at once. And I say, oh, they're correlated because they consistently change all at once. Or I could say these things change in sequence. And therefore, they're a sequence, but, but I don't think everything's a sequence. That's why I said, are you meant by sequence time? I think not all, lots of examples, I'm, I can come up with examples where time is not involved. but sequence is in a state changing from, to another state. that's why I asked you if it was time involved. Okay, sorry, I, when it So changing to another state I answered that incorrectly. One says that actually time has expired, and just one says things change simultaneously.

you call it, to me the word sequence implies more than one element changing, right? You've got a series of things. but there are behaviors where there is no time involved. you're just saying, then I wouldn't use the word sequence. That's, at least it's confusing to me to use the word sequence for that. Interesting. Okay. that's why I said, is time involved? Is there a sequence of elements? Is it some time expire? Not necessarily. yeah. Okay, but that's why I asked, because I said, that's how I interpret sequence. I guess time is always involved in the sense that, nothing can change without some infinitesimal small amount of time. yes, time is involved in that sense, but it's not, like A sequence of oh, every one second something happens. All right, often things are like that. The stapler opening is a sequence. They can be, but I'm saying that's not what I'm saying all sequences are. I've learned over the years that I have to challenge every word because I know often we use the same word for different things. And that was the very first, you used the word sequence, I said, what did you mean by sequence? Is it a mean? I meant, does it mean a time sequence? and, because there are lots of examples, we can't rely on that. there are many examples where there is not a time sequence. Yes, obviously time has expired, but It's not like a series of elements over time, like the stapler top. many things are like that, but there are examples where things aren't like that.

So I guess just one thought, irrespective of whether time is involved or not. one thing that I always worry about a bit with representing your sequences, but I think I already mentioned in, when I presented some slides before, it might not be a problem actually, is that sequences are a bit similar to displacements. So if you have just a, just one degree of freedom where you have the stapler opening and closing, it's easy to imagine it as a sequence. But if you have more than one degree of freedom, like a joystick that can move in all directions, it's a bit harder to imagine how that's modeled with discrete sequences. But then one thought I had was like a lot of these things, we might actually be able to learn all the different sequences and we could have like small sub sequences like moving left to right, to left, up to down. Exactly. To all the joint type sequences. Objects. So I think it's practicality. I think that's what I mentioned before is I couldn't think of an example where we would encounter a completely new behavior where we couldn't have learned all the possible sub sequences.

Maybe that's not an issue, but just to throw it in there, that with sequences, it seems like we would have to at least once observe all the possible sequences to be able to path integrate. Yeah, and it basically, it's similar to observing all the edges in this sense, but if you just do that in a local one, and there's some way you can generalize that. to, to broader spaces than it's less of an issue, because yeah, I agree. Otherwise it's, way too many states to learn. one of the nice things about the, HTM sequence memory is that, it, it always tried to learn, indefinitely long sequences, but if it doesn't get exposed to, it, it'll learn shorter segments. you might say, start off by saying, hey, I'm, I'm learning how this joystick moves through some space. But it doesn't repeat, and the only parts that repeat are local actions. and so it just picks that up automatically, you don't have to, that was one, I'm just pointing out that it's a natural property of the network, it, figures how much it can learn, and, and, it'll expand beyond that if, there's some long sequence, that you repeat over and over again, it'll learn it, but mostly it'll just learn the short subsets that it sees often enough, so it just handles that problem nicely. Yeah. Yeah, and I guess on the HTM stuff, it's definitely not a developed thought, but just By the way, what I want to think more about is Can I, ask a favor? when you say HTM, it doesn't mean anything to me at this point in time. So we have the sequence memory, we have the neuron model, on its own, it doesn't mean anything. So if you want to say the HTM sequence memory, I know what that means. If you want to say the HTM neuron model, I know what that means. But HTM is a thing, it doesn't mean anything to me. overloaded, yeah. the sequence memory. Okay, so we need to say But in, in the way that could be like conditioned on object ID, it just seems like that kind of conditioning, which was implemented via the dendritic prediction and stuff, could naturally be useful for things like conditioning on, states of neighbors, conditioning on actions. conditioning on global state. Basically, I look at it a different way than you, okay? I just look at it as if I have a neural representation of something and it changes in a consistent, in a repeatable way, it'll learn that. So anything that transitions over time and repeats, it'll learn it. you know what, you can put like global state or actions, I don't know, are these things changing over time? If they're changing over time, it'll learn it. if it's repeatable. I'm just saying, you and I have very different mental pictures in our head when we use these words. I can tell that. and, and, I'm just, it's hard for me because I have this picture in my head and you're putting these words out there and I'm like, oh, do those words represent what I'm thinking? I don't know.

yeah, I guess what I'm trying to in, in the original temporal, sequence memory, you had the kind of. L3 layer with the object ID, and then you were going through different features, and depending on which object it was predicting via the 8th as I remember, different, different, SDRs for those features. and that was, the kind of unique, unique, fingerprint for the different, It's the same, the, sequence memory is exactly the same as the using the reference frames and the features of reference frames. You have a series of SDRs that all represent the same object. And then you do temporal pooling, saying, okay, these all have to map to some constant ID. So whether it's, whether the sequence is determined by movement of the sensor and what you sense, or whether it's determined by time, it really doesn't make any difference. It's a sequence of SDRs that get pooled to the same ID. So it's really the, it just says there's two ways you can, you can represent a unique, you can find out a unique representation of a point in space and that's one through time and one through movement of the sensor and keeping track of the location. Yeah, maybe it'll be helpful at some point, I can put together a slide actually showing diagrammatically what I mean.

I just want to make sure that's also important for the new people here. It's the sequence memory in our, memory reference frame are really just two flavors of the same thing. They're just really not fundamentally different. In fact, Subutai wrote a paper on that, I think.

How you can mix and match them, they just naturally combine together.

So for example, imagine I move my finger over an object in the exact same order every day. it'll learn that. It'll learn that as a sequence, like a melody. but the first time I didn't have to do that. I could have put my finger in random order. It's all, it just all changes the same result. That may not help.

Okay. That was, that was everything I had, though. yeah, I'm just trying to find the paper, but, we can do that another time. I want to try to reconcile what you're presenting with how I'm thinking about this, and, and I think I need to do a similar presentation to what you did, and I need to say, here's how I'm thinking about these same issues, and see if we can come to some agreement on them.

I'm working on that. I wasn't working on the presentation, but I'm working on the ideas, so maybe, I can present that next week. Is that okay?

Yeah, that's good. My presentation won't be nearly as nice as yours. probably just, words, but, but maybe I'll throw a few images in there.

I think, during today's conversation, I threw a lot of the ideas out there because I'm trying to match them up to what you're presenting. I want to come to, reach a consensus on this.

okay. Yeah.

Yeah, I'm just thinking. Yeah, I hope, Yeah, I hope I didn't assume too much in terms of, HTM and stuff. I didn't, it's helpful. I just thought we could look briefly at, at this. Helpful for who? I made this figure, so it's not going to be helpful for me, but maybe other people. Yeah, I'm also reminding myself, but, Yeah, maybe this is better for another, meeting. I'll just, I'll try to do a recap of HDM sequence memory and then how it might be related to, sequences of behavior states. Again, I'll say it again, just maybe repetition might help, I don't know, you got a layer of neurons that are representing something in a sparse way, and, and the sequence, the HCM sequence memory was basically explaining how you might come up with a sparse representation and what would happen if, you went through a series of these SDRs in the same set of neurons, and they could learn arbitrarily long, high, order sequences in a very powerful way, and make predictions about what's going to happen next.

and it does it in a very simple way that matches biology beautifully and explains a whole bunch of stuff that no one explained before. that's all it does. And so I'm constantly thinking oh, I got to know, if I have a variable, a state variable, that's, changing, that, that, state variable is going to be on a location basis. Thank you. Or it can change on a location by location basis. And that state variable now is, is also changing for whatever reason, then I can learn sequences, if it changes in a consistent way. and if it's not consistent, then I wouldn't learn sequences. So that's how I'm thinking about, learning behaviors and learning causal relationships behaviors and all this stuff in the back of my mind.

Oh gosh, that's, this stuff is hard.