[
    {
        "text": "I guess like I posted, we thought\nwe could talk a bit about depth.",
        "start": 9.456,
        "duration": 2.35
    },
    {
        "text": "I have a few slides I can go through.",
        "start": 12.676,
        "duration": 1.32
    },
    {
        "text": "and yeah, Hojae, also put some stuff\ntogether on, structure from motion and",
        "start": 15.026,
        "duration": 5.36
    },
    {
        "text": "then yeah, but we, I thought we can start\nby talking about the thing I found most",
        "start": 20.386,
        "duration": 6.96
    },
    {
        "text": "confusing was just how parallax works and\nhow it relates to Monty and really just",
        "start": 27.346,
        "duration": 4.42
    },
    {
        "text": "to think through it in concrete terms.",
        "start": 31.766,
        "duration": 1.77
    },
    {
        "text": "And then, yeah, eventually this\ndiscussion could maybe get into",
        "start": 34.456,
        "duration": 4.1
    },
    {
        "text": "like, where's this happening in\nthe brain and things like that.",
        "start": 38.556,
        "duration": 2.56
    },
    {
        "text": "And,",
        "start": 41.116,
        "duration": 0.2
    },
    {
        "text": "but yeah, unless,",
        "start": 44.796,
        "duration": 0.92
    },
    {
        "text": "any objections, I'll\njust get right into it.",
        "start": 48.026,
        "duration": 2.0
    },
    {
        "text": "so yeah, I posted some notes, in the\ngroup about kind of various things",
        "start": 54.866,
        "duration": 4.34
    },
    {
        "text": "I'd, I've been reading about depth\nperception and, that was like a broad",
        "start": 59.206,
        "duration": 5.24
    },
    {
        "text": "view of, everything from monocular to.",
        "start": 64.456,
        "duration": 2.24
    },
    {
        "text": "Binocular cues and things like that.",
        "start": 67.171,
        "duration": 1.81
    },
    {
        "text": "but I thought the kind of key thing or\nlike one of the most important things for",
        "start": 70.761,
        "duration": 3.89
    },
    {
        "text": "like actual, fine grained depth perception\nand, also I, I felt like one of the more",
        "start": 74.651,
        "duration": 6.88
    },
    {
        "text": "kind of, less clear kind of computational\nthings is, the role of parallax.",
        "start": 81.531,
        "duration": 4.52
    },
    {
        "text": "So I just put together some\nslides discussing that and then,",
        "start": 86.061,
        "duration": 4.62
    },
    {
        "text": "some stuff discussing how it\nrelates to active perception.",
        "start": 90.931,
        "duration": 3.09
    },
    {
        "text": "of the, and inference of depth.",
        "start": 94.811,
        "duration": 1.96
    },
    {
        "text": "but yeah, definitely stop\nme if anything's unclear.",
        "start": 99.161,
        "duration": 3.12
    },
    {
        "text": "Sounds great.",
        "start": 102.291,
        "duration": 0.68
    },
    {
        "text": "I feel like I'm, I feel\nlike I'm back in college.",
        "start": 103.051,
        "duration": 1.73
    },
    {
        "text": "I'm like, yeah, basic, lecture here.",
        "start": 104.781,
        "duration": 1.85
    },
    {
        "text": "It's great.",
        "start": 106.631,
        "duration": 0.56
    },
    {
        "text": "Yeah.",
        "start": 107.491,
        "duration": 0.19
    },
    {
        "text": "so parallax basically just refers to\nwhen you have, two different views.",
        "start": 111.861,
        "duration": 6.38
    },
    {
        "text": "here it's, in space, but it could\nbe in time with kind of motion,",
        "start": 118.941,
        "duration": 3.77
    },
    {
        "text": "but two different viewpoints.",
        "start": 122.761,
        "duration": 1.24
    },
    {
        "text": "and they're viewing two different,\nimages of approximately the same thing.",
        "start": 125.636,
        "duration": 4.0
    },
    {
        "text": "Any kind of displacement or,\nkind of change in that image.",
        "start": 130.236,
        "duration": 3.7
    },
    {
        "text": "is generally what's referred to as\nparallax, so in this example, if you",
        "start": 134.896,
        "duration": 4.71
    },
    {
        "text": "imagine this, is just some kind of\ntelescope, or it could be whatever, camera",
        "start": 139.626,
        "duration": 6.09
    },
    {
        "text": "looking out, and then there's this other\none, these are the kind of viewpoints,",
        "start": 145.716,
        "duration": 4.77
    },
    {
        "text": "these are the kind of the views that would\nbe perceived at these two, locations.",
        "start": 150.846,
        "duration": 3.78
    },
    {
        "text": "And if you imagine these objects are\nvery far away, at infinity, they're",
        "start": 155.251,
        "duration": 4.41
    },
    {
        "text": "going to be coming into, these two\ndifferent, locations basically in",
        "start": 159.661,
        "duration": 4.53
    },
    {
        "text": "parallel, there won't be any difference,\nand so the same image is perceived,",
        "start": 164.231,
        "duration": 3.77
    },
    {
        "text": "whereas this much closer object, it's\ngoing to be perceived on the right",
        "start": 168.481,
        "duration": 4.05
    },
    {
        "text": "hand side, for this, viewpoint, and on\nthe left hand side for this viewpoint,",
        "start": 172.561,
        "duration": 4.26
    },
    {
        "text": "and so that's the kind of shift\nthat's happening, this kind of shift.",
        "start": 176.831,
        "duration": 2.542
    },
    {
        "text": "Okay.",
        "start": 179.373,
        "duration": 0.042
    },
    {
        "text": "of the, star.",
        "start": 180.656,
        "duration": 0.54
    },
    {
        "text": "that's the basic idea.",
        "start": 185.326,
        "duration": 0.87
    },
    {
        "text": "I guess it's worth saying that if you had\na bunch of objects at different depths,",
        "start": 186.731,
        "duration": 2.915
    },
    {
        "text": "they would shift different amounts.",
        "start": 190.166,
        "duration": 1.41
    },
    {
        "text": "So they would sort themselves in\norder, in some sense, distance.",
        "start": 192.626,
        "duration": 3.11
    },
    {
        "text": "Yeah.",
        "start": 196.246,
        "duration": 0.37
    },
    {
        "text": "And the other thing is we tend to, because\nwe have mobile eyes that move, we tend",
        "start": 197.196,
        "duration": 5.73
    },
    {
        "text": "to fixate on, the object of interest.",
        "start": 202.926,
        "duration": 3.04
    },
    {
        "text": "and so to generally think about\nit the way we view the world.",
        "start": 207.146,
        "duration": 4.35
    },
    {
        "text": "is, imagine we have our kind of mobile\neyes, we're fixating on an apple, and this",
        "start": 212.366,
        "duration": 6.74
    },
    {
        "text": "apple then, or at least the center of the\napple, is going to fall on the fovea of",
        "start": 219.106,
        "duration": 5.26
    },
    {
        "text": "both of these, both of our, eyes, and so\nthere won't be a disparity for the apple,",
        "start": 224.406,
        "duration": 6.62
    },
    {
        "text": "because of this.",
        "start": 233.106,
        "duration": 0.76
    },
    {
        "text": "So this is different from\nthis kind of situation where",
        "start": 233.916,
        "duration": 2.32
    },
    {
        "text": "you're fixating that infinity,",
        "start": 236.236,
        "duration": 1.62
    },
    {
        "text": "and disparity, which is a term\nthat's often used, is I don't think",
        "start": 240.956,
        "duration": 5.16
    },
    {
        "text": "anyone's super consistent with the\nterminology, but I think the best",
        "start": 246.116,
        "duration": 3.72
    },
    {
        "text": "way to define it is essentially like\na computed estimate of the parallax.",
        "start": 249.836,
        "duration": 2.99
    },
    {
        "text": "So parallax is a property of\nthe world, a property of optics.",
        "start": 252.836,
        "duration": 4.47
    },
    {
        "text": "Disparity is what is the retina\npicking up in terms of, the relative",
        "start": 257.766,
        "duration": 4.5
    },
    {
        "text": "difference between, where an object\nis falling in these two images.",
        "start": 262.266,
        "duration": 5.27
    },
    {
        "text": "and as I said, because we can move our\neyes, there's no disparity, at the,",
        "start": 270.026,
        "duration": 3.92
    },
    {
        "text": "fovea for the item we're fixating there.",
        "start": 274.356,
        "duration": 2.31
    },
    {
        "text": "but there is disparity for the orange,\nand that can then tell us something",
        "start": 277.986,
        "duration": 5.43
    },
    {
        "text": "about its, relative depth to, the apple.",
        "start": 283.416,
        "duration": 3.36
    },
    {
        "text": "but then what's interesting is that,\ngenerally that's not sufficient.",
        "start": 289.946,
        "duration": 4.7
    },
    {
        "text": "So this kind of gives you some sense of\nrelative depth, but you can see how in",
        "start": 294.646,
        "duration": 5.04
    },
    {
        "text": "different instances, instance A, where\nboth objects are far away, and instance",
        "start": 299.716,
        "duration": 5.385
    },
    {
        "text": "B, where they're both closer, the relative\ndisparity sensed for the orange, is",
        "start": 305.101,
        "duration": 5.9
    },
    {
        "text": "the same, based on these angles here.",
        "start": 311.011,
        "duration": 2.35
    },
    {
        "text": "And in general, this is combined with\nsome additional depth cues, such as",
        "start": 315.021,
        "duration": 4.29
    },
    {
        "text": "like how turned in your eyes are,\nhere they're turned in much more, so",
        "start": 319.311,
        "duration": 3.88
    },
    {
        "text": "that implies your point of fixation\nis closer in space, here they're more",
        "start": 323.191,
        "duration": 3.36
    },
    {
        "text": "parallel, so that implies This only\nmakes a difference if you're trying to",
        "start": 326.551,
        "duration": 3.09
    },
    {
        "text": "figure out the actual distance, right?",
        "start": 329.641,
        "duration": 1.61
    },
    {
        "text": "it's still Yeah.",
        "start": 331.461,
        "duration": 0.91
    },
    {
        "text": "It's still figuring It still is\naccurately replying the relative distance.",
        "start": 332.451,
        "duration": 3.31
    },
    {
        "text": "It's still saying which ones are further\naway than others, which for a lot of",
        "start": 336.651,
        "duration": 4.68
    },
    {
        "text": "tasks, that's really all you need.",
        "start": 341.341,
        "duration": 1.18
    },
    {
        "text": "Yeah.",
        "start": 345.271,
        "duration": 0.21
    },
    {
        "text": "If you're not like\nreaching to grab something.",
        "start": 345.481,
        "duration": 1.95
    },
    {
        "text": "If you're just trying to, decide\nwhere the boundaries of an object",
        "start": 348.911,
        "duration": 3.71
    },
    {
        "text": "are or something like that.",
        "start": 352.621,
        "duration": 0.8
    },
    {
        "text": "but one kind of important thing\nfor this to work is the eyes, the",
        "start": 357.881,
        "duration": 4.93
    },
    {
        "text": "retina or the eye or the brain kind\nof whatever level it's happening.",
        "start": 362.811,
        "duration": 3.14
    },
    {
        "text": "the kind of know the commonality between\nwhat's being perceived in the two eyes.",
        "start": 366.626,
        "duration": 4.0
    },
    {
        "text": "in order to sense that the orange\nhas shifted, across these images,",
        "start": 372.296,
        "duration": 5.11
    },
    {
        "text": "you actually need to understand that\nit's the same object that's there.",
        "start": 377.736,
        "duration": 3.27
    },
    {
        "text": "and this is what's known as\nthe correspondence problem.",
        "start": 381.796,
        "duration": 2.03
    },
    {
        "text": "how do the kind of features that\nare present in one image correspond",
        "start": 384.716,
        "duration": 2.68
    },
    {
        "text": "to the features in another?",
        "start": 387.396,
        "duration": 0.93
    },
    {
        "text": "and I think it's important to realize that\nthe brain, in general, is only solving",
        "start": 392.616,
        "duration": 4.22
    },
    {
        "text": "this at, kind of fine levels of detail.",
        "start": 396.836,
        "duration": 3.46
    },
    {
        "text": "and the way it does this, it's\nbelieved, is with these kinds",
        "start": 401.496,
        "duration": 2.62
    },
    {
        "text": "of disparity sensitive neurons.",
        "start": 404.116,
        "duration": 1.56
    },
    {
        "text": "So you can imagine,",
        "start": 406.636,
        "duration": 0.94
    },
    {
        "text": "at the point at which you're fixating,\nlet's say on the apple, even there,",
        "start": 409.696,
        "duration": 3.21
    },
    {
        "text": "there's going to be disparity, in\nthe images in terms of what each",
        "start": 412.906,
        "duration": 4.19
    },
    {
        "text": "apple, what parts of each apple\nare falling where on the retina.",
        "start": 417.136,
        "duration": 4.36
    },
    {
        "text": "and you can imagine having some neurons\nthat have binocular, receptive fields, so",
        "start": 423.516,
        "duration": 4.47
    },
    {
        "text": "they're receiving inputs from both eyes.",
        "start": 427.986,
        "duration": 2.25
    },
    {
        "text": "And then they, are looking for kind of the\nsame feature, but with some displacement.",
        "start": 431.451,
        "duration": 4.86
    },
    {
        "text": "make that more concrete.",
        "start": 437.291,
        "duration": 1.08
    },
    {
        "text": "Imagine these kind of simple stimuli.",
        "start": 438.631,
        "duration": 1.56
    },
    {
        "text": "These are going into both eyes.",
        "start": 440.761,
        "duration": 1.74
    },
    {
        "text": "And most of these, stimuli are\nthe exact same for both eyes.",
        "start": 443.761,
        "duration": 4.78
    },
    {
        "text": "that's what's shown\noutside of the red box.",
        "start": 449.371,
        "duration": 2.83
    },
    {
        "text": "And then within the red box, the\nstimulus has been shifted, so everything",
        "start": 452.686,
        "duration": 5.09
    },
    {
        "text": "outside of the red box, your eyes can\neasily fuse and perceive as a single",
        "start": 457.816,
        "duration": 3.97
    },
    {
        "text": "stimulus because they're identical,\nboth eyes perceive the exact same thing.",
        "start": 461.796,
        "duration": 4.48
    },
    {
        "text": "But within this box, this kind\nof stimulus that's being shown",
        "start": 468.316,
        "duration": 4.32
    },
    {
        "text": "is simulating some disparity.",
        "start": 472.656,
        "duration": 1.79
    },
    {
        "text": "Essentially, all these black, points here\nhave been shifted over by a small amount.",
        "start": 475.106,
        "duration": 5.66
    },
    {
        "text": "And so a disparity neuron would Basically\nhave a receptive field that responds to",
        "start": 482.706,
        "duration": 6.595
    },
    {
        "text": "this stimulus, say, of course this is\njust a toy example, but a white box with",
        "start": 489.311,
        "duration": 4.73
    },
    {
        "text": "a black box next to it, but on, in this\nkind of retinal space, on the retina, it",
        "start": 494.041,
        "duration": 5.97
    },
    {
        "text": "responds at this location, but on this\nother one, it responds at this location.",
        "start": 500.011,
        "duration": 3.95
    },
    {
        "text": "So it will be sensitive to this precise\nkind of disparity of that feature.",
        "start": 504.591,
        "duration": 5.11
    },
    {
        "text": "And that basically gives these,\nneurons are known to exist.",
        "start": 512.931,
        "duration": 2.97
    },
    {
        "text": "Is this or is this a hypothesis?",
        "start": 515.901,
        "duration": 1.59
    },
    {
        "text": "Yeah, The, so throughout definitely at\nthe stage of V one and later they, exist.",
        "start": 518.021,
        "duration": 7.39
    },
    {
        "text": "Whether they exist even earlier than that.",
        "start": 525.411,
        "duration": 1.89
    },
    {
        "text": "It's funny because in this example, the\nthing that really matters is this, if,",
        "start": 527.301,
        "duration": 3.69
    },
    {
        "text": "this is as if you're fixating in something\nat a distance and there's something",
        "start": 531.141,
        "duration": 3.23
    },
    {
        "text": "that's closer to you that you're not, that\nyou're not really paying attention to.",
        "start": 534.371,
        "duration": 3.24
    },
    {
        "text": "It exists at two different locations\non the two different retinas,",
        "start": 538.031,
        "duration": 3.43
    },
    {
        "text": "but that's not really the thing\nyou want to attend to, right?",
        "start": 543.231,
        "duration": 2.11
    },
    {
        "text": "that's, the thing in the little rectangle\nis not the thing you want to attend to.",
        "start": 546.161,
        "duration": 2.78
    },
    {
        "text": "That's just something that's in the way.",
        "start": 548.961,
        "duration": 1.49
    },
    {
        "text": "And you don't want to attend to it.",
        "start": 550.981,
        "duration": 1.45
    },
    {
        "text": "So here, yeah, so a more realistic\nportrayal, maybe this is what the,",
        "start": 554.391,
        "duration": 5.17
    },
    {
        "text": "yeah, a more realistic portrayal is\nthere are some things that would be the",
        "start": 559.691,
        "duration": 3.17
    },
    {
        "text": "exact same within the box, that's the\npoint of fixation, but there's going",
        "start": 562.861,
        "duration": 5.14
    },
    {
        "text": "to be stuff nearby around it that's\ngoing to shift if there's any depth.",
        "start": 568.001,
        "duration": 3.84
    },
    {
        "text": "Okay, okay, so yeah, wherever you're\nfixated, wherever you're fixated.",
        "start": 571.841,
        "duration": 5.62
    },
    {
        "text": "There should be commonality, and then\nwhere you're not fixated, it should",
        "start": 578.381,
        "duration": 3.84
    },
    {
        "text": "be displaced, or have disparity.",
        "start": 582.221,
        "duration": 1.47
    },
    {
        "text": "And and I'll get back to this.",
        "start": 584.311,
        "duration": 1.54
    },
    {
        "text": "This example was a little bit odd, because\nthe thing in the center was not the thing",
        "start": 585.851,
        "duration": 3.3
    },
    {
        "text": "you're fixating on, because it was moving.",
        "start": 589.151,
        "duration": 2.58
    },
    {
        "text": "Yeah.",
        "start": 592.251,
        "duration": 0.54
    },
    {
        "text": "Yeah, let's maybe assume that this\nis what you're fixating on, and so",
        "start": 592.981,
        "duration": 2.87
    },
    {
        "text": "that's the same for everything else.",
        "start": 595.851,
        "duration": 1.49
    },
    {
        "text": "So while, we were sitting here, you\ncan do this real experiment right",
        "start": 597.351,
        "duration": 3.02
    },
    {
        "text": "here while we're sitting here.",
        "start": 600.371,
        "duration": 0.7
    },
    {
        "text": "Just look at a wall away from you.",
        "start": 601.071,
        "duration": 1.38
    },
    {
        "text": "and attend to the wall and then hold\nyour finger in front of your face.",
        "start": 603.041,
        "duration": 2.72
    },
    {
        "text": "Yeah.",
        "start": 605.801,
        "duration": 0.3
    },
    {
        "text": "And, you'll see two fingers, right?",
        "start": 606.361,
        "duration": 2.07
    },
    {
        "text": "Yeah.",
        "start": 608.431,
        "duration": 0.2
    },
    {
        "text": "Unless you focus on the fingers.",
        "start": 609.231,
        "duration": 1.31
    },
    {
        "text": "So that's, the example of what\nyou're just doing there is that,",
        "start": 610.811,
        "duration": 2.37
    },
    {
        "text": "but it's I'm attending to the\nwall and therefore the fingers.",
        "start": 613.361,
        "duration": 2.71
    },
    {
        "text": "no, so, I'm trying to show the more fine\ngrained example where this is happening",
        "start": 616.311,
        "duration": 5.38
    },
    {
        "text": "at a small enough level that you have\nneurons selective to this disparity.",
        "start": 621.711,
        "duration": 4.29
    },
    {
        "text": "So I'll talk about the finger later.",
        "start": 626.021,
        "duration": 1.62
    },
    {
        "text": "The finger is where the\ndisparity is so large that your",
        "start": 627.931,
        "duration": 2.47
    },
    {
        "text": "eyes aren't able to fuse it.",
        "start": 630.401,
        "duration": 1.28
    },
    {
        "text": "Okay.",
        "start": 631.681,
        "duration": 0.12
    },
    {
        "text": "And so you see double.",
        "start": 632.091,
        "duration": 1.12
    },
    {
        "text": "But why would I want to fuse it\nif it's at a different distance?",
        "start": 633.821,
        "duration": 3.0
    },
    {
        "text": "There, because then if you just, if\nyou have a small object like this, and",
        "start": 637.721,
        "duration": 4.12
    },
    {
        "text": "you're focusing on this point, Which one?",
        "start": 641.841,
        "duration": 2.55
    },
    {
        "text": "You see this?",
        "start": 644.391,
        "duration": 0.25
    },
    {
        "text": "No.",
        "start": 645.531,
        "duration": 0.36
    },
    {
        "text": "Oh, right there, okay.",
        "start": 646.681,
        "duration": 0.85
    },
    {
        "text": "You have a small object.",
        "start": 647.711,
        "duration": 0.56
    },
    {
        "text": "A small object like this.",
        "start": 648.291,
        "duration": 1.23
    },
    {
        "text": "You're fixating on here, on this corner.",
        "start": 649.531,
        "duration": 2.03
    },
    {
        "text": "There's going to be zero disparity there.",
        "start": 652.041,
        "duration": 1.73
    },
    {
        "text": "I don't see the corner.",
        "start": 654.381,
        "duration": 0.76
    },
    {
        "text": "which corner?",
        "start": 655.661,
        "duration": 0.74
    },
    {
        "text": "Let me, sorry, I can't actually\njust, use the words like the red",
        "start": 656.801,
        "duration": 3.24
    },
    {
        "text": "rectangle is the object, right?",
        "start": 660.041,
        "duration": 1.44
    },
    {
        "text": "that's what I was trying to say.",
        "start": 661.751,
        "duration": 0.93
    },
    {
        "text": "the within the red rectangle is an\nobject, and there's some parts of it",
        "start": 664.161,
        "duration": 3.59
    },
    {
        "text": "that there's the point of fixation.",
        "start": 668.291,
        "duration": 1.74
    },
    {
        "text": "Let's say that's four E, so that's gonna\nbe the exact same across the images.",
        "start": 670.121,
        "duration": 4.46
    },
    {
        "text": "Yeah, but everything else\nis shifting by small mouth.",
        "start": 675.381,
        "duration": 3.7
    },
    {
        "text": "You think because the object itself\nhas depth, is that what you're saying?",
        "start": 679.081,
        "duration": 3.03
    },
    {
        "text": "Exactly.",
        "start": 682.141,
        "duration": 0.63
    },
    {
        "text": "So that's why, it's like the box.",
        "start": 682.771,
        "duration": 1.41
    },
    {
        "text": "So I'm looking at a curved\nsurface of an apple.",
        "start": 684.181,
        "duration": 1.86
    },
    {
        "text": "And one point the apple is going to\nbe and the other point is going to be.",
        "start": 686.471,
        "duration": 3.12
    },
    {
        "text": "So is it, do we know that the\nbrain actually wants to fuse",
        "start": 689.851,
        "duration": 3.87
    },
    {
        "text": "those other parts or is it?",
        "start": 693.721,
        "duration": 1.629
    },
    {
        "text": "It does.",
        "start": 695.35,
        "duration": 0.231
    },
    {
        "text": "Yeah.",
        "start": 695.611,
        "duration": 0.35
    },
    {
        "text": "How do we know that?",
        "start": 697.121,
        "duration": 0.82
    },
    {
        "text": "but that's how you perceive.",
        "start": 699.281,
        "duration": 1.29
    },
    {
        "text": "That's how you perceive fine\ngrained, depth detail, like,",
        "start": 700.571,
        "duration": 4.29
    },
    {
        "text": "the curvature of the surface.",
        "start": 704.861,
        "duration": 1.16
    },
    {
        "text": "so let me just play devil's advocate here.",
        "start": 707.101,
        "duration": 1.58
    },
    {
        "text": "So I'm thinking like a single\ncolumn looking at this.",
        "start": 708.681,
        "duration": 2.06
    },
    {
        "text": "That single column is a patch.",
        "start": 712.096,
        "duration": 1.73
    },
    {
        "text": "I don't, nobody's looking\nat the entire apple.",
        "start": 715.066,
        "duration": 2.5
    },
    {
        "text": "I'm looking at, that column is looking\nat a patch at a time, so for that",
        "start": 717.566,
        "duration": 5.03
    },
    {
        "text": "particular one column, I would, I\nguess the different columns could be",
        "start": 723.106,
        "duration": 4.74
    },
    {
        "text": "looking at different patches of the\napple and they'd be at different depths.",
        "start": 727.846,
        "duration": 3.12
    },
    {
        "text": "So for, some, I wouldn't want the one\nright in the center of my fixation,",
        "start": 731.466,
        "duration": 3.13
    },
    {
        "text": "maybe I want this, but maybe the\nones that are off to the side or.",
        "start": 734.596,
        "duration": 2.74
    },
    {
        "text": "Other columns are looking at, the side of\nthe apple, which is a little further away.",
        "start": 737.791,
        "duration": 4.71
    },
    {
        "text": "And you're saying for that column,\nwants to fuse the two together.",
        "start": 743.101,
        "duration": 3.98
    },
    {
        "text": "Yeah.",
        "start": 747.861,
        "duration": 0.35
    },
    {
        "text": "okay.",
        "start": 748.821,
        "duration": 0.38
    },
    {
        "text": "It's maybe, I'm not 100 percent\ncertain of that, but okay, I'll",
        "start": 749.401,
        "duration": 2.55
    },
    {
        "text": "go with that, at the moment.",
        "start": 751.951,
        "duration": 2.58
    },
    {
        "text": "and then that, provides the signal\nfor the, kind of relative depth.",
        "start": 754.901,
        "duration": 2.85
    },
    {
        "text": "And",
        "start": 758.531,
        "duration": 0.58
    },
    {
        "text": "what this means is that with these kinds\nof fine, shifts, I You perceive depth.",
        "start": 761.521,
        "duration": 5.94
    },
    {
        "text": "So the classic way to test this is\nwith this random dot stereogram, which",
        "start": 767.471,
        "duration": 3.81
    },
    {
        "text": "is something like what is being shown\nhere, but just a much higher resolution.",
        "start": 771.281,
        "duration": 4.86
    },
    {
        "text": "And basically each eye sees a, to one\neye, a totally random stimulus, but",
        "start": 776.901,
        "duration": 4.49
    },
    {
        "text": "because there's correlations across\nthe images that Fire up these disparity",
        "start": 781.391,
        "duration": 6.795
    },
    {
        "text": "detecting neurons, you end up perceiving\nthat as a consistent stimulus like a",
        "start": 788.586,
        "duration": 4.68
    },
    {
        "text": "banana, or a star, or an elephant, or a I\nprogrammed some of these when I was young.",
        "start": 793.376,
        "duration": 4.48
    },
    {
        "text": "but this also works with one eye.",
        "start": 798.766,
        "duration": 1.6
    },
    {
        "text": "I don't need two eyes to see this brute.",
        "start": 800.446,
        "duration": 1.82
    },
    {
        "text": "Yeah, so that's across time.",
        "start": 802.276,
        "duration": 1.61
    },
    {
        "text": "I'm showing it here with, time, so that\nwe can actually perceive it, because I",
        "start": 804.296,
        "duration": 4.385
    },
    {
        "text": "don't have a way to show you two images.",
        "start": 808.691,
        "duration": 1.73
    },
    {
        "text": "okay, so, I'm testing this because, okay,\nyeah, I agree across time, it makes sense.",
        "start": 810.891,
        "duration": 4.4
    },
    {
        "text": "I'm, I was, yeah, I trust you, but I,\nit wasn't obvious to me that this would",
        "start": 815.871,
        "duration": 3.67
    },
    {
        "text": "actually occur, without time on two,\ntwo, a column looking to the side would",
        "start": 819.541,
        "duration": 6.17
    },
    {
        "text": "somehow fuse these two together somehow,\nroute them, route the, in general, what",
        "start": 825.711,
        "duration": 4.44
    },
    {
        "text": "we're asking for a column to do, but\nimagine a column that's looking at the.",
        "start": 830.151,
        "duration": 2.57
    },
    {
        "text": "And we're asking it to say,\nOh, I'm looking at a patch of",
        "start": 835.681,
        "duration": 4.4
    },
    {
        "text": "retina, but there's two retinas.",
        "start": 840.081,
        "duration": 1.56
    },
    {
        "text": "And so somehow I have to take the input\nfrom those two retinas, which are now",
        "start": 842.491,
        "duration": 5.0
    },
    {
        "text": "the, those inputs aren't the same.",
        "start": 847.531,
        "duration": 2.27
    },
    {
        "text": "And somehow I have to shift\nit to make it the same.",
        "start": 849.801,
        "duration": 2.06
    },
    {
        "text": "I don't know how, I don't\nknow how that would happen.",
        "start": 852.601,
        "duration": 1.67
    },
    {
        "text": "That's what I'm saying.",
        "start": 856.071,
        "duration": 0.58
    },
    {
        "text": "There seemed to be, or at least one\nway the brain seems to solve it.",
        "start": 856.931,
        "duration": 3.44
    },
    {
        "text": "It's probably multiple solutions.",
        "start": 861.151,
        "duration": 1.38
    },
    {
        "text": "is to have neurons that are essentially\nhard coded for a particular kind of",
        "start": 862.981,
        "duration": 5.89
    },
    {
        "text": "subtle feature at a particular disparity.",
        "start": 868.871,
        "duration": 2.42
    },
    {
        "text": "So this kind of green neuron here receives\ninputs from both the fovea and this",
        "start": 872.141,
        "duration": 6.86
    },
    {
        "text": "point which is displaced from the fovea.",
        "start": 879.011,
        "duration": 1.54
    },
    {
        "text": "and it's detecting the same\nfeature, but with that offset.",
        "start": 881.676,
        "duration": 2.16
    },
    {
        "text": "So that's what I was trying to show here.",
        "start": 883.836,
        "duration": 1.6
    },
    {
        "text": "These cells are known\nto exist in the cortex.",
        "start": 885.436,
        "duration": 4.87
    },
    {
        "text": "Yeah.",
        "start": 890.986,
        "duration": 0.46
    },
    {
        "text": "Yeah.",
        "start": 892.736,
        "duration": 0.23
    },
    {
        "text": "You can measure them.",
        "start": 893.026,
        "duration": 0.82
    },
    {
        "text": "I have a question.",
        "start": 895.816,
        "duration": 0.58
    },
    {
        "text": "Yeah.",
        "start": 897.366,
        "duration": 0.32
    },
    {
        "text": "any idea how, so like in the case\nwhere there's static images, you",
        "start": 898.816,
        "duration": 6.18
    },
    {
        "text": "can imagine there's some kind of\ndifference being taken, locally",
        "start": 904.996,
        "duration": 2.776
    },
    {
        "text": "between, we've got input from both eyes.",
        "start": 907.772,
        "duration": 2.165
    },
    {
        "text": "There's some local\ndifference being computed to,",
        "start": 909.937,
        "duration": 1.685
    },
    {
        "text": "to, create these disparity cells.",
        "start": 914.161,
        "duration": 1.6
    },
    {
        "text": "Any idea how you're using motion\nto artificially drive those?",
        "start": 916.181,
        "duration": 2.92
    },
    {
        "text": "Yeah, as in what's happening here?",
        "start": 921.271,
        "duration": 1.53
    },
    {
        "text": "Yeah.",
        "start": 923.241,
        "duration": 0.42
    },
    {
        "text": "I think it's just something where,\nyeah, I haven't thought about it too",
        "start": 925.151,
        "duration": 5.37
    },
    {
        "text": "much, but I think it's just something\nwhere Kind of the same complications",
        "start": 930.521,
        "duration": 3.99
    },
    {
        "text": "happening, but you are, there's a\nbuffer, so that comparison can happen",
        "start": 934.511,
        "duration": 7.21
    },
    {
        "text": "as long as these kind of stimuli are\nshown close enough, together in time.",
        "start": 941.811,
        "duration": 4.08
    },
    {
        "text": "Kind of a similar, comparison is done.",
        "start": 946.881,
        "duration": 2.03
    },
    {
        "text": "Maybe I could, speculate\non this a bit, right?",
        "start": 949.611,
        "duration": 2.51
    },
    {
        "text": "So the only thing that could possibly fire\nhere, there's no features, the only thing",
        "start": 952.121,
        "duration": 5.045
    },
    {
        "text": "that fires is motion detection, right?",
        "start": 957.166,
        "duration": 1.755
    },
    {
        "text": "So there's a series of points in\nthis image where the motion is",
        "start": 958.941,
        "duration": 3.76
    },
    {
        "text": "being detected and that is typically\nwould be your magnocellular cells.",
        "start": 962.701,
        "duration": 4.65
    },
    {
        "text": "in the retina that detect motion, right?",
        "start": 967.936,
        "duration": 2.28
    },
    {
        "text": "The parvicellular cells\ndo not detect motion.",
        "start": 970.216,
        "duration": 2.09
    },
    {
        "text": "They do not fire when things are\nmoving, but so you have a set of",
        "start": 973.046,
        "duration": 3.39
    },
    {
        "text": "magnocellular cells that are firing,\nat the borders of this thing.",
        "start": 976.886,
        "duration": 5.29
    },
    {
        "text": "And, I'm just going to start with that.",
        "start": 983.116,
        "duration": 4.12
    },
    {
        "text": "And then for the columns that are,\nreceiving Input from those magnocellular",
        "start": 987.276,
        "duration": 5.035
    },
    {
        "text": "cells would say, oh, there's a feature\nhere, there's something going on here.",
        "start": 992.341,
        "duration": 2.69
    },
    {
        "text": "And obviously the feature really is\njust, it's almost there's no features",
        "start": 995.111,
        "duration": 4.8
    },
    {
        "text": "here, but there's a set of columns that\nare active, that surround these objects.",
        "start": 999.911,
        "duration": 5.62
    },
    {
        "text": "And",
        "start": 1005.561,
        "duration": 0.45
    },
    {
        "text": "and it's just that literally it's\nlike saying, oh, there's features that",
        "start": 1008.361,
        "duration": 3.23
    },
    {
        "text": "there's some feature at this location.",
        "start": 1011.631,
        "duration": 1.74
    },
    {
        "text": "I, there is no feature, but there's\nsomething at this location and",
        "start": 1014.331,
        "duration": 3.73
    },
    {
        "text": "that is apparently sufficient to\nrecognize some of these things.",
        "start": 1018.071,
        "duration": 2.99
    },
    {
        "text": "Now, I don't know what the image on\nthe right is, I can't even tell what",
        "start": 1021.811,
        "duration": 2.63
    },
    {
        "text": "that is, but one of the things I\nlearned when I did this earlier is that",
        "start": 1024.441,
        "duration": 3.35
    },
    {
        "text": "your limit to recognize a particular\nobject is very limited in this regard.",
        "start": 1027.881,
        "duration": 3.93
    },
    {
        "text": "That is, if you start making something\nthat's a little bit more complicated,",
        "start": 1032.341,
        "duration": 2.37
    },
    {
        "text": "you just can't tell what they are at\nall, and I was surprised when I did that.",
        "start": 1035.241,
        "duration": 4.55
    },
    {
        "text": "Here I could see, oh, it looks\nlike a pepper and a star and a,",
        "start": 1039.791,
        "duration": 2.47
    },
    {
        "text": "a star is a different thing, but\nthe elephant, I don't know what",
        "start": 1043.151,
        "duration": 1.88
    },
    {
        "text": "that other thing is on the right.",
        "start": 1045.031,
        "duration": 1.2
    },
    {
        "text": "I think it's meant to be\nlike a jeep, like a car.",
        "start": 1046.781,
        "duration": 1.85
    },
    {
        "text": "Oh, I didn't get it.",
        "start": 1049.106,
        "duration": 1.15
    },
    {
        "text": "See, I couldn't tell that.",
        "start": 1050.266,
        "duration": 0.75
    },
    {
        "text": "so there's a very limited ability\nto recognize things in this regard,",
        "start": 1052.156,
        "duration": 3.21
    },
    {
        "text": "but anyway, I would argue the\nmechanism is magnocellular cells are",
        "start": 1055.816,
        "duration": 4.48
    },
    {
        "text": "foreign because they detect change.",
        "start": 1060.786,
        "duration": 1.78
    },
    {
        "text": "And, so a bunch of columns being\nactivated at those, and that's it.",
        "start": 1063.096,
        "duration": 5.03
    },
    {
        "text": "All you have is the idea that there's\nsomething here, and maybe you can",
        "start": 1068.156,
        "duration": 4.17
    },
    {
        "text": "get the orientation of that thing.",
        "start": 1072.326,
        "duration": 1.31
    },
    {
        "text": "Yeah.",
        "start": 1075.146,
        "duration": 0.4
    },
    {
        "text": "Yeah.",
        "start": 1075.546,
        "duration": 1.179
    },
    {
        "text": "I don't think this is necessarily,\ncontradictory, but I, guess Scott,",
        "start": 1079.586,
        "duration": 4.0
    },
    {
        "text": "like just in terms of this kind\nof view of it where it's not",
        "start": 1083.586,
        "duration": 6.88
    },
    {
        "text": "necessarily that dependent on motion.",
        "start": 1090.466,
        "duration": 1.48
    },
    {
        "text": "It's more that kind of like at any given.",
        "start": 1091.966,
        "duration": 2.36
    },
    {
        "text": "point, the, these cells are\ngoing to be getting a stimulus,",
        "start": 1095.276,
        "duration": 5.93
    },
    {
        "text": "I guess one of the stimuli, the\nfirst one is going to come here.",
        "start": 1103.856,
        "duration": 4.1
    },
    {
        "text": "And then the one that's shown like\na quarter of a second later or",
        "start": 1108.706,
        "duration": 3.51
    },
    {
        "text": "whatever is firing up that point.",
        "start": 1112.216,
        "duration": 2.92
    },
    {
        "text": "And then at the next time\npoint, you get another shift.",
        "start": 1115.916,
        "duration": 3.31
    },
    {
        "text": "And so that's why It gets fused\ntogether so that it feels like it's",
        "start": 1119.236,
        "duration": 5.38
    },
    {
        "text": "both 3D, but also that it's wiggling.",
        "start": 1124.706,
        "duration": 2.31
    },
    {
        "text": "it doesn't feel like it's a 3D\nimage that's, static in space.",
        "start": 1128.216,
        "duration": 3.51
    },
    {
        "text": "Isn't it true?",
        "start": 1131.766,
        "duration": 0.71
    },
    {
        "text": "Isn't it true that there really\nis no disparity in those images?",
        "start": 1132.806,
        "duration": 3.02
    },
    {
        "text": "There's no disparities.",
        "start": 1136.636,
        "duration": 1.05
    },
    {
        "text": "But that's the thing.",
        "start": 1137.726,
        "duration": 0.79
    },
    {
        "text": "I think the brain perceives\ndisparity because of how closely",
        "start": 1139.136,
        "duration": 3.76
    },
    {
        "text": "in time they're presented.",
        "start": 1142.896,
        "duration": 1.52
    },
    {
        "text": "I see.",
        "start": 1144.486,
        "duration": 0.89
    },
    {
        "text": "I disagree.",
        "start": 1145.376,
        "duration": 0.58
    },
    {
        "text": "I think it's gotta be,\nthen it's, a change, right?",
        "start": 1145.956,
        "duration": 3.94
    },
    {
        "text": "The brain is, this only works because\nthe cells are detecting change.",
        "start": 1149.906,
        "duration": 3.24
    },
    {
        "text": "There is never a point where there's any\npossible thing to look at to say there's",
        "start": 1153.846,
        "duration": 4.88
    },
    {
        "text": "a disparity between these two things.",
        "start": 1158.726,
        "duration": 1.66
    },
    {
        "text": "it's just edges of change.",
        "start": 1161.766,
        "duration": 2.12
    },
    {
        "text": "I'm not saying disparity cells\ndon't exist, but I don't think",
        "start": 1164.536,
        "duration": 2.11
    },
    {
        "text": "that they're playing, I'm guessing,\nI don't think they play a role.",
        "start": 1166.656,
        "duration": 2.8
    },
    {
        "text": "Yeah, in a special one.",
        "start": 1169.456,
        "duration": 0.91
    },
    {
        "text": "Maybe.",
        "start": 1170.856,
        "duration": 0.24
    },
    {
        "text": "I guess the question is like, Is this\ntriggering a depth percept for you or not?",
        "start": 1171.096,
        "duration": 3.98
    },
    {
        "text": "it's not a very strong\ndepth percept for me.",
        "start": 1175.856,
        "duration": 2.52
    },
    {
        "text": "I get this more of a surface texture\nsegmentation, slight depth, like it",
        "start": 1178.986,
        "duration": 5.55
    },
    {
        "text": "may be driving the depth a little bit.",
        "start": 1184.546,
        "duration": 4.04
    },
    {
        "text": "I don't, think this is a depth\nperception example, is it?",
        "start": 1189.216,
        "duration": 2.12
    },
    {
        "text": "This is just a figure\nof separation example.",
        "start": 1192.656,
        "duration": 2.22
    },
    {
        "text": "Yeah, this is a more pronounced\nexample where there's more cues.",
        "start": 1195.946,
        "duration": 4.14
    },
    {
        "text": "But I would argue I perceive this\nas being almost like a 2D, sorry,",
        "start": 1200.086,
        "duration": 6.2
    },
    {
        "text": "3D like paper world, like it looks\nlike they're like paper cutouts",
        "start": 1206.316,
        "duration": 3.95
    },
    {
        "text": "that are inserted into a 3D scene.",
        "start": 1210.296,
        "duration": 2.8
    },
    {
        "text": "So it's like any individual\nperson looks kind of 2D.",
        "start": 1213.856,
        "duration": 3.35
    },
    {
        "text": "But the arrangement of them within\nthis, street looks 3D to me.",
        "start": 1217.486,
        "duration": 3.9
    },
    {
        "text": "but I think it's an artifact of\njust the way this is presented.",
        "start": 1222.976,
        "duration": 2.75
    },
    {
        "text": "first of all, you can, all these\nperceptions, I don't know about the",
        "start": 1227.746,
        "duration": 4.11
    },
    {
        "text": "disparity neurons, but almost all\nthese effects can occur with one eye.",
        "start": 1231.856,
        "duration": 3.81
    },
    {
        "text": "And and typically when you're walking\ndown the street, if you're walking down",
        "start": 1236.366,
        "duration": 3.86
    },
    {
        "text": "that street, your head's constantly\njust jiggling a little bit one way.",
        "start": 1240.226,
        "duration": 3.32
    },
    {
        "text": "You don't have to try to do it,\nyour eyes don't have to move,",
        "start": 1243.576,
        "duration": 1.73
    },
    {
        "text": "you just, that's just natural.",
        "start": 1245.306,
        "duration": 1.22
    },
    {
        "text": "And so there will be that kind of,\nthe thing you just illustrated in that",
        "start": 1247.146,
        "duration": 4.0
    },
    {
        "text": "street scene will occur in your head.",
        "start": 1251.146,
        "duration": 1.7
    },
    {
        "text": "And, I think the, fact that it\nfeels like two, sheets of paper",
        "start": 1253.596,
        "duration": 5.54
    },
    {
        "text": "is, probably because it's a very\nunnatural way of presenting it to us.",
        "start": 1259.386,
        "duration": 4.525
    },
    {
        "text": "The world doesn't jiggle like\nthat, without our motion.",
        "start": 1263.931,
        "duration": 2.89
    },
    {
        "text": "Like we, we typically move\nour bodies, we sense it,",
        "start": 1266.831,
        "duration": 2.28
    },
    {
        "text": "but it's, really no different\nthan you just moving your head",
        "start": 1271.141,
        "duration": 2.25
    },
    {
        "text": "back and forth a little bit.",
        "start": 1273.401,
        "duration": 1.01
    },
    {
        "text": "There's, technically no difference\nbetween those two things.",
        "start": 1274.661,
        "duration": 2.11
    },
    {
        "text": "Yeah.",
        "start": 1277.681,
        "duration": 0.38
    },
    {
        "text": "and so I, I don't think you should\nread too much into it, but other,",
        "start": 1278.701,
        "duration": 3.13
    },
    {
        "text": "that it feels like sheets of paper.",
        "start": 1281.871,
        "duration": 1.82
    },
    {
        "text": "But that effect is what's happening,\nand it doesn't take two eyes to do it.",
        "start": 1284.171,
        "duration": 3.38
    },
    {
        "text": "I guess it could be disparity over time.",
        "start": 1288.501,
        "duration": 2.74
    },
    {
        "text": "but I It's the same, I think\nit's the same idea ultimately.",
        "start": 1293.121,
        "duration": 3.4
    },
    {
        "text": "yeah, disparity over time, you\nstill, whether it's over time,",
        "start": 1297.081,
        "duration": 3.09
    },
    {
        "text": "and I guess Hojae's presentation\nmight go into this more as well.",
        "start": 1300.251,
        "duration": 2.53
    },
    {
        "text": "you still need to solve this\ncorrespondence problem, and so the way",
        "start": 1303.356,
        "duration": 4.35
    },
    {
        "text": "the brain seems to solve it, at least\nfor static inputs, is to have neurons",
        "start": 1307.706,
        "duration": 3.92
    },
    {
        "text": "selectively tuned for these features.",
        "start": 1312.516,
        "duration": 1.84
    },
    {
        "text": "but, I, it's interesting because if\nyou think about the street scene, you",
        "start": 1315.186,
        "duration": 5.52
    },
    {
        "text": "don't have to solve a disparity problem.",
        "start": 1320.706,
        "duration": 1.79
    },
    {
        "text": "You, fixate at some point, and then\neverything that's not at that depth,",
        "start": 1323.846,
        "duration": 3.78
    },
    {
        "text": "you fixate at some depth, and everything\nthat's not at that depth is changing,",
        "start": 1328.486,
        "duration": 2.82
    },
    {
        "text": "so you can just ignore it in some sense.",
        "start": 1331.306,
        "duration": 1.68
    },
    {
        "text": "It becomes blurry, it doesn't, you're\nnot trying to solve a desired problem.",
        "start": 1333.406,
        "duration": 3.97
    },
    {
        "text": "This is when I thought, I was surprised\nyou mentioned the disparity neurons",
        "start": 1337.836,
        "duration": 2.62
    },
    {
        "text": "because the only way I can imagine that\nis like you're trying to You're trying",
        "start": 1340.456,
        "duration": 3.94
    },
    {
        "text": "to, focus on multiple depths at the same\ntime, and that was the example of the",
        "start": 1344.396,
        "duration": 4.65
    },
    {
        "text": "apple which is curving away from you.",
        "start": 1349.066,
        "duration": 1.54
    },
    {
        "text": "that, it was like, oh, that's,\nlike a different problem.",
        "start": 1352.266,
        "duration": 2.65
    },
    {
        "text": "That's I'm actually trying to\nperceive multiple things at",
        "start": 1354.926,
        "duration": 2.7
    },
    {
        "text": "different depths at the same time.",
        "start": 1357.746,
        "duration": 1.88
    },
    {
        "text": "Where normally I've been thinking about\nthis problem, it's oh no, I just want to",
        "start": 1359.946,
        "duration": 2.98
    },
    {
        "text": "ignore all the stuff that's not there.",
        "start": 1362.926,
        "duration": 1.24
    },
    {
        "text": "Not that, I'm looking at the woman and\nthe child, and everything that moves",
        "start": 1364.596,
        "duration": 3.49
    },
    {
        "text": "relative to them is not part of the\nwoman and the child, it's something else,",
        "start": 1368.086,
        "duration": 2.48
    },
    {
        "text": "and I can tell how far away they are.",
        "start": 1370.576,
        "duration": 1.44
    },
    {
        "text": "The disparity neurons, if they exist,\nthey would say, oh, this is this",
        "start": 1372.996,
        "duration": 3.86
    },
    {
        "text": "far away, or that's that far away.",
        "start": 1376.856,
        "duration": 1.69
    },
    {
        "text": "as opposed to attending, like fusing them.",
        "start": 1380.256,
        "duration": 2.72
    },
    {
        "text": "That's the part that's weird to\nme, is we're trying to fuse those.",
        "start": 1383.716,
        "duration": 2.42
    },
    {
        "text": "Yeah, because I guess the way I'm\nthinking about it is say the, I think,",
        "start": 1386.936,
        "duration": 4.935
    },
    {
        "text": "the receptive field of a V1 neuron is\nsomething like your two thumbs held out",
        "start": 1392.061,
        "duration": 4.74
    },
    {
        "text": "at arm's length, so it's not, nothing.",
        "start": 1396.841,
        "duration": 3.34
    },
    {
        "text": "It is a reasonably,",
        "start": 1400.211,
        "duration": 1.27
    },
    {
        "text": "decent amount of information,\nand so it's like within that sort",
        "start": 1403.711,
        "duration": 3.13
    },
    {
        "text": "of receptive field, you have a\nperception of depth all at once.",
        "start": 1406.841,
        "duration": 3.86
    },
    {
        "text": "It's not You only, it's not like\nyou always perceive everything that",
        "start": 1410.741,
        "duration": 4.96
    },
    {
        "text": "you attend to as just being a single\nplane, relative to everything else.",
        "start": 1415.701,
        "duration": 4.64
    },
    {
        "text": "so like we got, so So it's\nwithin that kind of local but",
        "start": 1420.931,
        "duration": 4.2
    },
    {
        "text": "let's say I have, I have two,",
        "start": 1425.541,
        "duration": 3.46
    },
    {
        "text": "let me just write it this way, I have\ntwo eyes, and they are trying to focus",
        "start": 1433.081,
        "duration": 7.47
    },
    {
        "text": "on something that's in that, in the\nreceptive field of that neuron, but maybe",
        "start": 1440.551,
        "duration": 5.57
    },
    {
        "text": "the thing that they're focusing on, or\nthe things they're trying to attend to.",
        "start": 1446.121,
        "duration": 2.579
    },
    {
        "text": "it's smaller than the receptive field of\nthat neuron, and, and it's just smaller.",
        "start": 1449.481,
        "duration": 5.67
    },
    {
        "text": "And so I would, normally, I\nwouldn't want to pay attention",
        "start": 1455.491,
        "duration": 2.88
    },
    {
        "text": "to things that are further away.",
        "start": 1458.371,
        "duration": 1.11
    },
    {
        "text": "I just want to say, Yeah, the only\nfeatures I'm really interested in are the",
        "start": 1459.481,
        "duration": 3.525
    },
    {
        "text": "ones that are in focus, the ones that come\nfrom both eyes at once, that are aligned,",
        "start": 1463.006,
        "duration": 5.57
    },
    {
        "text": "and anything that's not aligned would\nnot be a feature that I'm attending to.",
        "start": 1469.116,
        "duration": 3.3
    },
    {
        "text": "and so that would be a, that would\nbe a quick way of saying, yeah,",
        "start": 1474.226,
        "duration": 4.24
    },
    {
        "text": "there's, a bunch of input coming\nfrom the retina over this area, some",
        "start": 1479.316,
        "duration": 5.1
    },
    {
        "text": "size of a little circle or something.",
        "start": 1484.606,
        "duration": 1.5
    },
    {
        "text": "But actually the thing that's of\ninterest to me is smaller than that.",
        "start": 1486.756,
        "duration": 2.65
    },
    {
        "text": "And, only, the axons from both eyes that\nare co aligned will, will be, recognized.",
        "start": 1489.871,
        "duration": 8.1
    },
    {
        "text": "And the axons that are non co aligned\nwon't, they'll just be ignored because",
        "start": 1497.991,
        "duration": 4.44
    },
    {
        "text": "I don't really want to tend to them.",
        "start": 1502.431,
        "duration": 1.15
    },
    {
        "text": "I don't want to see more, I just don't\nwant to, I just don't want to see",
        "start": 1503.581,
        "duration": 4.61
    },
    {
        "text": "the stuff that's beyond it or closer.",
        "start": 1508.191,
        "duration": 1.81
    },
    {
        "text": "so you're, it's funny because\nyou're trying to unite them and",
        "start": 1511.526,
        "duration": 2.62
    },
    {
        "text": "I'm trying to separate them.",
        "start": 1514.146,
        "duration": 1.19
    },
    {
        "text": "I'm trying to say, yeah, the things\nthat are further closer away, I",
        "start": 1516.116,
        "duration": 2.01
    },
    {
        "text": "don't want to, I don't want to.",
        "start": 1518.126,
        "duration": 1.22
    },
    {
        "text": "So I'm, agreeing with that\nfor, like larger differences.",
        "start": 1519.606,
        "duration": 5.91
    },
    {
        "text": "I guess I'm just trying to say\nthat within a small narrow field,",
        "start": 1525.556,
        "duration": 2.88
    },
    {
        "text": "there are often cases that we\nwant to perceive true depth there.",
        "start": 1528.436,
        "duration": 3.529
    },
    {
        "text": "that, that is how primates like\nare able to like break camouflage,",
        "start": 1532.126,
        "duration": 3.86
    },
    {
        "text": "for example, that they can see even\nif something in a 2d input looks.",
        "start": 1535.986,
        "duration": 5.46
    },
    {
        "text": "The exact same.",
        "start": 1541.946,
        "duration": 0.68
    },
    {
        "text": "It's that disparity at that kind of\nfine grain that makes stuff pop out.",
        "start": 1542.626,
        "duration": 5.16
    },
    {
        "text": "I'm questioning whether that's,",
        "start": 1548.746,
        "duration": 1.42
    },
    {
        "text": "that's true.",
        "start": 1553.596,
        "duration": 0.85
    },
    {
        "text": "I don't, the hidden animal\npops out because it moves.",
        "start": 1554.476,
        "duration": 3.85
    },
    {
        "text": "If the animal doesn't\nmove, you don't see it.",
        "start": 1559.766,
        "duration": 1.66
    },
    {
        "text": "it's just, you can though, yeah, like\nthat's one of the, I guess the innovations",
        "start": 1563.061,
        "duration": 4.68
    },
    {
        "text": "or whatever of depth perception is that\nyou can, something that, an animal that",
        "start": 1567.741,
        "duration": 4.26
    },
    {
        "text": "doesn't have depth perception will be\nunable to see, against the background,",
        "start": 1572.001,
        "duration": 4.08
    },
    {
        "text": "something like a primate can, because\nof the 3D depth popping out, because",
        "start": 1576.771,
        "duration": 3.77
    },
    {
        "text": "there's this disparity, I'd like to see\nexamples of that, because everything",
        "start": 1580.541,
        "duration": 3.7
    },
    {
        "text": "I've ever noticed and thought about in\nthis regard, It's just the opposite.",
        "start": 1584.241,
        "duration": 3.25
    },
    {
        "text": "You can't see these\nthings, until they move.",
        "start": 1587.831,
        "duration": 3.16
    },
    {
        "text": "so I guess there's, I guess all I'm\ngoing to say is there's different ways to",
        "start": 1595.151,
        "duration": 3.51
    },
    {
        "text": "think about these problems and I'm, and\nI've been thinking about it differently",
        "start": 1598.671,
        "duration": 2.35
    },
    {
        "text": "than you're thinking about them.",
        "start": 1601.021,
        "duration": 0.88
    },
    {
        "text": "I've been thinking about how it is I\neliminate information that isn't at",
        "start": 1603.221,
        "duration": 3.53
    },
    {
        "text": "the right depth and you're trying to\nsomehow fuse information at different",
        "start": 1606.751,
        "duration": 4.35
    },
    {
        "text": "depths, which is the exact opposite of\nwhat I would normally want to do, right?",
        "start": 1611.101,
        "duration": 5.1
    },
    {
        "text": "yeah, maybe if I, Move on, because\nthen I'll talk about, I think, more",
        "start": 1617.491,
        "duration": 4.575
    },
    {
        "text": "what you're describing, which is this\nis just within a particular area of",
        "start": 1622.216,
        "duration": 3.83
    },
    {
        "text": "focus, But then your eyes are constantly\nmoving, constantly looking at different",
        "start": 1626.046,
        "duration": 3.6
    },
    {
        "text": "things, and then so that means that,\nas you say, most things that you're",
        "start": 1629.666,
        "duration": 2.92
    },
    {
        "text": "not attending to are, not in focus.",
        "start": 1632.586,
        "duration": 2.77
    },
    {
        "text": "Okay, I'm, gonna still lodge my, my,\nconcern about this idea that a single",
        "start": 1635.356,
        "duration": 5.24
    },
    {
        "text": "columns, retinal patches are trying\nto unite different depths on it.",
        "start": 1641.116,
        "duration": 4.43
    },
    {
        "text": "I'm not aligned with that yet, maybe\nI'm wrong, but then we can go on.",
        "start": 1646.116,
        "duration": 3.02
    },
    {
        "text": "Okay, yeah.",
        "start": 1650.126,
        "duration": 0.49
    },
    {
        "text": "so anyway, so in theory this kind\nof having these disparity neurons",
        "start": 1653.536,
        "duration": 3.86
    },
    {
        "text": "helps you, can help you have this.",
        "start": 1657.496,
        "duration": 3.0
    },
    {
        "text": "Fused percept of some depth in a\nsmall area, but this depends on having",
        "start": 1661.081,
        "duration": 5.49
    },
    {
        "text": "neurons that are tuned to particular\noffsets across the two retinas, and also",
        "start": 1666.571,
        "duration": 4.41
    },
    {
        "text": "particular features, whatever those kind\nof very simple low level features are.",
        "start": 1671.011,
        "duration": 3.64
    },
    {
        "text": "Of course, you can't have this for all\npossible disparities and, for all possible",
        "start": 1676.051,
        "duration": 5.26
    },
    {
        "text": "features, so the reality is Can I, ask I'm\nsorry to interrupt again, Niels, but this",
        "start": 1681.321,
        "duration": 5.17
    },
    {
        "text": "is research, this is what we do, right?",
        "start": 1686.531,
        "duration": 1.57
    },
    {
        "text": "I would have If I read about this, I\nwould assume the disparity neurons are",
        "start": 1690.351,
        "duration": 2.86
    },
    {
        "text": "doing something completely different,\nsomething that I need to do, and I say,",
        "start": 1693.211,
        "duration": 3.82
    },
    {
        "text": "oh, wow, they could solve that problem.",
        "start": 1697.031,
        "duration": 1.5
    },
    {
        "text": "It's very difficult, for a single\neye to determine absolute depth.",
        "start": 1699.171,
        "duration": 4.13
    },
    {
        "text": "two eyes can.",
        "start": 1705.736,
        "duration": 0.91
    },
    {
        "text": "And one of the problems we have with\nvision is we have to know, where",
        "start": 1707.076,
        "duration": 3.26
    },
    {
        "text": "are, where are we observing things\nin the reference frame of an object?",
        "start": 1710.336,
        "duration": 4.39
    },
    {
        "text": "And so this, if I had a,",
        "start": 1715.516,
        "duration": 2.89
    },
    {
        "text": "a column that was, and it had some\ndisparity neurons in it, I could say,",
        "start": 1722.416,
        "duration": 3.21
    },
    {
        "text": "oh, or there's, I could, somehow I\ncould use these disparity neurons",
        "start": 1725.676,
        "duration": 3.93
    },
    {
        "text": "to determine the absolute depth of\nthe distance to the thing to me.",
        "start": 1729.606,
        "duration": 3.79
    },
    {
        "text": "and that would be very useful\nnot because I want to recognize",
        "start": 1735.076,
        "duration": 4.08
    },
    {
        "text": "a feature or unite these things,\njust to know the actual distance.",
        "start": 1739.156,
        "duration": 2.92
    },
    {
        "text": "Just to say, hey, this\nfeature I'm observing, which",
        "start": 1742.726,
        "duration": 3.22
    },
    {
        "text": "is, at certain depth for me.",
        "start": 1746.326,
        "duration": 2.26
    },
    {
        "text": "and therefore the disparity therein\nwouldn't be to unite or fuse",
        "start": 1749.526,
        "duration": 2.82
    },
    {
        "text": "images, but it would just be to\ndetermine the distance to them.",
        "start": 1752.366,
        "duration": 2.93
    },
    {
        "text": "I wonder if that idea has been discussed.",
        "start": 1756.366,
        "duration": 2.13
    },
    {
        "text": "That's at least how I understood it\nfrom this picture, that this is the",
        "start": 1759.891,
        "duration": 4.75
    },
    {
        "text": "purpose of it to detect the absolute\ndepth, but the way that it does that",
        "start": 1764.651,
        "duration": 5.57
    },
    {
        "text": "is it has to recognize where, which\nfeatures correspond to each other, and",
        "start": 1770.231,
        "duration": 4.82
    },
    {
        "text": "then when it knows, okay, this feature\non the left eye retina corresponds to",
        "start": 1775.051,
        "duration": 4.72
    },
    {
        "text": "this feature on the right eye, and this\nis the This disparity between them,",
        "start": 1779.771,
        "duration": 4.465
    },
    {
        "text": "and that tells it the absolute depth.",
        "start": 1784.566,
        "duration": 2.05
    },
    {
        "text": "Okay, in this case, all we need is\nthe absolute minimal feature that",
        "start": 1786.966,
        "duration": 3.0
    },
    {
        "text": "will satisfy that requirement.",
        "start": 1789.986,
        "duration": 1.39
    },
    {
        "text": "It doesn't have to be a feature that is\nrelative to the object itself, right?",
        "start": 1792.036,
        "duration": 4.1
    },
    {
        "text": "it literally could be a progression\nof, dot differences or something,",
        "start": 1797.176,
        "duration": 5.02
    },
    {
        "text": "you know what I'm saying?",
        "start": 1802.456,
        "duration": 0.41
    },
    {
        "text": "It's not like a feature that's on the\nobject that I'm trying to It's just,",
        "start": 1803.046,
        "duration": 3.9
    },
    {
        "text": "add part of my object representation.",
        "start": 1807.916,
        "duration": 1.9
    },
    {
        "text": "It's just the minimal thing that could\nbe done that would achieve the disparity.",
        "start": 1810.286,
        "duration": 4.5
    },
    {
        "text": "Yeah, it doesn't require any\nmodels or anything, it would",
        "start": 1815.006,
        "duration": 3.05
    },
    {
        "text": "really just be to figure out\ncorrespondence between the two images.",
        "start": 1818.056,
        "duration": 3.899
    },
    {
        "text": "So that could be all hardwired and,\nor not, but it could be hardwired and,",
        "start": 1821.956,
        "duration": 5.37
    },
    {
        "text": "then, but that makes it not useful for\nbeing part of a model that says, oh,",
        "start": 1827.326,
        "duration": 3.93
    },
    {
        "text": "you It's not like this is a feature of\nthe object, it's just, no, it's just a",
        "start": 1831.256,
        "duration": 4.46
    },
    {
        "text": "feature I'm using to determine depth.",
        "start": 1835.716,
        "duration": 1.61
    },
    {
        "text": "And therefore, I thought Niels was\nsaying Yeah, I, no, sorry, I'm not",
        "start": 1838.506,
        "duration": 5.1
    },
    {
        "text": "trying to imply that this is going\nto be a feature that then becomes",
        "start": 1843.606,
        "duration": 2.52
    },
    {
        "text": "part of the object, if that was\nwhat it sounded like I was saying.",
        "start": 1846.166,
        "duration": 3.74
    },
    {
        "text": "I I guess what I was talking about the\napple and seeing around the side of the",
        "start": 1850.106,
        "duration": 2.92
    },
    {
        "text": "apple and the depth of the, it's like\nagain, no, it's, more just to get the",
        "start": 1853.026,
        "duration": 6.54
    },
    {
        "text": "sort of features we're getting right now.",
        "start": 1859.566,
        "duration": 1.47
    },
    {
        "text": "So a, basically a feature at a location.",
        "start": 1861.046,
        "duration": 3.44
    },
    {
        "text": "No, but it's not even a\nfeature at a location.",
        "start": 1865.496,
        "duration": 1.45
    },
    {
        "text": "It's just, all we want to\ndo is calculate distance.",
        "start": 1866.956,
        "duration": 3.23
    },
    {
        "text": "That's all we're trying to\ndo is calculate distance.",
        "start": 1870.196,
        "duration": 1.41
    },
    {
        "text": "Yeah, that's what I mean by\nlocation, but there's no feature,",
        "start": 1872.256,
        "duration": 3.58
    },
    {
        "text": "it's just distance, it's not great.",
        "start": 1875.856,
        "duration": 2.97
    },
    {
        "text": "How I'm putting it into context also of\nMonty is that, it seems like what we know",
        "start": 1879.986,
        "duration": 7.32
    },
    {
        "text": "about these neurons and vision, that there\nis a way to extract depth from binocular",
        "start": 1887.306,
        "duration": 6.1
    },
    {
        "text": "input very early in visual processing.",
        "start": 1893.466,
        "duration": 2.65
    },
    {
        "text": "maybe like the first input into V1,\nyou can extract depth by taking these",
        "start": 1897.426,
        "duration": 5.52
    },
    {
        "text": "disparity neurons, seeing how, like\nwhat the difference is and taking,",
        "start": 1902.946,
        "duration": 5.17
    },
    {
        "text": "getting the absolute depth from that.",
        "start": 1908.166,
        "duration": 1.46
    },
    {
        "text": "And this depth is not, it's.",
        "start": 1910.096,
        "duration": 3.45
    },
    {
        "text": "It's like, Monty gets depth input as like\nit's sensory input features, and it's",
        "start": 1914.701,
        "duration": 5.42
    },
    {
        "text": "needed to determine the locations where\nthe actual feature on the model is at.",
        "start": 1920.571,
        "duration": 5.62
    },
    {
        "text": "So this is like what we are doing\nin modeling to extract that.",
        "start": 1928.411,
        "duration": 4.24
    },
    {
        "text": "I didn't follow all that.",
        "start": 1932.651,
        "duration": 0.97
    },
    {
        "text": "Oh, sorry.",
        "start": 1934.391,
        "duration": 0.28
    },
    {
        "text": "Yeah.",
        "start": 1934.831,
        "duration": 0.3
    },
    {
        "text": "Yeah.",
        "start": 1935.131,
        "duration": 0.23
    },
    {
        "text": "I know that was a bit convenient.",
        "start": 1935.361,
        "duration": 1.07
    },
    {
        "text": "Monty, we've been assuming\na camera with a depth.",
        "start": 1936.951,
        "duration": 2.23
    },
    {
        "text": "Yeah, exactly.",
        "start": 1940.016,
        "duration": 0.81
    },
    {
        "text": "So yeah, we assume a depth camera.",
        "start": 1940.826,
        "duration": 2.0
    },
    {
        "text": "And I guess now we've been going back\ninto the literature to figure out whether",
        "start": 1942.886,
        "duration": 4.47
    },
    {
        "text": "it's reasonable that depth information\nis available and that this can be",
        "start": 1947.636,
        "duration": 4.57
    },
    {
        "text": "extracted without too much knowledge\nof a model or too much pre processing.",
        "start": 1952.206,
        "duration": 5.0
    },
    {
        "text": "And I guess this would be, at\nleast for me, the context for why",
        "start": 1957.836,
        "duration": 3.7
    },
    {
        "text": "we're talking about this stuff.",
        "start": 1961.536,
        "duration": 0.68
    },
    {
        "text": "And on the point of it being hardwired,\nI posted a summary earlier today about",
        "start": 1964.486,
        "duration": 5.26
    },
    {
        "text": "actually how babies learn depth perception\nand it seems like at birth, they don't",
        "start": 1970.256,
        "duration": 6.29
    },
    {
        "text": "have binocular depth perception, but it is\nlearned very quickly in the first months.",
        "start": 1976.546,
        "duration": 5.92
    },
    {
        "text": "So essentially they first have to\nlearn, have to separate the input",
        "start": 1982.886,
        "duration": 4.51
    },
    {
        "text": "from the right and left eye, in V1.",
        "start": 1987.396,
        "duration": 4.43
    },
    {
        "text": "So you actually see these stripes in V1.",
        "start": 1991.856,
        "duration": 2.66
    },
    {
        "text": "If you put in some dye and after\nthey have learned that separation,",
        "start": 1994.926,
        "duration": 4.99
    },
    {
        "text": "then they learn, then they get,\nbinocular depth perception within a",
        "start": 1999.926,
        "duration": 5.05
    },
    {
        "text": "couple of weeks, like very quickly.",
        "start": 2004.976,
        "duration": 2.07
    },
    {
        "text": "but it seems like after that, it's\npretty much, It's quite fixed because",
        "start": 2008.066,
        "duration": 6.05
    },
    {
        "text": "if for some reason a child or a monkey\nor whatever's, deprived sensory input",
        "start": 2014.146,
        "duration": 5.34
    },
    {
        "text": "during that formative period, they\nhave like lifelong, impairments.",
        "start": 2019.486,
        "duration": 5.69
    },
    {
        "text": "if you are cross eyed during that\nperiod, or if a cat has the eye, eye",
        "start": 2025.396,
        "duration": 5.54
    },
    {
        "text": "patch during the first few months that\neye is functionally blind for the rest.",
        "start": 2030.936,
        "duration": 4.58
    },
    {
        "text": "I guess, I was, I slightly misspoke there\nwhen I said it could be fixed or not.",
        "start": 2035.566,
        "duration": 7.18
    },
    {
        "text": "What I meant by that is it's not something\nthat you would learn throughout life.",
        "start": 2042.901,
        "duration": 3.21
    },
    {
        "text": "It's not like a features, we learn new\nthings throughout life, but I was thinking",
        "start": 2046.121,
        "duration": 3.94
    },
    {
        "text": "this would be something that once it's\nset up, it doesn't have to change.",
        "start": 2050.071,
        "duration": 2.94
    },
    {
        "text": "And yes, I can see that it could be part\nof this developmental period, certainly.",
        "start": 2054.041,
        "duration": 4.08
    },
    {
        "text": "when I think in some sense, it's\nquote, some sense learned, but to me,",
        "start": 2060.021,
        "duration": 3.82
    },
    {
        "text": "when I say learned, it's oh, I see\nsomething new, I'm going to learn it.",
        "start": 2063.841,
        "duration": 2.67
    },
    {
        "text": "No, it's not like that.",
        "start": 2066.511,
        "duration": 0.81
    },
    {
        "text": "It's this is a part of the development.",
        "start": 2067.331,
        "duration": 3.54
    },
    {
        "text": "You just set this up and then it goes.",
        "start": 2070.901,
        "duration": 1.58
    },
    {
        "text": "the thing is, it's interesting about,\nand I've talked about this before, but in",
        "start": 2073.706,
        "duration": 3.44
    },
    {
        "text": "primates, V1 has these extra layers, and\nonly V1, and I think it's only primates.",
        "start": 2077.196,
        "duration": 7.17
    },
    {
        "text": "And I've always said, what\nthe hell is going on there?",
        "start": 2084.986,
        "duration": 2.55
    },
    {
        "text": "And it always felt the difference\nthere is that we're trying",
        "start": 2087.546,
        "duration": 3.83
    },
    {
        "text": "to perceive at a distance.",
        "start": 2091.376,
        "duration": 1.85
    },
    {
        "text": "their fingers are right on the,",
        "start": 2094.121,
        "duration": 3.06
    },
    {
        "text": "the, the, object.",
        "start": 2100.421,
        "duration": 1.73
    },
    {
        "text": "You have other ways of knowing where\nyour fingers are, but I were seeing",
        "start": 2102.231,
        "duration": 4.41
    },
    {
        "text": "a distance where some sound, and so I\nfigured, this, that's really tricky,",
        "start": 2106.641,
        "duration": 3.46
    },
    {
        "text": "and so I always felt maybe those\nextra layers in V4 are calculating.",
        "start": 2110.101,
        "duration": 4.12
    },
    {
        "text": "And, doing that depth and, and look,\nthere's a bunch of calculations that",
        "start": 2114.536,
        "duration": 6.0
    },
    {
        "text": "have to be accomplished because, it's\nnot only the distance, but then when",
        "start": 2120.556,
        "duration": 5.14
    },
    {
        "text": "your eyes move, how far they're moving\non the object depends on the distance.",
        "start": 2125.696,
        "duration": 3.6
    },
    {
        "text": "So you have to know the distance, and\nthen you have to use the distance to",
        "start": 2129.546,
        "duration": 2.87
    },
    {
        "text": "calculate the displacement on the object.",
        "start": 2132.416,
        "duration": 1.63
    },
    {
        "text": "And so I said, that's something that\nonly applies to eyes, and therefore",
        "start": 2134.686,
        "duration": 3.02
    },
    {
        "text": "maybe that's what's going on in those\nextra layers, those input layers.",
        "start": 2137.706,
        "duration": 3.87
    },
    {
        "text": "So I still think it's a good hypothesis.",
        "start": 2142.291,
        "duration": 1.33
    },
    {
        "text": "I don't know whether the\ndisparity neurons exist in B1.",
        "start": 2143.621,
        "duration": 3.469
    },
    {
        "text": "Yeah, so I think there's evidence\nthat could be exactly corresponding",
        "start": 2147.471,
        "duration": 4.08
    },
    {
        "text": "to these, the processing in layer 4.",
        "start": 2151.551,
        "duration": 3.0
    },
    {
        "text": "There's at least evidence that's\nyeah, that's where the first binocular",
        "start": 2155.661,
        "duration": 5.35
    },
    {
        "text": "inputs, Really come together.",
        "start": 2161.021,
        "duration": 1.91
    },
    {
        "text": "And then, and the way I've ignored that\nfor all these years, because we have,",
        "start": 2163.161,
        "duration": 3.96
    },
    {
        "text": "we have this common cortical algorithm,\nis we could assume we have a camera with",
        "start": 2167.351,
        "duration": 3.88
    },
    {
        "text": "depth, or we can say, look, an animal with\none eye is pretty damn good at vision.",
        "start": 2171.231,
        "duration": 4.77
    },
    {
        "text": "you can do 95 percent of what you\ncan do with two eyes with one eye.",
        "start": 2178.181,
        "duration": 4.15
    },
    {
        "text": "And, and so let's, not\nfocus on that too much.",
        "start": 2182.851,
        "duration": 3.83
    },
    {
        "text": "that was my excuse.",
        "start": 2187.841,
        "duration": 0.94
    },
    {
        "text": "Yeah, and yeah, the, core principles\nof this, of like basically parallax",
        "start": 2188.791,
        "duration": 4.98
    },
    {
        "text": "and all this stuff, apply whether\nit's the two images are across",
        "start": 2193.781,
        "duration": 4.58
    },
    {
        "text": "space or they're across time.",
        "start": 2198.361,
        "duration": 2.05
    },
    {
        "text": "but Right, but I think there's a big,\nthere's a big The difference between the",
        "start": 2201.471,
        "duration": 6.22
    },
    {
        "text": "point of this is to fuse features, or\nthe point of this is to determine depth.",
        "start": 2207.691,
        "duration": 4.42
    },
    {
        "text": "And I guess I was reacting to\nthe suggestion that they're",
        "start": 2213.731,
        "duration": 4.89
    },
    {
        "text": "trying to fuse features together.",
        "start": 2218.721,
        "duration": 1.46
    },
    {
        "text": "Yeah, I guess it's just the fusing of the\nfeatures is a way of perceiving depth.",
        "start": 2221.821,
        "duration": 4.59
    },
    {
        "text": "Okay, as long as it's not the\nfeatures that we're going to apply",
        "start": 2226.791,
        "duration": 4.77
    },
    {
        "text": "to an object, like it's not, the\ninput to an object that's, what",
        "start": 2231.561,
        "duration": 3.64
    },
    {
        "text": "is the feature at this location?",
        "start": 2235.201,
        "duration": 1.32
    },
    {
        "text": "That is definitely going to\nbe, learned, throughout life.",
        "start": 2236.771,
        "duration": 4.52
    },
    {
        "text": "You could change what features\nyou, a column can, assign to it.",
        "start": 2241.301,
        "duration": 4.44
    },
    {
        "text": "Yeah, and you could totally do that\nin this case, like you, whatever",
        "start": 2245.741,
        "duration": 3.41
    },
    {
        "text": "features are being detected, That\ncould change, if there is, I'm,",
        "start": 2249.201,
        "duration": 5.28
    },
    {
        "text": "no, I'm saying, I'm, saying, I'm\ntrying to go the opposite direction.",
        "start": 2254.481,
        "duration": 4.15
    },
    {
        "text": "I'm trying to say, we're using the\nfeatures for two different things.",
        "start": 2258.651,
        "duration": 2.64
    },
    {
        "text": "There's a retinal feature, which\nis just whatever the minimum that's",
        "start": 2261.801,
        "duration": 3.6
    },
    {
        "text": "required to figure out depth.",
        "start": 2265.401,
        "duration": 1.31
    },
    {
        "text": "Then there's features\nof our object models.",
        "start": 2267.321,
        "duration": 2.52
    },
    {
        "text": "And that's something completely\ndifferent in my mind.",
        "start": 2270.241,
        "duration": 1.59
    },
    {
        "text": "and it's a common use of that word.",
        "start": 2273.241,
        "duration": 2.78
    },
    {
        "text": "I'm, pushing back on the idea that there's\na point of saying, Hey, let's fuse these",
        "start": 2276.831,
        "duration": 5.71
    },
    {
        "text": "features together and then feed them into\nour model, as opposed to, oh, we're fusing",
        "start": 2282.541,
        "duration": 4.01
    },
    {
        "text": "these features and we're using disparity\nneurons just to determine the depth,",
        "start": 2286.661,
        "duration": 3.57
    },
    {
        "text": "of the neurons that are not disparate.",
        "start": 2292.281,
        "duration": 1.79
    },
    {
        "text": "The ones that I want to pay attention\nto, the ones that are actually in",
        "start": 2294.876,
        "duration": 2.58
    },
    {
        "text": "plane, and anything that's not in\nplane, is the one I want to ignore.",
        "start": 2297.456,
        "duration": 4.65
    },
    {
        "text": "No, I, think that's, yeah, I guess\na good way of emphasizing that, as",
        "start": 2303.396,
        "duration": 2.8
    },
    {
        "text": "you say, it's what you are fixating\non that is the most important.",
        "start": 2306.196,
        "duration": 3.86
    },
    {
        "text": "So really, this is just giving you a\nbit of depth information around that.",
        "start": 2310.056,
        "duration": 3.17
    },
    {
        "text": "That makes sense to me.",
        "start": 2314.086,
        "duration": 0.88
    },
    {
        "text": "So it's the kind of language we're\nusing and it just confused me a bit.",
        "start": 2314.966,
        "duration": 2.75
    },
    {
        "text": "But yeah, so, that's, yeah, this is\ngiving you, so you can almost imagine",
        "start": 2318.456,
        "duration": 3.47
    },
    {
        "text": "it's this is, Basically saying, it\nwould be reasonable for us to assume",
        "start": 2322.276,
        "duration": 3.32
    },
    {
        "text": "something like a depth map we currently\nhave, at least near to the point",
        "start": 2325.616,
        "duration": 4.42
    },
    {
        "text": "of fixation, just around it, from\nthis, from these disparity neurons.",
        "start": 2330.036,
        "duration": 4.92
    },
    {
        "text": "But, as said, they can't\ncover the full space.",
        "start": 2334.956,
        "duration": 3.24
    },
    {
        "text": "and okay, what happens when\nyou, when they don't work, when,",
        "start": 2339.866,
        "duration": 5.03
    },
    {
        "text": "basically disparity neurons aren't\ndoing what they're meant to do?",
        "start": 2344.906,
        "duration": 2.34
    },
    {
        "text": "And this is exactly what we were\ntalking about earlier, Jeff, where if",
        "start": 2347.526,
        "duration": 3.11
    },
    {
        "text": "you hold your finger at arm's length,\nso very easy, to, if you fixate on",
        "start": 2350.636,
        "duration": 5.85
    },
    {
        "text": "it, to, to perceive it as a single\nobject, but then you, fixate on in",
        "start": 2356.486,
        "duration": 3.63
    },
    {
        "text": "the distance, you will perceive your\nfingers as, your finger as, being double.",
        "start": 2360.116,
        "duration": 4.93
    },
    {
        "text": "It's not confused.",
        "start": 2365.106,
        "duration": 0.86
    },
    {
        "text": "I don't know where you're going with\nthis, but I don't think, I think in",
        "start": 2367.126,
        "duration": 2.01
    },
    {
        "text": "this goal, the purpose of the whole\nsystem is not to, see the two fingers.",
        "start": 2369.136,
        "duration": 4.57
    },
    {
        "text": "Yeah, I'm not arguing that, it's meant\nto, no, so my point is just, this",
        "start": 2374.191,
        "duration": 4.77
    },
    {
        "text": "shows that it only works in a very\nkind of narrow, you can almost imagine",
        "start": 2378.961,
        "duration": 4.87
    },
    {
        "text": "if you're familiar with cameras, like\na very narrow depth of field is where",
        "start": 2383.851,
        "duration": 3.38
    },
    {
        "text": "this is around where you're focusing.",
        "start": 2387.231,
        "duration": 1.52
    },
    {
        "text": "is where that part of depth\nestimation is going to work.",
        "start": 2389.136,
        "duration": 4.34
    },
    {
        "text": "But then, in addition to that, then you\nhave all this active perception of depth.",
        "start": 2394.156,
        "duration": 4.15
    },
    {
        "text": "And in particular, you need to figure\nout where to actually fixate, where",
        "start": 2398.366,
        "duration": 5.23
    },
    {
        "text": "your eyes should converge, and how\nmuch the lenses should accommodate.",
        "start": 2403.596,
        "duration": 3.58
    },
    {
        "text": "So that you have the kind of stimulus of\ninterest in, in your kind of fixation.",
        "start": 2407.626,
        "duration": 5.61
    },
    {
        "text": "And initially, if you're, again, just\nfixating at infinity, then any kind",
        "start": 2413.826,
        "duration": 5.17
    },
    {
        "text": "of objects near you are going to be\ndoubled, and all this kind of stuff.",
        "start": 2418.996,
        "duration": 2.34
    },
    {
        "text": "somehow you need to estimate where\nshould my eyes actually converge",
        "start": 2421.566,
        "duration": 3.5
    },
    {
        "text": "to, to focus on this tree trunk.",
        "start": 2425.066,
        "duration": 2.739
    },
    {
        "text": "How far away is it so\nthat I can focus on it?",
        "start": 2428.276,
        "duration": 2.12
    },
    {
        "text": "and then on that tree trunk, let's say\nthere's a beetle, this is literally the",
        "start": 2431.746,
        "duration": 3.66
    },
    {
        "text": "example they give as a paper, a beetle\nwith camouflage, then you could use those",
        "start": 2435.406,
        "duration": 4.97
    },
    {
        "text": "disparity neurons to perceive that beetle\nstanding out from the bark of the tree.",
        "start": 2440.456,
        "duration": 5.18
    },
    {
        "text": "and yeah, so there's different\nways that you might do this.",
        "start": 2447.271,
        "duration": 2.74
    },
    {
        "text": "This was a, this paper talked about\nthis kind of contour stereopsis.",
        "start": 2450.581,
        "duration": 3.93
    },
    {
        "text": "It doesn't really matter too much,\nbut basically you can imagine you can",
        "start": 2455.001,
        "duration": 2.45
    },
    {
        "text": "do correspondence problem for very\nbig, obvious things like, the tree",
        "start": 2457.451,
        "duration": 4.28
    },
    {
        "text": "trunk, things like that, so that you\ndon't have these kinds of hardwired,",
        "start": 2461.731,
        "duration": 4.1
    },
    {
        "text": "which call it disparity neurons for\nthings like this, but it's pretty",
        "start": 2468.101,
        "duration": 3.66
    },
    {
        "text": "obvious to each of the eyes that\nit's seen, something large like this.",
        "start": 2471.761,
        "duration": 3.54
    },
    {
        "text": "And using that kind of information,\nI had this basic idea, it's funny.",
        "start": 2475.341,
        "duration": 6.53
    },
    {
        "text": "I'm thinking about the\nbeetle on the bark, right?",
        "start": 2482.031,
        "duration": 2.13
    },
    {
        "text": "Yeah.",
        "start": 2484.711,
        "duration": 0.27
    },
    {
        "text": "and if you, I'm literally thinking\nabout situations like this where you",
        "start": 2486.321,
        "duration": 3.39
    },
    {
        "text": "see something and you're not really\nsure if it's something different.",
        "start": 2489.711,
        "duration": 2.48
    },
    {
        "text": "my first reaction is to move my head.",
        "start": 2493.781,
        "duration": 2.14
    },
    {
        "text": "I move my head to the side to look\nat that edge from the side to see",
        "start": 2496.551,
        "duration": 4.33
    },
    {
        "text": "if the beetle is protruding from the\nsurface of the, or if it sees it, see",
        "start": 2500.881,
        "duration": 3.59
    },
    {
        "text": "if it moves separately from the bark.",
        "start": 2504.471,
        "duration": 1.89
    },
    {
        "text": "I think my, my, I'm just, personal\nobservation is that my ability",
        "start": 2507.641,
        "duration": 3.68
    },
    {
        "text": "to determine depth using these\ndisparity neurons is very limited.",
        "start": 2511.321,
        "duration": 3.72
    },
    {
        "text": "it's It's pretty hard to determine\nif it's a well camouflaged beetle.",
        "start": 2516.661,
        "duration": 5.23
    },
    {
        "text": "The whole point is it's camouflaged\nmeans that there are no local",
        "start": 2522.361,
        "duration": 3.62
    },
    {
        "text": "features which can be, maybe the\ndisparity neurons can work with.",
        "start": 2525.991,
        "duration": 2.94
    },
    {
        "text": "and so then you've been, I'm\njust making an observation.",
        "start": 2530.951,
        "duration": 2.42
    },
    {
        "text": "The way that I would really solve\nthe problems, I would move my",
        "start": 2533.381,
        "duration": 2.21
    },
    {
        "text": "head around to the side and look\nat it from the side and see.",
        "start": 2535.591,
        "duration": 2.72
    },
    {
        "text": "I guess that will improve the\nparallax, but yeah, maybe for by",
        "start": 2538.861,
        "duration": 4.0
    },
    {
        "text": "the bay I can bring, I don't know\nif I can find some camouflaging.",
        "start": 2542.861,
        "duration": 3.57
    },
    {
        "text": "it's a big thing they talk\nabout in the literature that,",
        "start": 2548.116,
        "duration": 2.42
    },
    {
        "text": "one of the main reasons for,",
        "start": 2551.006,
        "duration": 1.44
    },
    {
        "text": "depth of this, fine grainedness is how\nit breaks camouflage, and I think the,",
        "start": 2554.616,
        "duration": 4.64
    },
    {
        "text": "person who discovered this in, the 50s\nor 60s, he was actually a military,",
        "start": 2559.256,
        "duration": 3.96
    },
    {
        "text": "we call it technician who would\nlook at tanks and they knew in the",
        "start": 2566.746,
        "duration": 4.9
    },
    {
        "text": "military that in order to spot tanks\nthat are camouflaged, you need to",
        "start": 2571.646,
        "duration": 3.09
    },
    {
        "text": "make sure you give two images, one to\neach eye of the technician, because",
        "start": 2574.736,
        "duration": 4.26
    },
    {
        "text": "then using depth, it'll pop out.",
        "start": 2578.996,
        "duration": 2.04
    },
    {
        "text": "but, at the, time, that wasn't\nreally appreciated and, perceptual,",
        "start": 2582.466,
        "duration": 2.85
    },
    {
        "text": "but the whole point of the whole\npoint of camouflage painting.",
        "start": 2585.316,
        "duration": 4.22
    },
    {
        "text": "is that it doesn't give you, it\nmakes it very hard to find edges",
        "start": 2590.436,
        "duration": 4.78
    },
    {
        "text": "where you can do the disparity.",
        "start": 2595.216,
        "duration": 1.84
    },
    {
        "text": "It's like there are, that's\nthe whole point of it.",
        "start": 2597.966,
        "duration": 3.02
    },
    {
        "text": "It's like that the, boundaries of\nthe, there's lots of little boundaries",
        "start": 2601.036,
        "duration": 4.64
    },
    {
        "text": "and they're matching lots of little\nboundaries in the background.",
        "start": 2605.706,
        "duration": 2.54
    },
    {
        "text": "And, it makes it very hard to, that's the\nwhole point of camel straw is coloring, is",
        "start": 2608.826,
        "duration": 4.81
    },
    {
        "text": "it makes it hard to pick out those edges\nthat are moving relative to each other.",
        "start": 2613.636,
        "duration": 3.85
    },
    {
        "text": "Anyway, I'm just thinking out loud.",
        "start": 2618.006,
        "duration": 1.19
    },
    {
        "text": "that's interesting.",
        "start": 2619.686,
        "duration": 0.36
    },
    {
        "text": "I'm glad, I'm sure there's\npeople who study this a lot.",
        "start": 2620.956,
        "duration": 1.85
    },
    {
        "text": "I'm just thinking, in the back of my head,\nthinking, what do we need to do for Monty?",
        "start": 2623.296,
        "duration": 3.12
    },
    {
        "text": "what are these things, which\nof these are appropriate?",
        "start": 2627.271,
        "duration": 1.77
    },
    {
        "text": "I already in my mindset,",
        "start": 2629.191,
        "duration": 1.93
    },
    {
        "text": "we don't need to have two eyes.",
        "start": 2633.641,
        "duration": 1.29
    },
    {
        "text": "we don't need to do this converging thing.",
        "start": 2636.261,
        "duration": 1.6
    },
    {
        "text": "We could, but, it isn't necessary,\nnot absolutely necessary, or maybe the",
        "start": 2637.871,
        "duration": 9.47
    },
    {
        "text": "bigger thing we could do is to have two\ncameras and just use them for parallax.",
        "start": 2647.341,
        "duration": 3.27
    },
    {
        "text": "You bounce back and forth between the two.",
        "start": 2651.591,
        "duration": 1.79
    },
    {
        "text": "Yeah,",
        "start": 2654.941,
        "duration": 0.1
    },
    {
        "text": "I was going to keep interrupting.",
        "start": 2657.641,
        "duration": 1.2
    },
    {
        "text": "No, it's fine.",
        "start": 2659.511,
        "duration": 0.494
    },
    {
        "text": "Sorry, was that Will?",
        "start": 2660.486,
        "duration": 1.02
    },
    {
        "text": "Or Ramy?",
        "start": 2661.966,
        "duration": 0.61
    },
    {
        "text": "That was me.",
        "start": 2662.616,
        "duration": 0.85
    },
    {
        "text": "are these disparity neurons\nalso useful for calculating",
        "start": 2665.076,
        "duration": 3.03
    },
    {
        "text": "how to fixate on an object?",
        "start": 2668.126,
        "duration": 1.48
    },
    {
        "text": "so we basically want to minimize\nthe disparity on, some objects.",
        "start": 2670.576,
        "duration": 3.32
    },
    {
        "text": "So can we use those?",
        "start": 2673.896,
        "duration": 1.11
    },
    {
        "text": "I think so.",
        "start": 2675.006,
        "duration": 0.7
    },
    {
        "text": "Yeah.",
        "start": 2675.766,
        "duration": 0.32
    },
    {
        "text": "I think for like fine perception, it would\nmake sense that you would use it, but like",
        "start": 2676.086,
        "duration": 3.52
    },
    {
        "text": "you firstly, you coarsely fixate on the\ntree trunk, but then again, say, something",
        "start": 2680.276,
        "duration": 6.11
    },
    {
        "text": "in the middle of it is catching your eye.",
        "start": 2686.386,
        "duration": 1.26
    },
    {
        "text": "Okay, that's when you fixate\non the beetle or whatever, the",
        "start": 2688.001,
        "duration": 3.1
    },
    {
        "text": "tree branch, and then, yeah.",
        "start": 2691.101,
        "duration": 3.6
    },
    {
        "text": "Other than depth, it would be,",
        "start": 2695.621,
        "duration": 3.1
    },
    {
        "text": "yeah, so it would be something else other\nthan just calculating depth but also",
        "start": 2700.951,
        "duration": 3.2
    },
    {
        "text": "how to guide your eyes into fixating on\nan object just to minimize disparity.",
        "start": 2704.151,
        "duration": 3.48
    },
    {
        "text": "I don't know if it guides your eyes\nor it would tell you when you're, when",
        "start": 2708.101,
        "duration": 2.91
    },
    {
        "text": "you have fixated on it, it doesn't tell\nyou, clearly you, when you're reading",
        "start": 2711.011,
        "duration": 6.5
    },
    {
        "text": "like a small text, it you want to keep\nthe letters in focus, I'm not sure",
        "start": 2717.551,
        "duration": 5.94
    },
    {
        "text": "these disparity neurons would tell you\nthey might, but I, think, to think of",
        "start": 2723.491,
        "duration": 5.63
    },
    {
        "text": "them as part of an active perception\nI think is a little weird for me, it",
        "start": 2729.121,
        "duration": 2.91
    },
    {
        "text": "might be Ramy, but to me it's more like\nsaying, hey, when I, when my two eyes",
        "start": 2732.031,
        "duration": 3.72
    },
    {
        "text": "are converging, there will be some point\nwhere there, there's some depth where",
        "start": 2735.751,
        "duration": 4.59
    },
    {
        "text": "these things will co align, and yeah,\nI guess it could the way you want, you",
        "start": 2740.341,
        "duration": 5.88
    },
    {
        "text": "think about it, but I was, It's just, I\ndon't think it's part of a, like it's not",
        "start": 2746.361,
        "duration": 5.6
    },
    {
        "text": "guiding your eyes like saccade over here.",
        "start": 2751.971,
        "duration": 1.97
    },
    {
        "text": "It could be like, it could be tweaking\nthe eyes slightly, saying oh, you're a",
        "start": 2754.491,
        "duration": 4.79
    },
    {
        "text": "little bit out of focus, move it this\nway, a little bit out of focus, move",
        "start": 2759.281,
        "duration": 2.29
    },
    {
        "text": "it this way, that kind of guiding.",
        "start": 2761.571,
        "duration": 1.85
    },
    {
        "text": "That's what I was reacting to.",
        "start": 2763.881,
        "duration": 0.99
    },
    {
        "text": "It's not oh, move over here.",
        "start": 2764.871,
        "duration": 1.78
    },
    {
        "text": "It's more you're trying to look at\nthis thing, and it could give fine",
        "start": 2766.831,
        "duration": 4.0
    },
    {
        "text": "level control to the eyes to say,\njust tweak it a little bit, tweak",
        "start": 2770.831,
        "duration": 3.38
    },
    {
        "text": "it a little bit, keep it in focus.",
        "start": 2774.211,
        "duration": 1.08
    },
    {
        "text": "Yeah, if that's what you\nmeant, then I'm with you.",
        "start": 2776.226,
        "duration": 1.68
    },
    {
        "text": "Yeah, I agree.",
        "start": 2778.426,
        "duration": 0.57
    },
    {
        "text": "The move over here is, something probably,\nmaybe high level, but Right, it would be.",
        "start": 2779.296,
        "duration": 6.06
    },
    {
        "text": "So if that's going to be\nmodel based, or motion based,",
        "start": 2785.366,
        "duration": 3.6
    },
    {
        "text": "unexpected motion, or model based.",
        "start": 2789.016,
        "duration": 2.1
    },
    {
        "text": "So I was reacting to the word guide.",
        "start": 2792.346,
        "duration": 1.92
    },
    {
        "text": "It's okay, yeah, it's a\nlimited word for guide.",
        "start": 2794.376,
        "duration": 4.7
    },
    {
        "text": "It's just it's like a local feedback\nloop to keep things in focus.",
        "start": 2799.076,
        "duration": 4.51
    },
    {
        "text": "yeah.",
        "start": 2804.396,
        "duration": 0.909
    },
    {
        "text": "Thanks.",
        "start": 2805.586,
        "duration": 0.37
    },
    {
        "text": "Yeah, and I guess on the model based\npoint, I think one of the nice things",
        "start": 2806.616,
        "duration": 2.78
    },
    {
        "text": "about this and, how we build Monty is,\nobviously, because it has these internal",
        "start": 2809.396,
        "duration": 4.68
    },
    {
        "text": "models, that's another, very natural cue\nfor having a sense of oh, where should I",
        "start": 2814.076,
        "duration": 4.7
    },
    {
        "text": "fixate, I'm at my desk, where do I think\nmy computer is going to be relative to me?",
        "start": 2818.776,
        "duration": 4.82
    },
    {
        "text": "I know where it is in the world.",
        "start": 2823.616,
        "duration": 1.44
    },
    {
        "text": "that already gives your visual\nsystem some sense of where",
        "start": 2826.206,
        "duration": 2.87
    },
    {
        "text": "the eyes should be converging.",
        "start": 2829.076,
        "duration": 1.05
    },
    {
        "text": "And then, just in general, based on what\nthey do focus on, that gives you some",
        "start": 2830.866,
        "duration": 6.26
    },
    {
        "text": "sense of, okay, what I thought I was\ngoing to focus on is in front of that.",
        "start": 2837.306,
        "duration": 4.7
    },
    {
        "text": "And so you can have, an iterative process,\nImproving the actual accommodation, but",
        "start": 2842.276,
        "duration": 6.77
    },
    {
        "text": "all this, is just to say that there's\nthese two, this two stage process, it",
        "start": 2849.866,
        "duration": 4.82
    },
    {
        "text": "seems, where you have an initial course\nkind of sense of where this object is",
        "start": 2854.686,
        "duration": 6.22
    },
    {
        "text": "so that you can fixate on it, and then\nthe kind of disparity neurons are really",
        "start": 2860.906,
        "duration": 3.55
    },
    {
        "text": "just doing this small amount around that.",
        "start": 2864.456,
        "duration": 2.974
    },
    {
        "text": "Point of fixation.",
        "start": 2868.291,
        "duration": 0.75
    },
    {
        "text": "Sorry, all my noisy comments were\nreally just trying to, I didn't",
        "start": 2869.761,
        "duration": 5.15
    },
    {
        "text": "understand that's where you're going.",
        "start": 2874.911,
        "duration": 1.16
    },
    {
        "text": "If it's a disparity just for this\nfine tuning of it, then I get it.",
        "start": 2876.301,
        "duration": 3.55
    },
    {
        "text": "Okay.",
        "start": 2880.671,
        "duration": 0.49
    },
    {
        "text": "But using the word features and\nall this stuff is confusing.",
        "start": 2881.251,
        "duration": 2.31
    },
    {
        "text": "Yeah, sorry.",
        "start": 2884.751,
        "duration": 0.79
    },
    {
        "text": "Fine tuning mechanism.",
        "start": 2887.131,
        "duration": 1.28
    },
    {
        "text": "But yeah, on a high level, I think this\nfits in really nicely with what we're",
        "start": 2889.046,
        "duration": 4.21
    },
    {
        "text": "doing in Monty and to me, puts a lot of\nthings into place and kind of validates",
        "start": 2893.256,
        "duration": 7.18
    },
    {
        "text": "that it's reasonable for us to assume\npatches can estimate depth at some level.",
        "start": 2900.436,
        "duration": 5.9
    },
    {
        "text": "yeah.",
        "start": 2908.126,
        "duration": 0.38
    },
    {
        "text": "Yeah.",
        "start": 2908.766,
        "duration": 0.5
    },
    {
        "text": "I think, I'm sure someone's done the\nmath on these things, but if you know the",
        "start": 2910.696,
        "duration": 4.32
    },
    {
        "text": "granularity of retinal ganglion cells, and\nyou know the physics, You can determine,",
        "start": 2915.406,
        "duration": 6.05
    },
    {
        "text": "the ranges of which, the accuracy of\nwhich these two mechanisms can work.",
        "start": 2923.016,
        "duration": 3.89
    },
    {
        "text": "how much can these disparity\nneurons actually correct for?",
        "start": 2930.906,
        "duration": 2.74
    },
    {
        "text": "There'd be a small amount, they\ncould calculate that probably,",
        "start": 2933.676,
        "duration": 3.33
    },
    {
        "text": "and then, What accuracy did you\nget just from, parallax and so on?",
        "start": 2937.006,
        "duration": 4.545
    },
    {
        "text": "These are all things that I think\nare estimable, mathematically.",
        "start": 2941.561,
        "duration": 6.01
    },
    {
        "text": "I'm sure they've done that.",
        "start": 2948.271,
        "duration": 0.92
    },
    {
        "text": "Yeah, I didn't come across any specific\nfigures, but in general it did seem",
        "start": 2951.001,
        "duration": 2.86
    },
    {
        "text": "that people were consistent, I think,\nwith our intuition talking about",
        "start": 2953.861,
        "duration": 3.63
    },
    {
        "text": "small, very small differences for this.",
        "start": 2957.551,
        "duration": 2.909
    },
    {
        "text": "Yeah, it only, it can only work\nfor, I can only imagine how it",
        "start": 2961.171,
        "duration": 4.94
    },
    {
        "text": "works for small differentials.",
        "start": 2966.111,
        "duration": 0.51
    },
    {
        "text": "And, again, you can test, we can\ntest it ourselves with this finger",
        "start": 2967.171,
        "duration": 3.0
    },
    {
        "text": "example, like it, it clearly doesn't\nwork for, and that's not particularly,",
        "start": 2970.171,
        "duration": 4.49
    },
    {
        "text": "I don't know, hard stimulus.",
        "start": 2976.571,
        "duration": 1.26
    },
    {
        "text": "So I know Hojae is going to talk more\nabout motion parallax, but I just",
        "start": 2979.041,
        "duration": 3.63
    },
    {
        "text": "thought it was useful to at a high level\nor kind of like bigger picture, just",
        "start": 2982.671,
        "duration": 4.47
    },
    {
        "text": "touch on the concept that, or the fact\nthat essentially the same concepts,",
        "start": 2987.341,
        "duration": 4.9
    },
    {
        "text": "same kind of mathematics of parallax.",
        "start": 2992.471,
        "duration": 2.04
    },
    {
        "text": "Apply to images gathered over time as they\ndo to binocular or some animal has even",
        "start": 2995.046,
        "duration": 6.52
    },
    {
        "text": "more eyes or a Monty system has more eyes.",
        "start": 3001.566,
        "duration": 2.51
    },
    {
        "text": "It's really the same ideas about the\nperception from different points in space.",
        "start": 3004.366,
        "duration": 4.7
    },
    {
        "text": "And you can see how, again, something\nlike smooth pursuit makes sense",
        "start": 3010.446,
        "duration": 5.48
    },
    {
        "text": "in terms of you're essentially\nfoveating at a point in space that's",
        "start": 3015.926,
        "duration": 3.97
    },
    {
        "text": "associated with zero disparity.",
        "start": 3019.896,
        "duration": 1.38
    },
    {
        "text": "And then everything else is relative\nto that, and then, but zero disparity,",
        "start": 3021.801,
        "duration": 5.56
    },
    {
        "text": "but you have also, some absolute\nsense of depth of that location.",
        "start": 3027.361,
        "duration": 3.05
    },
    {
        "text": "and I was going to confuse when looking\nthrough the literature by just the sheer",
        "start": 3033.891,
        "duration": 3.72
    },
    {
        "text": "kind of variety of the terminology used.",
        "start": 3037.611,
        "duration": 2.96
    },
    {
        "text": "So if this is helpful to anyone,\nin general, you can think of",
        "start": 3040.571,
        "duration": 3.645
    },
    {
        "text": "motion parallax as, It's broadly\nequivalent to structure from motion.",
        "start": 3044.216,
        "duration": 4.515
    },
    {
        "text": "Sometimes people refer to structure\nof motion as when the eye is",
        "start": 3049.711,
        "duration": 3.73
    },
    {
        "text": "static and other things are moving.",
        "start": 3054.041,
        "duration": 2.0
    },
    {
        "text": "Whereas if the eye is moving,\nthat's motion parallax.",
        "start": 3056.231,
        "duration": 1.78
    },
    {
        "text": "There's a kind of computer vision\nterm of stereophotogrammetry.",
        "start": 3060.081,
        "duration": 2.89
    },
    {
        "text": "It's essentially the, again, the\nkind of same disparity matching",
        "start": 3063.141,
        "duration": 4.42
    },
    {
        "text": "correspondence problem that's happening\nin stereopsis that I was just describing.",
        "start": 3067.841,
        "duration": 3.21
    },
    {
        "text": "But done through a kind of\ncomputer vision process.",
        "start": 3071.561,
        "duration": 2.27
    },
    {
        "text": "And then as mentioned, the structure\nfor motion and or like whether",
        "start": 3074.231,
        "duration": 4.55
    },
    {
        "text": "it's motion parallax or it's\nstereoscopic vision, again, it's",
        "start": 3078.781,
        "duration": 4.61
    },
    {
        "text": "all kind of the same type of thing.",
        "start": 3083.391,
        "duration": 1.4
    },
    {
        "text": "So that also means that structure\nfor motion and stereo photogrammetry,",
        "start": 3084.791,
        "duration": 2.05
    },
    {
        "text": "it's all using similar algorithms.",
        "start": 3087.611,
        "duration": 1.63
    },
    {
        "text": "So these, things aren't as distinct as\nI think they might seem on the surface.",
        "start": 3090.251,
        "duration": 4.24
    },
    {
        "text": "And just a last note, what I going\nback to what I think's nice about",
        "start": 3097.601,
        "duration": 3.93
    },
    {
        "text": "how this all ties in with Monty.",
        "start": 3101.541,
        "duration": 1.28
    },
    {
        "text": "When you are solving this correspondence\nproblem to do this kind of processing",
        "start": 3104.421,
        "duration": 3.68
    },
    {
        "text": "in computer vision, it's really\ncomputationally expensive and",
        "start": 3108.101,
        "duration": 2.92
    },
    {
        "text": "really challenging because they try\nand do it over the entire image.",
        "start": 3111.021,
        "duration": 2.59
    },
    {
        "text": "take something like this, two images of\nNotre Dame, and you try every, find every",
        "start": 3114.451,
        "duration": 3.08
    },
    {
        "text": "single point in the image that corresponds\nto Point in the other image, and that",
        "start": 3117.531,
        "duration": 5.515
    },
    {
        "text": "gives you a depth map of the entire image.",
        "start": 3123.046,
        "duration": 1.58
    },
    {
        "text": "But, we are concerned with a fovea\nor, a narrow, point of perception.",
        "start": 3125.136,
        "duration": 7.08
    },
    {
        "text": "And so that would make the\nproblem much easier, much less",
        "start": 3132.936,
        "duration": 2.39
    },
    {
        "text": "competitionally expensive.",
        "start": 3135.336,
        "duration": 1.04
    },
    {
        "text": "in general, I couldn't find much\nkind of active research on this.",
        "start": 3137.146,
        "duration": 3.01
    },
    {
        "text": "maybe there's stuff in robotics that\nI missed, but I think it makes sense",
        "start": 3140.446,
        "duration": 4.01
    },
    {
        "text": "because, of course, there's not any Monty\nlike systems that are just perceiving",
        "start": 3144.456,
        "duration": 3.92
    },
    {
        "text": "the world through these kinds of, narrow,\napertures, everything tends to be trying",
        "start": 3148.376,
        "duration": 5.66
    },
    {
        "text": "to view the whole world all at once.",
        "start": 3154.036,
        "duration": 1.77
    },
    {
        "text": "it's funny, just showing the picture\nof Notre Dame there, it reminds us,",
        "start": 3156.786,
        "duration": 3.48
    },
    {
        "text": "this is why disparity neurons can only\nwork locally, because the computational",
        "start": 3160.336,
        "duration": 4.96
    },
    {
        "text": "requirement to do this over the\nwhole image, It's requiring disparity",
        "start": 3165.296,
        "duration": 3.77
    },
    {
        "text": "detection over very long distances.",
        "start": 3169.096,
        "duration": 2.14
    },
    {
        "text": "yeah, exactly.",
        "start": 3172.676,
        "duration": 0.465
    },
    {
        "text": "That's exactly what we said.",
        "start": 3173.141,
        "duration": 0.755
    },
    {
        "text": "That's exactly what we said.",
        "start": 3174.216,
        "duration": 0.88
    },
    {
        "text": "Disparity neurons can't do that.",
        "start": 3175.106,
        "duration": 1.24
    },
    {
        "text": "They're going to, neurons can't do that.",
        "start": 3176.346,
        "duration": 1.274
    },
    {
        "text": "They're going to have to\ndo something very local.",
        "start": 3177.62,
        "duration": 1.666
    },
    {
        "text": "so that's just a reflection of\nthe fact that they're, it's just a",
        "start": 3180.786,
        "duration": 2.81
    },
    {
        "text": "different way of looking at the same\nthing to say, yeah, that's disparity",
        "start": 3183.596,
        "duration": 3.33
    },
    {
        "text": "neurons can't have to be simple.",
        "start": 3186.926,
        "duration": 1.63
    },
    {
        "text": "They're small.",
        "start": 3188.846,
        "duration": 0.57
    },
    {
        "text": "No, thank you.",
        "start": 3190.516,
        "duration": 0.54
    },
    {
        "text": "Yeah, exactly.",
        "start": 3191.056,
        "duration": 0.69
    },
    {
        "text": "Yeah, and also just integrating over\nneurons that come from the entire",
        "start": 3193.116,
        "duration": 5.67
    },
    {
        "text": "visual field into V1 would be, crazy.",
        "start": 3198.826,
        "duration": 4.02
    },
    {
        "text": "yeah, I can, I don't know.",
        "start": 3205.176,
        "duration": 1.25
    },
    {
        "text": "I found this image very\nhelpful for myself, at least.",
        "start": 3206.426,
        "duration": 2.78
    },
    {
        "text": "I don't know if you can see the\nsecond screenshot, yeah, basically.",
        "start": 3210.056,
        "duration": 5.02
    },
    {
        "text": "Stripes that form in V1, after the\nfirst learning period where like",
        "start": 3216.516,
        "duration": 6.06
    },
    {
        "text": "they correspond to input from the\nleft eye versus the right eye.",
        "start": 3222.936,
        "duration": 2.81
    },
    {
        "text": "these are ocular dominance columns, right?",
        "start": 3226.346,
        "duration": 1.6
    },
    {
        "text": "Yeah, exactly.",
        "start": 3227.966,
        "duration": 0.58
    },
    {
        "text": "Stripes, yeah.",
        "start": 3228.546,
        "duration": 0.67
    },
    {
        "text": "Yeah, the ocular dominance columns.",
        "start": 3229.436,
        "duration": 2.49
    },
    {
        "text": "and Yeah.",
        "start": 3232.836,
        "duration": 1.94
    },
    {
        "text": "So if we have a little cortical\ncolumn, it can integrate over a",
        "start": 3235.336,
        "duration": 3.8
    },
    {
        "text": "small, difference in left and right\nfield between these two inputs.",
        "start": 3239.136,
        "duration": 6.47
    },
    {
        "text": "But if we would look at the entire\npicture and find correspondence,",
        "start": 3245.636,
        "duration": 3.62
    },
    {
        "text": "we would have to look from over\nhere to all the way over here.",
        "start": 3249.256,
        "duration": 3.08
    },
    {
        "text": "That's another way of putting it.",
        "start": 3252.686,
        "duration": 1.1
    },
    {
        "text": "Exactly.",
        "start": 3254.156,
        "duration": 0.54
    },
    {
        "text": "It's you can imagine during a\nneuron doing, maybe one or two",
        "start": 3255.036,
        "duration": 3.96
    },
    {
        "text": "stripes, but beyond that it\ngets a combinatorial problem.",
        "start": 3258.996,
        "duration": 5.61
    },
    {
        "text": "Yeah.",
        "start": 3264.676,
        "duration": 0.014
    },
    {
        "text": "Yeah,",
        "start": 3265.101,
        "duration": 0.26
    },
    {
        "text": "Nice.",
        "start": 3268.131,
        "duration": 0.26
    },
    {
        "text": "Yeah.",
        "start": 3268.391,
        "duration": 0.2
    },
    {
        "text": "So I just had one last slide\nwas, is just that to summarize,",
        "start": 3268.591,
        "duration": 4.28
    },
    {
        "text": "in general, extracting depth from\neither binocular moving images",
        "start": 3275.141,
        "duration": 3.83
    },
    {
        "text": "is not easy, even for biology.",
        "start": 3278.981,
        "duration": 2.3
    },
    {
        "text": "And as I was just showing you, it's\na really hard problem in computer",
        "start": 3281.796,
        "duration": 2.79
    },
    {
        "text": "vision, but fortunately people have\nworked out the algorithms that we need",
        "start": 3284.586,
        "duration": 2.96
    },
    {
        "text": "to do, given two kind of 2D images\nto solve that correspondence problem.",
        "start": 3287.556,
        "duration": 5.06
    },
    {
        "text": "But it's much more tractable if you\nhave something like Monty, where you're",
        "start": 3293.316,
        "duration": 3.1
    },
    {
        "text": "moving in the world, so you can get\nkind of crude estimates of depth,",
        "start": 3296.426,
        "duration": 2.74
    },
    {
        "text": "fixate, and then you just have this\nfine estimate, and that fine estimate",
        "start": 3299.386,
        "duration": 3.9
    },
    {
        "text": "is just over a narrow view of the world.",
        "start": 3303.286,
        "duration": 2.17
    },
    {
        "text": "and yeah, basically the kind of\ntenets of, what we're doing, which I",
        "start": 3307.281,
        "duration": 4.45
    },
    {
        "text": "thought was a nice, a happy accident,\nor I guess in, in terms of what",
        "start": 3311.731,
        "duration": 5.1
    },
    {
        "text": "sort of depth information we need.",
        "start": 3316.831,
        "duration": 1.34
    },
    {
        "text": "Yeah, very nice.",
        "start": 3323.011,
        "duration": 0.65
    },
    {
        "text": "That was great.",
        "start": 3323.661,
        "duration": 0.42
    },
    {
        "text": "That was a nice summary.",
        "start": 3324.131,
        "duration": 1.6
    },
    {
        "text": "I'm glad we discussed it and debated it.",
        "start": 3326.451,
        "duration": 2.4
    },
    {
        "text": "I have a better understanding now.",
        "start": 3328.871,
        "duration": 1.22
    },
    {
        "text": "Cool, thanks.",
        "start": 3330.491,
        "duration": 0.65
    },
    {
        "text": "Yeah, and it definitely helped me\nbecause Yeah, I read snippets of",
        "start": 3331.251,
        "duration": 4.445
    },
    {
        "text": "parallax, but it never really made\nactual sense, but it was nice to see",
        "start": 3335.696,
        "duration": 3.75
    },
    {
        "text": "that it fit in with what we want to do.",
        "start": 3339.446,
        "duration": 1.89
    },
    {
        "text": "Of course, I'm gonna, I've concluded\na long ago, maybe erroneously, that",
        "start": 3341.346,
        "duration": 4.03
    },
    {
        "text": "most parallax occurs because of motion.",
        "start": 3345.596,
        "duration": 2.27
    },
    {
        "text": "maybe Hojae's going to talk about that.",
        "start": 3348.156,
        "duration": 1.22
    },
    {
        "text": "Is that what you said?",
        "start": 3350.826,
        "duration": 0.63
    },
    {
        "text": "I, yeah, so I didn't really touch\non that, that much, but, one of",
        "start": 3352.036,
        "duration": 4.74
    },
    {
        "text": "the cool I thought you said Hojae\nwas going to talk about that.",
        "start": 3356.776,
        "duration": 2.219
    },
    {
        "text": "yeah, But I guess I was just gonna say\none of the cool papers, that, that I",
        "start": 3359.846,
        "duration": 5.46
    },
    {
        "text": "came across was how basically mice,\nthey detected almost like this death map",
        "start": 3365.306,
        "duration": 4.98
    },
    {
        "text": "already in V1, precisely in the setting\nwhere the mice aren't moving around.",
        "start": 3370.306,
        "duration": 5.945
    },
    {
        "text": "Of course, it's just in the,\nthe field of one of their eyes,",
        "start": 3376.491,
        "duration": 3.01
    },
    {
        "text": "but through motion parallax.",
        "start": 3379.881,
        "duration": 1.41
    },
    {
        "text": "So I think there's good, there's almost\nbetter biological evidence that depth",
        "start": 3382.661,
        "duration": 4.42
    },
    {
        "text": "from motion parallax emerges really\nearly than depth from binocular fusion.",
        "start": 3387.101,
        "duration": 4.6
    },
    {
        "text": "and of course rats and rodents\ndon't have binocular vision.",
        "start": 3392.251,
        "duration": 2.66
    },
    {
        "text": "I'm afraid.",
        "start": 3395.111,
        "duration": 0.4
    },
    {
        "text": "Yeah, I think they have a little\nbit just in front of them.",
        "start": 3395.751,
        "duration": 1.94
    },
    {
        "text": "It's a little overlap, but I\nwouldn't call it binocular vision.",
        "start": 3398.021,
        "duration": 2.38
    },
    {
        "text": "My perception is that they have\nno binocular vision because",
        "start": 3401.641,
        "duration": 2.79
    },
    {
        "text": "they're, the center of their visual\nfields are just not, can't align.",
        "start": 3404.431,
        "duration": 3.22
    },
    {
        "text": "So there's a touch overlap on\nthe, in those, on the edges.",
        "start": 3408.181,
        "duration": 2.94
    },
    {
        "text": "Maybe that works, I don't know.",
        "start": 3411.121,
        "duration": 1.119
    },
    {
        "text": "But my assumption has always been\nlike, they're there more for detecting",
        "start": 3412.911,
        "duration": 4.59
    },
    {
        "text": "predators all around them as opposed\nto discerning things that prey that",
        "start": 3417.601,
        "duration": 3.54
    },
    {
        "text": "they might find in front of them.",
        "start": 3421.141,
        "duration": 1.56
    },
    {
        "text": "Very.",
        "start": 3424.031,
        "duration": 0.36
    },
    {
        "text": "I have some thoughts I want\nto mention about this, but",
        "start": 3427.941,
        "duration": 2.02
    },
    {
        "text": "we'll wait to Hojae's time.",
        "start": 3429.961,
        "duration": 1.15
    },
    {
        "text": "We have time.",
        "start": 3431.941,
        "duration": 0.49
    },
    {
        "text": "Yeah.",
        "start": 3432.431,
        "duration": 1.689
    },
    {
        "text": "Yeah, mine's pretty short.",
        "start": 3434.121,
        "duration": 0.72
    },
    {
        "text": "So the only thing that I'm\nsaying is that there, all this.",
        "start": 3434.961,
        "duration": 4.33
    },
    {
        "text": "In computer vision, there is some kind\nof ways that we can estimate some depth,",
        "start": 3440.251,
        "duration": 5.44
    },
    {
        "text": "let's see, that I think has a lot of\nparallel to what Niels talked about,",
        "start": 3447.971,
        "duration": 5.1
    },
    {
        "text": "Yeah, so there's many cues that\nallows us to perceive death.",
        "start": 3455.516,
        "duration": 3.69
    },
    {
        "text": "so Niels mentioned, convergence\nand like accommodation.",
        "start": 3460.156,
        "duration": 3.47
    },
    {
        "text": "I'm still like learning these\nterms, but there are many ways",
        "start": 3463.626,
        "duration": 2.48
    },
    {
        "text": "that we can perceive death.",
        "start": 3466.106,
        "duration": 0.95
    },
    {
        "text": "the one that we've been focusing on\nin this presentation was parallax.",
        "start": 3468.416,
        "duration": 3.98
    },
    {
        "text": "parallax can happen.",
        "start": 3473.856,
        "duration": 0.82
    },
    {
        "text": "I think we talked about this a\nlot, but can happen because we",
        "start": 3475.336,
        "duration": 2.95
    },
    {
        "text": "have, when you have parallax.",
        "start": 3478.286,
        "duration": 1.039
    },
    {
        "text": "Binocular vision, because we have\nsome inter pupilary distance, that",
        "start": 3480.166,
        "duration": 6.2
    },
    {
        "text": "is one way paralympic can happen.",
        "start": 3486.486,
        "duration": 1.44
    },
    {
        "text": "And then the other, way that it\ncan happen is through motion panel",
        "start": 3488.256,
        "duration": 3.6
    },
    {
        "text": "ax, which, can be monoculars.",
        "start": 3491.856,
        "duration": 2.58
    },
    {
        "text": "If, you have one eye, we\ncan still estimate death.",
        "start": 3494.546,
        "duration": 2.65
    },
    {
        "text": "I'm not sure how good, but I also\nagree with, Jeff, that, with some",
        "start": 3498.486,
        "duration": 5.45
    },
    {
        "text": "like physics and math, there's\nprobably a way to estimate, like how.",
        "start": 3504.346,
        "duration": 4.14
    },
    {
        "text": "Accurate it can be, though that's\nnot the focus of this presentation.",
        "start": 3509.031,
        "duration": 3.49
    },
    {
        "text": "structure from motion, so is a way to\nperceive death using, I guess I like to",
        "start": 3514.101,
        "duration": 5.16
    },
    {
        "text": "call it one eyeball, and a movement, which\nis what I think Monty's distant agent is",
        "start": 3519.261,
        "duration": 5.61
    },
    {
        "text": "already, that's the setting that we have.",
        "start": 3524.871,
        "duration": 2.13
    },
    {
        "text": "Again, is this movement of the\nobject or movement of the eye?",
        "start": 3527.521,
        "duration": 3.2
    },
    {
        "text": "Movement of the eye,\nmovement of camera or eye.",
        "start": 3531.816,
        "duration": 2.53
    },
    {
        "text": "Okay.",
        "start": 3534.606,
        "duration": 0.28
    },
    {
        "text": "All right.",
        "start": 3534.946,
        "duration": 0.33
    },
    {
        "text": "So how's that?",
        "start": 3535.486,
        "duration": 0.75
    },
    {
        "text": "Is that different than motion parallax?",
        "start": 3536.606,
        "duration": 2.07
    },
    {
        "text": "I don't think so.",
        "start": 3540.516,
        "duration": 0.69
    },
    {
        "text": "Okay.",
        "start": 3541.706,
        "duration": 0.33
    },
    {
        "text": "All right.",
        "start": 3542.036,
        "duration": 0.3
    },
    {
        "text": "Cause you had motion parallax and then a\nseparate bullet is structured for motion.",
        "start": 3542.336,
        "duration": 2.76
    },
    {
        "text": "So I didn't understand.",
        "start": 3545.096,
        "duration": 0.52
    },
    {
        "text": "Yeah.",
        "start": 3546.446,
        "duration": 0.15
    },
    {
        "text": "I was trying to get it.",
        "start": 3548.306,
        "duration": 0.68
    },
    {
        "text": "Yeah, exactly.",
        "start": 3549.196,
        "duration": 0.63
    },
    {
        "text": "It's like the biological term\nversus the computer vision term.",
        "start": 3549.826,
        "duration": 2.89
    },
    {
        "text": "Okay.",
        "start": 3553.136,
        "duration": 0.52
    },
    {
        "text": "Yeah.",
        "start": 3553.786,
        "duration": 0.38
    },
    {
        "text": "We can come back to a\nsix second video later.",
        "start": 3556.246,
        "duration": 1.81
    },
    {
        "text": "yeah, so I, I think that, so I guess\nthe main argument that I'm making is",
        "start": 3560.146,
        "duration": 4.11
    },
    {
        "text": "that, in Monty, we can, just with the\ncurrent settings that, without any extra",
        "start": 3564.256,
        "duration": 8.32
    },
    {
        "text": "cameras or changing the, settings, we\ncan remove the, information coming from",
        "start": 3572.576,
        "duration": 9.015
    },
    {
        "text": "depth and still be able to estimate\ndepth with what we have currently.",
        "start": 3581.601,
        "duration": 5.02
    },
    {
        "text": "So yeah, but I guess the caveat is that\nI'm not sure if that depth map is going to",
        "start": 3589.501,
        "duration": 4.6
    },
    {
        "text": "be as good as like the ground truth one.",
        "start": 3594.101,
        "duration": 1.8
    },
    {
        "text": "yeah.",
        "start": 3598.351,
        "duration": 0.18
    },
    {
        "text": "Yeah, so this is like the classical kind\nof output from, structured from motion.",
        "start": 3599.926,
        "duration": 5.54
    },
    {
        "text": "Is this the cool video?",
        "start": 3606.426,
        "duration": 0.46
    },
    {
        "text": "No, it's not the cool video, but, yeah.",
        "start": 3608.226,
        "duration": 2.53
    },
    {
        "text": "Oh, I see what you mean.",
        "start": 3610.756,
        "duration": 1.759
    },
    {
        "text": "but this is, I think, another cool video.",
        "start": 3612.896,
        "duration": 1.73
    },
    {
        "text": "So basically, there was a research where,\npeople took a bunch of images from Flickr.",
        "start": 3614.626,
        "duration": 5.89
    },
    {
        "text": "So all these kind of black,\nTriangular cone things are cameras.",
        "start": 3620.516,
        "duration": 4.17
    },
    {
        "text": "So when you up, apparently, when you\nupload pictures to Flickr, you can,",
        "start": 3624.696,
        "duration": 3.85
    },
    {
        "text": "some like phone information, location\ninformation is stored and, you have the",
        "start": 3629.276,
        "duration": 3.95
    },
    {
        "text": "corresponding picture and people try\nto use those pictures, from Flickr to",
        "start": 3633.226,
        "duration": 4.85
    },
    {
        "text": "try to reconstruct this coliseum in 3D.",
        "start": 3638.076,
        "duration": 2.94
    },
    {
        "text": "and there's a bunch of other\nexamples and this website",
        "start": 3642.146,
        "duration": 3.19
    },
    {
        "text": "called Building Rome in a Day.",
        "start": 3645.336,
        "duration": 1.37
    },
    {
        "text": "So what you saw was the coliseum\nhere, but there's a tray fountain.",
        "start": 3646.736,
        "duration": 3.32
    },
    {
        "text": "This one's pretty cool too.",
        "start": 3650.536,
        "duration": 1.17
    },
    {
        "text": "Yeah, just because a lot of people take,\npictures of these kind of, landmarks.",
        "start": 3652.291,
        "duration": 4.44
    },
    {
        "text": "But nowadays, structure for\nmotion, is used in, a lot",
        "start": 3657.211,
        "duration": 3.97
    },
    {
        "text": "for, like mapping, terrains.",
        "start": 3661.181,
        "duration": 4.02
    },
    {
        "text": "they would send out drones, take\npictures, and try to, map out.",
        "start": 3665.431,
        "duration": 3.44
    },
    {
        "text": "So they're actually, in these videos,\nthey're actually creating a 3D model,",
        "start": 3668.881,
        "duration": 2.88
    },
    {
        "text": "because you could make the same video\njust by linking together images.",
        "start": 3671.891,
        "duration": 3.21
    },
    {
        "text": "but they're actually, yeah, they're\ncreating, are they creating a real",
        "start": 3676.291,
        "duration": 2.51
    },
    {
        "text": "3D model or are they just looking,\nthey're creating point clouds, they're,",
        "start": 3678.801,
        "duration": 3.46
    },
    {
        "text": "creating point clouds, the output are\nthese points in 3D space, yes, and",
        "start": 3682.261,
        "duration": 4.6
    },
    {
        "text": "then they figure out what it looks\nlike from different, so they could",
        "start": 3687.271,
        "duration": 3.04
    },
    {
        "text": "view the system from a novel direction.",
        "start": 3690.321,
        "duration": 1.73
    },
    {
        "text": "Yes.",
        "start": 3692.871,
        "duration": 0.44
    },
    {
        "text": "Okay.",
        "start": 3693.986,
        "duration": 0.34
    },
    {
        "text": "Yeah.",
        "start": 3694.796,
        "duration": 0.2
    },
    {
        "text": "And I guess just to hammer home the\nkind of parallels between the stereopsis",
        "start": 3694.996,
        "duration": 4.74
    },
    {
        "text": "and, structure from motion, like in,\nin this instance, you, could argue",
        "start": 3699.766,
        "duration": 4.95
    },
    {
        "text": "that this is stereopsis, but where\nyou, instead of binocular vision, you",
        "start": 3704.716,
        "duration": 4.14
    },
    {
        "text": "have a thousand cameras all viewing\nthe same thing at the same time.",
        "start": 3708.856,
        "duration": 4.54
    },
    {
        "text": "I think it's just helpful to recognize,\nI think that, yeah, the sort of",
        "start": 3714.496,
        "duration": 4.55
    },
    {
        "text": "calculations that you need to do to,\nwork out the, depth of what you're",
        "start": 3719.046,
        "duration": 4.87
    },
    {
        "text": "seeing is basically the exact same.",
        "start": 3723.916,
        "duration": 1.31
    },
    {
        "text": "Yeah, so I guess already from this\nkind of point cloud, it reminded me",
        "start": 3726.531,
        "duration": 4.62
    },
    {
        "text": "a lot about Monty because we do make\ngraphs slash point clouds of objects.",
        "start": 3731.151,
        "duration": 4.29
    },
    {
        "text": "so these are very detailed because\nthere's thousands of cameras, but,",
        "start": 3736.061,
        "duration": 3.12
    },
    {
        "text": "the minimum requirement, let me go\nback to this, is just, two images.",
        "start": 3740.801,
        "duration": 4.845
    },
    {
        "text": "So",
        "start": 3745.646,
        "duration": 0.18
    },
    {
        "text": "theoretically , it's po.",
        "start": 3748.306,
        "duration": 1.71
    },
    {
        "text": "it's possible to, reconstruct\nthree structure from as, I guess",
        "start": 3751.066,
        "duration": 6.13
    },
    {
        "text": "it starts from two, and then we can\nrefine it as, we take more images",
        "start": 3757.196,
        "duration": 4.43
    },
    {
        "text": "or as we do more steps in Monty.",
        "start": 3761.626,
        "duration": 2.1
    },
    {
        "text": "Okay, so, SM is the technique to, which\nutilizes series minimum of two of 2D",
        "start": 3765.336,
        "duration": 6.9
    },
    {
        "text": "images to reconstruct 3D structure.",
        "start": 3772.236,
        "duration": 1.62
    },
    {
        "text": "And the final output is point cloud,\nsimilar to 3D models that output by LiDAR",
        "start": 3774.536,
        "duration": 5.46
    },
    {
        "text": "sensors, which are More expensive, and\nthe minimum requirement is that the two",
        "start": 3780.036,
        "duration": 6.52
    },
    {
        "text": "pictures, the, there should be, again,\ncorrespondence, the features need to",
        "start": 3786.556,
        "duration": 5.15
    },
    {
        "text": "be visible across those two or three\npictures, more is better, and the idea is,",
        "start": 3791.706,
        "duration": 6.54
    },
    {
        "text": "a mathematical idea is that if, in this 3D\nworld, the, a camera is capturing lights",
        "start": 3798.866,
        "duration": 10.45
    },
    {
        "text": "from different parts of the 3D world.",
        "start": 3809.336,
        "duration": 2.15
    },
    {
        "text": "And we're taking an image, so in\nthis case, point 1 ends up here in",
        "start": 3811.941,
        "duration": 4.99
    },
    {
        "text": "this first image, point 2 ends up a\nlittle bit to the right in this image.",
        "start": 3816.931,
        "duration": 5.11
    },
    {
        "text": "But if we move the camera, now the",
        "start": 3822.041,
        "duration": 3.58
    },
    {
        "text": "point in 3D is projected to\nthis location in 2D, etc. So",
        "start": 3827.691,
        "duration": 5.2
    },
    {
        "text": "that's the setup for this.",
        "start": 3835.071,
        "duration": 2.78
    },
    {
        "text": "And does the camera actually have to\nbe in motion for this or can it just",
        "start": 3839.146,
        "duration": 5.58
    },
    {
        "text": "use a lot of different points of view?",
        "start": 3844.726,
        "duration": 1.61
    },
    {
        "text": "the camera, so you can have\ntwo people with two different",
        "start": 3847.626,
        "duration": 2.65
    },
    {
        "text": "cameras taking the big picture.",
        "start": 3850.276,
        "duration": 1.67
    },
    {
        "text": "it doesn't need to be like that\none camera need to be like moving.",
        "start": 3852.306,
        "duration": 2.98
    },
    {
        "text": "Oftentimes this is extracted also from\nlike video where one person has the",
        "start": 3855.606,
        "duration": 4.15
    },
    {
        "text": "same camera and is moving across time.",
        "start": 3859.756,
        "duration": 2.34
    },
    {
        "text": "But like in the Flickr example, those\nare all probably people's pictures.",
        "start": 3862.506,
        "duration": 3.11
    },
    {
        "text": "iPhones, I don't know, or\nSamsungs, taken at different time.",
        "start": 3865.636,
        "duration": 5.19
    },
    {
        "text": "Yeah, very little.",
        "start": 3871.136,
        "duration": 2.02
    },
    {
        "text": "most, because most cameras\nhave zero depth ability, right?",
        "start": 3873.306,
        "duration": 3.0
    },
    {
        "text": "but if we're doing this with eyes, we\njust talked about all the different",
        "start": 3877.976,
        "duration": 2.32
    },
    {
        "text": "ways we can determine depth.",
        "start": 3880.296,
        "duration": 1.41
    },
    {
        "text": "And in Monty and, in eyes,\nyou don't have to move, right?",
        "start": 3882.216,
        "duration": 3.57
    },
    {
        "text": "You can just be in one spot, as\nlong as you can see the points.",
        "start": 3885.786,
        "duration": 3.06
    },
    {
        "text": "Yeah, so the overall algorithm is fairly\nsimple and I think a lot of has a lot",
        "start": 3889.746,
        "duration": 6.04
    },
    {
        "text": "of correspondence to what we talked\nabout earlier in Niels presentation.",
        "start": 3895.786,
        "duration": 3.49
    },
    {
        "text": "So just go through each one, try\nto put a picture of what that is.",
        "start": 3899.646,
        "duration": 3.25
    },
    {
        "text": "that algorithm means without using\nmath, but so the first one, extracting",
        "start": 3904.101,
        "duration": 4.77
    },
    {
        "text": "feature, so the feature in this case\nis not featuring location, but the",
        "start": 3908.891,
        "duration": 3.1
    },
    {
        "text": "retinal features, that Jeff mentioned,\nfeatures from image that the sensor gets.",
        "start": 3912.001,
        "duration": 6.64
    },
    {
        "text": "okay.",
        "start": 3919.571,
        "duration": 0.25
    },
    {
        "text": "if you're going to do it, if\nyou're going to do it this way,",
        "start": 3919.941,
        "duration": 2.9
    },
    {
        "text": "do the whole image at once.",
        "start": 3923.361,
        "duration": 1.33
    },
    {
        "text": "Okay.",
        "start": 3924.691,
        "duration": 0.05
    },
    {
        "text": "Then you need more than\njust a retinal feature.",
        "start": 3925.111,
        "duration": 2.16
    },
    {
        "text": "Yeah.",
        "start": 3927.891,
        "duration": 0.18
    },
    {
        "text": "Oh yeah.",
        "start": 3929.331,
        "duration": 0.031
    },
    {
        "text": "So I'm not, if the retinal feature\nonly works on that very small distance,",
        "start": 3929.362,
        "duration": 2.519
    },
    {
        "text": "you can say, oh, there's an edge and\nit's moved over a little bit here.",
        "start": 3931.881,
        "duration": 2.79
    },
    {
        "text": "I have to say there's a gazillion\nedges that it could correspond to.",
        "start": 3934.671,
        "duration": 2.61
    },
    {
        "text": "I have to say, no, this is, this\nparticular cornes that is, is over here,",
        "start": 3937.281,
        "duration": 4.62
    },
    {
        "text": "is this particular corner over there.",
        "start": 3941.901,
        "duration": 1.38
    },
    {
        "text": "So it has to be a much more\ncomplicated features in this case.",
        "start": 3943.281,
        "duration": 2.86
    },
    {
        "text": "Yeah.",
        "start": 3946.171,
        "duration": 0.24
    },
    {
        "text": "Yeah.",
        "start": 3947.721,
        "duration": 0.24
    },
    {
        "text": "I, think that this, so in Monty, obviously\nthe example is a picture 'cause nobody is.",
        "start": 3948.881,
        "duration": 4.95
    },
    {
        "text": "not nobody, but not a lot of people upload\npictures of, the mug, very, very close by.",
        "start": 3955.546,
        "duration": 5.54
    },
    {
        "text": "for example, this is, the whole building,\nbut I think this would work, I'm not",
        "start": 3961.716,
        "duration": 5.27
    },
    {
        "text": "sure how well, with, the 64 by 64\nsmall images that we see in patches.",
        "start": 3966.986,
        "duration": 5.11
    },
    {
        "text": "For Monty, you can imagine those\ninstead of these two pictures.",
        "start": 3972.546,
        "duration": 3.05
    },
    {
        "text": "But anyways, it's the point I'm making\nis that it's not yet, this step can",
        "start": 3977.416,
        "duration": 6.23
    },
    {
        "text": "happen in the sensor modules without\nhaving gone to the learning module, so",
        "start": 3983.646,
        "duration": 3.48
    },
    {
        "text": "we haven't learned those features yet.",
        "start": 3987.126,
        "duration": 1.45
    },
    {
        "text": "anyway, so it can't be done on\nthe big scale like this, right?",
        "start": 3990.766,
        "duration": 3.91
    },
    {
        "text": "No, it cannot be done.",
        "start": 3995.436,
        "duration": 0.99
    },
    {
        "text": "It can only be done very, locally.",
        "start": 3996.746,
        "duration": 1.76
    },
    {
        "text": "Yes, yeah, Which doesn't tell you,\nit doesn't tell you where that",
        "start": 3998.506,
        "duration": 4.6
    },
    {
        "text": "feature is in the overall object.",
        "start": 4003.106,
        "duration": 1.42
    },
    {
        "text": "It just tells you, Yes.",
        "start": 4004.586,
        "duration": 1.525
    },
    {
        "text": "Yeah.",
        "start": 4008.341,
        "duration": 0.36
    },
    {
        "text": "yeah, our pictures, or the Monty pictures\nare, we have usually very small, 64 by 64.",
        "start": 4009.701,
        "duration": 7.85
    },
    {
        "text": "Usually, it's like a, very , nommed\nin picture of a mug, right?",
        "start": 4018.671,
        "duration": 5.6
    },
    {
        "text": "Like the kind of images\nthat Scott has showed me.",
        "start": 4024.271,
        "duration": 3.6
    },
    {
        "text": "but still,",
        "start": 4030.151,
        "duration": 0.54
    },
    {
        "text": "but, so whatever the underlying\nimages, there, let's say there",
        "start": 4032.811,
        "duration": 6.46
    },
    {
        "text": "is a way to extract some kind of\nfeature, like feature from computer",
        "start": 4039.271,
        "duration": 4.82
    },
    {
        "text": "vision such as shift or something.",
        "start": 4044.091,
        "duration": 1.44
    },
    {
        "text": "deep learning is like another thing, but\nwe don't need to use that, but anyway,",
        "start": 4046.601,
        "duration": 4.14
    },
    {
        "text": "first step involves identifying some\nfeatures, and then next step is the",
        "start": 4052.101,
        "duration": 5.74
    },
    {
        "text": "correspondence problem, so when we have\nfeatures from one step, and, we take, we",
        "start": 4057.861,
        "duration": 5.49
    },
    {
        "text": "move a little bit, and then, we have a\nnew image, and then we have a new image.",
        "start": 4063.351,
        "duration": 2.524
    },
    {
        "text": "that we need to be able\nto match those features.",
        "start": 4067.656,
        "duration": 2.49
    },
    {
        "text": "So this is a corresponding\nproblem that Niels talked about.",
        "start": 4070.156,
        "duration": 3.18
    },
    {
        "text": "it, mathematically or like\ncomputationally, this comes out,",
        "start": 4074.146,
        "duration": 5.71
    },
    {
        "text": "the features comes down to like\nin computers as a vector, for this",
        "start": 4079.886,
        "duration": 5.3
    },
    {
        "text": "particular location.",
        "start": 4087.606,
        "duration": 1.03
    },
    {
        "text": "Basically there'll be some vectors\nand basically we're trying to",
        "start": 4088.686,
        "duration": 2.57
    },
    {
        "text": "find, similar vector values.",
        "start": 4091.256,
        "duration": 2.28
    },
    {
        "text": "we can do like a, Euclidean\ndistance between these vector",
        "start": 4094.056,
        "duration": 3.285
    },
    {
        "text": "values to see how close they are.",
        "start": 4097.341,
        "duration": 1.69
    },
    {
        "text": "I'm just trying to make this like\nmore concrete, how this might be",
        "start": 4100.111,
        "duration": 4.77
    },
    {
        "text": "done on Monty or, But, Hojae, didn't\nwe agree that this is exactly not",
        "start": 4104.881,
        "duration": 5.43
    },
    {
        "text": "the thing we want to do in Monty?",
        "start": 4110.311,
        "duration": 1.17
    },
    {
        "text": "This is the computer vision way\nof doing things, but Monty doesn't",
        "start": 4112.171,
        "duration": 3.73
    },
    {
        "text": "look at images like this and try\nto figure out the different parts.",
        "start": 4115.921,
        "duration": 3.02
    },
    {
        "text": "I just want to make sure that what\nI'm understanding is Yeah, I think",
        "start": 4121.451,
        "duration": 4.525
    },
    {
        "text": "this is useful to see how it's done in\ncomputer vision, and maybe we would take",
        "start": 4125.976,
        "duration": 4.81
    },
    {
        "text": "approximations of this, like Yeah, to what\nyou were saying earlier, Jeff, like we",
        "start": 4130.786,
        "duration": 3.7
    },
    {
        "text": "can use much simpler features and just in\na local area and all this kind of stuff.",
        "start": 4134.486,
        "duration": 3.839
    },
    {
        "text": "this is exactly what we don't\nwant to, this is the kind of",
        "start": 4138.496,
        "duration": 2.22
    },
    {
        "text": "things we want to avoid in Monty.",
        "start": 4140.716,
        "duration": 1.44
    },
    {
        "text": "we want, Monty does a, thousand brains\nbasically does a patch at a time and",
        "start": 4143.076,
        "duration": 5.9
    },
    {
        "text": "integrates them in space, as opposed\nto trying to do images at a time.",
        "start": 4149.026,
        "duration": 5.42
    },
    {
        "text": "And so the only important\nthing is to understand for that",
        "start": 4156.226,
        "duration": 2.16
    },
    {
        "text": "patch, where is it in space?",
        "start": 4158.386,
        "duration": 1.59
    },
    {
        "text": "And the next patch, where is it in space?",
        "start": 4159.976,
        "duration": 1.67
    },
    {
        "text": "And the next patch, where is it in space?",
        "start": 4161.646,
        "duration": 1.41
    },
    {
        "text": "Yes, I guess in Monty it would be maybe\nslightly useful in the case where we",
        "start": 4163.891,
        "duration": 7.21
    },
    {
        "text": "have a small patch moving but it's not\nbeing moved by the agent itself or we",
        "start": 4171.101,
        "duration": 4.47
    },
    {
        "text": "have an object moving in the patch, but\nso it could be an alternative to using",
        "start": 4175.571,
        "duration": 7.11
    },
    {
        "text": "optical flow or something like that.",
        "start": 4182.731,
        "duration": 1.654
    },
    {
        "text": "A similar approach to that,\ntrack how, the sensor is moving.",
        "start": 4184.836,
        "duration": 5.39
    },
    {
        "text": "I don't understand that.",
        "start": 4191.176,
        "duration": 1.0
    },
    {
        "text": "it, there's no place in mind\nyou should ever be looking at",
        "start": 4193.086,
        "duration": 2.4
    },
    {
        "text": "the entire image and trying to\ncorrelate across the entire image.",
        "start": 4195.486,
        "duration": 2.14
    },
    {
        "text": "Yeah, no, it's, I'm thinking of this\nmore as what does the approach do?",
        "start": 4198.026,
        "duration": 3.66
    },
    {
        "text": "So replacing the image of the cathedral\nwith a small patch on the object.",
        "start": 4201.686,
        "duration": 5.42
    },
    {
        "text": "And then the idea is basically\njust, okay, we have a small patch.",
        "start": 4207.486,
        "duration": 2.94
    },
    {
        "text": "Now that small patch\nmoved over a little bit.",
        "start": 4210.726,
        "duration": 2.1
    },
    {
        "text": "How do we find out how much it has moved?",
        "start": 4213.346,
        "duration": 2.29
    },
    {
        "text": "We do it by finding specific\npop, like low level features.",
        "start": 4215.676,
        "duration": 3.81
    },
    {
        "text": "so doing it very locally again.",
        "start": 4219.726,
        "duration": 2.11
    },
    {
        "text": "Yeah, exactly.",
        "start": 4221.886,
        "duration": 0.6
    },
    {
        "text": "Yeah, It's a complex because\nhow much you move depends on how",
        "start": 4224.386,
        "duration": 5.2
    },
    {
        "text": "much you move depends on how far\naway it is, and the orientation.",
        "start": 4229.586,
        "duration": 3.14
    },
    {
        "text": "Imagine also you're looking at\nthe facade of Notre Dame from",
        "start": 4233.166,
        "duration": 3.099
    },
    {
        "text": "the side, from a skewed angle.",
        "start": 4236.266,
        "duration": 2.08
    },
    {
        "text": "And now you have even more difficulty\nbecause you're moving in depth",
        "start": 4239.056,
        "duration": 3.29
    },
    {
        "text": "as well as moving, laterally.",
        "start": 4242.376,
        "duration": 2.06
    },
    {
        "text": "It's, really complicated.",
        "start": 4244.916,
        "duration": 1.15
    },
    {
        "text": "Yeah.",
        "start": 4248.886,
        "duration": 0.34
    },
    {
        "text": "So again, for example, there's this\nnice cathedral, for practical purposes,",
        "start": 4249.526,
        "duration": 5.31
    },
    {
        "text": "think of these, replace these images\nas patches that Monty sees, the 64",
        "start": 4254.866,
        "duration": 4.84
    },
    {
        "text": "by 64 patches, the tiny little, dots.",
        "start": 4259.726,
        "duration": 5.66
    },
    {
        "text": "so anyway, between the two patches, we'll,",
        "start": 4267.156,
        "duration": 4.5
    },
    {
        "text": "If we go this route, we can extract\nsome features, we'll try to match",
        "start": 4274.011,
        "duration": 3.33
    },
    {
        "text": "some features between two patches, and\nthen, I'm skipping a lot of the math",
        "start": 4277.351,
        "duration": 6.33
    },
    {
        "text": "here, but basically, if we have the\ncorresponding features, and there is",
        "start": 4283.691,
        "duration": 4.0
    },
    {
        "text": "some epipolar geometry that we can do\nto put these, images in 3D space in the",
        "start": 4287.701,
        "duration": 8.02
    },
    {
        "text": "same kind of, same coordinate system.",
        "start": 4295.721,
        "duration": 3.39
    },
    {
        "text": "Unfortunately, I used common\nreference frame speculation",
        "start": 4299.911,
        "duration": 2.58
    },
    {
        "text": "overloaded, the term a little bit, but",
        "start": 4304.281,
        "duration": 1.73
    },
    {
        "text": "but basically this\nprocess, overall is called,",
        "start": 4308.191,
        "duration": 3.63
    },
    {
        "text": "I hadn't gone to the math here, but\nthere's a process called triangulation",
        "start": 4314.771,
        "duration": 5.01
    },
    {
        "text": "that we are able to, once we have\nthese two images with corresponding",
        "start": 4319.781,
        "duration": 3.34
    },
    {
        "text": "points, then we can estimate what\nthe 3D point is, and I know that's",
        "start": 4323.121,
        "duration": 2.8
    },
    {
        "text": "the whole point of knowing this, but,",
        "start": 4325.921,
        "duration": 1.48
    },
    {
        "text": "and then just for the algorithm it's,\nSIG, the final bundle adjustment is",
        "start": 4330.451,
        "duration": 5.355
    },
    {
        "text": "when you have, so we do this starting\nwith two images, so this algorithm is",
        "start": 4335.806,
        "duration": 5.14
    },
    {
        "text": "iterative in a sense that okay, once we're\ndone with the two images, we'll try to",
        "start": 4341.316,
        "duration": 2.81
    },
    {
        "text": "add another one, fourth one, yadda and\nthat's what the final kind of point is.",
        "start": 4344.136,
        "duration": 5.83
    },
    {
        "text": "I don't have a better\nvisualization of this.",
        "start": 4351.481,
        "duration": 1.79
    },
    {
        "text": "I think it starts falling apart.",
        "start": 4353.271,
        "duration": 2.242
    },
    {
        "text": "That idea starts falling apart\nwhen we're talking about patches.",
        "start": 4355.513,
        "duration": 4.228
    },
    {
        "text": "just, again, typically what we'll do is\nwe'll fixate someplace and then we'll move",
        "start": 4362.601,
        "duration": 4.64
    },
    {
        "text": "some distance and we'll fix it again and\nwe'll move some distance and fix it again.",
        "start": 4367.481,
        "duration": 3.54
    },
    {
        "text": "we don't move our eyes smoothly\nover an object doing this,",
        "start": 4372.346,
        "duration": 2.89
    },
    {
        "text": "this integration smoothly.",
        "start": 4376.356,
        "duration": 1.46
    },
    {
        "text": "It doesn't happen.",
        "start": 4377.826,
        "duration": 0.84
    },
    {
        "text": "and we don't want it to happen that way.",
        "start": 4379.276,
        "duration": 1.1
    },
    {
        "text": "Yeah.",
        "start": 4381.596,
        "duration": 0.2
    },
    {
        "text": "Maybe if something else is moving,\nif there is a moving object, like",
        "start": 4381.796,
        "duration": 3.58
    },
    {
        "text": "a car driving past or something.",
        "start": 4385.376,
        "duration": 1.71
    },
    {
        "text": "I don't know.",
        "start": 4388.386,
        "duration": 0.35
    },
    {
        "text": "Maybe.",
        "start": 4389.116,
        "duration": 0.54
    },
    {
        "text": "I think we should analyze\nthat problem separately.",
        "start": 4391.286,
        "duration": 2.08
    },
    {
        "text": "It's like a different task.",
        "start": 4393.366,
        "duration": 1.61
    },
    {
        "text": "Or just, it's just an object, even\nif it's not moving, it's just like",
        "start": 4396.861,
        "duration": 3.15
    },
    {
        "text": "behaving like a bird is flapping\nits wings in front of you or bobbing",
        "start": 4400.011,
        "duration": 3.54
    },
    {
        "text": "its head or something like that.",
        "start": 4403.551,
        "duration": 1.33
    },
    {
        "text": "That's a separate problem.",
        "start": 4409.321,
        "duration": 1.43
    },
    {
        "text": "Yeah.",
        "start": 4412.201,
        "duration": 0.31
    },
    {
        "text": "Yeah, so that's the end of my\nstructure of what structural motion is.",
        "start": 4415.036,
        "duration": 4.07
    },
    {
        "text": "It's one of the ways to, one of many\nways to estimate depth, with I think",
        "start": 4419.106,
        "duration": 4.8
    },
    {
        "text": "probably the least minimal requirements,\nlike one eyeball is fine, one movement",
        "start": 4423.966,
        "duration": 5.06
    },
    {
        "text": "is fine, and then we don't need,\ntwo eyeballs like changes in Monty.",
        "start": 4429.026,
        "duration": 5.465
    },
    {
        "text": "I think we're agreeing, Jeff, I don't\nknow how, well this will work in patches.",
        "start": 4435.671,
        "duration": 4.76
    },
    {
        "text": "in computer vision y terms, it's because\nI think the patches are quite featureless.",
        "start": 4440.841,
        "duration": 4.79
    },
    {
        "text": "there's not like interesting, a lot\nof interesting edges, interesting",
        "start": 4445.981,
        "duration": 3.57
    },
    {
        "text": "features, like in the cathedral example.",
        "start": 4449.551,
        "duration": 2.36
    },
    {
        "text": "and so one, there's\nnot that many features.",
        "start": 4452.741,
        "duration": 2.09
    },
    {
        "text": "And two, because when we see one\npatch, there's a lot of edges there.",
        "start": 4454.851,
        "duration": 4.639
    },
    {
        "text": "There's a lot of edges\non the cathedra, right?",
        "start": 4459.641,
        "duration": 1.86
    },
    {
        "text": "in some sense, it's almost\ndefined by a bunch of edges.",
        "start": 4461.651,
        "duration": 4.66
    },
    {
        "text": "Yeah.",
        "start": 4466.961,
        "duration": 0.55
    },
    {
        "text": "But it would only work locally, right?",
        "start": 4468.701,
        "duration": 1.27
    },
    {
        "text": "We've agreed this, we're not going to\ntry to do this the way they did it in",
        "start": 4469.971,
        "duration": 3.18
    },
    {
        "text": "these computer vision systems, right?",
        "start": 4473.151,
        "duration": 2.619
    },
    {
        "text": "It's just, it's something\nthat can be done locally.",
        "start": 4475.771,
        "duration": 2.0
    },
    {
        "text": "in the bottom line, just\njump to the conclusion here.",
        "start": 4478.191,
        "duration": 3.24
    },
    {
        "text": "it's really interesting\nthere how biology does this.",
        "start": 4482.321,
        "duration": 2.17
    },
    {
        "text": "but if we had a perfect depth camera,\nwe wouldn't need any of it, right?",
        "start": 4485.926,
        "duration": 5.01
    },
    {
        "text": "Is that correct?",
        "start": 4491.116,
        "duration": 0.58
    },
    {
        "text": "Yeah, it's just interesting\nto know that we can make that",
        "start": 4491.696,
        "duration": 5.16
    },
    {
        "text": "assumption that we can have depth.",
        "start": 4496.856,
        "duration": 2.0
    },
    {
        "text": "And if we needed something else, we\ncould ask ourselves, oh, maybe we'll",
        "start": 4500.396,
        "duration": 3.04
    },
    {
        "text": "use LiDAR, which is a different depth.",
        "start": 4503.436,
        "duration": 2.13
    },
    {
        "text": "That's another depth camera.",
        "start": 4505.576,
        "duration": 1.13
    },
    {
        "text": "Yeah.",
        "start": 4507.606,
        "duration": 0.324
    },
    {
        "text": "so it's, really, it's, and it's also\nuseful to say, why is this extra machinery",
        "start": 4510.051,
        "duration": 4.65
    },
    {
        "text": "in the neocortex with V1, because maybe\nit has to do these computations, but",
        "start": 4514.701,
        "duration": 3.87
    },
    {
        "text": "we don't have to do those computations.",
        "start": 4518.571,
        "duration": 1.29
    },
    {
        "text": "Yeah.",
        "start": 4521.031,
        "duration": 0.28
    },
    {
        "text": "Yeah, I guess one of the reasons we were\ntalking about it was, there was a few",
        "start": 4522.481,
        "duration": 4.49
    },
    {
        "text": "things, yeah, in terms of applications of\nMonty, like depth cameras are expensive,",
        "start": 4526.971,
        "duration": 4.45
    },
    {
        "text": "a lot of people don't have them.",
        "start": 4531.471,
        "duration": 1.25
    },
    {
        "text": "So it was just interesting, like what\nwe can do with 2D cameras, since that",
        "start": 4532.931,
        "duration": 3.36
    },
    {
        "text": "seems to be sufficient for people.",
        "start": 4536.291,
        "duration": 1.37
    },
    {
        "text": "there was, yeah, to Viviane's point,\nthe biological matching, at the",
        "start": 4539.161,
        "duration": 4.98
    },
    {
        "text": "moment, we're assuming this depth\ninformation is available basically",
        "start": 4544.141,
        "duration": 2.56
    },
    {
        "text": "in the first cortical column.",
        "start": 4546.701,
        "duration": 1.25
    },
    {
        "text": "Does that mean that we are",
        "start": 4548.471,
        "duration": 1.04
    },
    {
        "text": "somehow making incorrect assumptions\nabout what cortical columns can do.",
        "start": 4551.681,
        "duration": 2.8
    },
    {
        "text": "what if the first cortical column\nwasn't, what if V1 was entirely",
        "start": 4554.941,
        "duration": 3.19
    },
    {
        "text": "responsible for getting the depth\ninformation in the first place?",
        "start": 4558.161,
        "duration": 2.06
    },
    {
        "text": "then we'd have to rethink\nwhat the columns are doing.",
        "start": 4560.901,
        "duration": 2.02
    },
    {
        "text": "Unfortunately, that doesn't\nseem to be the case.",
        "start": 4563.391,
        "duration": 1.53
    },
    {
        "text": "and then, yeah, I guess\nthose were the main two, but,",
        "start": 4566.831,
        "duration": 3.15
    },
    {
        "text": "that was what led us down\nthis, vein of thought.",
        "start": 4572.441,
        "duration": 3.17
    },
    {
        "text": "It seems, if we wanted to,\nit's an interesting question.",
        "start": 4575.651,
        "duration": 2.02
    },
    {
        "text": "if we really had to do some sort of\ncost reduction or a different type of",
        "start": 4577.961,
        "duration": 3.44
    },
    {
        "text": "camera, I suppose you could just, You\ncould go to just having two cameras,",
        "start": 4581.401,
        "duration": 4.19
    },
    {
        "text": "like two eyes, just, separated by\nsome space, of course, the larger the",
        "start": 4585.601,
        "duration": 4.97
    },
    {
        "text": "distance, the better parallax you'll get.",
        "start": 4590.571,
        "duration": 1.69
    },
    {
        "text": "and, and build a system\nthat works like that.",
        "start": 4594.001,
        "duration": 3.77
    },
    {
        "text": "where you can just alternate back\nand forth and determine depth.",
        "start": 4599.561,
        "duration": 3.39
    },
    {
        "text": "But that would be all outside\nof the cortical column, it would",
        "start": 4603.211,
        "duration": 2.26
    },
    {
        "text": "be all in the sensor module.",
        "start": 4605.491,
        "duration": 1.49
    },
    {
        "text": "the sensor module would have, would\nget input from both these cameras",
        "start": 4608.316,
        "duration": 2.78
    },
    {
        "text": "and, figure what to do with it.",
        "start": 4611.506,
        "duration": 1.27
    },
    {
        "text": "so that would be one thing we could do.",
        "start": 4614.416,
        "duration": 1.61
    },
    {
        "text": "Yeah.",
        "start": 4616.776,
        "duration": 0.28
    },
    {
        "text": "I think one other thing I'd come\nacross that I thought was useful to",
        "start": 4617.056,
        "duration": 3.73
    },
    {
        "text": "remember or whatever is just that,\nlike depth cameras are generally quite",
        "start": 4620.786,
        "duration": 3.94
    },
    {
        "text": "limited in that, so they tend to work\nby projecting some form of light.",
        "start": 4624.726,
        "duration": 4.3
    },
    {
        "text": "So for example, they use this\ntime of flight algorithm or this",
        "start": 4629.716,
        "duration": 3.63
    },
    {
        "text": "kind of structured light space.",
        "start": 4633.366,
        "duration": 1.945
    },
    {
        "text": "Thanks.",
        "start": 4635.311,
        "duration": 0.034
    },
    {
        "text": "Where they kind of output that and\nbasically, but basically in both cases,",
        "start": 4636.686,
        "duration": 2.79
    },
    {
        "text": "they then measure that light when it\ncomes back to them, but that fails",
        "start": 4639.496,
        "duration": 4.36
    },
    {
        "text": "very quickly, for example, in daylight.",
        "start": 4643.856,
        "duration": 1.78
    },
    {
        "text": "So depth cameras are\nvery difficult to use.",
        "start": 4646.296,
        "duration": 2.32
    },
    {
        "text": "except for LIDAR LIDAR is popular.",
        "start": 4649.136,
        "duration": 3.52
    },
    {
        "text": "Because it's lighter, so\nyeah, I guess also expensive.",
        "start": 4654.296,
        "duration": 3.07
    },
    {
        "text": "Anyways, I guess it's just, yeah, it's\nnice that what the brain does seems to",
        "start": 4657.466,
        "duration": 5.77
    },
    {
        "text": "be robust in a lot of different settings.",
        "start": 4663.256,
        "duration": 1.95
    },
    {
        "text": "I, don't know the current state\nof the art of depth cameras.",
        "start": 4668.256,
        "duration": 2.62
    },
    {
        "text": "I thought they were pretty cheap\nthese days because they have them in",
        "start": 4672.226,
        "duration": 2.275
    },
    {
        "text": "game consoles and things like that.",
        "start": 4674.501,
        "duration": 1.515
    },
    {
        "text": "maybe they're not very good.",
        "start": 4677.706,
        "duration": 1.11
    },
    {
        "text": "Yeah, I'm not sure the one in, yeah,\nI think ones like, I think decent",
        "start": 4679.951,
        "duration": 3.72
    },
    {
        "text": "ones like the Intel RealSense one\nor whatever can cost nearly 500.",
        "start": 4683.681,
        "duration": 5.33
    },
    {
        "text": "is it, there's a depth, there's an\ninfrared depth camera in my phone, right?",
        "start": 4689.941,
        "duration": 4.07
    },
    {
        "text": "Don't they use infrared depth information\nto do face recognition on a phone?",
        "start": 4694.301,
        "duration": 3.47
    },
    {
        "text": "yeah, that's why we did the Monty\nmeets world with the, iPhone",
        "start": 4700.451,
        "duration": 4.93
    },
    {
        "text": "because it has this camera in it.",
        "start": 4705.391,
        "duration": 1.87
    },
    {
        "text": "But to get a standalone\none is Not that easy.",
        "start": 4707.871,
        "duration": 3.96
    },
    {
        "text": "I think actually buying a gaming\nconsole is the cheapest option.",
        "start": 4711.831,
        "duration": 3.66
    },
    {
        "text": "All right, we don't have to worry\nabout, what it costs us to get one",
        "start": 4715.561,
        "duration": 3.59
    },
    {
        "text": "and what it costs to build one.",
        "start": 4719.151,
        "duration": 1.22
    },
    {
        "text": "Obviously, they're not very expensive.",
        "start": 4720.651,
        "duration": 1.31
    },
    {
        "text": "They're putting them in every phone.",
        "start": 4721.961,
        "duration": 1.02
    },
    {
        "text": "they're going to be really cheap.",
        "start": 4724.241,
        "duration": 0.91
    },
    {
        "text": "those are going to be, pennies,\ndollars, max, I imagine, on",
        "start": 4726.991,
        "duration": 6.48
    },
    {
        "text": "a phone, something like that.",
        "start": 4733.471,
        "duration": 0.96
    },
    {
        "text": "So they can be built cheaply.",
        "start": 4735.211,
        "duration": 1.59
    },
    {
        "text": "We don't have to worry\nabout that right now.",
        "start": 4736.961,
        "duration": 1.65
    },
    {
        "text": "Unless we need to go out and buy\none, then we can worry about it.",
        "start": 4738.991,
        "duration": 2.24
    },
    {
        "text": "But in terms of, the limitations of\nMonty or limitations of sensorimotor",
        "start": 4743.351,
        "duration": 4.64
    },
    {
        "text": "learning, it's not really a concern.",
        "start": 4748.001,
        "duration": 1.76
    },
    {
        "text": "There's lots of ways of getting around it.",
        "start": 4750.641,
        "duration": 1.29
    },
    {
        "text": "Yeah, I feel like a nice maybe takeaway\nfrom all the reading that we've done is",
        "start": 4753.321,
        "duration": 4.35
    },
    {
        "text": "that if we need to revisit this and build\ndepth perception from 2D images, There's",
        "start": 4757.671,
        "duration": 6.08
    },
    {
        "text": "lots of ways we can do it that fit really\nnicely with Monty and stuff like that.",
        "start": 4763.751,
        "duration": 3.35
    },
    {
        "text": "But yeah, to your point that we can\nprobably just keep using the depth",
        "start": 4767.141,
        "duration": 3.0
    },
    {
        "text": "camera like we are for the moment.",
        "start": 4770.141,
        "duration": 1.64
    },
    {
        "text": "think about the ultrasound\nsystem that we've talked with",
        "start": 4773.151,
        "duration": 2.6
    },
    {
        "text": "the Gage Foundation about.",
        "start": 4775.761,
        "duration": 1.15
    },
    {
        "text": "We talked a long time ago.",
        "start": 4777.281,
        "duration": 0.94
    },
    {
        "text": "I don't know if you guys talked since.",
        "start": 4778.221,
        "duration": 1.18
    },
    {
        "text": "There's a, that's an interesting,\nthere's like a camera that is,",
        "start": 4779.821,
        "duration": 3.72
    },
    {
        "text": "I, don't know, I assume they get, they,\nthey must get depth perception from",
        "start": 4785.701,
        "duration": 3.18
    },
    {
        "text": "that, but they also, you really can't\ninterpret those images at all until",
        "start": 4788.881,
        "duration": 3.375
    },
    {
        "text": "you start moving the sensor, and that\nis not like a saccade, that's like a",
        "start": 4792.266,
        "duration": 3.62
    },
    {
        "text": "continuous motion, or maybe, I don't know,\nI have to think about that some more.",
        "start": 4795.926,
        "duration": 2.83
    },
    {
        "text": "I'm just saying, there's a practical\nsystem that you might want to, it's",
        "start": 4800.436,
        "duration": 2.94
    },
    {
        "text": "like a camera, and it's moving,\nbut it doesn't move like eyes.",
        "start": 4803.376,
        "duration": 4.57
    },
    {
        "text": "something to think about.",
        "start": 4809.936,
        "duration": 1.1
    },
    {
        "text": "Yeah, actually, so that reminds me of the\nthird point that I forgot about, of why",
        "start": 4811.266,
        "duration": 3.27
    },
    {
        "text": "we wanted to talk about this, was that, we\nhave some of these challenges like, How do",
        "start": 4814.536,
        "duration": 5.01
    },
    {
        "text": "we recognize, after a lifetime of exposure\nof 3D, the 3D world, how do we recognize",
        "start": 4819.546,
        "duration": 5.44
    },
    {
        "text": "images, in a 2D picture or a painting?",
        "start": 4825.006,
        "duration": 3.19
    },
    {
        "text": "And it was just thinking about, what\nkind of information from depth perception",
        "start": 4829.436,
        "duration": 5.7
    },
    {
        "text": "and how that emerges could inform that.",
        "start": 4835.176,
        "duration": 1.98
    },
    {
        "text": "And I think what was interesting from\nthat is, is, as you I think everyone",
        "start": 4837.156,
        "duration": 4.52
    },
    {
        "text": "would have guessed, there's lots of\nmonocular cues for depth perception that",
        "start": 4841.726,
        "duration": 4.46
    },
    {
        "text": "don't have anything to do with movement.",
        "start": 4846.186,
        "duration": 1.22
    },
    {
        "text": "And that's things like\nshadow and lighting.",
        "start": 4848.426,
        "duration": 2.06
    },
    {
        "text": "Or even just relative size, if I have\na set of features, and let's say a",
        "start": 4851.311,
        "duration": 6.25
    },
    {
        "text": "set of features are the letters in\na word, and now all of a sudden the",
        "start": 4857.811,
        "duration": 3.51
    },
    {
        "text": "letters on one side are smaller and\nthe letters on the other side are",
        "start": 4861.321,
        "duration": 2.35
    },
    {
        "text": "smaller, and it has the right sort of",
        "start": 4863.671,
        "duration": 1.98
    },
    {
        "text": "skew to the whole thing, you'd say,\noh, that's, this word is facing away,",
        "start": 4868.321,
        "duration": 2.92
    },
    {
        "text": "it's moving away from me, it's like\nit's in depth, it's in, it's moved,",
        "start": 4871.291,
        "duration": 3.72
    },
    {
        "text": "it's rotated in depth and plane.",
        "start": 4875.061,
        "duration": 1.94
    },
    {
        "text": "So there's size cues too, That's an\ninteresting one because this one actually",
        "start": 4877.911,
        "duration": 5.435
    },
    {
        "text": "relies on model, having learned models.",
        "start": 4883.346,
        "duration": 2.51
    },
    {
        "text": "We only have a couple of minutes here.",
        "start": 4889.431,
        "duration": 1.2
    },
    {
        "text": "Can I just throw out\nsomething to think about?",
        "start": 4890.631,
        "duration": 1.91
    },
    {
        "text": "Yeah.",
        "start": 4893.601,
        "duration": 0.08
    },
    {
        "text": "Something that's been, something that's\nbeen, something I've worried about.",
        "start": 4893.861,
        "duration": 2.98
    },
    {
        "text": "I'm not worried, but I've always,\nit's puzzling and I haven't really",
        "start": 4896.841,
        "duration": 4.08
    },
    {
        "text": "thought about it too much, but it's\nstill, and it's related to this.",
        "start": 4900.921,
        "duration": 2.33
    },
    {
        "text": "Think about an animal learning\nin a model of its environment.",
        "start": 4904.751,
        "duration": 2.6
    },
    {
        "text": "And the grid cells in\nthe enthorhinal cortex.",
        "start": 4907.891,
        "duration": 2.49
    },
    {
        "text": "The reference frame is a plane,\nin the plane of the environment.",
        "start": 4911.251,
        "duration": 4.34
    },
    {
        "text": "it's like a map on the surface\nof the environment, right?",
        "start": 4917.051,
        "duration": 3.99
    },
    {
        "text": "but we never see that view.",
        "start": 4921.891,
        "duration": 1.76
    },
    {
        "text": "we don't look down upon\nour environment from above.",
        "start": 4924.011,
        "duration": 2.48
    },
    {
        "text": "We don't look and look down\nlike we're looking at a map.",
        "start": 4927.111,
        "duration": 2.26
    },
    {
        "text": "We're seeing it skewed from the, side.",
        "start": 4929.381,
        "duration": 2.94
    },
    {
        "text": "And, the views we see are never the model\nwe end up with is not what we observe.",
        "start": 4934.301,
        "duration": 5.97
    },
    {
        "text": "We observe these different skewed\nthings and yet we end up with",
        "start": 4940.871,
        "duration": 3.61
    },
    {
        "text": "this model which is like a map.",
        "start": 4944.481,
        "duration": 1.37
    },
    {
        "text": "And, and you can see this\ntoo, it's very difficult to,",
        "start": 4946.511,
        "duration": 3.1
    },
    {
        "text": "it's very easy to draw a map.",
        "start": 4949.691,
        "duration": 1.68
    },
    {
        "text": "View if I ask me to draw a map of\nyour house, but if I said, draw what",
        "start": 4951.686,
        "duration": 3.42
    },
    {
        "text": "your living room looks like, looking\nthrough the door to the kitchen, which",
        "start": 4955.106,
        "duration": 3.0
    },
    {
        "text": "is something you see all day long,\nit's gonna be really hard to draw that.",
        "start": 4958.106,
        "duration": 3.59
    },
    {
        "text": "And if you've, unless you're a practice\nartist and you've learned to, to practice",
        "start": 4961.696,
        "duration": 3.63
    },
    {
        "text": "on perce on depth perception issues.",
        "start": 4965.326,
        "duration": 2.46
    },
    {
        "text": "So there's this sort of gap between\nwhat we actually observe and then",
        "start": 4968.626,
        "duration": 6.02
    },
    {
        "text": "what, we actually, the model we\nactually present, which is not.",
        "start": 4975.246,
        "duration": 3.42
    },
    {
        "text": "It's, there, there's a gap there,\nand, the same thing, I think, is",
        "start": 4979.166,
        "duration": 5.65
    },
    {
        "text": "true for, We assume right now there's\nthree dimensional models in Monty,",
        "start": 4984.816,
        "duration": 5.12
    },
    {
        "text": "and if you assume you have a finger\ntouch up sensor, it's not a problem,",
        "start": 4990.436,
        "duration": 4.2
    },
    {
        "text": "but visually it would be a problem.",
        "start": 4995.166,
        "duration": 3.17
    },
    {
        "text": "It's if I'm looking at an object visually,\nlike a face, and I'm seeing faces at",
        "start": 4998.746,
        "duration": 5.34
    },
    {
        "text": "skewed angles to me all the time, the\nmodel I have of a face is more 2D.",
        "start": 5004.086,
        "duration": 4.85
    },
    {
        "text": "It's oh, there's a nose in the\nmiddle and two eyes and a mouth.",
        "start": 5008.936,
        "duration": 2.36
    },
    {
        "text": "But that's not usually what I see.",
        "start": 5011.751,
        "duration": 1.48
    },
    {
        "text": "Usually I see these\nvery odd looking things.",
        "start": 5013.231,
        "duration": 1.85
    },
    {
        "text": "and so it's the same problem exists in\ncortex, that there is this, I don't know",
        "start": 5016.811,
        "duration": 6.135
    },
    {
        "text": "if you understand the problem, why it's\nso puzzling, but how do we convert from",
        "start": 5022.946,
        "duration": 3.85
    },
    {
        "text": "what we see to what we actually map?",
        "start": 5027.056,
        "duration": 1.77
    },
    {
        "text": "Maybe part of this is, maybe a little\nconfounding factor in there is like",
        "start": 5030.216,
        "duration": 5.64
    },
    {
        "text": "the, decoding problem, the way the,\nbasically that we're not very good",
        "start": 5036.616,
        "duration": 4.28
    },
    {
        "text": "at drawing in 3D, but if you would.",
        "start": 5040.896,
        "duration": 2.65
    },
    {
        "text": "And I think that if you could actually\nwalk into a room and it would look",
        "start": 5043.591,
        "duration": 2.55
    },
    {
        "text": "different from that perspective,\nyou would be surprised, like you",
        "start": 5046.141,
        "duration": 3.2
    },
    {
        "text": "would make the correct predictions\nfor how the 3D face would look like.",
        "start": 5049.341,
        "duration": 3.89
    },
    {
        "text": "The room would look like.",
        "start": 5053.831,
        "duration": 1.045
    },
    {
        "text": "So the model must be 3D and have it.",
        "start": 5054.876,
        "duration": 2.595
    },
    {
        "text": "But it, I feel like even mental\nimagery, like if I imagine my",
        "start": 5058.841,
        "duration": 4.23
    },
    {
        "text": "kitchen and things, or if I imagine\nsomeone's face from the side, I",
        "start": 5063.071,
        "duration": 5.0
    },
    {
        "text": "feel like I can have a pretty good.",
        "start": 5068.071,
        "duration": 1.6
    },
    {
        "text": "It's certainly way better than I can\ndraw, image of what it looks like.",
        "start": 5070.336,
        "duration": 4.205
    },
    {
        "text": "that's the thing.",
        "start": 5074.777,
        "duration": 0.708
    },
    {
        "text": "It's interesting because, first\nof all, how do you learn that",
        "start": 5075.486,
        "duration": 2.87
    },
    {
        "text": "model from your observations?",
        "start": 5078.366,
        "duration": 1.79
    },
    {
        "text": "And clearly, when I see a face\nfrom an angle, I will recognize",
        "start": 5080.696,
        "duration": 3.76
    },
    {
        "text": "if something's wrong about it.",
        "start": 5084.456,
        "duration": 1.06
    },
    {
        "text": "Literally, right away.",
        "start": 5086.026,
        "duration": 0.98
    },
    {
        "text": "But it's not a janitor model.",
        "start": 5087.486,
        "duration": 1.37
    },
    {
        "text": "I can't say, oh, let's draw that.",
        "start": 5088.856,
        "duration": 1.72
    },
    {
        "text": "It is extremely hard to draw a face\nthat's even slightly realistic.",
        "start": 5090.576,
        "duration": 4.32
    },
    {
        "text": "if you've tried it, try it sometimes.",
        "start": 5095.906,
        "duration": 1.73
    },
    {
        "text": "It's really hard.",
        "start": 5097.696,
        "duration": 1.06
    },
    {
        "text": "And, it just can't do it.",
        "start": 5099.136,
        "duration": 2.36
    },
    {
        "text": "And so it's like you have this model,\nit's more like to me, it's like you",
        "start": 5101.576,
        "duration": 6.22
    },
    {
        "text": "have a model of the environment that's,\nreference frame is, anchored on the floor.",
        "start": 5107.806,
        "duration": 5.89
    },
    {
        "text": "It's like a map of the floor in some\nsense, and yet somehow we're able",
        "start": 5113.776,
        "duration": 4.29
    },
    {
        "text": "to on the fly generate 3D images,\nnot that we can create them, but we",
        "start": 5118.066,
        "duration": 4.9
    },
    {
        "text": "would know if they're wrong, and we\ncan infer from those skewed views and",
        "start": 5122.966,
        "duration": 5.2
    },
    {
        "text": "skewed angles, no problem whatsoever.",
        "start": 5128.186,
        "duration": 2.01
    },
    {
        "text": "in fact, that's how we do it all,\nthat's almost all we do, and yet",
        "start": 5131.616,
        "duration": 3.79
    },
    {
        "text": "the model itself is not that view.",
        "start": 5135.406,
        "duration": 1.65
    },
    {
        "text": "I have this other meeting here now in a\ncouple minutes, so I have to run to it.",
        "start": 5137.276,
        "duration": 3.29
    },
    {
        "text": "I'm in the office today, by the way,\nI'm at the office, I haven't been",
        "start": 5140.746,
        "duration": 2.78
    },
    {
        "text": "here, haven't been here in months.",
        "start": 5143.526,
        "duration": 1.33
    },
    {
        "text": "Yeah, basically we have the group,\nbecause I think we've talked about some",
        "start": 5144.856,
        "duration": 4.84
    },
    {
        "text": "stuff around the bottleneck of goal\nstates and how, which I think is what",
        "start": 5149.696,
        "duration": 3.86
    },
    {
        "text": "Viviane was also getting into earlier.",
        "start": 5153.556,
        "duration": 1.98
    },
    {
        "text": "And how that Yeah.",
        "start": 5155.966,
        "duration": 0.813
    },
    {
        "text": "Yeah.",
        "start": 5156.779,
        "duration": 0.133
    },
    {
        "text": "Yeah.",
        "start": 5156.912,
        "duration": 0.133
    },
    {
        "text": "Yeah, basically the model is in the\ncolumn, but then when we actually",
        "start": 5157.736,
        "duration": 4.18
    },
    {
        "text": "want to produce actions to draw it\nor, yeah, to draw it, we can't just",
        "start": 5161.916,
        "duration": 5.57
    },
    {
        "text": "take the model and put it on paper.",
        "start": 5167.496,
        "duration": 1.51
    },
    {
        "text": "We have to send action commands to\nour hand to draw it and, Because we",
        "start": 5169.006,
        "duration": 6.385
    },
    {
        "text": "can't communicate the entire model,\nwe recognize mistakes when features",
        "start": 5175.391,
        "duration": 3.9
    },
    {
        "text": "come in, but we can't send it out.",
        "start": 5179.291,
        "duration": 1.83
    },
    {
        "text": "But think of it this way.",
        "start": 5181.681,
        "duration": 1.04
    },
    {
        "text": "there's a huge amount of evidence\nin the enthorhinal cortex that",
        "start": 5183.421,
        "duration": 2.72
    },
    {
        "text": "the models are two, basically two\ndimensional, and somehow, we're",
        "start": 5186.501,
        "duration": 6.22
    },
    {
        "text": "able to tack on three dimensional\nobjects onto that two dimensional",
        "start": 5192.721,
        "duration": 3.9
    },
    {
        "text": "model and then generate views of it.",
        "start": 5196.631,
        "duration": 2.77
    },
    {
        "text": "I'll leave it as a, to me, it's a puzzle.",
        "start": 5201.481,
        "duration": 1.89
    },
    {
        "text": "It is, we're not doing this in\nmoney, we're just doing direct.",
        "start": 5204.121,
        "duration": 3.29
    },
    {
        "text": "oh, we have a X, Y, Z location\nand rec, write it down.",
        "start": 5207.741,
        "duration": 3.21
    },
    {
        "text": "And our models are three dimensional\nand we could create, we could in theory.",
        "start": 5211.781,
        "duration": 4.38
    },
    {
        "text": "anyway, this goes back to the question\nin the brain, are all these models",
        "start": 5217.761,
        "duration": 5.86
    },
    {
        "text": "really two dimensional and with.",
        "start": 5223.621,
        "duration": 2.475
    },
    {
        "text": "3D appendages.",
        "start": 5226.471,
        "duration": 1.4
    },
    {
        "text": "Or are they 3D?",
        "start": 5229.181,
        "duration": 1.569
    },
    {
        "text": "And, I'm not so certain.",
        "start": 5230.751,
        "duration": 1.89
    },
    {
        "text": "this is, because grid cells are basically\ntwo dimensional and, yet somehow they work",
        "start": 5233.191,
        "duration": 4.9
    },
    {
        "text": "to do this three dimensional modeling.",
        "start": 5238.091,
        "duration": 2.07
    },
    {
        "text": "Anyway, I just wanted to throw that out\nas, we're talking about these issues about",
        "start": 5241.241,
        "duration": 4.38
    },
    {
        "text": "vision, this problem really surfaces in\nvision and, and that's all I want to talk",
        "start": 5245.621,
        "duration": 7.17
    },
    {
        "text": "about, it doesn't surface with touch.",
        "start": 5252.791,
        "duration": 1.88
    },
    {
        "text": "And so that's another sort of mystery of\nvision, in my mind, how does that work.",
        "start": 5255.821,
        "duration": 4.3
    }
]