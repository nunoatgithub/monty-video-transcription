Yeah. and, we can, as interactive as we can make it, the better. and I'm gonna talk about this from a biological point of view, right? Like the, neuro architecture and, that can inform the decisions, but it's not, I'm not gonna talk about it from Amani perspective specifically, but I think it might be helpful for people to see or at least understand some of the concepts if they're not obvious, or you haven't been exposed to 'em before.

again, I'm not sure where everyone's mindset is about this on hierarchy, what, so let me just, I can just jump right into it. and I'm just gonna do this verbally and just interrupt me if you have any questions really. That would be much better than me just talking. when we talk about hierarchy in the neocortex, this comes about from two basic techniques that they use, some or two basic endeavors. One is anatomical evidence, like this is how neurons are connected. So they look at how, what connects to what the physical structure of the brain. And those connections define a hierarchy. The other way they look at it is from a physiological point of view, like how do the cells respond? you show an image or a sound or something like that, and then you can look at different cells in the brain and you can see oh, they, they're not responding the same way. And so these, and how they respond and to what kind of responses they make is also evidence of hierarchy. So these two things working together and anatomy and physiology are the basic means by which we understand the hierarchical structure of cortex. There are very few theories about how this actually works in any detail. and I think we have some of the best.

but there's a lot of data, huge amounts of empirical data on anatomy and physiology. And I've say this many times. You, would be blown away by how many papers in the details of 'em and how hard they are to read. but there's so much data. So maybe we can just start off with I think the whole idea of hierarchy really got kicked into gear with this famous 1992 paper by Feldman, Vanessa, and we talk about it a lot. And so maybe I could just show you that paper unless there's any questions before we get into that.

Okay. I need to share my screen then. I'm gonna do that by hitting the little share screen button. I just wanna maybe add something to what you said. First of all, echo how difficult it is to really understand hierarchy in depth, but it's also in parallel. It's surprising to me that how many people have a very narrow view of hierarchy in the literature. and the all thing is this one thing, A lot of it's from this felman and venison paper and in other words, and they just don't consider all of the other evidence that's out there. it's, quite remarkable to me. and how much, and like almost no one seems to understand like these few really important things about it that are like 90 of the people don't consider. Yeah. Also feel like from, yeah, I just, from like computational viewpoint, I feel like this whole idea of hierarchy for object recognition and a lot of work from like Jim DiCarlo and my whole group is again very dominant and it's so focused on just recognizing objects. And so all that kind of results in is basically you have okay, cat versus dog. Yeah. And that's the extent of your representation and how rich, or rather not rich it is. And there's just very little thought.

What the dog looks like and any other kind of richer understanding about what a dog is. And it's no, You just, you separate them in a high dimensional space. And then that's what h is for. and part of the thing, he and others, also have lots of actual data and empirical data. So any other view has to be somewhat compatible with that data. It has to also explain, that.

so if you haven't seen it, this is this paper. the film and Esen paper is very famous. it for quite long, there's a lot of data in it. what they basically did is they took a whole bunch of studies, mostly about the Macco monkey. And these were, anatomical studies primarily, meaning they would, they could take, they collect, for example, inject a dye in one part of the neocortex. And that dye could, would then tell you where that part of the neocortex projects, or that would be an antegrade jot dye or retrograde dye, meaning it would tell you what parts of the cortex project to it. And there's lots of ways of doing this. There's many different techniques. I'm not gonna go through them. And so the data that this paper is built on is different. They're all monkeys, but they're different ages of monkeys, different techniques, different preparations, different methods. So they're trying to really wrestle a whole bunch of stuff together. This is like a picture of a monkey's neocortex, flattened out. Here's what it looks like in the Macco monkey. And these, things are all different regions, in the cortex. And again, these are not obvious. If you look at the cortex, you don't see any of this stuff. They only determine this through various, anatomical and physiological techniques to say, oh, there's actually, this is the V one, this was the vision goals and so on. So anyway, there's, all these regions that they've determined, and then they ask out, how do we determine how they're connected together? So then there's all this data about studies about it we're not gonna go into. but here's the basic technique here. These are all sort of very cartoon images of a little piece of cortex. And they're showing, and the cortex is showing upper layers, middle layers and lower layers. And they're basically saying, if I look at two regions, I see how they're connected. Which cells in one region connect to what cells in another region? and, and it's different, right? It's not all the same. And, so this asymmetry defines what is going up the hierarchy and going down the hierarchy. So that's, this is how they built their map. So here's, some, cells in the middle layers of this region. They say, they project on forward, they project to lower and upper region. then here's some other cells in another region that project. These are in the upper and lower regions, and they project. differently than there's that these, connections are not all identical. So they're able to say, okay, a certain set of connections we're gonna call ascending, meaning that they're going forward in processing. There's some connections would seem lateral, meaning they don't seem to be forward or backwards. And in these case, the regions that are projectors, that's not obvious here, but the reasons that are projecting each other, the same cells project to the same cells. So there's no asymmetry to the way they're projecting. And then there's some of these connections between regions are descending. and they'll say, because they just have a different connectivity profile than the ascending ones and, the lateral ones. And it's really difficult to do this. It's a very difficult study for them to do. But they, this is a basic method by which they said if something hierarchically higher or lower than another region, this put through these types of connections. 'cause you could say, oh, V one and V two are connected together in both directions, but projections from V one to V two, which would be considered ascending, look different than the projections from V two to V one, which would be descending. And then there's some other reasons where the projections are similar both ways. And then we'd call those lateral projections. So that's the basic method. Is there any questions about that?

Okay. We'll go on. And then the conclusion of all this just jumped down the bottom. These are all the studies that they, in the data, ended up with this famous diagram. Lemme make this a little smaller so you can see it.

and this is just the visual parts of the monkey. And you can start down here. This is at the very bottom here is the retina. These are retina gang ganglia cells. And then this is the LGN, which is the thous, which we'll talk about in a minute. And then it goes to essentially the V one, the V two, and so on. And now, so the point of this diagram, and there's a lot of, it's not a very good picture because there's a lot of these boxes are just white. I don't know why that is. so there's LIP and seven A, so there's several dozen in here. And so they basically tried to figure out which ones are hierarchically, above which ones are hierarchically below, and so they have different layers of the hierarchy. This layer here, if you can see my cursor, then another layer here and another layer here, and so on. And at the very top, they show this projecting to the enter R cortex in the hippocampus, which is where the people study the grid cells. And the momentary memory. And as we pointed out many times before, this is just a wiring diagram and there's a lot of surprising things about it. First of all, how connected it is, how many regions connect to, so how many other regions. It's this incredible number. it's, not like a simple flow chart, right? And there's a lot of things at the same level that connect to each other and or don't connect to each other, but they're still at the same level. And so there's something like 40 of all the connectivity between regions exists in this picture, which is complicated. And, it's just doesn't look like a strict hierarchy in any sense. a very simple sense of the world. Information is flowing all over the place. So this idea that this information is processed step by step through a series of regions, that is true if you just look at the series of regions that are step by step like this, but they're also skipping around. V one doesn't just project to V two V one, you can see over here, V one also projects the V four and projects to, the, this thing here, an MT and so on, they would go all over the place. So I never quite believed the idea that it's a hierarchical processing that's in a strict form. that, that, people talk about this, it's much messier than that. And so you have to understand clearly different animals have different sets of regions and their different arrangements, and it all seems to work.

and if you drop out one of these regions, you damage it. the, animal might have some deficit, but the whole system doesn't fall apart either. they still continue to do various things, but this is, this was just like, oh look, it's a hierarchy. It's like a flow chart. And this became dogma about it. and now it's a little, interesting because even in their abstract, they state that something like, 40 of all con possible connections actually exist, which, really contradicts again, this idea of this strict feed forward.

And as, as Neil's pointed out, I think it was Neil, that, it's all so often this is done vision. This is all visual regions and the monkey and a lot of the physiology is vision, and we can talk about that. But that's really, and so it's all been built around each other. And when you think about vision, they rarely even think about motor behavior at all. So this entire analysis of this, there's nothing about motor behavior here whatsoever. they, most of these studies were done early on with anesthetized animals who aren't even able to move their eyes or think, and they show them, various sorts of, abstract patterns that aren't meaningful to the animal, even if the animal was alive. And then try to figure out how the cells are responding in these different regions. now it's, not, it's gone a lot beyond that since then, but there's this long history of yeah, how do we, recognize an image? there's an image of a dog as an image of a cat, and not like real vision where your eyes are moving and you're moving around in the world and so on. let's just, if we, want, I can now contrast this to, so the opposing or an alternate view of this. unless there's more questions about this, and if this is not interesting, let me know because I, you all know this, no one's gonna wanna speak up and tell me that, but you could. so we've been fans of these two scientists, Murray Sherman and Ray Gil Gui died recently a few years ago, so he is no longer with us. but Dave, for many years had been promoting two big ideas about cortical organization that are missing from the Sherman, from the, Vanessa Felman and Vanessa idea. And, speaking personally to Murray Sherman, he found it very frustrating that his ideas were never really adopted by a lot of people. A lot of people know them, but they weren't, they didn't become mainstream. But, it's very clear to me these guys are onto the right thing. So let's just jump down here. jump to, a picture. This is a picture that we've used or we've used variations of this. And, it's, still about hierarchy, but it's an, it's a slightly alternate review of the hierarchy. so Sherman Gilley don't say there isn't a hierarchy, but it's it's different. There's two major differences in, what they propose. And so up at the top of this diagram, you have three blue, boxes. Those represent cortical regions, if you will, like V one, V two, V four, that kind of thing. and this, and what they're showing. Some of this is showing the classic view. So the classic view, if this was the vision system from the periphery, that would mean from the retina. And it goes, and the optic nerve goes from the retina. It goes through this talus, this what's called the VGN, vental, gen nucleus. and these are called relay cells. And and then they projects up to the first cortical region, which would be V one. And then the classic view from we saw from Valium and Vanessa is that, they B one. Now we project to the next blue region, which we projects to the next blue region, which products to the next blue region and so on. So that's how, Thalman Ian showed it and they showed the Falmouth as being coming from the retina. I pointed it out that coming from the retina, it goes to the Falmouth, these relay cells, which people say, we really don't do anything, but we know what they do. We know that do something a lot. and then it's all processed up here. So the first thing that Sherman and Guillory argued was that, there's an alternate pathway between these regions of the cortex, and they argued this pathway exists everywhere. and that's shown here in more, pink circles. These are other regions of the Falmouth. This is standing first order. This is high order. So these regions of the thalamus also have relay cells, just like this first order relay like the, here they look very similar, but they don't get direct input from the eye. Instead, what they do is they get input from a cortical region. So here you see, they show a, cell in layer five, which projects down here goes to this thalamic relay cell, which then comes up here and projects here. And this region also has a layer five cell. It goes down here to another thalamic relay cells and projects up here to the next cortical region. So this is an indirect pathway. It's instead of from cortex to cortex, cortical, it's cortical thalamic, cortical, thalamic, cortical. And, but these, high order relay cells look very much like the first order relay cells here. And so they argued, they've argued that not only is this an alternate pathway, they've made many arguments. This is the dominant pathway. This is the most important pathway. The most important pathway is not the ones that go directly from cortex to cortex, but the ones that go from cortex to thalamus to cortex. These cells are bigger. The role you see here when it comes from the retina, it projects to the layer four that's similar to how it comes through this high order related in projection to this region. so this is the number one thing they propose. That there are is at least another alternate pathway in the cortex defining the hierarchy that was not even mentioned in the felman Esan paper. and that, and they've made all kinds of arguments why this actually more important than the direct cortical. And, and I think I understand why, what's going on here? I didn't for a long, time, but I think I understand why. And I've been arguing about this recently. I'm, working on it, I'm writing it up. But the idea that if, there's a coordinate transform or a specific, an orientation transform, let's say you have an input that's coming from the retina, either a movement vector or it's a sense, pattern. You have to rotate it to match the object in the cortex. And so the cortex itself tells this region, the cortex tells it what transformed to do. Now the output of this region is gonna go into another region. And this region has to do the same thing, whatever the output of this region. And it goes back through here and says, look, I have to transform the orientation of this object to, the new, this sub object, this my input. I have to transform it to, if there's like an edge coming from the eye and now we have a rim of the cup, now we have the rim of the cup has to be oriented to the body of the cup, something like that. So this is the first thing they proposed, that there's this alternate pathway, which is the major pathway and exists everywhere in the cortex. And we should be thinking about that, is defining the hierarchy. And in this case, this is why it's essential to understand what the is doing, because it's part of the hierarchical structure. of the, cortex. It is not an added thing on the side. And so in our, in my world, our world, we would look at the following and say, one of the things that's going on with the cortical projection, could be voting. If these guys were all looking at the same object, it turns out that they're not doing sub objects. We're looking at the same objects, and proceed the same option. You wanna be able to vote on 'em, which is something important. but if there was a hierarchical structure to it, like this is looking at a letter and this is looking at a word, then you would want to be able to, run through this pathway and, basically encode the, handle, the orientation difference between these two sub objects and pob. I know that's a lot to, try to absorb at once. but that's the, that's, and this question, I'll go on to the second thing that they talked about. Do people understand what Jeffs just said? Yeah. So when you say that, with the hierarchical connection, it, should probably go through the thalamic connection. could it be that the cortical connection, still transmits like a feature information and then only the pose information goes? Yeah, it could be.

it could be.

in fact, I think that's, I don't know. the, pose has to, the, you have to chance for, you have to change the feature to match the pose. if I'm building a model in these blue boxes, I have to take the current pose of the feature and turn it in. At least I said the orientation of the feature and put it into the, form of the object itself. I think it's a good question, Vivian. it, we don't really know. I think this is where a theory can really help us, right? We're not gonna get answers to questions like that from the, from the neuroscience literature. I think where we can get answers to the questions like that is we define very clear problems that we know the cortex has to solve, like hierarchical modeling and or compositional structure. And then say, okay, what are the absolute requirements to do that? And where could they, where could those things occur? so it's a good question and I think theory can help us answer that question. When you say pose includes scale in there or, no one will talk about any of those things in this literature. Just, be, so that's a question for Vivian. Yeah, it's a question for Vivian. I think scale is held, is handled differently, but, maybe other people different.

Again, I neuroscience we.

We can address, independently of the neuroscience or dipping back into the neurosciences. So when I say oh, I think the thalamus could be doing this or couldn't be doing this, you might have a better image in your mind of what it, what I'm talking about.

one of the arguments they make is that this pathway from the relay cell into cortex, therefore is much stronger than the, than the cortico cortical pathway. And yeah, so what you're saying is true. We have to have a model that says feature information is not quite as, can be more like context or, weaker than the actual post information. It kind already happened. It's like that, right now the matching, we can recognize the morphology independent, independent like features can just add, evidence, but as in like color, just adds evidence, but it doesn't subtract evidence, but it's morphology is crucial. Okay. But that's a good insight. yeah. Another question I would have is that here they make the distinction between first order and higher order of thalamus. Is there like, distinction also in the functionality there?

if you look at the anatomy in the physiology of the cells, there isn't a distinction that it's very, similar. Of course what the cells respond to is different. By the way, this same organization exists for somatosensory or touch and hearing. And so obviously there's a lot of, there's a lot of thalamic relay centers. a lot of those higher order centers, and they're, the cells in them are gonna respond to different types of sensory input or different, and higher up. The higher up you get, the more, the more conceptual or the more, object like type of responses you get in these cells. so they won't have the exact same, cell responses, but they're doing the same thing basically. I, it's hard to imagine that these high order relay centers are not performing the same function just on different data. Yeah. How, I'm sorry. No, go ahead. I was just say, is there evidence on how localized the projections are, because I guess the thalamus is a fairly small structure compared to the cortex, and so if you have all these relay cells, like how, for example, you, presumably you don't have enough of them to have a one-to-one mapping. and so is there a possibility that these connections are more course, broad spectrum influence? And it's actually just the opposite. Okay.

the projections to the thalmus and the projections back from the thal are very constrained. meaning they don't spread broadly at all, and that's why they're called relay cells. Literally, it looks as if, imagine how, imagine this is the optic nerve, this green line here. You can see my cursor, I hope. yeah. There's about a million fibers on the optic nerve and there's about a million relay cells leaving the thalmus. And it looks, literally, it looks as if a single spike coming on one of these relay, one of these, accidents from the eye produces a spike on one of the relay cells leaving. so this is getting to your point a little bit that actually these are constrained numbers. You may think a million is a lot, but there's a lot more cells up here. And in fact, this connection here, you see this connection from layer six back to the thal. Yeah, that's about 10. That's about 10 million cells. And in this particular, it's 10 to one. it's roughly about 10 to one. And this is more diffuse this in some sense, like this is encoding some sort of more complex signal, which I'm arguing is like a pose signal, where this is really just almost like it look like you're just relaying it, right through. Now the numbers work out so that even though these thalmus thalamic relay centers are small, they're plenty large enough to handle all the cells that are coming, projecting to and from layer five. So there's it. Literally every one of these layer five cells, there's two types, but the ones we're talking about here project down to a relay cell here, and then that projects up here to the next one and so on. So these are very precise, connections. there, it's not like a diffuse thing. It's not, yeah, and you don't see any mixing. You don't see the first auto thumb is projecting over here or anything like that. now it, it gets woner than this. So even though I, just said there's like a one-to-one correspondence going through. If you actually look at these, at the cells from the retina, and this is again, this is, I checked this weekend. This is true for other sensory as well. True for touch and vision, a touch and hearing. There seems to be a single cell which responds that relay cell. But this axon doesn't make connections to just one relay cell. It makes connections to a bunch of 'em, not a huge number. I didn't get, I think it's like 20, it's 15 to 30, somewhere in that range, right? Is that what Yeah. And, the, connections that are made from a single axon coming in here to these 20 or 30 relay cells, the connections look identical. That is, there's a special type of synapse. It looks very unique. It's as if this thing is connecting to 20 relay cells, but only one relay cell is doing anything and the others are silent.

And, but clearly the connection is there for them to affect those others. And I have, I found a paper on that. you know what the hell's going on here, right? So yeah, it's doing a relay function, but somehow it seems like it could be doing it to any 20 or 30 self. And we sub myself and this researcher, Carmen Harmon, I forget her last name. What's her last name? Carmen. Ella. Ella, yeah.

we concluded that this, each of these cells could be like a, a multiplexer that is the signal coming back from the cortex could tell wh which relay cell this input is supposed to be routed to. It doesn't. It just, it is like one gets active and of course when you do studies with an acidized animals, that'll never change. It'll only be one and the other connections will be inactive. but it looks like that the other detections could be inactive. So we propose that this is doing a routing, it's, taking this input and able to route 'em to different outputs, which is essentially would be what you would need to, you could, map a pattern to another pattern, which would, was something you could do with an orientation change. so that's, I don't know if it got to your question, Neil. Yeah, no, that's really helpful. Thanks. Because yeah, when thinking about what the potential functionality is, if, it, yeah, these are very strong. These are very axons. They make big. Important synapses on the layer four cells where they project and the other cells they project they are, whereas these other direct cortical, the cortical connections, they seem, weaker. There's a lot of 'em, but they're, really enc, they're clearly encoding some spatial code, like the sparse distributor representation where these guys, Sherman and Gillum, call Gil, call 'em drivers. They go these accidents are pretty strong. They're gonna make cells fire here. these connections between cortical regions directly don't seem strong enough to make things fire. they're weaker. So that would be perfect for our kind of voting mechanism or, any kind of, prediction where you're depolarizing cells. so their argument, this is the strong, thing. Now another thing is if you believe in the canonical circuit from Vernon Mal Castle, like all colorful columns are the same, then this makes Sherman Guillory view makes a hell of lot of sense that the cortex, you have a regional cortex and associated thalamic relay cells, that is the unit. And if you're gonna do it on the first input to the brain, why wouldn't you do it on the next input and the next input and the next input. So this is the actual cortical column in some sense would incorporate both of these things. it's part of its circuitry. and now you have a parallel, architecture all the way around, everywhere in the cortex, everywhere in the cortex. It looks like this. and I'm not as Sherman.

he said, we haven't looked everywhere, but everywhere we've looked, this is what it looks like.

now the, other big thing here, which is really puzzling at, first, or maybe still is puzzling, but I think I understand it better now, these cells in layer five that do the speed forward here, they also, they split, you see the split right here, they, divide in two and the other half of it goes down and it generates the motor behavior. So what does that mean? Like these in the visual system, this would be the part of the old brain called the superior colus, which is what actually moves the eyes.

and, the parts, the other parts, of the cortex, they always predict to something else that would move, that would change the input to this region. So in some sense, each cortical region, it has a motor output, which changes what it gets.

are those two separate, neuron populations? is it the same signal that goes to the th exactly the same. It's the same cell. Imagine this.is one cell, it has an axon. The axon splits into two parts, and one part goes here and one part goes here. So it is the exact same signal now. So people like a corollary discharge, or ference copy of those terms, it's like literally. Okay. Yeah. Now, one way about this.

When I think about, now, I'm arguing recently, when the eye is sending information to the cortex, it's sending two types of signals. It's sending, what, it's the pattern that it's seeing like a patch of retina, but it's also sending a signal representing how the retina is moving, that's detected by the retina. and so there are two things passing through here. There's the, and they're separated. They're, I can show you pictures of this, th this, there's multiple sets of relay cells associated with this first order relay, and some of 'em are representing, parts of the retina, which are detecting motion. And some are representing parts of detecting, sense features. So both motion and features are going through this. And I believe both motion and features have to be, converted to the proper orientation so that, you know how it is, it's moving relative to the object. So now if I understand that this, there's, beha, there's a, there's motion tingle going through the thal here. then that same thing hap is gonna happen here. If, this region is outputting. Don't think of this as just it's an out, it's a motor output. It's going back and it has to tell the next region up. Here's how I'm, planning on moving the world. I'm trying to, how I'm planning on moving the The retina or it's moving, this is the motion signal. And I'm going to, I need to tell the next guy up. I'm moving the, this guy says I'm moving the, retina to the left by four degrees, let's say. It has to tell the motor system to do that. And also you can tell the next guy up Hey, you're, I'm letting you know that I'm about to move the motor system by four degrees.

Okay? There's something else going on which is not shown in this picture. I apologize how complicated this is.

this is the, part of the brain that moving the eyes, right? And notice it gets direct input from the eyes themselves. So when the eyes, the, literally the, ganglion cell, the accident from the cell in your retina, it splits here. One, one goes up to the, thalamus, whether it's representing sensation or movement, it doesn't matter. And the other, split goes over here. And so what's going on here is that this is the thing that actually moves the eye. This is the cells in here make the eyes or move or flow or whatever. And so it's possible that the input from the eyes themselves can make your eyes move. And there's a little, if there's a little flash of light in the corner of your eyes, will automatically over to that. You don't have to think about it. You can't. It just happens.

Now what's not shown in this picture is that the cells that actually generate the motor, a behavior here also come out split. Like they, they show it right here. You see the split right here and the show going up here. But it happens everywhere. So it actually would come out. This is the actual motor behavior that's being generated. This is the actual behavior. This is like a request for behavior. This is the actual behavior. These split and they go to each of these thalamic relay cells. So if I were to look at what's coming into the Falmouth here, the, LGN, the first order Almas provision. I've got two types of signals from the eye. I've got what's sensed and how the eye is moving detected by the sensor. But I also get the ference copy directly from the superior colus, which comes over here and also goes to this, the first, this thout. So there's two sense sources of movement behavior. One is coming from what's detected by the eye. the eye says I'm moving, here's, the things are flowing across the retina. This one says I'm about to move the eye. I'm sending a command to move the eye. You're gonna get that earlier than the actual detection of the movement. But these are all segregated and he kept separate as they move through the soic relay. and then they're all being processed in the same way. So the idea here is that you could have a motor command that's being generated by the motor system. You could have a motor command being generated by some other cortex or being detected by the century. There's different ways the brain can know how the eyes are moving or about to move, but in all cases, they go through these thalamic relay cells. So my point of pointing this out is that's true for these, I believe it's true for these relay cells as well, that it's not just this cell that's coming down into it now, it's also getting input from the motor system, which is also going to the high order thalamic relay. So there's either there's a, there's an internally generated motor command, or there's one that's coming from the motor system itself. all being passed through separate relay cells, all be converted through this feedback from the cortex.

this does not explain a little bit of a mystery. Is there a sensory feature being passed through the, thalmus here, the high ortho thalmus? remember, if I detect an edge in the, my, in my retina, that's gonna go through this first sort of thalmus. It's not, a clear pathway for how that would get down to here and back up. and so it's possible that maybe just the motor command has to be transferred through this and that the direct connections are representing features, like this detected, handle, and this is the coffee cop that goes directly, but maybe the motor behavior, which represents some orientation. I don't really understand all, at, I have more clarity on it, but.

Diagram that we think about when we think about, hierarchy in the cortex from a, anatomy and functional point of view. I think from a Monte perspective, we can walk away with a couple things. Is that there, that every region, every learning module has to be processing sensory data and motor data. the motor data could come from different sources, whether it's coming from, a motor system or, from a sensory system or some internal generated motor behavior. Like, this layer, this cell, here could be telling this region what it's planning on moving. so that's something that has to occur. And, and that there's clearly some sort of transform that is going on between, a learning module. And especially in this case, we can say the learning module is, doing some sort of transform on, the sensation and the movement, command. and it's doing 'em separately, meaning they're separate cells, even though they're all getting, they're all getting the same command. It'd be like saying, I'm gonna change the orientation of the movement and I'm gonna change the orientation of my sensation and something like that. So we have to be just aware of that. And when we think about hierarchy, it's, there is a mystery we have to really resolve, which is how does motor behavior operate in a hierarchy? And maybe some of you guys already thought about that a bit. But that is not clear to me, what's going on from here to here and what's going on from here to here? what, how's that from a hierarchical point of view? Makes sense. I think this, the other one that, the one that says we're about to move is pretty critical because that, allows you to predict what you're going to see. And then, go on from there, right? And that's how I think everyone viewed that. it was a fairly, five years ago epiphany on my part. that the, retina itself is also telling you how it actually is moving, which is not as good. The reason you just pointed out, it's like that's after the fact, right? The retina says, hey, I moved, as opposed to this guy can tell you're about to move. So as you point out, this one you can predict on this one is whoops, he moved. And I think that the reason this is, is this is ground truth. The eye can tell you actually, how it's actually moving. And these, cells here, which actually may be move in the eye and they're projecting up to this region of the cortex, how's this region of cortex supposed to know how to interpret these movements? It's just a bunch of fibers coming in. And by the way, all these things change over your lifetime, right? All these things are learning, are changing and modifying and so on. So there's, there isn't like a genetically determined motor plan that says these cells mean X, Y, and z. this region's getting these motor signals, but it doesn't know how to interpret them necessarily. So I think what's going on is that the, input from the retina, it says, oh, the retina has just moved. It's moving at a speed of this speed to the, right that can now, that's being projected up here as well as the actual motor signal that was generating the thing injected up here. And now you have a training signal, so the cortex can say, oh, I know how to interpret this signal. Now th this is the ground truth. This is the thing that generated the ground truth. Now I can, learn how to interpret, this signal coming from here. and I'm pretty certain that's what's going on. And I bet you if, we might even be able to find some papers hidden down in the archives of who knows where that could talk about, the physiology of the cells and how they might do that. But I, that's how I think it, it's going on. So this is the one we, is that motor output going to the next higher order area or does it go back into the same region that generated it? that's a great question. I don't know the answer to that question. that's a good, that's probably available some point, like the question is here, you've got these cells that are, this is not just a blob of cells in theus, it also has a laminar structure and it has different parts, projected different parts of the cortex.

I was under the impression, but I might have made it up that it just projects back to here. But it's possible it could project forward as well. Totally could. Yeah. How's that synchronized? Like it's a sequential parallel. Oh, that's a great question. the classic view is that it's all sequential. Like information comes in here and it goes to here, then it goes to here, then it goes to here, then it goes to here. But they've, but there, there's some real holes in that. First of all, not shown on this diagram, I, another confusion is that some of the cells right from the retina go right to the high order. They go right to here. they skip, they even, they go to both maybe, I don't know, but they go, there are direct connections from the retina to here and direct connections from the retina to here. And maybe even here, like three or four regions in the row they connect to. So everything else is still right, but it's it's not like they, that they only get connections. the fountain, the retina only projects to be one. That's not true. And then here's another thing. If they've shown that sometimes the response in this second blue region can occur before the response in the first blue region. That is, and they can even get that response sometimes, but when they freeze this one, so it can't operate. So, that tells you that this view of kach, ka, kach is not true. It's it's going go on in parallel here to some extent. simultaneously, these upper reasons can respond quicker than the lower reasons under some, on some conditions. And so that's another sort of thing we have to deal with. a thousand brain theory does that pretty well. We say, Hey, this blue region here is only can learn objects as well. but they're gonna be larger scale. so for example, if I look at how much of the retina projects to a patch of V one, it's a small part of the retina, very small. If I look at how much of the retina projects to a patch of V two, it's bigger. So V two will be looking at a bigger area of the retina, and V four will be looking at a bigger area still. so these all could be modeling similar objects but at different scales. because, this only can look at a tiny, small part of the visual field. This looks at a much larger part of the visual field, but still there. This, there's these connections that are, that go from here to here. They also don't show up, but they're also connections that go from here to here There's backwards projections from, from B four to B two to B one. they tend to be, they tend to have a very particular connectivity to, to the up layer one. It's like the general belief is that when you project that counter, it's biasing this guy saying, you should be seeing X here. So this upper region says, given what I'm seeing, like a coffee cup, you should be seeing a handle. Or, or you should be seeing the logo or something like that. but all these things can occur. It can be, obviously a very small thing. It can only be recognized down here. It could be something, it could be recognized in multiple regions at once. It could be falling from here to here, but often sometimes these guys respond before this guy does.

for example, if I was looking at a fairly large object, let's say a big picture of a coffee cup, D one may not really have much to help me with because it, can only see fine detail. And so the fine detail is not very helpful when you're dealing with a bigger object. object recognition could occur here primarily.

you, mentioned that those direct connections between the, cortical regions might be voting, but, would that actually make sense for different hierarchical regions to vote or would it make more sense? It, could be because, okay, so I have, I see I can bring up another paper, which I don't have, I can't bring it up right at this moment. It shows there are multiple sort of cell pa cell populations that seem to be projecting forward and backwards. and it voting could make sense. For example, what if I was looking at, an object that was recognizable by V one and recognizable by V two? 'cause it was small enough that I could recognize here, but it's not, there's no cutoff between the two. and it's large enough that it can recognize here. then they could vote. And so there are connections which seem to be, not shown here. Connections that go from like layer two to layer two and layer three to layer three, that could vote.

and that would make sense if they're perceiving the same object, which often they are, right? They, if there's only one thing to look at, that's what they're gonna be perceiving if they can do it. There are other connections between these, which are more of the hierarchical form. So layer three cells that project the layer four that was in the felman SEN paper. So there you go. That's a hierarchical connection layer three to layer four. Whereas before I was saying layer two, the layer two is not a hierarchical connection. So layer two to layer two could be, voting and layer three to layer four would be more like, Hey, this is the logo on the coffee cup. more of a feature type of thing. So unfortunately for us, all these things can seem to be occurring at once or, have combinations that can occur.

the way I try to get past this.

Theory of what I know a region has to do, what a learning module has to do to learn a module, and truly trying to understand this really clearly and then tiptoe my way into saying, okay, how would I then explain the layer two to layer two connections? that could be explained by voting. How would I explain the layer three to layer four connections? that could be explained by hierarchical composition, that kind of thing. but always start with oh, objects. I have to be able to learn objects, I have to learn their behaviors, I have to learn their composition, that kind of stuff.

so I, I didn't promise this, it'd be, concise or easy, but, I know this figure is actually really nice. I feel like there's nothing in there that like completely contradicts what, we're doing right now. And, yeah, it's a really nice overview. Yeah, I didn't talk about the physiology, but too much here, but it's worth mentioning. 'cause I think, just to reiterate, when you, probe cells as you go up in the hierarchy here, you find cells that respond to more and more conceptual objects.

they, don't find cells that respond to coffee cups down here. They only find cells that respond to edges, but they might find a cell somewhere, four levels up in the high find coffee cups. Also. These, whatever you detect here, this is gonna be on a very local area of the retina. And what you detect here tend to be over much larger areas of the retina. Now, this could argue, you might argue against a thousand brain theory, but the thousand brain theory says, what this, lower legion is recognizing is not an edge at, some location on retina. It's doing sensory motor integration. So it's tracking the movement of the retina over time. And because it can track it over time, it can learn an object representation down here, composed of edges at different locations. and the way they do the physiology and test the, these cells, they would never see that. They just wouldn't, they wouldn't, not, I can explain why, but they wouldn't see that. They would just miss it completely. and when they try, when they look at the cells in these regions, they can only make sense of about 40 of 'em, about 60 of the cells. They have no clue as to what they're doing. They just don't, they can't get 'em to respond in a way that makes sense to them, so they just ignore them. So it's very clear to me that even a low level region like this could be learning a com more complex object. The reason you might find like a face cell or a cup cell or something like that in a higher region. I believe is what's going on is that the output of the lower region is already recognized an object like a cup. And that is now the input to the next region. It's not that the next region's recognizing the cup, the next input's getting an input, which is a cup. And so they say, Hey look, this is this cup cells up here. Yeah, that's because I've already recognized a cup down lower region. so like I would never, you wouldn't find a cup cell here, you'd find a sparse distributor representation in this V one that represents cups, but you wouldn't find a single cell that seems to be a cup you, but you could look at a sparse pattern and you could decode it as cup. Whereas once you start moving, then you take that, sparse distributor representation and you feed into layer four here, then you start getting representation of things like cells that do represent cups because of the spatial pool that turns them into that. so there's a lot of physiology where people would argue oh no, V one could never recognize an object. We don't see any cells that do anything like that and it's 'cause they don't know how to look for them. they're missing it. I dunno what got me on this, but there's a lot of physiology as you go up here. You do find it get more and more complex object over large and larger parts of the, receptive field. but none of that's inconsistent with what we're doing or the thousand brains theory as far as I'm concerned.

I don't have more information. See, sorry, this if you already went over this, but, I'm just curious about that motor output box. Is there also hierarchy in that box or is it there's a whole bunch of stuff a many to one mapping to this one motor output region? I, don't know if there's any hierarchy. I think what it, if you look at this precalculus, this is the one I've read in the most papers on. It has a very specific architecture. So there are, there'll be cells array in a layer that represent how far, the eye will move if you innovate that cell. if you ate the cell, I might move 30 degrees in this direction. If you innovate in another cell further, it might move 20 degrees in a certain direction, that kind of thing. So there's order to it, there's structure in it. there's layers in it, but I don't think the layers are hierarchical. I might be wrong about that, I'd have to check, but there's certainly nothing like the hierarchy C in the cortex. It's a fairly small organ.

there's equivalent ones again for different sensory modalities. but it's, I don't believe, I don't believe there's like a clear hierarchical organization to it. Although it's, there is a lot of organation. It's not like a blob itself. And there are many, papers on it and I guess we could, probably search pretty quickly and find out if there's any sort of hierarchical representation. I'm not, I.

I don't know. that's, good to know. And then just a follow up to that, the eye is like a relatively simple thing to move. Do we know anything about how the structure of that motor box changes when it's like moving a multi-joint thing? Yeah. Yeah. we in the royal we do. Me as Jeff, no. I started reading this book that Vernon Mountcastle wrote about the hand. I started reading that, yesterday. it's a big book, like a thousand pages and I was searching through it for information on that very topic, that very question. And it's really complicated. And I gave up and my arm was hurting and so I just stopped. So there, there are answers to that. There are, if we wanna know, we can dig in and we'll be able to find lots of papers that talk about what happens in the somatic sensory system. When these layer five cells project down to some part of the spinal cord or whatever, what is, what happens there?

but I don't know the answer to that question. It's a really good question. Obviously the eyes all move at once, right? You can't move part of the eye. Not well, you got two eyes. So you can move them somewhat separately, but you can't move part of what the retina separate from the retina other part where you can do that with your fingers. So that's a good observation and something we have to be aware of. that's what I was, I always think of it as like this guy is basically trying a layer five cell is trying to say, Here's how I want my patch to move. It doesn't know about anybody else's, it's just saying, I, my input, this is how I want my input to move.

Yeah. But I guess from a computational point of view, I guess you could argue it's hierarch. Like I think there's evidence that yeah, if you stipulate a certain part of motor cortex, you can initiate like a complex movement, which seems to be like, yeah, I guess a, series of similar movements and they similar, you might just get a simple movement, I think, but I dunno what, how that maps onto to anatomy or Yeah. I think you're right. It, I bet you're, I think you're making the theoretical argument that if you look, especially the Somato motor system where your limbs can, fingers can move independently, that there has to be some sort of hierarchical representation that's subcortical. I think that's what, yeah, like I think there's, I definitely dunno the papers, but I think there's studies showing if you stimulate a particular part of a monkey's brain, it will like, make like a gravity motion. You simulate a different part, you'll just get a finger that twitches. And that there's, you can seem to be able to break that down into the hierarchy of complexity. Yeah. and there's a, there's, another part of the brain called the cerebellum. Which has actually got the most cells of any, most neurons of the entire brain. It's not as big as the cortex, but it has more cells in it. and the cerebellum, one of the things it does is it's related to these fine motor commands. And so it has a lot to do with executing fine motor skills. And if you lose your cerebellum or it's damaged, you end up losing a lot of fine motor skills. things get awkward and jerky and so there's a complex, I think maybe Neil's point is that there's a very complex motor system that underlies, thematic sensory system. That is certainly true, whereas it doesn't appear to be as complex underlying the visual motor system that, it's pretty, the superior colus is if I call it, pretty direct control of the muscles of the eye. So it's a simpler system. I nice for us from the point of view of Monte that like, we don't need to worry too much about Yeah. Kind of because of the simplicity of, I guess the camera moving or whatever. We just need to be like, okay, camera move here. You don't need to have a complex half planning algorithm or something, right? yeah, how do, I remove my head and my body and my torso and my legs to move the eye over there? We.

and sorry if you guys have already thought about this because that's no, no reason to apologize, but, so we have three, pieces of cortex in blue here, and each one of those with that motor output is saying, I wanna move my patch of the retina here. so what if there's conflicting motor outputs, how do different motor signals from the cortex get resolved by that motor output box? I have no idea and I have no idea unless someone else does. This gets back to the question of hierarchy. is there a hierarchical preference for these, right? is somebody more important than somebody else? do they work together?

there, I'm sure there's no, there, I'm sure there's papers on that question, but, I, say that 'cause I, don't wanna just volunteer oh, I'll go look 'em up. Because to me it's a really slow process. It takes forever to, look these things up. but I could, we could do it. It's important if we get down the point, we really need to know what's going on in the brain of this thing. We can dig into that and, I am, I'm, almost certain that we'd find some papers that describe that, those questions, so I don't know how they, that I don't how they coordinate. Yeah. What if one of one reason says, move this way and the other reason says, move that way? what happens? I.

From lower regions, then that doesn't necessarily have to be like this patch of skint appear now. Yeah. It's not clear to me, by the way. what, okay, so, Sherman said every region has these layer five cells, project subcortical someplace motor, oh, now it's coming back to me a bit. Oh, it's coming back, in the, in many regions, that, that projection could be to the basal ganglia, which is a set, of regions, a set of subcortical functions that are really complex and they, that probably has hierarchical organization to it. And that may generate all kinds of behaviors and effective behaviors and so on. So it's, not gonna be simple like, oh, here's an output and, move a muscle. It's, gonna be, it could be like I have a desired movement of some sort, but it could be telling a very complex subcortical system, that might have a whole bunch of sub behaviors and so on to it.

it's this, the, visual system is the simplest one in that regard.

Thanks.

I should tell you one other thing that's interesting about this. Remember I said, that there were two sources of movement behavior for the visual system. One's coming from the, eyes and one's coming from Superior. There's actually a third source I forgot to mention, which is, coming from your inner ear, the, what do you call it? System, come on circles. Little balance system. What's it called? yeah, like the semicircular canals. Yeah. what's the name of that? What's the name of that sensory system? Has a name? No, it's yeah. Go. What's it called? Yeah, blank.

it's not the Propriocept system. Yes, I do, I was gonna say it begins with a VI knew it begins with a v Yeah. Vest stimulus system. So the vest system is also projects to these, thalamic relays because the vestibular system is also a movement command. Vestibular system will tell you how your head is moving.

and so that also feeds into the thalamic relay cells. It's, crazy. but we don't have to deal with all that complexity. We can take a very simple system, has a simple movement, and try to get the, get it to work. Alright. I.

Oh yeah. Alright. That was a, complex way to get started. I'll stop sharing my screen. That was so useful.

Yeah. Yeah. So now we have to like, pretend we didn't know all that and just go back and say, okay, what are we gonna do for, I feel like that actually fit pretty well about how I've been thinking about how we might add hierarchy. so yeah, I think it was actually really nice to see that. Are you gonna continue on today with some of your questions? What's your plan? Yeah, so I was thinking maybe we could just, yeah, I made a slide with kind of open questions that we have and maybe we could just go through them and see if there are some other questions that you guys have up. so we, set a framework of what all we need to answer in the next week.

yeah, so basically, everything on the bottom part of this diagram we have implemented and now the main part that we need to resolve this, the connectivity to the next layer and what's actually happening in the.

Yeah, I can just go through these questions that I came up with so far and then we can see if there are any other questions. So I think one main question we just need to answer is what problems do we want to solve with hierarchy, because that will just inform everything else. and then how should we implement hyper key, which would, include what's the communication protocol? So what's the input and output format of lower, level learning modules to higher level learning modules. What's the connectivity? So this one learning module connect to one other learning module. Is there more like many to one or many to many connectivity and then some kind of pooling going on.

and then related to that would be what's the information routing? is there like some kind of attention mechanism or something in this direction, to decide which information goes, gets routed to what higher level learning module.

and then yeah, related, I guess to your question was like what's the temporal sequence of this information processing? Do we like update the lower level learning modules and then send it to the next one and then update those or does everything like happen at once and then take several steps, information reaches.

how do we represent object ID to higher level learning module? That's what it relates to what we talked about before. It's maybe creating an SDR representation of the object ID that expresses something like similarity between the front objects.

and then, yeah, which models are learned at what level? So does the lower level of the hierarchy learn, more the, like the detailed models or does it learn like very course models that then get com composed together in the higher levels of the hierarchy? so like this kind of question, oppositional was decompositional or associative hierarchy.

and then yeah, related to that, do we supervise this process somehow? Like how do we tell the system actually which learning what you are supposed to learn, what we just see input how we do, we tell a learning module. Yeah, you're lower level learning module, you should learn the basic shape and you're a higher level learning module. You should learn like the composition of those shapes. Does this happen naturally or do we have to have some supervising signal or learning speed or something that, yeah, so that's the question.

I ask one question, it's hard do write representation because we're skipping layers. We went back and forth. Yeah. Level me. Yeah, that's another good question. So yeah, actually I I like to most, most associative hierarchy idea of like just associate information between different learning modules. So it's not necessarily like one level, like you, like slack, say slack, a hierarchy.

Yeah. So it wouldn't be like as clear cut as here where you have one level and then the next level more like some learning modules associate there and others, but there might be like, like one of those on the top row might get input from a sensor actually. so what does it mean to be a hire team? Yeah. I think that's, that was, I think partly this will come from what do we want the different, where do we, how do we expect models to be represented in different parts? Because I think partly it comes from language that you implicitly have an understanding of hierarchy when you think about an object. And so that's what we're mapping on too, or trying to map onto this that we might expect or, for.

But at least from the point of view, like representational complexity, it might be higher up and higher, even though that doesn't map off exactly to what does it mean for that communication protocol, for example. yeah. So then I guess that could be separate, like what is the communication that needs to exist to solve those kind of hierarchical representations? Maybe a very parallel and one that's, yeah. that's not probably a straight hierarchy. Yeah. I mean it's, I feel like it's gonna be like this diagram where there's, like the hierarchy is artificially introduced by saying, oh yeah, these had a lot of stages before. But actually it also, they're also connections that go almost directly from the first layers there. So I think actually, if I remember right, in their paper, they were like a lot of different options how we could have ordered these, regions in the diagram. And this was, but yeah, it's not maybe a crazy thought to be like, yeah, is it better to say what problems do we wanna solve with multi-level processing, rather than what problems do we wanna solve with hierarchy? Because yeah, I guess hierarchy is a very loaded term. That's true. Yeah. And we definitely, Thinking about it more as yeah, multilevel processing that kind of acknowledges the fact that it's not easily separated. Yeah, that's a good point.

I, I haven't been able to hear everything. But the associative hierarchy, I think you're saying it really is in the hierarchy, is I, it's two reasons that are associated with the other, isn't it? Isn't it just like voting? It is I could have a learning module that's getting a vision and other learning module that's getting touched and they would be voting to each other, and trying to agree on, what they're doing or, two vision modules next to each other. is that what associative men in that case? So I see it a bit. So the voting to me is more like learning modules that have models of the same object, talk about, talk with each other about if it is this object they both know about, I don't know, the pencil. but then in hierarchy it would be more like, the module that gets input, as a compositional model of the output from the lower object. So it doesn't have also the model of the pen, but it has like a model of, so how that sounds like com.

Soft version of it where, there are like a lot of skip connections and it's not really clear that something on level five of the hierarchy has gone through five learning modules before it arrived there, but it might gone through one and then, but you're still talking about compositional structure, right? I think for me at least, sometimes I think about, or I feel like compositional is more, like statistically regular associations. I, appreciate, I'm using the word associative again, but whereas instantaneous few shots stuff is more associative. So I feel like a logo on a coffee cup is, would be a more associative representation, whereas a handle to a coffee cup is a more compositional one. Why I'm, missing it. Why is that? It seems like the handle and the logo are similar and to my mind, what's similar? not all coffee cups have a logo. so maybe it's statistically more likely to have a handle, but, other than that, there's, some substructure that, that's a location on a larger structure. So I'm not, I don't see, I guess I, I feel like compositional objects are when, so like we keep seeing this thing that's like a cup with a handle and so we develop a compositional representation for, coffee cup. Whereas I guess, a more kind of.

Binding kind of representation would be, oh, this is a menta coffee cup. so I dunno. It's basically just incorporating frequency information. Like when I see something that looks like a coffee cup, just with high probability, I expect there to be a handle. And, but I can't say with high probability there's gonna be an mental logo because there can be some other logo or maybe logo. But that's, all just the probabilities, right? I could live in a world where there's more logos and less, handles. it doesn't seem anything fundamentally different about the two problems. It's the statistical regularity of them. I guess I feel one, one more defines one more defines the object identity. One is more an association. I guess maybe a better example would be like, a cat's face. Like a cat's face has ears. Sure there are cat that don't have ears, if it's been removed or whatever. But, the presence of the ears kind of informs the identity of cat's face. So that's compositional, I feel. Whereas associated is like, oh, this cat is wearing a hat. Like it's, that's just, it happens to be associated at this point in time. Yeah, but it inform. Of, and I feel like it's still the same process. It's just on a different of scale, I think. For sure. I think it might be a similar like short term memories. Yeah. For sure. I think it might be a similar process, but at least I feel like that's maybe at least, yeah, there could be cats that, that just happen to have hats all the time. And that's maybe then, but then we probably find a name for that. Like horses that always have And then you develop like a new, I guess I see it's like a spectrum, right? It's, a spectrum of probabilities. But yeah. I completely, so then I would rather, then I'd rather treat it that way as opposed to something totally unique. But what is decompositional hierarchy? I'm not sure. I don't understand what that is. What that word means. Yeah. Basically the idea would be at the lowest level of the hierarchy, you have basic shapes, so shape and then higher levels of hierarchy. Basically specify details at different locations on this object. it's just, it's just the difference is just, where and the hierarchy is what story. Okay. Never thought of that as a possibility. Is that a real possibility or are you just throwing it in there for completeness? Yeah. And this terrible drawing, it's like a tree on the one side. And then on each location we have features associated with it, like the color or the structure of the leaf or the tree trunk or something. And the difference between compositional or decompositional would be whether the left side is the top level, lm or the right side, it's the top level. Do, is there any thoughts at all that the right side could be the top level?

is that, that, I feel like it, alright. Yeah. So this is an issue, but I was just gonna say, yeah, I think it'd be really cool if we could get both, because from what we've discussed about this decomposition one, it has, I feel like the example you gave, which was a nice one, was, like a blurry photo of a tree. you don't recognize leaves or anything like that. The features are extreme, extremely impoverished. but you still recognize it a tree. So it is almost like the gestalt like way of representing something where you first just get like a core shape, and then you then get more detail. Yeah. And yeah, maybe this whole like, oh, this, sometimes the higher level of the anatomy is responding, won, go higher, is responding before. Like maybe that's because both of these things are happening in parallel and the whole thing is yeah. it strike me. The evidence would be, there's a lot of them suggesting very strongly that if you go higher in the hierarchy, you're gonna get these more complex, bigger objects. And, but you can do decomposition by flowing down the hierarchy. Yeah, It can be represented. Yeah. To me that's to where the decomposition goes. I could have something at the highest level and say, look, I don't have the details, but I'm gonna predict them, and try to look for them. but I would, I'd view that as just two different flow directions of flow on a hierarchical structure, going up and going down. Yeah. It's basically it might still be it cortex rather than V one that's representing the, this course tree model. But then there's just a lot of information flow, which is doing the decompositional hierarchy you're talking about, but anatomically it just happens to be starting that to the top of the book.

Think like this as hierarchy idea, just multi processing, input is a good way to think about it. and you don't necessarily need to recognize all the leaves before you can recognize the tree. But you can get, for example, you could also just get like a skip connection put to B2 or B before with a large receptive, recognize the course outline of the tree, but then whatever the detailed features on the tree are, doesn't matter too much. It could be like tree with snow. but it should go both ways, right? imagine I have very simple, let say, have two levels. The first level recognizes leaves, the second level recognizes trees. So if I see leaves, I can suggest there should be a tree. And if I see a tree, I can project backwards and suggest there should be leaves. It's, that's. It just seems like the same structure and the hierarchy could do both.

Am I missing something there?

No, I've tried drawing like some early drawings to try and think about where the analogy breaks or like, where it's less clear how these two would there's some things where it feels like you can lay out the decompositional and the compositional and they just Yeah. Work together. And like you say, Jeff, it's just like information flow the other way. And then there's some examples of representations that we think might appear in a certain type of this processing where it's not obvious. And in general, I think it's in the middle, it's, they seem to easily mesh, but then it's at the extremes where you have yeah, either like very core shapes versus like very detailed features, like how do those fit into the two? Yeah. But, but yeah, so maybe having some drawings.

as I was suggesting earlier, the anatomy suggests that when you go from V one to V two or V two back to V one, there are connections that are really associative, meaning voting like connections or just, and then there's others that are look really hierarchical. And, we know that a high level object could be learned and you could learn a copy in both of those. So it seems like, there has to be a way of the, in the brain at least, that these learning modules can flow seamlessly between these extremes of, of.

whether they're representing the same thing or compositional things. It's, it's, yeah. It's not obvious, but, okay. I get at least you answered my question. I know what you meant by it.

by what you meant by decom, I think. Yeah. Yes. Maybe some session we just draw some more. I think once we decide on some of the earlier questions, like the communication protocol stuff, maybe we'll already clear. I feel like all three of those are, can become equivalent very easily. it's just a way, just a question of perspective in some sense. Especially if we're saying we don't have this strict sequential processing of one level hierarchy and the next Yeah. To be honest, in my humble take on this is that, honestly the compositional decompositional and associative, all of those things just associate with my definition of compositional. So that's what I keep hearing. So I think maybe it might be simpler to tame this beast by just thinking about compositionally and then different types of connections, like from higher levels back to lower levels or lateral connections. Yeah.

Or different timescales like we discussed earlier, but frankly, everything still seems fundamentally compositional as far as I can see.

Yeah, So back to the, questions.

are there any, other questions you would add here?

Anything you feel like that? more attention, I dunno if we'll have time, but, how do we represent optic? I to high level related to this is also like, how do we learn that representation? So that was something we talked about that when but if we are gonna, for example, use it SDRs, then that raises questions about exactly how we let those SDRs, like a couple different things. But, that could be like a subpoint, but how do we learn those? So like I feel like that's, it's, like a sub question that could lead to a lot of different possibilities. Like we might agree on how we want to represent it, but, still be unsure about how the best way to achieve those representations is basically, it's like time versus learning time, right? Yeah, exactly.

Do you wanna try to list out what the different types of problems you might wanna solve with the hierarchy? It seems yes. The first question basically. Yeah. I can only think of one that I'm curious what the other ones are. Yeah, so I have always a few slides of my own snaps at these questions, but, yeah. One would be the fast association that Neil was talking about, like the logo on the cup, without requiring to relearn the whole coffee cup or the whole logo to being able to fast quickly associate this. And then secondly, be representing like higher level object product relationships, like letters. You still have those three bars that they could be further away or longer or shorter or tilted or something. Yeah. It was a form of robustness. Yeah. To in variance, Yeah. You respond regardless of particular, you recognize that as a, or whatever. Yeah. Or Korean character.

You see those, as fundamentally different or as on a spectrum. Yeah.

Yeah. Again, probably just on a different time scale, I wouldn't, yeah. Just to play devils advocate, I feel like it could be that there is something different. Just looking at the evidence from psychology, like there is, I feel a fair amount of evidence that path associations, it's a very serial process that people do well, only if you can, what's call devote attention to it. whereas, these kinds of more familiar associations that you've been exposed to many times, are, can be processed in parallel, and without the need for attention. And that doesn't necessarily mean that they're completely different processes. Like maybe it's just like attention is helping or something like that. but I do feel like there's some evidence that there is a still a difference there. It's it's of course it reminds me of, the very fast memory that you can form in the hippocampus versus slow memories it takes from the cortex. there's the thing about what it takes to recognize an object. There's the graph, which is oh, these are the features at these locations. But that is on itself is not a rep. That's, that is a, that's not a, momentary representation of the object. I can't say what's the name of that object. it's I can say, yeah, I know all these pieces are in this arrangement, but I don't have a singular name for them. I can't, if you ask me to identify it, how to describe it, I feel like you could learn a melody without having a name for the melody. Or you could learn an arrangement of furniture in a room without having a name for that type of room.

and so this is what the Temple Pooler did. It essentially says, oh, we take all these different points on the graph and we can associate with a common representation, a common, id. And therefore, I can say, if I know what graph I'm on, then I can know what the idea is, and then I can, I could, I have a label for it. The problem with that is that it takes a lot of memory to do that. the Temple pool requires pooling of a whole bunch of unique patterns onto a changing patterns onto a single pattern. It takes a lot of memory to do that. It's not easy. So I always felt so this idea of a fast, I think it's really easy to learn a new graph. It's oh, these are things arrange relative to each other, just add 'em onto the graph really quickly. But learning the temporal pooling name of a thing could take a lot longer. And I'm, wondering if it's just really, that's the only distinction you're making there is, that, we don't come up with labels for everything we, we learn. It's just too expensive, but we can learn the relationships between lots and lots of things without having a label on them. Does that sound like it's the same thing you were just talking about?

yeah. I'm more, it's maybe related or, but Yeah, it's more kind of like how you eat regardless of. Whether you have a name for something, I guess it's like, how do you, how do you basically identify, something and when those features that the kind of the comal features that define it, if those are statistically regular, something you've seen many times versus something that you've only seen or okay. that seems to go back, that seems to go back to this issue in the brain where we've got these, these inactive synapses in the hippocampus where you can learn something really rapidly, right? Instantaneously. where most of the brain, you can't do that. You have to be exposed to it over and over again. So the synapses grow. That seems like it's related to that difference. Yeah. And but, so I guess then the question is like how you can use those representations. So just for example, if you ask people, like a search task where basically you have a bunch of objects on the screen and you ask people to, identify a particular, object. So for example, you have a bunch of objects on your screen and you say, okay, tell me, is X object somewhere here? Yeah. And so you might have, let's say a bunch of letters. And you have a bunch of A letters and a bunch of B letters. but in this case you have a bunch of B letters and you have one A. Okay. Is the letter A here? Sometimes the A isn't there? And then so how quickly do people respond to that? And how quickly is people's response a function of. The number of like letters in this case. And if you, for example, if it's, let's say it's just a diagonal bar and it's, and vertical bars, but you're looking for that diagonal bar that's green and there's vertical and diagonal bars that are either red or green, but there's one that's diagonal and green. Finding that looking through all the objects seems to require you basically looking through every object, Until you find it. Whereas looking for Ts versus Ls, and this is even the case, if they're slightly skewed, you can do like almost instantaneously. Yeah. So how's that, but how's that relate to hierarchy here? I'm confused by that. because a t or an L is a compositional object formed from, ver vertical and horizontal bar, and you could argue that a diagonal line or vertical line or whatever happens to be that's the color green is also a compositional object. But one, the T and the L are defined by their statistically regular associations. The other one you've just decided to associate green with a vertical feature and said, okay, this is the object that we're looking for. so that's the one I'm saying that's more the fast associated one and the one that we seem to have more of a bottleneck in terms of how we, can process it. Okay. Yeah. I guess also related.

You just have association that you haven't learned like an object category itself yet. So for the letters, you have learned the category for the L or the T itself. And it's like its own model of the object, but the fastest association. Not yet its own model. It's just, I detect these two things, together. Yeah. Yeah. And so it may be that as you develop like a more, like a different representation, whatever the form of that is, that captures the kind of regularity. Then you also form an ID label, or as you were saying, Jeffrey, you could form the label and then later you can be told, okay, this name of the song is, but I, feel like that's more like a language thing that like Yeah. Do you have a name for a particular thing? Yeah. If you have the same name for different instances and it's, you have to like the category for it. if you call multiple things a.

Those differences. Yeah. But I guess like you, if you're doing the search paradigm and you say, okay, a green vertical bar is called a, it doesn't help, it doesn't make people factor to say, oh, okay, that's what an is, whatever. But could you, if you did this exercise over and over again, would you get really good at it? Yes. So that's, so it used to be this dogma that, oh, there's something special magical about color. and this was like the research from treason and stuff that like, color has to be bound with shape or whatever. But there's evidence that, for example, a yellow banana is much, you're quicker to identify than a blue banana, for example. so where there's regularity in that association then yeah, you are quicker, at identifying. So it's, again, it's, likely on a spectrum, it's unlikely to be a hard, it sounds like a trend is basically the speed of imprint is related to the frequency. Familiar. And also if you take the T and the L and you rotate them more, so you make them less familiar in terms of the structure that you used to, again, you become slower. So just that's, yeah. So I think in terms of on tv, wanna focus on like mostly the second part and com learning composition models. And then this first associative property comes out naturally because we.

From some columns, and then our learning paradigm could incorporate that if we see an association of things often enough, build a new model of that. And then we can recognize this new model of the Yeah, I think I, if I understood what you said, I think I agree with that.

yeah, I think there's a, so it's been a while since I worked with you guys, but I think there was also something going on where there was like a ranking of most likely objects based on the sensory input or, so sounds like that might come into play here too, because like you might just start your guess saying, okay, it could be all of these objects, but my guess is it's the most likely one. And if that turns out to be right, then like you have it instantly. But if you have to search around a lot and then reshuffle the order of those objects, possibly bring something that's not likely into the queue of what the most likely, it seems like that would take longer. So I'm wondering if this's already this phenomenon is already available through implementation.

yeah. I guess in a sense if we don't have a model of the logo plus coffee cup, then we would switch the most.

Most likely hypothesis.

but like the case that you have an hypothesis coming up later on is I guess more if there's a lot of noise or you switch from one object to another object.

Okay. so maybe the, so that's helpful, but maybe the more important question is is object frequency encoded in your implementation so far? if you have sensory input, and you've seen like the mug 10 times as many times as you've seen, chair or whatever it is, does the mug come up to the front of that queue faster? Yeah, not yet. So right now we have like flat fry, so every object is equally likely. So you could have a prior, like if you in more associated items.

No, that, that helps explain why it makes sense, why you have not incorporated that yet.

Because it sounds like it would basically just be like, based on the number of episodes, like if I did five episodes with the mug in one episode with the chair, like only then would that.

Exercise right now. Yeah. Yeah. I think the current setup doesn't, wouldn't because we just test objects on, I guess it make sense context Yeah. To have some context that into prior what you expect to see faces, faces in light outlets or whatever. Yeah. Yeah. Okay. but yeah, so coming back to this question for the problems that we like to solve, would you all agree that those three things are like problems we wanna solve with composition, which is then like object categories and related to that, to just be able to, model structurally complex objects in a more efficient way. Like we could have a model of a complex airplane in one module where it would require tons of data points and it wouldn't be so robust as if we have the different parts of an airplane, separate models, and then we can come post them together in a, in like the overall airplane model.

Yeah, I think efficiency.

So there's the top two bullet points, and then there's the next three bullet points.

yeah, so like in, in terms of if we're going away with a short list of what the problems we wanna solve are. Yeah. So I guess, first two are more like examples and then those three are like the general capabilities. but yeah, it's, yeah. No, it's not very clear, No, that's, yeah. Yeah.

first two would be both related to categories and composition, and then the efficient way is just some practical reason.

Okay. Yeah. I, this might be off in the woods a little bit, but I like, one question I have is, is maybe the notion of objects state only exists for like certain objects, so like a door with a handle that can spin and then open, like those are actions that you can apply to a door. It changes the state of the door. But maybe these lower level modules are only seeing like small parts of the door. So when you make a change to the object state, the lower level modules don't know what they're gonna see. But the higher level modules that have the notion of the door and the handle simultaneously. that might be true, but I would rather my first take on that would be not to do it that way. My first take on that would be say, how can a single learning module solve that problem, even if it can't do it for a very complex or structurally complex object. But you remember again, I've always, resisted trying to use hierarchy to solve fundamental problems, that have to occur everywhere. I know, I guess I'm just, I'm throwing out my bias on that one. My bias to say ask, could we solve that problem within a learning module itself? it's more received. Yeah. And maybe we can't but it, at first bls I would say it's not obvious. You can't do that yet, Okay. Yeah. I guess like object states we don't really deal with, yet at all. So I guess that be something we add on later. But then I think you're right, like some, like a large object, we need to cognize like more global state. It would be difficult to do one learning, or at least like with the point, it just be very much more inefficient to do module.

I think The structurally complex object is one that sort of suggests you need multiple modules. but the basics of behaviors, it's not clear to me that's, it's almost like a. Behaviors are almost like, object categories with, behavioral linkages between them, yeah. It touches on an interesting point that like if we do categories or we wanna achieve, categorization with hierarchy, the way we define categories is also not really clear. So far we think of it a similarity, but it could also be like behavioral similarity, like a shares something you sit down on, but the morphology can be very, different.

yeah, I guess we, we have to think about that as well. Yeah. I feel like that could be like almost like a parallel classification system that we tack on later, like Yeah. Yeah. it would also be related to this maybe SDR representation object id, How that, what is the similarity there?

yeah. Just in terms of these problems, I think, I feel it would help me if we wrote out in slightly more where it's like exactly what the kind of problem is.

an example problem. An example or more, or just for example, for example, object categories. So describing object categories as a problem. I dunno. Okay. that's too broad, you're saying? Is that what you're saying? Yeah, or just like understanding, like why is something in part public? So for example, for me, something that it cleared to me is what do we wanna solve? We wanna solve, like what's a problem? Being able to robustly recognize, compositional objects. So for example, the, letter. So it's, a problem because yeah, I guess it vary.

yeah. And so then hierarchy might resolve that. And then object categories, Like how do we, I guess it's challenging to, how do you, how do you represent objects? object categories of different granularity? I don't know, maybe it's pedantic, but at least I feel like I would have a clear sense of what I'm trying to achieve, like later down the line. If, yeah, I've always found it helpful, almost essential to pick a problem, a specific problem that then you can answer those questions about. you can easily pick a bad problem. So that's a challenge there. But sometimes it's helpful just to have a very specific task involved, even though I've used the logo and they call the cup as one, but lots of them like That that itself can help you enumerate what the specific details of this challenge is, or so I'm just suggesting that you can do Yeah, I feel like that would help me as well. Like a specific example of, for each one. Yeah. Categories so comes out composition and, representing structurally complex object in an efficient way because basically an object category is a definition of, a composition of features and it's always the same. even if features vary with, so like a cat, it's always two eyes, one, three years, but the relative displacement between them can slightly vary and the color of the eyes, everything can be very different. so it's like a set of similar compositional objects that we summarize it into a category and, but I guess this is what I feel like there's like multiple problems there potentially. there's the problem of yeah, how do you, consistently recognize a cat despite changing displacement and stuff. And then how do you represent, there's like cat versus there's like tabby cat versus tiger or whatever. So I feel like both of those kind of, and so I guess I'm wondering is it would just be helpful to explode, slightly to be Yeah, in terms of what the specific, like potential problems are, because I feel like they may have different solutions like having in variance to the kind of features of a cat space. Is it necessary, could we have the same solution through hierarchy as like how do you decide to represent different granularities of like cat labels or yeah. And what you define as a category depends on your interaction with it as well. I don't speak Chinese, so I just represent all Chinese characters as one category. Like this character is Chinese, but if I would be able to reach Chinese, each of them would be its own category. So it's also a bit arbitrary of where we say category not, I dunno. Should we like, just write down, make a new slide and write down someone we could write on the Yeah. May maybe it's quicker to type actually writing on what was, I think it's a great idea. I'd to, excuse myself right now.

okay. I'm, little uncomfortable and I also have to, have to do something with my granddaughter, but I'll be there tomorrow.