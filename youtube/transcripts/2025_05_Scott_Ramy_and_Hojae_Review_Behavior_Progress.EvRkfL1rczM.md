Okay. So this was an interesting and actually pretty challenging review. I may have, spent a little too much time on the early, I wanted to go back and trace some, the evolution of some of the ideas, and hopefully I didn't over sample on the early stuff that didn't cover it too much in this, but, oh, what, okay. Interesting. all So some of the main themes, that I was interested in touching on were having to do with, where behavior models are and who they operate on. and especially in the earlier days, we talked a lot about them sort of being side by side in the same column as every tier. And, at some point we pivoted to thinking about the more in the, parent column. I think it's interesting and, I'm curious about the biology of that and what implications that might have for, the idea of, columns having a slightly different, character and different and lower versus higher sensory area areas. Do we, do you wanna comment as we go? Or do you wanna Yeah, please. I, don't think maybe you, I, unless you ended up where I thought every column can have behavioral models. it's just that, the behavior model we ended up with the behavior model didn't act on objects in its same module. it's like, it acted on child objects. So in some sense it's yeah, that, that was the difference in the beginning we said, oh, I, in this one learning module I could have a behavioral model and a morphology model. And then, and they could interact, which seems natural. And, but then we ended up thinking, no, the behavioral model, acts more on the child objects. so behavior is just describing how child objects move relative to the parent, but that doesn't mean that there are different learning models. They all have behavioral models and, So I guess the question is what are behavior models doing in the lowest level? Like a one? Or you could still use at the lowest level, you could still have a behavior model that can recognize behaviors, but then you wouldn't be able to apply the behavior to a child object 'cause there's no lower level. But, it, it, should still be possible to, learn about changing things in the world and to recognize them again later on. It is a little bit weird to think what is it gonna do with that knowledge?

it's I think I said this once before the, the. learning modules at the bottom of the hierarchy are like the exception because, at the end they're like a, an endpoint. There's nothing below them. So there's a bunch of things that are a little bit different there.

so I, guess I haven't been too worried about it, but it's a good point.

and what do you think, Vivian, is there anything, could that, other than recognizing behavior, would it do anything?

yeah, I think recognizing it is already very useful. 'cause it can then vote with other columns as well that are, that might be at a higher level. but Oh yeah. Unless we, we wanna add another mechanism, maybe similar to what I was proposing with the balloon, last time. Yeah. Where it is possible to apply a behavior within a column. Yeah. Unless we would, and there's another idea too, by the way. we haven't really talked about how columns, We should just say learning modules. Generate behaviors from these models. And it could be that even a primary sensory column or learning module could be generating behaviors based on its, behavioral model, right? it's right. And we, just don't have a theory of that yet. that's an open, that's a possibility. And then the third purpose could be to assign behaviors to location locations on a parent object. Like basically knowing that the, at some location on the state that there is the hinge behavior. So like basically that the behavior ID becomes a feature on the parent object model.

So I guess in summary, Scott, there's a bunch of questions about this, but they're not, fundamentally at odds with overall theory yet just is questions we haven't really resolved. Would that be a good summary?

Okay.

and then some of these bullet points are just interesting things that kind of popped up along the way. which also maybe get into in a little bit more detail. I said pseudo parent objects. That's Jeff's example of the logo, the magical logo that can just move around whether or not you put it on a fridge or on a mug or whatever. Just, a kind of interesting thing to think about. and then, there was some discussion about model sharing and things like that. I have one example, maybe talk about, and I thought the Ps I thought the pseudo parent, thing actually in my mind was resolved. It so I didn't see any open issues with that. And maybe you do. I don't know. no, a lot of these things are like just things that are in my mind that I could use some clarification on. I think one interesting thing that came out of the pseudo parent idea is that we can use the mechanism for modeling object behaviors to model like general movements of objects in the world, like physics and like how a ball moves through the room or something like that. I guess even with that was was is, it an actual three layer model that we're talking about concretely? is it not a pseudo parent or is it a real parent? Does it actually take two columns to have a logo and then a third column that also has the cup? And we, you wouldn't, you don't. In general, the way I look at this is you, you could do everything of two. that's what we, compositional objects, right? You could have a, you can have a, composition structure that goes down many layers, but you can really only attend the two at the same time.

and so maybe the same thing applies here. It's if I'm looking at an object like a cup with the magic logo that's spins around, just, I found it easier to remember that with the little square around it. Just almost like you can visualize a little square around the logo so you can see what the apparent object to that spinning logo is, and then you'd say, oh, there's that square. Oh no, the square has this moving behavior.

and so maybe the same thing is happening even if the square is not there. That's a good question though.

it just occurred to me like the human body is like that magic logo. we have all these parts, but every part moves, every part can move.

So it's not like we're not very rigid, right? We're not really rigid things. So it's, it may be even, something like the human body is, it fits into the same category that there's a, parent object called the body, but all the components of it can move in different ways. And so there's nothing static about it. anyway, just a thought. Yeah. Could popped in my head.

and, so the next major bullet point here is precisely how the behavior model, is used to update object models or make predictions on object models, which we've discussed a lot lately. as just, I guess a reminder to myself, Object and behavior models. They can be like co-align if we're learning the objects and the behavior at the same time. But we want them to be sufficiently decoupled such that if that behavior is observed on a new object, it may occur at a different orientation and so on and so forth. I don't know, I find something interesting about this, connection during learning versus inference and how to, how, that's going to work, exactly I guess. But that's just a regular comment.

and I guess this last point here, treating application of behavior models like sensor movements. I'm just underlining it because it didn't really sink in all that well up until doing this review for some reason. it's pretty fundamental, it's just clicked. so I guess I'm just noting that, and here this is just. Stuff we don't need to look at. There's some slides here we don't need to look at, but I put 'em here just in case nobody else did.

does anybody wanna look at this or, yes. This is gonna be the style of this, presentation. It's just, here's some stuff and you, we may don't have to look at it if you don't want, but, it's beautiful.

Oh, I didn't, first of all, I didn't make any slides. I took everything from everybody else, so I think Vivian made this one though. Yeah.

we can just, oh, we can come back to this one. Just talk through this figure once, just to recap everything and make sure we all on the same page with it. Sure. so I. We've got two columns that are hierarchically arranged. Essentially we've got sensors, sensor that sends in, static features into layer four. And changing features like, like an edge moving across the patch of retina or something like that, moves into L three, layer three.

we have coexisting, reference frames for the object model. I guess sometimes we call it a morphology model. I'll just call it an object model and a behavior model. And, they both perform, they're independent, they're not necessarily go aligned, and, they both have their own, set of rotations that they, essentially ask the hypo, thalamus to apply.

we also have a timing signal coming in from the matrix cells, and, that comes into layer one, which we need for the behavior model. And, essentially on the next layer up, in addition to, relays through like high order thalamic, nuclei, we have direct connections that basically map feature changes into, the object model. Like a, as far as I understand it, a, feed, a changing feature can be a feature into the object model and the, at least that's how we discussed it into higher, order, model and so forth. But this is an earlier, I'm confused about this. Where's the. Where's the projection from region two to region one? Really? Where the, I just need a refresher on this. the behavioral model, how does it communicate to column one? Oh, this figure was made before we came up with that idea of applying. Okay. Oh, okay. I was gonna say also, I wouldn't know actually which anatomical connections we would, propose for that. So right now, I actually wouldn't know how to draw that arrow in there. but, it needs to be a, there needs to be a connection. So yeah, basically we would want a connection between the movement stored in layer three of region two down to the reference frame of the morphology model in, in region one. But I'm not sure, that's the movement. The big idea was the movement command has to be sent back down. And that's not shown, that's not shown in this figure. So I made that figure I think like a month ago. So then we hadn't had that idea yet. We're looking, at the, less optimal figure here. Yeah. this is old. I feel like, going through these videos of the last couple months feels like we're definitely gonna need a, what was it? The presentation that Vivian gave was like Monty going around the, map and just, discovering all the new things. there were a lot of twist legend of Monty. Yeah, the legend. They're gonna need a legend of object behavior version.

so just to recap, we're taking the composition compositional object framework and repurposing it with the inclusion of behavior models. this is a relatively newer one. This is the, review of the. Compositional idea where locations on the logo, or sorry, locations on the cup, are essentially associated with locations on the logo and so forth.

and this also is older, so this is where we have a behavior, essentially some or behavior model is, somehow communicating with the So this is old, this is, old, is, we've, we're, we've abandoned this, right? Yeah. We're past this. You're confusing us, Scott. You're bringing back things. we get these things. These are like our exes, we don't wanna think about 'em. I bet. So that's an analogy. Oh, it was hard for me to, just review the, hang on. what, was abandoned about the previous one? that, the child, that the behavioral model is in the lower column informing the stapler morphology model in the upper column. Oh, but I don't, that's not what I was showing there. It was more about assigning the behavior to an object on a location by location basis. So basically, oh. Different behaviors can exist at d on different locations, on an object, and at different orientations and scales. So basically that's the same thing as we can have different child. Yeah, no, but, what's, the scenario where we would have a behavioral model in the child object, communicating with the parent object? basically if, for example, the parent object is modeling the human body, and then the bo the body has a bunch of different behaviors at different locations. And so you would assign like the hinge behavior or the ball and socket behavior to the place where you have joints and you'd assign a different behavior to the eyes and the mouth, and the head. So Or if you have an object where, alright, so this is right. Okay, so this is, the behavioral model in the right diagram here is not informing anything about behavior, it's just saying No, It's just saying there's a behavioral model at this location. Yeah, exactly. So basically then if we see the stapler, we can right infer that it should have that behavior again. Okay. So I saw it as, oh, this is where we're acting on this behavior here. It's not, no. This is not for predicting the morphology or anything like that. It's just about storing where on an object behavior exists and watch, orient. I think the figures are, may be a little bit confusing in that regard because, in, in some sense we have, it would be better maybe to combine these figures. I'd say, we have essentially you have an object like the stapler and it has, fixed morphology and changing morphology and it has behaviors and it has. features. And they're both part of the composition of the stapler is what you're arguing. yeah. So they both be, they should be shown at the same time, some sort of simpler picture.

Yeah. So I guess here I was just trying to make that one point in the figure, but like both of these columns would have behavior and morphology models. And this is what I mentioned earlier as like the third reason why we might wanna have a behavior model at the lowest column, right? 'cause then that way we can assign behavior to different locations on an object. Like with the traffic light, the change of the color is at a specific location on the traffic light, right? maybe the, maybe in, in terms of a summary diag, a summary presentation, Scott, what we're, looking at, snippets that are on their own, makes sense to talk about, but they're not the big picture. which is what stripping me up a bit. So this Viv, you said this is a particular point. But it's not the overall picture, which is I keep thinking of, oh, we're gonna get an overall picture of what's going on, but this, these are not it. these are components of the overall picture. Would that be a correct way of saying it? Yeah. I didn't really attempt to make a comprehensive review of where things are at this point. yeah, I really just tried to pick a couple things that I thought were interesting and wanted to know more about. Oh, okay. but I think this slide summarizes a, good point, which is basically, the first idea we had was that we use for modeling object behaviors. We use pretty much the same mechanism that we use for modeling object morphology. And in this slide is again, the same point. We already have a mechanism for learning compositional objects. We assign child objects to a parent object on a location by location basis using hierarchy. And then we, again, can use the exact same, mechanism to assign. Are, we, confident that this right side is actually happening? Is it necessary?

does, I think if there's like change, so observation from the sensor is going directly to the higher level column, then that behavior, like the individual arrows can be learned on a location by location basis on the higher level instead of like on the lower level. And then, assigning that to a location on the higher level. But, I, don't see why not. It could also be in the lower level. yeah, I just wanna Sure. If it's necessary in that particular diagram. Yeah. I think, like Hoge said, if we have direct sensory input, I. You can probably do a lot without that, but one in higher regions you might not have direct sensory input. And two, I think we already have access to these mechanisms. So I feel like this is just naturally happening. If we have an object behavior ID that is recognized in a lower level column, that will just become a feature in the higher level column. so it, it's not like we're adding any mechanism, we're just using the mechanism we already have to deal with a new kind of feature that is being detected at the lower level. But the behavior model in the lower column assumes that the, that requires something's changing relative to a parent. And it's not clear that's actually happening down there.

there would be more just like local flow that's detected in the sensor like movement relative to the Yeah, but to, have a beha, to have a behavioral model requires that I have an object and, I'm representing the changes to that object.

it's not just movement. if I, if the, if we had the logo on the left and the logo is rotating, as we said earlier, that's not really, that unless it's the magic rotating logo, which introduces another reference frame. But if it's just rotating on the cup, that's not really a behavior of the logo. It, there, there be no spinning model of behavior model of spinning on the lower of a column. That would just be from the lower column point of view. It's just, there's a logo and it's orientation is changing. not a behavior. The behavior model only exists on the right. Yeah. With orientation you can, I guess just change the orientation, but you would still learn the timing of it, right? no. Not on, I don't think so. I don't think you'd learn that on the left side. The left side is just saying, Hey, I'm, seeing a logo and it's moving. Either it's moving relative to the sensor or it's moving. 'cause the bright column is telling me to, it's, acting like it's moving the sensor. But I don't, see, I guess this is the high level review we should be discussing here. It's to me, a behavior always is a, an object whose features are changing relative to the base, to the background reference frame. And, in, in this case, I don't see that there would be a, hinge mechanism on the left.

Because, you'd have to be recognizing the stapler to realize there's a hinge movement and the stapler is only on the right. The stapler, again, is a complicated one. 'cause because the parent trials are not really, known upfront the, that, that's why I prefer the logo and the cup changing. 'cause it's easier to understand.

but I'm not, I just don't, I'm still not convinced that the behavioral object would exist on the left side here In this particular case, what about if, we were in like a second and third level in the hierarchy, like in the second level, you definitely have a behavior model, right? Would you be able to assign that idea of the behavior to a location in the third level in the hierarchy?

so imagine, we have the stapler has a behavior model which is not shown here. And that behavior model would be in the right column. It's and it represents how it was learned by observing the a stapler. and then the question is, if the stapler is part of some larger object like the desk, or I don't know, would, would that hinge behavior? I don't think so. I'm not, I You have to, you might be right. Maybe. I don't think so. I, don't see why there's a need for that. It feels, to me it's just Hey, there's a stapler and there's, a child object that has some behavior. It could be the stapler, which we learned it with. It could be something else. But, I don't know. I guess you'd have, I'd want to see an evidence why you have to work it through, why it's required. I don't see it. I just keep coming back. The way I think about it is a behavior model is always, and I started off earlier in presentations, previous ones, the behavior model is an object. Where some one or more features of the object are changing over time.

And, so I'm always asking that question. So if I see this behavior model in the left column, I say, what is the parent object where that behavior is occurring? it I didn't learn hinge unless, I saw there had to be something on the left that was learned. I, don't know what is the parent object there that behavior is related to? Yeah. It's not the top of the staple or the top of the staple. The top of the staple itself is not exhibiting a behavior, it's just moving through space. But as the top of the space as a morphology object, it's not changing. Yeah. So I guess not to derail this review too much, I just wrote two open questions down for the brainstorming. Okay. So one, do we have behavior models at the lowest level? and second, do we need to assign behavior IDs to locations on a morphology model? or is that unnecessary? does that kind of capture it? Yeah, I guess those are good questions. I guess when I think about the stapler, if we assign behavior IDs to different parts of the stapler and say that it's hinge, hinge ness, who do I assign that to? Because I can open a stapler like this, but, I can also move the bottom half, which, which, I, it depends on how you learned it.

and some of the mug examples I presented previously. I touched on this problem, remember where the logo could go up and down. There's no clear home position for it. and so if you learn the stapler where you, the staples on the desk and the top moves, then I think you would learn a model at the bottom. Is that the fixed part and the top is the moving part. If, however, all staplers had the, generally the behavior was you pull something down from the bottom, you might learn like a little trap door or something. You might learn that the top part is the fixed part. Okay. it doesn't really matter because, I think if I took a traditional stapler and I learned it, the top is the child object that's moving. And now in the future I hold it and I pull the bottom away. That's like I'm changing the orientation of the entire stapler. I'm, I, that's how it would feel. It would feel like, oh, I'm rotating a stapler, but if I just pull the top up, I don't feel like I'm rotating the stapler. The stapler isn't a fixed position, it's just the tops moving. And the other case I would say is the whole stapler is, rotating and just turns out that the top is stationary as it rotates. It's a, in one case it just wears the, reference name anchored.

it's gotta be anchored to some part, something.

Does that make sense? Yeah, it does. you can just mentally go through these exercises and say, see how it would feel if you learned it one way or the other.

Yeah.

Okay.

let's see if we can, anybody have anything else they wanna say in this slide? I'm just gonna move to this next more recent version, okay. Yeah. This is a updated in the sense that here we're leaving out, first of all, the sort of overall point, which is what these last couple slides are, is just underlining the repurposing of the compositional object framework into a, behavioral setting. And so this is from Jeff's slides compositional model over here, composition plus behavior. And here, as opposed to the previous slides we're, really leaving off behavior, which it sounds like is still a continuing, topic to for discussion here.

yeah, so I think we've pretty much covered this, but, I think it's just worth pointing out the, point of this was, the thing that Vivian and I both came up with, which is that the way you make a prediction about a moving child, component of a parent is that the behavioral model sends, movement commands to the child object. And the child object doesn't really know if it's moving through the world or if its sensors moving relative to it. It's equivalent. Yeah. So that's how it, how we make predictions about a child as it's moving. That was the key insight I think.

over the last few weeks. Okay. then this next, figure kinda hammers that home, Just as a reminder, we've got a compositional object here. This logo is moving up and down, but this example, the sensor is fixed. so the sensor is picking up on movement, which then passes into the behavioral model, into the next like higher level. LM using a sequence of sense movements, we can infer where the behavior, like where we are in the behavior essentially.

and we can take the inverse of the movement stored in the behavior model.

here, this line can't see it, and, send, apply the inverse in the same way. As you said that we would apply movement commands to the sensor, to navigate through the object model space. It's a really nice idea, and nice animation.

that's just a recapitulation and like, I said, like I understood it, but, clicked a lot better as I was doing this review of this, it's like pretty parsimonious, concept of, repurposing the, motor commands to, to perform this task.

there was a, like an issue or like a two parts set of issues here. I'm skipping over the first one and just moving directly into deformations.

so for this one, like what's special about this balloon behavior is that it's non rigid essentially, and. If at some point the behavior, or sorry, the inflation stops then and we've only kept our sensor in one spot, once you freeze it, it's very hard to make predictions about the rest of the, where the balloon locations are. 'cause every location has changed, over the entire surface of the, surface of the balloon. So a few solutions were proposed. First we just handle it, handle it like as if there were a million child objects basically.

and then there was like this alternate solution that Vivian proposed, which is essentially a deformation of the object model space. I was thinking about this and thinking is this, we'd still have to store a lot. Sort of point by point data as if, almost like as if we were, had a whole ton of child objects, but, and thinking about it a little more, I guess what that gets you is generalizability. even though you're storing a lot of point by point information, but the deformation, you do have the ability to repurpose it for other non balloon objects. Yeah. So the key reason why I went forward with this idea is because like normally I, I would say this is unrealistic to be able to store, so many point by point associations and all I. All like how every location distorts, how this whole space distorts. But if it is possible to do this, learn this on a common space for all objects. and then apply it to any object, it, you basically only once have to learn all of that and then, yeah. Like you just said, be able to generalize it to, any o object space. But that would be the same if you're just trying to remember all the individual components.

there's another way this. It wouldn't be specific to any features or any components. It would just be the locations at which you expect features, change. But it is not related to any specific features. It's not related to the balloon at all. It's just that basically the location space distorts. Do you wanna, how much do you wanna keep this as a review session? How much do you wanna make it a brainstorming session, David?

I think it would be worth to keep it mostly review for now and then Okay. Collect the topics that we wanna go into depth, in just note that I had a, I had an a, a thought about the help clarify this problem, but we can leave that for later.

yeah, I'll, write it down and then hopefully we'll have some time towards the end. But yeah, I don't want to dig too deep into just this idea, right now. Okay. The common space for all objects, it seems like naturally located in a higher tier. Lm, if we're talking about, a higher lm, which has multiple child objects, like what space is that exactly, if not a common one?

I guess is a.

I have a mug and next to a fork or something. Is that its own unique space?

You mean like a temporary scene that we learned? Yeah, yeah. would that be an independent, a space independent of mug next to Spoon? It seems like we can't create a unique space for every, scene, some element of commonality to a composed scene at least. scenes are a bit different maybe than nested objects, but yeah, I guess the, maybe the mechanism so far would say that, if you recognize that this a new scene, your cells would just anchor in a unique way. To, and then you have a unique location space, but we also talked in the past about if this mechanism works, like during object recognition, when you have no idea about what object you're in yet, like what space would you be moving through? if you like, you don't know which unique, look, location station isn't, there? in the grid cell literature, I'm just wanna make sure I'm not hallucinating about this. I believe that if an animal is put into a, an unfamiliar environment, and there's no way for the animal to, to recognize the environment. It's a white box, no features, no walls or anything like that. I think, that the grid cells form a sort of common, like a default configuration. like this, there's like a. There might be a, there might be a space for things where there's no obvious way to, to mark the, if I just imagine you had a spoon and a fork floating in space and there's nothing else to say, oh, this is in my living room, or this is someplace. or rats see a couple of features, but it doesn't have anything that are near each other. But it has no way of recognizing the environment that there might be a common, like a default, good cell anchoring. Yeah, it sounds like, yeah. that's what I was thinking of. yeah, it just reminded me of what you were saying. Just remind me and so that you go and say, okay, I don't really know where I am, but I could at least learn to build up positions with a fork and the spoon. and then all of a sudden I say, Hey, wait a second. Oh no, this is, this is in this particular space here. I then I'll create a new space and associate those. So you, you can have a bunch of children without a parent and then it just goes to some default parent space.

Anyway, is that enough about that?

okay. I'm just gonna move to various other things I thought were interesting that kind of got dropped along the way.

and, this being, I guess the, sort of stopping point for, I, okay, so I guess briefly mentioned that Nils also had a proposed, avenue for this kind of problem, which is, a really course rescaling. I'm thinking as parameterization, like scaling re parameterization, I just wanna drop the note in that. I. He had brought up the idea that we, may not actually make that precise predictions about this kind of thing. and that, I don't remember him talking about that, but I, the way you phrased it, I agree with that. It's, it that was struck me as that this is very close to a scaling problem. And then we definitely could scale, just like we can change orientation, we can change scale as part of a movement, and then the more detail that it, the more it deviates from just pure scaling. So the balloon isn't purely a scaling issue, but the more it deviates, then the more points you have to learn. And you can imagine, something that's changing where the balloon's expanding, but the local features, there's hundreds of 'em around the balloon. They're all changing and spinning and doing various things, and that would take a lot of memory. yeah. But yeah, in this case, I guess I would argue that there are lots of object deformations that aren't just changes in scale or rough changes. but that, but one of the things I learned with the compositional research we did is that when, like when the logo bent or the something changed or it, you had to store more information. If the logo did not change in inter form in any way, then you just, a couple points are sufficient to learn the learn everything. so the more unique the thing is, if you wanna make predictions, you've got the store points. There's just no way around it. So I could have a, really crazy, imagine this was a, a Rubik's cube, right? And when the Rubik's cube is rotating, they're rotating. I look at 'em, they all look like a blur to me. I don't recognize those faces. It's just oh, this is a mixed up Rubik cube. But a person's really good at solving it, recognizes those individual patterns as unique things and knows 'em all and knows a thousand faces of the Rubik's cube. So they just, I just haven't done that. So they're all, those are like, to me, I can't make predictions about what's gonna happen 'cause they're just, they're random. but I could spend a lot of time learning it. anyway, it's just an analogy.

I think I'm gonna have to accelerate this 'cause I've definitely exceeded in my 15 minute, expect, I'm sorry, as usual. It's mostly my fault. So it's weird that it's, I didn't tell it to do a click through sequence on the text, but whatever. That's fine. I figured out the behavior. okay, so this is, another thing I thought was interesting. Nils brought up this idea of islands of agreement for neighboring lms.

be, to be able to tell the difference between a stapler that's opening and closing and a stapler. That itself is just rotating like that. And we've talked a lot about whether or not a single LM can do this, whether or not. Even if it can do it, it would just take forever to learn it. So this is talking about the process of pooling, information from lms. I found this to be a nice idea and it was basically that LMS down here, let's say this, the top is rotating. LMS up here would be recognized stapler at given rotation. And elms down here would be saying also stapler, same object id, but different orientation. And maybe this is something, maybe this is just more related to the learning process. Essentially when you have two sort of islands of agreement during the learning process, that, but the islands are distinct from each other, then we learn about the, compositionally or about the object. so anyway, that was brought up. I thought we agreed on, maybe not, but I thought we agreed on the idea that when something's moving like the top, there's an automatic mechanism for isolating it and, masking it. That's your second bullet point there. Yeah. That was, related. is, that seems in somewhat alternate to what you just said, so maybe island's agreement intentional masking are two, two proposals. Is that it? It sounded like they were related. I'd like to dig into it and think get like maybe anyone knows this back, we can talk about this more, about the relationship between the two. Because you guys weren't disagreeing at least in the video that I watched, but it seemed like there was some tr handoff between the two. I'm very confident in the intentional I'm masking now, so it just, I'm trying to make understand it, how it relate. Okay.

this last point, I already mentioned and we talked through, which is having to do with rescaling and that's a alternative to, maybe not alternative to Vivian's like graph distortion idea, but more like places, constraints on how detailed that distortion model has to be.

or, not constraints necessarily, but has implication for efficiency. I think this last point, parametize rather than location medication, I don't think those are alternates essentially. I think what you mean by parameter, like what's the scale, what's the orientation, right? yeah. as I said with a moment ago, you could have one set of parameters that would, could in theory define the entire relationship between. Parent a child object. But when things get more complicated, then you, have to do it on a location basis. So that is what, that's what we learned about the compositional model. It's always done by a location, basis, but you don't have to learn many points if Parameterization works.

so a rotated logo is easy just to say, oh, at one point it is at this angle, and I can then, I can path integrate and know what it's gonna be at any other place. But if the logo bends in the metal, then I have to have two multiple locations where I learn the parameterizations. So it's not one of the other, that's what I'm reacting to here. It seems we, we do parameters, everything's, parameters. it's scale, location, orientation. It's a more a granularity, but you do it. The granularity. This has become very clear to me. the granularity is required if you wanna learn more, if you wanna know the details, like I mentioned with the. Like the Q Rubics cube. If you don't really care, then you don't see it, but if you would really wanna learn it, you gotta spend time paying attention to it. Okay. Yeah. Another analogy too, like if you're more familiar with maths, it's maybe a bit like the feature change since a module. If the parameters aren't changing, then you don't have to lay down a lot of points in your model. But if the parameters like scale and orientation are changing, then you have to start, laying down a lot more dense points. Similar to like the feature change sensor module you wear, if it detects no change in the features, like you're moving on the flat surface, it doesn't send a lot of points to the learning module, but Right. If the features are changing rapidly, it sends a bunch of points to the learning module and the evidence of neuroscience is that it. When things aren't changing, the, sensors don't send anything. So you, the entire thing is filled in, All right. I'm gonna hop off because we've only got 40 minutes left for the remaining, speakers, though. I did, I have been thinking about this problem a little bit lately. I, thought about maybe just posting it on the research channel to think about, what everybody thinks about, but this is like the inverse problem of a sensor moving around to sense something. let's, say somebody traces a letter on your hand and then they're all different sensors, basically. and yet it's like the opposite problem of a sensor moving around and collecting a bunch of data. It's all different sensors receiving input at different time, and somehow you're able to temporarily pool them into creating a, letter. Just throwing it out there, because I was thinking about, I. this is a really good, I don't think I can do that. Sorry. Don't you have written letters in someone's back? Yeah. Like that. That's what I looked, it's gonna say if somebody writes something on my back, I don't think I can recognize it. Even a letter. I just tried. Kay. And I was like, like, I know it's a case. So I guess, anyways, go ahead. Yeah. Too, much sharing here. But I've done this with my wife and she's done it with me, and you draw, read, write on your back and you can do it. You can't do it extremely accurately, but you can do basic letters. It's doable. But I think on the hand you can do it more accurately because you probably 'cause it. I think what this gets to that issue I brought up recently over and over again when we're talking about, the issue of, shared learning. And I propose that the hierarchy is how this is done. I don't think you could do this at a single region with multiple columns. I think this would require moving the, these data, points into a higher level of representation in the cortex, which is also visual in some sense, right? It's visual or touch. this, we haven't resolved this issue, but I think that's require this, I it's a good, it's a good example, Scott, because I don't think there's any way a single region could do this. I think that's at least through introspection, what I feel like you do when someone draws on your back, you actually try to visualize it, right. A good look, It's not like you're just paying attention to touch, you're actually trying to mentally visualize it. That's my point. And that's what happens when you learn an object through touch, right? If you reach your finger into a box and you're tracing the, cup or tracing an object, you simultaneously are visualizing the 3D structure and you can, and see what it would look like. As you're doing that. So that just tells you that you're feeding this up into a region that is, is already integrated, multiple columns in, and you're forming a representation that's not specific to the, prom or the hand or the back or anything like that. You're forming a representation that's in independent, more generic. We haven't dealt with that, but it's a good example. Help us think. Yeah.

couple more thoughts on that, but I'm just gonna, table it. It is the exact opposite or flip of reaching a finger into black box to learn the shape of it is. Yeah. And it's not even quite the same as like tracing something out with a finger and relating it to vision because, it's not one sensor, it's many sensors. Like you never, anyway, but. Okay. I'm gonna, stop there. That's a good problem. I like that problem. We got, we, our series have to explain how it works. yeah. It'll fall out nicely I think. Think it's just a nice little, we another constraint on the hierarchy. good.

Rami, do you wanna go next? Let's think. You also have some thoughts.

I did create some slides, which is a kind of a risky move because of the complexity of the subject.

I only have a color if you want me to go next. I'm sorry. I only have X calor if you want me to go next.

so I, I didn't really address everything with my slides. so I realize now, after, Scott's presentation that I, there's a bunch of stuff that's missing here, and maybe the important stuff. let's see. I'll try to go through them quickly and, yeah. And Jja, if we don't get to you today, we can just pick it up there, at the beginning of the brainstorming week, but hopefully, yeah. Again, I'll try to go, through this quickly because most of this stuff is, we already know this stuff or we already, this is like a recap of not very new ideas, we'll go through this quickly.

we already know this building a morphology model and a, and, some lower level, column, the, movements and the features, and it's building a morphology model, and we're pulling that into an object id. And that's coming from, first order, the tele relay cells. And, we expand this to, ooh, a behavior model. Ooh, the fancy behaviors on this, I media hold lesson on how to do these fancy animations. It's easy in PowerPoint, but, now we just have delta features, so that's the only difference. we also, so we have the same, movements. they're changing a dnce, a different reference frame, which is the location reference frame of the behavior model. and we just have Delta features now. So any changes are going there, and we're just also pulling that behavior model into a behavior id.

I'm still, I think I'm, at the same place as, Scott and Vivian thinking that there's, behavioral model, everywhere, even in the lower level, columns. that's how I'm gonna keep presenting this, by the way. I agree with that too. I just was, I was questioning the, projection of the behavior model to the parent. Okay. yeah, I think I still have that in one of the slides. I, I realize now that there's a discussion on it, but I, don't want anyone to think that I'm going away from all columns, do everything. I think that all columns do everything, okay.

so now let's talk about a higher level column or high level, region column. so in this presentation, I'm just focus focusing on what is being fed into what, in the feed forward. And I will talk, briefly about the feedback, which is, I realize now is a big thing. but, I'm, not really drawing it here, but I'll talk about it. what are the inputs to a higher level morphology model? the first input we have is, the larger receptor field, features that are coming into the, layer four, which is, these are just features coming from the higher order, relay cells, thalamic relay cells. And that's also helping us build a, morphology model at the, in the, parent column. the other input is we're getting the object id. So everything that is static, basically we can, associate that in the parent column. So the object ID is also coming from the lower, region column. And what that's, helping us do is assign, like we can do here. We can say there's a TVP logo here, or there's a TVP logo here. this is a cup, which, I think is it's okay to say that there's a model of the cup in the higher and the lower, regions, and we just assigning, Just saying this, is a, it's a model of the cup. This is still a cup, and, it's being assigned at this location. So it's just saying this is an object ID of the cup, here.

so it's getting the object IDs. another thing that's getting is the, relative orientation. So I've added a little tag here that says, so basically this is the global orientation of the object that we've learned or the, behavior.

what, is getting here, as features is the relative orientation. So we can say the logo. so these, first of all, these orientations here are with respect to the sensor. that's basically saying how oriented the logo is with respect to the sensor and how oriented the parent object is with respect to the sensor. We can calculate the relative orientation and then send it up to the features, and we can store it. We can store these at locations as well. The, useful thing about this is that we can, now if we know the orientation of the parent object and we know the relative orientation that we stored at these locations, at any location, we can calculate what the child orientation will be because we already have stored the difference and we know what the parent is.

I know this is recap, but I'm just going through it again.

now, this is I guess the point of, confusion a little bit. I'm just assuming that if we already have a behavior model in the lower level, we can access it or we, can also associate different behaviors at different locations in the higher region. So in, in addition to pulling the object IDs and the rest of orientations and all that, we can also get the behavior, ID and say at any of these points we have this behavior. if you can think of, if you think of a stapler, you can say everywhere there's a hinge except for that little, deflection plate or the, anvil as we also known as an anvil. there's a slider, behavior, or there's, some, other behavior. on the parent object, we can just, assign, different child behaviors, at these, locations.

So now let's talk. So this was all just a morphology model, and it's getting all of the static features that we have, whether from the thalamus or from the, lower level region. now let's talk about the behavior model. The behavior model's only getting changes in those features, so I'm gonna go over these features again and just, it fits the behavior model in the parent. Now, right now, this is only the behavior model. Just for simplicity, I've just removed the morphology model, which we already, the, I guess the top text box should say, behavior id in the second column. Oh, Sorry, This is a mistake. Yeah. A type, yes. I just, my attention was just on this, but yes. the behavior model is pulled into a behavior id, over here.

so these are the delta features. So all of the four things that were input, before to the morphology model. Now we're going to inspect what the changes and features in here would represent for those.

We still get the, features coming from the thalamus, but these are going to be changes in large deceptive fields features. still getting the direct sensory input. I don't know how far this will go. like especially to like higher level vision. So this behavior is the one logo terms to the other is that this behavior, right? this example over here? Yes. Yeah.

but any change, so this is direct sensory input. So any change, it will basically capture it as just change in sensory features, direct sensory input. here we would not store anything and that's important. so nothing is getting stored into the behavior model because we're not seeing anything here similar to the lower level behavior model.

the other thing is, we're getting also a change in the object id. as this. Logo changes. We can store something like TBP to cup, or TBP to Menta logo. there's no change here, so we're not storing anything. my thinking is that anything that we store as a change is really useful in, in the feedback, connection because we can query at any, like at any timestamp in the behavior model, we can say, okay, we're in the middle of the behavior. I can see that I'm, the change is basically going from TVP to cup, then I can, feed that back into the lower level and bias what object Id I should be seeing now. I should, it'll go to the layer one and through the apical dice, connect to object ID in layer three and say, okay, you should be seeing now, a cup or an Ament logo or something like that. At least it would bias it. And then. It would consolidate with whatever input. Yeah. Point I tried to make, in the last few weeks is that this type of behavior is, has a qualitative difference than the behaviors of things moving. And there's there's nothing moving here, right? We're just changing an id and, so that's very much, that's very different than if the logo moved or if the staple top moved.

this is really just learning ID swapping. and I just wanna point it, it's quite different, so we have to learn it. I think the mechanism we have, we learn it, but it's a misleading one to think about initially because, it, there isn't any kind of movement information to be passed between the, and it's very specific. I can't turn this behavior learning that one logo turns into another. Into a different object with different logos because I, just, there's no way I could predict that, A-A-A-A-A Ford logo turns into a, Coca-Cola logo or something, you know what I'm saying? There's just no, there's no analogies there. and of the qualitative difference we talked about before between, if we just look at, object models, there's a difference between the oriented features, like oriented edges or the orientation of the child. Object to the parent versus specific features like the object idea of the child object, where we talked about hope, maybe the mini columns. And then the idea of the child object is. Specific activations in those mini columns. It's Right. It's it's very different. The way we represent the color is different than the way we represent the orientation of the edge. Exactly. Yeah. And so this is, you're right, that's a good analogy. That's what's going on here. So just let's be very careful. This is, to me, the less interesting example, the, one that's, really not very, it's not as useful, in terms of, creativity of a human or an animal or antique. I think it's a good, the easier example to start with, to explain the behavior models. 'cause like the first step in the mechanism storing changes. Yeah. Although again, these changes are changes in ID and not changes in, in beha shape or movement or, Most of what, we wanna have an intelligent agent manipulate the world. It's not gonna fall under this one.

The vast majority will be under things moving and, actions and things like that. But I, but this is, probably still going on. to be able to model these kind of, we have to, explain this one, but if we focus on this one, you're gonna miss the key parts. You would never have thought about mo sending movement vectors down to the child.

there's no movements. Yeah. Yeah. I think Robbie's getting there. Okay. it's really nice presentation, by the way. It is. I just wanna, I know that I spent a lot of time worrying to think about this, and it really took me a while to really crystallize. There are differences here, and this is a key difference between, so we don't wanna focus too much on this, but we can keep going, but I don't want anyone to think, oh, this is behavior. This is, a corner case of behavior and is qualitatively different than, most of 'em. The, so the way I think about it is the, there is no, movement that we can pass into the location, reference frame here. but there is, a change that we can pass into the object Id layer By what's happening.

I actually, I wish I had, more slides to cover the movement part, but I'm just, going to try and talk about them when, when we get there.

the other thing is the, changes in the relative orientation. So I'm not sure if this is, an old idea now. Or if this is still valid, but basically in, in addition now, so we were getting, in, the morphology model, we were getting the, relative orientation between the child and the and the parent. And we were storing that Here, we're getting the change in the relative orientation. So it's say we're at like 50 degrees and we're going 60 degrees, 70 degrees, whatever it is. Like it's a, change in that relative orientation. It's careful. This is not just a change in orientation. Remember I gave an example where you could rotate it around one end of the logo, right? And, so this is not oh, all you need to know is the orientation changing? I have to learn this on a location, basis. This is a change in location and orientation. it's tempting to think, oh, I'm just changing the orientation of the logo. No, you're changing its position and its orientation. and that the example I just gave is proof of that. you can't isolate this as just orientation features. It's. Orientation and location at each location. So what we're storing in the morphology model, we're storing the relative orientation only, or we're also storing the relative orientation. And the on the morphology model, you store the lo the location at an orient, an orientation at a location.

So basically we at the, like the features that are stored will be the relative orientation of the child to the parent. But that relative orientation is stored at a location in the reference frame of the parent. So if you have this logo rotating, you both have a change in orientation, but also you change at what locations that logo will exist. Y yeah. This, but this is all, all right. It's just a, an additional thing that will need to be learned. You can't just change orientation. That's not possible. Okay. and the proof is if I change the orientation based on a different point on the logo, I'd have different predictions. And, and so there isn't just a way of saying change the orientation logo. it's actually changing its location and orientation at multiple points.

I see.

But yeah, that doesn't invalidate the slide that you're showing there. everything you're showing here is like still, I just, I, It doesn't invalidate, but I know there's a tendency to think we're just changing orientation and I'm trying to banish that thinking. Yes. I just have to thinking more through this and, get back with questions. I guess that was part of the problem learning, compositional objects, is that we thought, oh, you could just learn the orientation of the, you just, no, you can't just learn. There is no home point. there's no anchoring point. It's. Anyway, I've said it enough already. Okay.

so the idea here for the feedback, would be that if we're storing that, change in relative orientation, can we also, so we ch we're storing the change in relative orientation and we know what the current orientation is. So the behavior model will be able to instruct, the morphology model to change. Its to basically know where to expect the, morphology of the child object to be as it changes. and that's still valid. the parent is going to send a movement command to the child, and the movement command can be both. It can include changes in orientation and it can include just displacement. Like non changes in orientation. just think about that, there both of those are valid movements. You could, there could be a rotation at some point and it could be change in orientation. So when the movement commands gets parsed by the child into, an updated orientation and location of the sensor.

Okay. So in, in this case, sorry, go ahead. Yeah, basic, so yeah, what you said is correct that the parent column can send a change in orientation to the child expects the logo to be at a different orientation, but at the same time, it also updates the location on the logo it expects to be on because, if you look at the little sensor patches, they change, right? Not just the logo, it doesn't change orientation. It also changes where the patches on the logo. So it will also move you through the reference frame of the child object. I see. Yeah. Okay. Got it. Yeah, this is the movement part. I'm, I think I'm, missing here. but yes, I, think I understand what you mean.

so this would assume that all of these movements that we store, whether for scale or for, the low going up and down, we would be just sending the movement back to the reference frame, the location, reference frame of the morphology model. And we would just be inverting that, and by inverting it, we're basically staying within the reference frame or there's nothing changing in the child, reference frame because we've inverted the movement that's coming from the higher level, the parent object. Yeah. I, would say scale is a bit more similar to orientation. that's more like a general transformer that's applied to everything that goes in, like to all of the movement vectors that go into the child column. Versus like movement of the whole child object is then actual movement vectors being applied to that reference frame. that's in, that's interesting because in the brain I don't think it would be that way. That's, that may be fine for Monte. if you think about the information coming from your retina, right? You're going back to the example, you're watching someone play a video game. And as you're watching that pump play a video game, if they're changing their orientation, if they're going forward, going backwards, turning left, turning right, there's one signal coming from the retina and the cortex figures out how to update the location and, orientation sign, from that vector. So in that case, we wouldn't be se if the brain, I wouldn't expect the brain to send it back a signal saying, change your orientation and or move in some direction. If it would model what you're getting from the retina, it would just be a movement vector that the lower millennium module has to interpret. It says, okay, what does this movement model mean? But we don't, we can do whatever we want in money. So I'm not saying money has to do it that way. I still feel like it's a qualitative difference because the orientation applies to the entire reference frame of that child object. So you apply the same orientation to all of the movement vectors that come in from the sensor versus the But in this case, But, we don't know that. The, if you were thinking about multiple fingers, the orientation of different fingers next to each other could be different. Yeah. Those are separate columns. So each of those have just one orientation relative to the object. So it's only you could say, is it the change of orientation at this point?

'cause you go to a different point, you might have a different orientation, so you could say, I'm applying it to the entire object, but. That's, it's really, I'm applying it to this point and I can interpolate that it's the same orientation everywhere, but it might change. The logo might have a proven or something, but then that would have to be learned by hierarchy. You wouldn't be able to, do that within one column.

all, this is learned in a hierarchy, right?

Isn't this, we're talking thought you, you were just talking about the, child co column, which is maybe at the lowest level changing the orientation at which it thinks the object is relative to the body. So we can do that reference frame, transform from. but you can only, say that's true at this point.

'cause you move to another point, you might get different instructions and say, oh, yes, we could. Without further information, we can change or change in the orientation of the entire object. But often there is additional information and the orientation as with the, logo that bends the orientation can vary at different points. So there is, but that's in the parent column that we have different orientations at different locations. That's basically what's stored in So I'm a child, I can say, all right, at this location I have disorientation. I can then interpretate, I can, predict what's gonna happen elsewhere. But if I go elsewhere, I might be told that the orientation has changed. So it's not always, yeah, that's more what's in the mini columns in layer four. But what I, thought we were talking about is like what layer six sends down to the thalamus to transform the movement vector into the objects reference. Ah, okay. maybe there's something we should discuss offline. Yeah. Maybe it's a misunderstanding because I feel like.

Yeah. 'cause I also think so I don't know if we handle the Oh, I see what you're saying. Vivian. I get your point. All right. I'll leave it at that. Yeah, I would be very confused if we disagreed on that. 'cause it's like a very Yeah, okay. Foundation. Okay. I just wanna make sure that everything's done point by point. And if you don't get any additional data that you can interpolate Yeah. But everything's done point by point. So you can't make an assumption about every, you can't make an assumption about an entire object. You a child object, you point by point and it, and yeah. You interpolate unless you get some additional data.

Okay.

and, in the case of, a level that is stretching like this, excuse me, this will be solved with the mechanism of. Movement, restoring the movement, of the, of the, be like the movement vector and the behavior of the parent object or in the behavior model and the parent object. And we'd be using that to change the, no, I, don't think so. this in your previous image or touching on the issue of scale. And you, if you go back in all of our previous talks, we've avoided talking about scale. Okay. this is saying the scale of an object is changing at certain locations.

again, at certain locations, it doesn't have to be, we can look at it and say, oh, the scale of the entire object is changing in the wide direction, but it could be dis thousand scales. It, changes, or it could become, wobbly shaped. So it's basically we're changing scale on, a location to location basis. Just like we can change orientation on location by location basis. I feel this is the distortion problem that I'm trying to get at. Like how, would we deal with those kind of distortions? 'cause it is not, just scale, it's scale in one specific direction, right? that's just but again, if you think about a point by point basis, you can do that, but not in the lower column. If it then stop, if the logo stops at the stretch part and then you move your, then you learn it, then you learn that, right? You learn it. I don't know. I think if I did that, I would still, I wouldn't learn as a new word. I would just learn that's a, logo that's stretched. It's a new one. All right. this is a good, this, identifies an area that we haven't really addressed, which is the scale issue. I think this is a scale issue and, and so scale and orientation can both change point by point if we want 'em to, or they can change in, all at once. So this is a good example, to, I don't think we've dealt with scale enough. Okay. The, and the summit disagrees. I don't talked about that.

so the other thing is, the other change that, may become a feature or a delta feature in the behavior model is a change in the behavior Id, we haven't really talked about this too much, I think. but I think this is how I couldn't think of an example, so I didn't put something here. But if, if the, if a, behavior id, so a static behavior ID is fed into the morphology model, but if the behavior ID changes, I wonder if that gives us some sort of compositional behavior. I can't imagine what that is. I can't either. Yeah, I think we talked about that before, that we can't think of a good example of a compositional behavior, so it might just not exist. Yeah. But I think it's. We may have the mechanism to, if we do it in a compositional way like this or a hierarchy, I can't even, I can't even think of anything that would make sense in this regard. Yeah, and that's because the behavior idea is usually over time, so you can't think of something changing at a specific location. no, the behavior idea is it's consistent over time. But you're saying, I think what you're saying is I have a staple at one moment the hinge goes up and another moment the hinge goes sideways or something like that. I don't know. like changes from changes something else, but I don't see how that would happen.

yeah. And I'm still questioning this fee forward projection as you're showing it. So yeah, I'm just trying to cover all the things that were static and we're going to the be to the morphology model. Now what happens if they're like, we're getting changes, of those into the behavior model. so yeah. So maybe that answers the, we don't really have compositional behavior. we can't have those.

No, I, this is not sure. Can you reach that conclusion? I think what you're changing is the behavior ID changes.

and we said no, but that doesn't mean it isn't composition. it's not compositional behaviors could be just a, I don't know. I just think about it. Yeah. 'cause every time I try to think of something, it, it ends up being a, like a causal relationship. I turn on the light switch and the light turns on or something, but it, I don't know if these are compositional behaviors or just a, some, causal behaviors. I, I think that we're getting sloppy with the language here.

and yeah, just to confuse myself, I think I just started thinking of, Breaking off a logo into, like different behaviors. And just thinking through, why do you say those to different behaviors? That's one behavior.

Some of them are stretching, so they're moving. It doesn't matter. It's one behavior.

because a behavior is defined as changes to the features of an object. And those changes can include everything like orientation, scale, rotation, location, that doesn't matter. So to me that this isn't multiple behaviors because these are all changing at the same time. But wouldn't you say, in this case, we would decompose the logo into multiple child objects that are basically the words of the logo and then each word has its own behavior. 'cause they move independently, but they don't really move independently. they move into, they're moving. Relative to each other, but they're moving together at the same time. it's not like the, it's not like the one word floating around the other word Floating in a different direction. Yeah. The timing is synchronized, which would be easy to do with the timing signal, but it just seems like, to me, it feels like this is one behavior. This doesn't feel like, oh, there's four behaviors going on here. If we do this at a location, basis, then yes, every, little feature is just creating one, one big behavior. It's orchestrated with like, all these changes, of the features are changing together. Just we could define a behavior of a stapler. Then when you open the top, the deflection plate rotates. This is just a flavor of that. You've got two parts of the object that are changing and they're changing independently. not the independently, they're changing at the same time. They're, tied together.

I, I I don't think this is one behavior here. This would be one behavioral model. This is not three behavioral model, I don't think, oh, the word project's gonna move up and down. Oh, and then, separately, the word thousands are gonna move up and down and up. No, they're all changing together. It's, we have to come up with, this is a single, model that this feels very strong. It has to be a single model. I think I, I feel very, very tempted to break it off into, separate objects because it, it is separate objects, but not one, not separate models. It's one behavioral model. Just like the, like even as you're describing it, you're breaking it into different parts. Just like the deflection plate. The deflection plate in the top of the stapler can be one behavioral model, even though they're a separate child. So all I'm doing here is I'm just turning, instead of having one child object, the stapler, I'm having four child, I'm taking something and breaking into four child objects.

Each one has, it's all part of one behavioral. it seems some obvious to me if, because these things cannot, they all change together consistently, then it's one behavior. I don't view this as four behaviors.

just conceptually you look at it, you don't feel that way. You just feel like, oh, I know what's gonna happen. I feel like we could build a behavior that is composed of all of these little behaviors happening together. But there, it's, it, I think it can be done with one behavioral model. I don't think you need multiple ones. I'll have to work through the details. but you identify this as a single thing, not as multiple things. You break it apart. Just like I break apart the top of the stapler from the bottom of the stapler, or just like I break apart, the top of the stapler from the deflection plate. this is an intentional mechanism. You have to attend all three, all four of these components to learn this behavior. but it's really no different than the staple top and the deflection plate, I think, and makes it a lot more difficult to do the solution of applying movement vectors to the child object to make predictions. If we would just say we com decomposes into four child objects in those move, then we can do that solution where we apply the movement vector and expect to be on different locations on the words. But if we, if the words are all moving in different directions, we can't do that anymore. We can't just apply the movement vector to the whole, right? So I think, this is a good example. Another one you've come up with several good examples, Romy, where we say, okay, how does our behavior model solve this problem? All I'm arguing Yeah. Done is a open question. All I'm saying is this is not four behaviors. This is clearly in my mind, one behavior. if these components moved independently of each other, yeah. It'd be four different behaviors. if, the word project could move sometimes and other words didn't and the independently did their own thing. Yeah, sure. But since they're all going together, we group these together as a single behavior. I wouldn't, I don't think this is, I, agree that we would be learning a single behavior, eventually, but I feel like it might be easier to assign to, to break them off and assign simpler, primitive behaviors to these and then build a higher level behavior. we'll have to see. let's leave that. I don't think it feels that way at all. Maybe that ties into the compositional behavior. Maybe. This clearly is, I don't say, oh, look at the word project is moving. Oh, look down here. The word thousands moving. No, all moving at once. I see it immediately. There's no question in my mind. This is one thing after I've seen it, after I've seen it repeat once or twice. Yep. That's one thing. So we have make shown as a question to tackle during the, I think this is a good extension of our behavioral model to see how do we handle this And clearly we have to break out the components, just like we broke out the top of the stapler.

so it just, that just, it just tells me that there's a separate, as part of a single behavioral model, the movement vector is I have to send different movement vectors to different, child objects.

And so the behavioral model has to manage that to do that.

Okay. just my last slide, I think only just talk about only the first point. I confuse myself a little bit making those slides. this is a question of, if we have a change of logo on a, of, just like the one we have, is this considered a behavior ID in region one that would be as, would be assigning to a morphology, model in region two? Or this is just a change in the object Id like from TP to, NOA. In region one and we'd store it as a beha in the behavior model of region two. So it could, I feel like it could be stored either in the morphology model as a behavior of the lower region, or it could be stored in the behavior model of the region two as a change in the object ID of region one. I note strongly to number two there. That's my vote. Change in object id. You're right. And I think, all these considerations of these, behavioral models are in region one are misleading. I see my feel. I'm just stating my opinion doesn't matter. I'm right. I'll make my point. I'll make my point in court in two weeks or whatever. It's, yeah. I think this is it. Sorry, oj. I think I, okay. That's my fault. Is it okay if I still present or? Yeah, do you guys just one? I like it at least just starting. Yeah. I just feel free to drop out if you need to. And I'll just, yeah, and I'll skip the, review portion of mine. 'cause everybody has reviews now. Okay. So can you see the xra? I think this is also in our group, like Xra, what is it? Like the, on the brainstorming scenes or something like that? Or the brainstorming, swimming, whatever. so yeah, everybody has done the review. I think the presentation that, Vivian gave, I think this was mid-April, so just like less than a month ago, something like that. There's like a huge, goes to the, the, like our current setup and the assumptions. I thought this was really good. So will, if you could put like a, oh, I don't know if will's here anymore, but the, the video, if this is a video on YouTube, it's put the video thing here. It's please click here. to see that. 'cause it's really, it's really good. And of course it's the research meeting that I missed, so no wonder why I missed a lot. No wonder why I was confused for so many weeks. yeah, it's not a problem. And yeah. And then the other, behavior movie that I thought was really good was Jeff's one. Sorry, I don't have a really good screenshot, but the key that I, I think the most important takeaway from this was like the, this section, I know there's like other important words here, but getting this movement out from behavior model was like a kind of a, that's a, oh yeah. Like that's a, novel idea that helps us predict what the, what the sensor will see, like what this Yeah. Is towards the movement. by the way, and then Vivian had this, Vivian had the same idea, but we used such different language that we didn't understand that there's the same idea.

and then I think it's probably worse revisiting, what we need to solve at the beginning of the brainstorming session and maybe updating it. I think from what I like, understand so far, I think that the, final open questions, at least for me is, talking more about the, how we learn the behavior model and then generalizing, the behavioral model to novel objects. I know we talked about like associations and so we did talk about this a little bit, but, even going back through the video, it's like a don't really quite, it's not very tangible for me yet. And then last week, Jeff presented this kind of, framework for slow learning and fast learning. sorry Jeff, I have no idea like what you're talking about still here. I know that you were gonna try to apply to object behaviors and I look forward to that. but, so far, like I. Yeah. But literally this was not about object behaviors, it was just about learning. I know, it's like a learning. Learning in general. Learning in general. Yeah. Oh, nice. Sorry, I didn't understand that. Yeah. Okay. Yeah, no, it's, yeah, it is what it is. so I just wanted percent how I am personally, like in my brain, like what I'm thinking about when we, think about behavioral models. So this is, very, low tech kind of behavioral model. Rolled out in time. So we have to learn some kind of change over time. So we're actually learning multiple things. That's Aspen, like always animated. so like for the stapler opening, for this particular location, imagine there's a stapler for this particular location. It's moving in this, direction next time point, in that, in this particular location, stapler, it's moving that, whatever. and same for t equals three. And I think stapler change opening is actually a little bit complicated.

but, and I think the mug changing color is a little bit easier to understand, but basically the, in the behavior model that we have in the little square animations that we always had, basically I just threw them out and then I put like a label for X and y to indicate that this is a change in a physical space, like the, like the, a particular location in a stapler is moving, in this. Velocity, whatever at a certain time, in a like muck changing, color. So imagine there's just a simple, I don't know, imagine this is like all green and it's just going like rainbow, like green to blue, to red, to whatever. in this case, at this particular location of, the mug. So maybe let's say this is the handle, like this location is like a point patch in the mug is changing color from red to yellow. And then the next sign is changing from yellow to green to blue.

this, in this case, this. Arrow or vector is not like movement in the physical sense, but movement in the color space. and to me, in my mind, I think this movement can be sent to the sensor, Hey, there is like some movement in the color space so that the sensor can still predict. Yeah, like I'm a neck, I'm gonna predict a yellow color now instead of red. so this is still quote unquote movement for me, just not in the traditional like movement in the physical. I think to be really careful using the word movement here, oj Okay. 'cause movement implies you can do like path integration. yes. In terms of location not happening here. There's no possibility of doing path integration. I can't say that red always turns, to yellow. There's no movement vector that says that. It's really just these are just random points. Red became yellow and there's, it could have become green. It could have become turquoise. I don't know. Yeah. there's no movement here. I think there's a change in time and I think that would be the better language to use that Id changes in time. Okay. Yeah.

and so I guess somewhat relate, like I, I agree with you that they're like, these changes are just tied to the location and the orientation perhaps, but not actual feature. this is not saying oh, and this is tied to like the redness of the cup. It's just like whatever it is, it's changing by a certain amount and over a certain amount of time. and the reason why I'm saying this is 'cause I think this is relevant. we don't want to learn like a change for every, feature. I don't want it to tie to a feature so that we can generalize to a object later, a different object later. so if we learn something that goes from red to yellow, like that behavior of changing color should be applicable, even if the starting color was, I don't know, pink or something. But, my point is how could it, how could I apply? One object changes from red, yellow to an object that's now green. How would I know what it's supposed to turn to? it just, there's no way of generalizing, right? It just There's, it's not a behavior that can be applied, that, that leads itself to that kind of generalization. you, I could say that another object's red might turn yellow. yeah, maybe you think of like a traffic light. you can apply that kind of red, orange, green behavior to, I just said that. I said you could do that, but you can't say, oh, now I see a traffic light has a blue light. I, can't predict what the, other lights are gonna be. It's like I've never seen a traffic light with a blue light. I can't, there's no, path integration to color unless you are very familiar with the color wheels and color comp composition. Yeah. Yeah. And you can say, oh, I just moved 30 degrees on the color wheel, so I'll, yeah, I'm gonna apply 30 degrees to the new color. Yeah. I guess pretty rare. I guess just some, like by drawing this axis, I was implying like, okay, look, I'm thinking about the hue, like in the color wheel stretch out or whatever. It's not a, big detail for my, like this section. but yeah, so I'll just move on for now. anyway, so in when we, in the behavioral model, like it, I know that we've always drawing in too deep because we understand that, but basically there it can be change in any of the features in any end dimensional, features. And we're just drawing, we just happen to be drawing in two dimension. 'cause that's easiest. but it doesn't, basically the, I just wanted to kinda separate that. this is not necessarily physical movement, but like movement in any, space of that feature.

so this is how I'm thinking about behavioral models is that if we, it seems that we, for me, like learning the behavioral models seems like we, we want to learn something like vector fields, except that we don't wanna learn every single point.

vector fields are usually, like dense, but we don't, I don't wanna learn like every single, arrow in every single, location of that object.

the, so if I fill the, like the above arrow example of the stapler opening, like the, what's implied there is that, at this location, staple is moving, a little bit up. Same for that location, I think for that location thing. For that location. And then there's no movement in these, but, And I, so I think the way that we can learn behavior, without having to learn every single point is that we, just interpolate. And maybe that's a cheap answer. but I don't really see how to do it otherwise. and we wouldn't store anything if there is no change. So like you Yeah. Case where you have dots, you just wouldn't, store anything. Yeah. but yeah, so yeah. So the, so yeah, this, so I was thinking about interpolation across time and interpolation across space. so if we want to, let's say, because beha, let's say stapler is opening pretty fast, so we only observe behavior at high equals one. And, we missed the two and then we, somehow caught high equals three. I feel and maybe this is just a, example that where it's like obvious, but, yeah, maybe I'm cheating myself, but, I think we can, if we learn a behavior, those, these arrows at time equals one and these arrows at time equals two, three, then what if we need to guess the morphology at technicals two, then I think we can interpolate between those two and get like an approximate morphology model. like basically it's oh, like I don't know exactly what the morphology will be at technical two 'cause it never stop there. But, if I had to make a prediction, it's okay, like I will interpolate, and then apply those movements to make a prediction about the, morphology. And then, so that's interpolation across time, interpolation across space. This is, I was thinking about the, example that Jeff gave last week, which was like squeezing a bowl into a egg or oval, something like that.

I, again, I think this is now listed a balloon where this is a case where all the vectors in the vectors fields are different and thus difficult to learn because, we either need to break it off into millions of children that, like Scott said, but again, I think we can cheat and interpolate. So if we know that, so if we're, if we know that we're squeezing on the top, by this much at one time point, so we're squeezing in like both ways, but less on the left, left right, and more on the top down. then, like I can reasonably, I think in that time point, I'm not observing, any of the other locations on the circle, this point or that point, but I can assume that, okay, this by interpolation, I. There is, there might be some behavior here if I need to. Like I, I don't think we need to store these. I, think we just need to calculate on the spot if we need to predict the morphology of a different patch of location, a different patch, for whatever reason. Yeah. So like I, when I think about, and I think also Neil's mentioned kinda like something like appro, like I approximate, like I don't think we have a, exact movement for every patch in our like models, but we need to on the spot, make some predictions and I think we do it approximately people. whatever mechanism that we use for interpolating of, an a morphology model, we'd probably be using that for the, behavior model. Yes. Like it, yeah. Okay.

Yeah, so I'm not sure if this gets around like the learning of every single point of the behavior model, but, I thought that this was just one idea that I had. but I think, again, the difficulty, this, depending on how we learn the behavioral model, I think that will significantly affect how we get to generalize it to other objects. 'cause again, like this is we are learning a behavior on a location by location basis. So we learned this, let's say on a stapler, how do we apply to a book? Like we need to somehow transfer the locations of the stapler. Like we have to map that into a book. And I'm not exactly sure how to do that, even if it's not tied to a feature, it's still tied to a location and orientation. So anyways, so I don't have an answer to that, obviously. And, hopefully, and maybe we will revisit it, when we get to a pretty swimming.

all Oh yeah, I didn't take 30 minutes. Yay.

Cool. Yeah, those were really nice, graphics too. I just. Open question also like interpolation in time and how to avoid storing too many morphology models slash key frames. Yeah. And yeah, I think interpolation is a likely, solution. But yeah, we can talk more about that too in the brainstorming week.

yeah. Great. Thanks to all three of you for putting together those presentations. That was really nice and a good, recap and also nice to hear these ideas in, different words and different framings. So yeah, a little list of questions that came up today. Maybe I'll put them into a document and then share them and you can add any other things that come to mind and then we can hopefully answer them all in two weeks.

Yeah, I made my own list too, And then, yeah, Jeff, you mentioned you had, some more ideas around the distorting objects, but maybe we talk about that. I'll do that next time. I'm gonna work on that. It's, I think there's a bunch of things we talked about today are interrelated and, that makes it difficult, to conceptualize everything. So I was thinking about the, role of the balloon in terms of, scale changes in scale and, but it, there's a general theme I'm working on here, which is, and it to interpolation with, there's a, range of how many data points you have to store to make correct predictions about something. And, we saw that with the, logo on the cup, right? If the logo's, just the logo, you don't have to store that many points. But if the logo's bending, a logo's changing scale, the logo's, the more deforms and changes in other ways you have to, there's no other way you have to store more points. It's just, it's logic. And, so that's relates to which Hoja was just talking about in the, behavioral model, that over time and the space, I think that's all related. Anyway, I came up with a list here. Basically the role of hierarchy and the attention, issue, like how do we form representations at the top are independent modalities. I think the, i, the example of the logo where the parts move separately is worth thinking through. the idea of changing ID versus changing orientation, scale and location. We have to make that very clear. And then the issues of things like the balloon and a circle becoming an oval have to really have a, clear theory about that.

so any of those things I'm gonna work on. So that was good. Today's is good getting us back in the mood here for this. I may not see you then. Forget about it during theon. I'm gonna be on vacation next week.

offline's not to think about the stuff, right? So I'm gonna come back on like Sunday and I think our research meeting starts on Tuesday, I'll be coming back with having, not really, maybe I'll be thinking about this over my vacation. Sometimes I do. So the middle of the night, in the middle of the night wake up, you just oh, that's fine. I usually have the best ideas when I'm Right. When there's no pressure on the weekend or something. So anyway, I look, I hope you'll have a good time with Hackathon. I hope it works out great.