Welcome to the Thousand Brains Project YouTube channel. This is the first video in the core video series, and it's a really special one. It's the inception of the Thousand Brains Project. We recorded this video in the end of 2021, so quite a while back already. And in it, Jeff talks about the main principles and ideas that this project is based on. We've been following the vision that he presents here ever since, so it's quite the key video to watch. There's one concept called the AI bus. If you've been reading some of our other documentation, you might have noticed that we're not using that term anymore. We now call it the cortical messaging protocol or CMP, but that's really just a change in terminology. Besides that, we stayed really close to this initial vision. There were a few small things that we noticed had problems that we didn't think of before where we made small adjustments, but overall, this is what the project is based on. without further ado, take a big sip of coffee, or tea, and focus all your 150, 000 cortical columns on this video. Cheers

I'm going to present some surprising things here. So just prepare for yourself for that. And really, it's a proposal to be run by people to get input on.

Let me dive into it. We're all familiar with this road map. Hopefully my sounds good for those people online. Let me know and I'm going to walk through the whole road map again. We've been working on this. I can't this doesn't work.

We're working on these components for a while. We started the work on sparsity, maybe 2. 5 years ago, something like that. Roughly, we've been working on active dendrites now, maybe roughly a year. I think the progress we've made has been very good. We've made a lot of progress in sparsity. We still work to do a large team. We're going to do some really amazing stuff, getting us all working on hardware. it's not clear we're getting towards the end of sort of our first day, but dendrites and we're not sure what to do next on it. You we're thinking about that. the reference frames in the cortical columns are in the future, so we've always had it like, okay, reference frames, planning, and then maybe cortical complete picture, more research. so we're at. Phase here where we've got something to be working on but we want to start the next thing and what is it? What's next? And that's been a hard thing to answer. It's not a it's not obvious and And it's it's you know And it's been a bit of a thought like we have to come up and figure out what our plan here So put some meat on this we talked about reference frames. Okay, we're going to add reference frames, but what exactly is a reference frame? Why are we adding it? What's the point? What's the goal of all this? And, and let's be, and so I want to put some more meat on that. To be more precise about what we mean about that, just to hone in on the idea, so I'm going to explore that idea a little bit first, and then I'm going to expand it beyond that. If you've got any questions that are burning, you can ask us, we don't want to. So I'm going to use this little, this is like a little taxonomy of models, machine learning models, if you will, or brain models. And I'm using this to talk about referencing, the big picture of what reference ends up. So this is how I think about it. I'm not proposing this as the be all end all. I view the world as sort of unstructured models and structured models. You can think of AI or machine learning. And unstructured models are ones that make no assumption, or very little assumptions, about the underlying data, the causes of the underlying data. So a classic neural network, artificial neural network, you have some input pattern, you have some labeling, a label for that. And, and beyond that, you make very little assumptions about what it means, or what the, what is the underlying cause, and you're learning a sort of a function between inputs and outputs. And then there's structured models. Structured models are ones that, assume there's some, It makes an assumption. It's a limiting thing. It says, okay, we're going to assume our data looks a certain way. And that's the way the model is going to work. So an example of that is temporal order. So you say, oh, I have these inputs coming in the series, but the order matters. And that's the thing we're going to, we're going to learn. So an example of that would be HTM sequence memory. It was a system that learned, temporal order. It is a system that learned temporal order. It's really good at that. It doesn't work for anything else. If you give it some other data that's not temporally ordered, it's not going to work. It's basic. It says I can learn this structure. I'm going to assume there's temporal order in the data. Brain can do that too. We can learn melodies and so on. In this case, label, you don't have to have labels. The system can learn without labeling it. You can learn a melody without having a name for it. You can just say, yep, I'm learning the order here. I put transformers with a question mark, because I think they're a class of this, but I'm not 100 percent certain, where it's the order of the words that matter naturally. And so you can train transformers. Without a lot of labeled data, you just throw out the text of the world and they'll learn, at least for, language networks.

then the second type of structured model is, is spatial. And this is the idea that you're trying to learn, the structure in the world where things are, have spatial relationships to each other. Their relative positions and locations in the world. And, and in this case, you have an input, but you also need to know how you're moving it through the world. So there's a second input there. And, but now we can assume that there's some spatial structure of the world. Examples of that, of course, the brain, the thousand brain theory is a sort of a reflection of the brain. Maybe SLAM is an example. This is, for those of you who don't know SLAM, it's a robotics simultaneously location mapping for robots.

And so when we talk about reference frames, I'll come back to it in a moment. There's a couple of interesting observations about these things. If you look at the pros and the cons of unstructured models, They can learn practically anything, because they make no assumptions about the data. Subatai always says they can, learn anything. I don't know that, but he says that, so I assume he's right. But, the point is that since you're not making any assumptions, you can basically, if you have enough training data, you can get it to work. The cons of this, the downsides, is it requires lots of training data. That's a lot of training, and it has to be labeled, for a lot of it has to be labeled. And because you have no underlying assumptions about what the data, what the model is supposed to look like, or what the world is supposed to look like, it's very, there's no inherent ability to generalize. There's no built in mechanism for generalization, because there are no built in mechanisms.

and, so there's some limitations of what you can do with them. the pros of structured models is you get very fast learning. we can, our temporal memory can learn in one pass. We feed a whole bunch of different melodies in one pass. Or you can make it a little slower if you want. there's the ability to generalize between, learned objects because there is structure to those objects and you can compare the relative structure. and so if I'm learning the spatial relationships and things, I can see if something else is a similar spatial relationship, it's oh, those are similar. Or even in melodies, I can say, oh, these are certain, typical patterns that I see in Baroque music versus, modern jazz, and I can infer things like that. You can also generalize, behavior if you have a spatial relationship model. we'll talk more about that. You also, when you have, structured models, if you have a bunch of structured models, then you have the ability to, for those models to collaborate with each other better. So this is, this part of the thousand brains theory is that, we have this idea of voting. between models. And one of the reasons you can do that is because we can have multiple models that all have the same internal structure. And therefore you can make some assumptions about how they can communicate with each other. and, in a, a way. the downside of this, of course, is that it only works if the world fits the assumed structure. If you try to get the system to learn something that doesn't fit that structure, then you're in trouble and it's one of the observations you and people made about AI is that today's AI, meaning mostly the unstructured models, are good at things that humans find hard to do and they're really bad at things humans find easy. And one way you can interpret that is that you take something like how to play game Go, which is a hard thing to do, and you're good at it. it probably doesn't fit in this spatial relationship and temporal order type of model. Therefore, we shouldn't be surprised if you take a neural network and you train the hell out of it with a gazillion, data points, which, generated by a computer. Then it's going to be really good at it, better than us, right? Because it doesn't fit these kind of models. On the other hand, if you ask, a classic neural network to say, what do you have to do to open this, Coke can with a robotic arm? It's going to be really bad at it. It just doesn't know how to do that. Because it, just, there's not enough training data to teach the world how to do all these things.

so that's the basic thing. But now, of course, I hope that's visible. It's got a little chunk in it on my screen here.

To do the spatial relationship, we're going to assume that the structure model is capturing spatial relationships in the world.

You need a reference frame, and I think, I think that's the last line. Yeah, you need a reference frame. So we need to be able to, some way of representing the relationship between objects, or relations between an observer and an object, or sensory organ and object. This is why we have reference frames. It's really because we want to build structured models that capture spatial relationships. and that's the point of it. not many people work in this area down here in the structure models compared to the above. There are people who do. and of course, the brain has both the temporal order and the spatial relationships. and, and that's why we did HTM sequence memory, and that's why in the broader looser concept of the thousand brain theory, we try to learn, we try to learn the behaviors of objects through sequence memory and so on. So we really want to, we really want to capture both of these.

So this is, the way I think about the models and why we need to have reference frames, because we want to build models that capture the spatial relationships in the world and the temporal order of those things and how things behave, but we are going to not be able to do as well on many problems that are, that classic ANNs can do really good at. that's not the point. So this is how I personally internalize thinking about models in the world. I don't know if other people, machine learning people, think about it this way or not. If there's any questions about it, let me know. Make sense? Okay. So now we spent a lot of time figuring out how the brain does this. And so I'll just talk a little bit about what we've learned, just a little bit about how the brain does this, and then, but I'm not going to go into too much detail.

As far as we know, the brain uses a combination of techniques to represent spatial structure. at least two of those are grid cells, which you consider matrix So I put a little matrix up here. So a grid cell sort of represents a regular structure, like a XYZ coordinate type of thing. And also uses these things called, vector cells, which are more like, polar coordinates. And so I represent those over here. And these, it seems to represent, use both of these methods for representing the spatial relationships of things in the world. So here's this little cartoon drawing of three objects in the world, A, B, and C, or you can think of these as three things in this room, or you can think of as parts of a bicycle, and you're trying to learn the structure of a bicycle, or something like that. And, and my brain can say, it's going to learn the relative positions of these things to each other. So you can do that with sort of vector cells, and these little purple arrows are like displacements. So you can say, A and B is at a certain direction and distance from A relative to some global direction. And then C is at a different displacement from A and so on. And Marcus and I, Marcus came up with this.

And so we can represent the structure of things by learning the position and orientation from each other. We think the brain is how it builds models of where things are relative to each other. Of course, these models have to be learned. And so here we show, the little circle on the bottom is an observer. You can think of that as a person in a room, you can think of it as your finger, or the patch of your retina, or something like that, but there's something making an observation, and the way we learn these models, the way that it seems, the only way we know how to do this, the way the brain does it, is we, we make a sequence of observations, and those are represented here by P1 and P2, which is pose one and pose two. So an observer looks at something and says, Oh, there's an A off in the distance at this angle, this distance, and says, Oh, there's a B over in this angle, this distance, and then it can calculate the displacement between A and B. We think neurons are doing this, And, and so we've now said, oh, there's some relationship between A and B that exists in the world. And if, and we do this over a series of observations, we go around the world, we're doing this constantly. Every time you look at something, every time you're basically determining where it is relative to you, and the brain can calculate where it is relative to the last thing you looked at. or sensed, whatever.

we want this to, the model should be independent of the location of the sensor. So if I moved an observer, the sensor moved to a different location relative to these things, and made two different observations, P3 and P4, meaning pose LA is off in a different direction, and a different distance and orientation, B, we should calculate the same displacement, so that it'll calculate the same displacement between A and B, independent of where the observer is. And so we have the observation and learning method that's very dependent on where you are, but in the end you build this model that's independent of where you are. I think mostly because we know that our models are not completely independent of the observer's position. You can see this like a classic example, you take a face and you turn it upside down and you still recognize that it's a face, but now you get really bad at recognizing the emotion of the face. so we're not completely invariant to location, orientation, and so on. But largely we are. If you walk into a room and you look around and you say, where are things, and then the next time you walk in from a different direction, I would still recognize them and I'd still be able to make predictions about it.

and then why grid cells, you don't really, so far this little triangle picture I've here doesn't require any grid cells. We think we know they're going to require for two, at least one thing required for doing path integration, meaning as a, as the sensor moves through the world. It has a location relative to A and B, and we have to figure out what its new location is going to be when it moves to make predictions. And so we know at least that, that grid cells are required to do this path integration of the sensor or the observer. And lately, as some of I've been talking about how I think grid cells may also be involved in coding the shape of space or the shape of an object. So that's a new idea. which we just started thinking about and it's complex and it's another, complication. One thing we can say for certain is we understand a lot of this, but we don't understand it completely. there is nothing here, we understand completely, but there's a lot of mysteries about all this stuff, and we keep digging deeper and deeper and it's oh, man, shit, more of this stuff, yeah, farther and farther as we go. but it's pretty miraculous what we figured out so far, and I say we, the royal we, not just us here, but the neuroscientists and everybody else. when I got into this field, 30 years, 35 years ago or something, none of this was understood. Absolutely none of it. And, and now we know a lot, and we've done a lot of great contributions too, ourselves.

it's really exciting, but on the other hand, we have to be honest. We don't understand this completely. I don't know how to build this yet. we don't know how to do that. now here's, I'm going to take that last picture and I'm going to repose it in this sort of conceptual block diagram. So I'm about, it's pretty much the same thing, I'm just going to present it in a different way. This is not a neuroscience diagram, this is a concept diagram, okay? And you could roughly think of this thing I'm talking about here as a cortical column. But I'm not going to state that exactly right the moment, but it is a model, so I'm just showing another, a modeling thing, and now you can look at this picture and say, okay, I broke it into two parts. One part is basically moving the sensor. It's inferring something like, oh, there's this, it's inferring the objects in its pose relative to you. And then, it repeats that. It's got your finger moving around, your eyes moving around, your body moving around, whatever it is. It's going to output some sort of object representation and a pose. And I wrote here pose RTS relative to the sensor. So this is the pose of the, the thing I'm touching relative to my finger. That's what I need to do to build this model. And, and then we pass it into the second block, and the second block is building that graph. It's figuring out what to do with it, even though I just told you we don't understand it completely, but that's what it's going to build that graph, that structure. that's the new model. So I recognize something down here and now I'm going to say, oh, we're building a new model by putting things relative to each other. That's pretty much what I just described a moment ago. This is pretty much what a cortical column does. I think now lately I've been starting to think that actually, to do this in cortical columns, you actually need two cortical columns. You need a what column and a where column. That's what I'm saying. It's not really a cortical column. It's more complex than that. But these are the basic operations.

Now we've proposed, we know in the brain, there's many models. That's a fact. There's no question about that. many models. You can think of one per cortical column. and, and all working on this basically the same. process. Not exactly the same, but pretty close to the same, you can think of these as three different fingers. You can think of it as a finger column, and an ear column, and a touch column, a vision column. You can think of it whatever you want. There's three different modeling systems. They may or may not have similar modalities to their sensors. They may be moving together or not moving together, like my fingers can move independently, but my eyes, the columns of my eyes all move at the same time. It doesn't really matter. And so we got multiple models here. And what part of the thousand brains there is a big part of the thousand brain theory was that we're doing this sensorimotor learning in the brain just like this. But then we also had this voting layer.

and Before I go into this, I've now come to understand or believe, at least I believe it, that this mechanism we described as voting in our columns paper is much more than we thought it was. It's much more powerful than we thought it was. It's a bigger part of the picture. It's not just voting on object ID. we understood some of this a long time ago, but now more of it's coming clear to me. and so I've shown it here with this green arrow, okay, and you can think of this green arrow as like a bus, it's, it's a communications layer that's going between parts of the cortex, in this case it's going between different models, and, I've come to affectionately call this the AI bus now, because I think it's actually turned out to be the, maybe the core or key idea to unravel all this stuff, I mean it was interesting, we had a brainstorming meeting a couple weeks ago. We were talking about what to do next, and I think it was maybe Ben or someone else also said it's hey, I was really intrigued by the voting thing. I think we should focus on the voting thing, so yeah, this is the voting thing, but it's more than that. I'm going to talk about it. So, it's going to pass around a bunch of things, more than we talked about in the columns paper. One thing it will, I'm just going to loosely say, it's going to talk about, it's going to pass around object ID. what, can, what are these things agreeing on that they're observing? And actually, I don't want to get into the details here. I could have put that green object up at the top. It doesn't really matter. We're passing on object ID, and these things have to learn about it. It's also passing around pose. Now, we didn't mind about that in the Columns paper, but, Markus, I think, was the first one to point this out, that when you touch something with your hand with your fingers, it's not that each finger is just voting what they're sensing, we're, they're also communicating their relative position to each other. And, that's a part of the voting. It's it's there's multiple sensors on multiple fingers and so on, where are they relative to each other? And we also have to do that actually between vision and hearing and touch and so on. And so we think the way this happens is that there's a different type of pose that's calculated. And I wrote it over here as RTB, relative to a shared point I'm using relative to the body. So think about it this way, when you, when I say, oh, I'm reaching out, you reach out and you pick up something like this can, where do you, have this sense of where it is. Okay. And there's, your brain has to calculate the sense where it is relative to each finger. It has to do that to make the predictions. But on the other hand, your personal perception is it's not the fingers, it's like relative to your body. It's like someplace relative to my body. And if I look at something, I do the same thing. And so when I want to reach for something, I have to have some sort of common language between what I'm seeing and where my hand is. And I said, Oh, my hand needs to be in that location. And so we believe what's being passed around this is pose thats relative to the body or shared point reference frame, if you will. And now, so that's not what we started with here. We had a pose relative to the sensor. So I put a little green circle there. That means there's a conversion that has to happen. we have to have two different types of poses. One that's used locally, which is for the column of the model, and the another one, which is now we can communicate. And by communicating elsewhere, we can all, then the different models can all agree, they can calculate where they are. So if I know where my left finger is relative to the can, then I, and I calculate on the green arrow where the can is relative to my body, then the finger can say where is it relative to the can. okay, this is getting information about where it is relative to the bottle, and you can calculate where it is relative to the can. it's like a messaging communication that's going on between them. this may seem really complicated, but we're pretty damn certain this is going on. it's this is the way it works. roughly, the detail, we don't understand. Now, what can you do with this, right? one of the things you can do with it is what we wrote about in the columns paper. Okay. What we wrote about in the columns paper, is you can have three different columns or many columns all modeling the coffee cup. And each one is getting a slightly different sensory input. Each one has a different location relative to that. We talked about it as three fingers, but it could have been a finger and an eye and an ear. It doesn't really matter, actually. and so they're all getting something, and now you can do this voting, and they can all come to agreement, very quickly. What you gain is you get inference with fewer movements. That's what you gain from this. flash inference, right? You can look at something and go, Oh, I know what that is, as opposed to looking through a straw going, Oh, I'm going to have to do this, or moving your finger around and just grab it by the hand. You get it. So that's, we've already written about that, and we showed that works really well. We didn't do that with the pose. We only did that in that paper with the object, but, but we didn't do it with the pose.

There's other things you can do here. Here's an example. This relates to something we've been talking about recently, and we've talked about a long time. It's that not all the columns can learn everything in the world, and so how do we transfer knowledge, in some sense, between some part of your cortex and other parts of your cortex? Here's one way of doing it. You can have On the left here, assume only the left model knows what a coffee cup is. It's learned what a coffee cup is. But now I'm, now going to sense the coffee cup with a different model, meaning a different part of my sensory system. That could be, like, I learned the coffee cup, what it feels like with my left finger, and now I wanted to, I'm going to sense the object with my right finger. Or maybe I learned what it feels like, and now I'm going to try to look at it, right? And so what can happen here is, because we go through this common information, as long as all the different modalities, all the different models can project the same sort of sub object, even something as simple as like an edge at some location to the body, then any, then it can be passed around to somebody who can recognize it. So then you can literally do this. You can say I can give you a couple examples. I can say you're gonna stick your hand in a black box and you're gonna learn the shape of five different new objects. I'm moving one finger. Then you can reach in with your left hand and you'll be able to recognize which of those objects you can infer from them. Or I can now show you those objects sitting on a table and you can't touch them, but you can look at them and you'll still be able to do it. You'll be able to say, Oh, I know that was the first one. That was the second one, third one. You might never look at it. I just touched it. So that has to occur. So this bus gives you the ability to do that. To route it around. Here's another thing you could do. I'm not saying this is happening everywhere in the cortex, but another thing you can do is you can learn with one finger, let's say, and train a bunch of models at the same time because you're basically passing around the same substrate that needs to be passed into each of these models to learn. And there's actual, there's good biological evidence that this happens locally. Meaning literally when the, there's papers that show that when you get sensory input on a very small part of your sensory system, whether the visual or touch or like that, literally that it spreads to the near neighboring columns in a way that suggests this is happening. And so you might, when I touch this with my left finger, it may actually be training other parts of my sensory apparatus near my hand on that same model. It wouldn't train the whole brain that way, but it could. So the idea is you could be getting input from one and then building multiple models of the same thing for different sensory modalities or different models at the same time. so there's a lot of flexibility that comes with this. Now, one thing that's become aware to me is That, this bus, if you will, the green thing has a lot more power to it. for example, we have what we call episodic memory, which is in the hippocampus in the brain. And, it's not part of the cortex, but it's communicating with the cortex. It's located right next to the cortex or something like that. And the hippocampus is known for doing very fast memory and recall. this is how you could say when you someone says, Oh, what did you do earlier? What did you just eat? What did you have for breakfast? where did you park your car? Somebody has to record that, right? And that's done in the hippocampus. and it's a very fast memory and it's a very quick and you can recall it, but it's not very long lived. You generally forget the stuff pretty quickly. but if you think about the things you remember from your. In your episodic memory is you remember very specific poses like I was here. The can was there. This was over here. And then I saw Christy across over there. I'm not remembering these models. I'm remembering the actual data that passed around these poses. where are the things that are relative to my body and what they were, and the sequence in which they occurred. And so now we have the ability, if you put a block like this, we'll call it the hippocampus, if you put a block on this bus, all of a sudden you have the ability to play back what happened and ask questions. What was going on in this network a little while ago? what's going, and how did we get here? What was the process? What things did you do earlier? which is a very interesting idea. But it's the same communications protocol. It's not a different communications protocol. It's the same information that these models need is what that, episodic memory needs. It's just, this has a different function. You can put it on the bus. I realize you can also do the same with language. Now, in the brain, there's these small regions in the cortex that are responsible for language. and I, in the recent, in research, I pointed out in a paper that it turned out they're very small. I didn't know how small they are. They're quite small. so there's, but they're really important. If they're damaged they're quite small. So I put a question mark there because they look like other cortical columns, but maybe they're slightly different. I wrote about this in the book. In the thousand brains is maybe they are a little bit different. They seem very similar. So I just put a question mark there. I don't have to deal with what, actually how it happens. But there's some things we know about language that are very interesting. Language, too, is, when we talk about things in language, much of what we talk about is in the same sort of languages as the green bar. We say, if I wanted to tell, describe, what my bicycle looked like to someone, I would say, I've got these two wheels, and they're attached to a frame, and there's one in the front, one in the back, and there's a seat on the top, and then, and there's a chain that goes around. I'm painting a picture which is very much in the language of the green stuff here. It's like You could be in his brain. He'd be imagining this thing at some point relative to his body. He's all looking at the front. Now. I said, imagine if I turn aside with okay, imagine it. So this idea that in that personal language, we have multiple ways of dealing with it. We can output an input language from hearing and touch and sight. So we have written language. We have braille and typing. We have spoken language. So there's clearly, there's a need to be able to get input into the language model and output to the language model of different modalities And the bus provides that mechanism and it tells us there has to be a routing mechanism here. I can say okay I wanted instead of speaking this talk I could type it up Or I could do it in sign language. Yet it's the same language, basically. So I put a little question mark there because the language model should be very cortical like it should be almost like every other model But we don't really know but the point is that this bus structure gives you this opportunity to add a language capability to this. So imagine that we had a machine learning system that worked like this, and it had the ability to do episodic memory and play it back. You could add a language model to it that just puts what's happening into words. It says, yes, at this point in time it did this, at this point in time it did this, and you could speak it or write it or something like that, or output it somehow. I don't really put a question mark there because, but it's an interesting idea that seems to be built on the same substrates in some sense. And of course, as, in the cortex, these are all connected together with these long range connections. By the way, I should point out that there might be multiple green busses in the brain. I can't guarantee there's only one. there could be different parts of the cortex that are connected together and other parts that are connected together. but the general idea looks like this.

and I would point out that these examples I just went through suggest a need for some type of a routing or attentional mechanism for the bus. You know, we have the ability to, as I said, we can take language and put it in different places. I can say, pick up the coffee cup with my left hand. I can say, pick it up with my elbows. I, have to be able to route information to different parts of your body to achieve these different results. So it's got that component to it too.

so what I thought about is that this is what the architecture of the brain really looks like at a different level, a higher level, this is what it looks like, and this is what we ultimately want to build. if I asked myself, what is machine learning and robotics going to look like in the future? That's really the trick of this system, to try to imagine what the future is going to look like. When we build these things, it seems like the biggest industry in the world. What is it going to look like? It's very hard to answer that question. It's very hard for pioneers of computers to understand what computers are going to look like. It's very difficult to do this. But I think this is a good, capture of it. Certainly, I would say that not many people are thinking along these lines. Maybe there are, there may be a few, but not many. This is not mainstream research. Yet I think this is the future in some sense. This is a, really what it's about. So the next question is, yeah. sorry to interrupt. What does RTS and RTB stands for again? Relative to sensor and relative to body. Okay. Yeah. There are different poses. I, didn't have that in there yesterday and I'm, I ran this by Subutai and Marcus and one of them said, that's confusing. So I put those letters there to differentiate them. It's still confusing, but now you know that they're not the same. Okay. What's confusing to me about that is the sensor is your body. the sensor, no, it's like a finger or, Yeah, but your finger's on your body. Yeah, but it's moving, so the moving, If I just say, where is this, Where is the can relative to my finger is different than where is the can relative to my eye is different than where is the can relative to my ear. Or relative to my toe, but I can also we can all agree if I can get into a common language that there's some centroid point, which feels like it feels like whereas I can as well. There's a relative position to a single point and then I can calculate where Individuals positions are so what is that common language? That's the part I'm missing. What else in the green line? Oh, good question. by the way, the relative to body is just one example. He said earlier in this slide that for example, the body, it may be some other kind of reference point for the hand that may be relative to the palm of the hand might be something else. But you're like watching it. Video screen like maybe something else. Yeah, it could be although it seems from an episodic memory point of view and from a language episodic memory point of view. It seems to be there seems to be a body centric representation. Again, I if I said you asked me like, okay You know where when I put this coffee can, when I put this, the last time I put this can down on the table, I can say, I know where it is relative to my body. Would I, can I tell you where, where this, what hand I was using? No. I, can I tell you where my finger was on the can? No, I can't do that. But I can tell you where the can is relative on my body. It's, I have this sense, it's oh, over there, this thing is over here in my mouse, over here. So anyway, yes, it is a relative to a central, it's still a common point, what I wrote. It's relative to some common point. And by the way, there's a lot of evidence the brain does this. There's, there are parts of the brain that look like they do these kind of transfer, these kind of reference frame transforms. and so this is not all made up. There's a lot of biological evidence for it too. All right, so going back to this question, how do we proceed? We don't fully understand any of the components. There's not a single thing on this picture that I completely understand. And yet we want to go forward. But how do you do? It's I have a proposal how to go forward. it's classic engineering. It is a classic large engineering problem solution. it's not a science solution, engineering solution. The solution is you define common interfaces and then you divide the problem.

I say we start by defining what this bus does. And we don't have to define it in, you don't have to define it in neural terms. You just say what are the things it has to do. And make a list. And then you say, here's how someone would interface with that. Here's how you'd input your information. Here's how you'd get your information out of it. Now the bus is pretty smart. It has to have routing. It has to do, resolve some sort of, conflict resolution. It has to do, various things. But we try to define it. So the bus is, the bus itself has its own behavior. But it interfaces to it. You want to talk to the bus, you have to put information in this form. And then the bus can accept it. And you have to accept this information out of the bus. These arrows are all bi directional here. I could, for example, I could say on this particular model on the left, I could say, here's a pose and it should be able to tell you this is what you're going to see the object. I could say, find this object, and it says this is where it's going to be relative to the, to that finger, right? So there's a protocol going back and forth. This guy can get down, below it, somebody can say, I have just observed something at this position, put it on the bus, and they can, someone else can say, yes, but now you need to move to this pose. And so this guy has to figure out how to move to that one. So you start here, and you define and implement this communications layer. I'm not saying this is going to be easy. I think it'll be easy to get started. I think it'll be really easy to make mistakes on it and leave things out, but you start. You just sit down and you define a bunch of engineering specs for this thing. literally, like an engineering spec. And then you can develop these other blocks independently. As long as everyone agrees on what the protocol is and what you have to pass in, Then you could do it in various ways. It just, you could, have three different teams building a vision model, or a sensor or something like that. They could take different approaches of it, but as long as everyone can plug into the same thing and they all can communicate in the same process, then you can develop these semi independently. I say semi independently because obviously the bus itself is evolving and we'll find problems with it. And so on. Now notice I wrote down here, develop these other blocks semi independently using best available methods. Now this is where it is, it might shock you. the best available methods may have actually nothing to do with neuroscience.

that's a possibility, right? But the point is to solve the problem of that box. And, and in any way we know how to do it. So let me talk about it a bit, before I go further. Oh, by the way, it's interesting in this approach, you could even start building these other models right away, these other modules. you could start building a language model. It could be a really crude language model, and it could be a really crude episodic memory model, but as long as it fits the bus, it's okay. as long as you've got a protocol, you can do it any way you want.

Okay, so what do I mean by best available methods? And so here, at Numenta have two goals, right? Number one goal is neocortical theory, and for those who have been around here for a while know that when we think about on a scale of biologically constrained theories, I've always argued we have to be all at the extreme left end. Meaning, not that our theories have to explain everything in the brain, but they can't violate anything we know about them. that's the requirement for scientific theory of how the neocortex works, and I've been really adamant about that. I've thrown away a lot of ideas because that's not how the brain does it, and we know that's wrong. And but when we come around to goal number two, applying neocortical principles to create true AI, What are the principles we care about? If the principles are in that previous block diagram I just showed you, then the actual details can be very, anywhere we want along this spectrum. And so it may turn out that we want to build some of these blocks using traditional, artificial neural networks. As long as the block fits into the bus structure. We might want to design the reference frame system using co ord cartesian coordinates. Could we know how to do that? why not? If it works. So one of the things I've always been concerned about at Numenta I haven't expressed this because it hasn't really raised its head yet, is that we've been spending so much time on goal number one, it's it's hard to break free from it. And it could be your Achilles heel in the end. Because, we may think everything has to be like the brain, everything has to be neurons and neurons and grid cells and all this kind of stuff. But other people aren't going to think that way. They're going to come along and they may solve these problems in different ways. And we don't want to be, we don't want to be bound by that first, the fact we got there. We figured this all out by studying the biology. We don't want that to, Constrain us going forward. and that's this is the part. I thought you might be surprised by. this is like the airplanes with wings that don't fly. Yeah, the point there is left by, so you pick and choose, right? You pick and choose. You don't have feathers. You don't have muscles. You don't have bones. You do have changing wing shape, that was an important part. That's what the Wright Brothers discovered. Controlled flight by twisting the wings. they also borrowed the wing shape, but propulsion? No, we don't do that. So it's pick and choose, right? And now we don't twist the whole wing. the original White Brothers planes, the entire wing was twisted. Now we just took the little back up, the flap at the end. Same idea. so now that means when we come back to this, thing here, we have the point is we shouldn't if we put teams on defining what I shouldn't stand up from the computer screen here. We put teams on finding what, what this, what this does what we all have to agree on this, let's say, but how to build this and how to build that, we don't these may be very non biological at all. They may not we could go, we can go back any way we want. I don't want to speculate now how we go about it. We could implement a subset of what it ultimately has to do. Maybe we focus, don't focus on the temporal aspects, maybe we focus on the spatial aspects. Maybe we use, CNNs and artificial neural networks to help us, and some glue to help us build these lower modules, things like that.

this is my proposal for going forward, I, is that we, start thinking about the problem this way. And, we start by defining this bus architecture, that's the first thing we define, and, and then, we start implementing the components, as best we can. There's no guarantee we can be successful at this. We may fail at this. I don't think this is wrong. I don't think there's, this architecture is wrong. I just think that it's a really hard problem. And difficult engineering problem and we're smart people maybe we can do it We should be able to do we should be able to make good progress here. but no guarantees. It will I don't know yet until we start hammering it out. We just really don't know how this is going to go but To me this captures, I always try to imagine what the future is going to look like What is the future going to be like? And try to ignore where we are today And then you say okay, if that's the future going to be like that we need to move toward that This is where you come out after all these years of studying this. This idea of this distributed modeling system that are able to vote and communicate with each other, in, a sensorimotor, learning of models of the world. none of this was understood when I started this, none of this was understood when I started this, 35 years ago. Even 20 years ago, we didn't understand any of this. but now I look at this and go, I can't imagine what else it's going to be like. That seems this seems like the basics. There's a lot of basics, of course, of, machine learning, but it's also the basis of robotics. And so you put in these modules, each one of these has a sort of motor output. You could start building more incrementally, more complicated robotics. And that too, we know it has to be a distributed problem in the same way. moving all your joints together. Maybe that makes the bus much more complicated. I don't know. Yet. so, This is a pretty different departure from what we've been thinking about, but I'm proposing it, as a way to get going here, literally like starting tomorrow. We could start talking about what the bus structure looks like and what would be contained in it, and, and start down a path that way. This is my last slide, and no more materials.