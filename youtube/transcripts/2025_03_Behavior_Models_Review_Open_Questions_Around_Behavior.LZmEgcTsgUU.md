cool. So yeah, there wasn't anything super specific. obviously we've got a bunch of, open questions still. And yeah, Viviane, if you haven't seen, made some really nice updates to, the document, just cleaning up some of the, the written notes and also making the, diagrams, not handwritten and stuff like that. and then we had the kind of neuroscience questions that was like four or five from last week. there was some discussion on the group. I dunno if anyone's done any reading beyond what we, discussed on there. But, yeah, so we can approach any of these we want. And then one thing we were, we're talking, it might just be useful to review the sort of existing. Model of how we think behavior might be working, just to clarify any uncertainties that might be there.

but yeah, maybe on the kind of neuroscience one or Yeah. What were you gonna say?

oh yeah, I was just gonna say, yeah, I think, on Ram's radar we had a couple of comments about how the, two models can be learned independently and applied independently. So yeah, just in the kind of recap of what we currently have as a framework, I think we were talking through that again to make sure everyone is on the same page because that's like one of the two key ideas I feel like. So just wanna make sure everyone understands that part. Yeah, that, that would be great. I feel a little lost and. Yeah. No, no worries. it's, complicated. oh yeah, and then also Jeff has been working on, writing up like a, version of this to be published so we can start publishing these research meetings, and more of a like patent disclosure style. that's where I took these diagrams from, but, yeah, we can hopefully share that this week. Nice.

but yeah, I can talk through the current state, but maybe it's actually better if, for one, because of my voice, but also because it might be good for one of you to test your understanding if someone else tries to explain it or tries to explain how they think we think about it.

I can try. Sure.

should I try and share my screen? Where's the, document? Let's see. Yeah, I feel like, yeah, those, figures might, helpful. it should be we share again, LinkedIn, the research meetings channel, I think.

Yep.

Can you see this? yes. Yeah.

Okay.

the, in the cortical column we have, a layer six A where there's the reference frames and these are.

Pathable and, we, it is basically just a physical location, with respect to the object. So it's in the reference, it's a reference frame with respect to the object. So any, movement of the eye, or movement of the sensorimotor is going to be transformed into, and it will be used to change the location in this reference frame. but there are other movements like, a change, like a local movement change, that is in the, basically a visual stimulus move or like an object, changing. And that will be going into a layer three.

so the, basically there are a lot of parallels between the morphology and, the, behavior model. But, In summary, it will be just basically the, there's two reference frames. One for the behavior and one for the location, and one for the, model, the morphology model. And then they will be moving in synchrony. but also the behavior one will be associatively linked to changes of the object. some movement of the object. and the morphology model will be associated, linked to, features like colors and or, edge orientations or edges and, stuff like that. everything you're saying is correct. I'm just, just, where you're pointing just to make clear the, or, purple ones are the behavior model, errors and the morphology one. And I, wrote, object model instead of morphology model, but we use those terms interchangeably right now. Okay. But yeah, go on. So the, associative connections between the two layers, between the, movement, between the location and whether it's, the static features or the changing features, the, movement features, that's what determines whether this is a morphology model or if it's a, behavior model. and it's just in a similar way to how we, pull, features at locations into object. IDs would be pulling movement at locations into behavior id.

and then these would be going to the higher level, or, that's, we could discuss that after. the time here that's coming from, we think it's coming from matrix cells and it's just encoding the, the intervals between, the, every time we receive a change that's, it's basically just encoding, how long between these changes it takes. So just like a, a tempo thing with, and I think that works for both the, fe both, feature change and the static features.

oh, the temporal part doesn't go into the morphology model, so at least not in how we talked about it so far. Basic. So that's what this, neuron that sends up, its apal Androids to L one. That one only is in the behavioral model. So only for the behavioral model do we have a temporal sequence of changes. And then for the static one, since it's static, there's nothing that changes over time. So we don't have a connection to layer one. So if we, so as we observe the, objects, the movement of the eye, yeah, I think it doesn't matter.

Okay. So the, intervals between when we get these static features doesn't really matter. at this point, no, because the eye movement is already integrated in layer six A. Okay. And like how we move over the object and in what sequence doesn't matter at all for recognizing the object. So we don't need to learn a temporal sequence there. Okay. And so in and in the sense a melody would be a behavior then?

yes.

Okay. Jeff is in the document. Should we like, ask, since he's looking at the same document, if he wants to join the Zoom as well.

just write in, read fake letters.

Hi.

I dunno if we can see or not.

Okay.

this is the part I understand, even though I've described it, very differently in my writeup, because I was trying to, propose a different thing. But, I'm interested in, so now I understand that the, these movements are in physical 3D space. So basically what we're learning as changes at locations, these locations. actually this, they describe the relative locations between, they basically describe relative locations in physical 3D space. So if we're modeling changes there, it'll be tied to whatever morphology is defined by the, relative locations. this is the part where I'm getting confused. so how is it, so the morphology model, I think that maybe that's a bit of the terminology. Terminology confusion. I guess when we say that this green one defines morphology is a sense that it stores like the point normals and curvature directions and curvature, like all these static features at those locations that define the morphology of the object, but. Just like only the locations themselves aren't like part of the morphology model, if that makes sense. Like just, movements relative to each other in space are that are encoded in the behavior model. They, don't represent anything about the morphology of object. They just represent which parts move at what points in time, in which directions or which points change their features, but not the features that are there themselves. Does that makes sense? Yeah. Okay. Yeah, it makes sense. but there's still, relative locations, sure. For the morphology model, we're storing edges at these relative locations and, that's how we understand the full model. but when we are, when we're dealing with a behavior model, we're storing the movements. Also at relative locations.

in some sense, these relative locations would not be the same if you're talking about a different model.

does, that make so for example, I, guess it ties in, I think talked about the, in some sense the, how you apply behavior to a, an object depends to a certain degree on its morphology. if there's no way to map those two, then it's it's not clear that you can map that behavior onto it.

so as in take a, I mean like a ball, like a, sphere can have the hinge behavior, but that happens by mapping like parts of a ball that kind of approximately look like a hinge and like splitting it in half. If you took the top curve of the ball and the bottom curve of the ball. They were doing like that's not really hinge or, that's, something different, I guess in some sense. so yeah, so I feel like there is an implicit, morphological kind of model there, but it's, that's kind of part, of how the behavior maps onto it. yeah, go ahead. Sorry.

yeah, several thoughts. again, maybe using the way we use morphology is a bit ambiguous because when we talk about the object model, that's really more than just the relative locations to each other, which is like what maybe you sometimes mean when you talk about its morphology, but then the point that you raised, Neil said the object has to have the correct shape to apply the behavior. Something that just naturally comes out of it. Like we won't anchor the reference frame of that behavior to an object if those changes at those relative locations are not occurring because the object doesn't exist at these locations. So for a, behavior to be applied to an object, those changes, the object needs to exist at those locations and the changes need to be happening at those relative locations. But it doesn't need to know anything about the object model itself, or it's not tied to that object model. You can still apply it even to these artificial setups, like even to the ball. You can make the hinge small enough to fit onto the ball and then imagine parts of the ball moving.

yeah, but only parts of the ball. You would not be able to map it on the new relative locations that are defining the ball.

I wouldn't be able to move the, upper hemisphere of the ball, like up and down to, to mimic that behavior. It'll still be tied to what? To the relative beha to the relative locations of the stapler. Why? Because just like you said, it, it is only going to move parts of the wall that, adhere to this relative location. Otherwise it wouldn't, be able, but it's nothing to do with the stapler. Like this column doesn't even need to have a model of the stapler it to recognize the hinge behavior. It's really just the changes at locations in a sequence of changes at locations, and these locations are in a reference frame that is unique to that behavior. So all of those locations are unique to that behavior, and it moves through that space in the sequence that it's learned for that behavior. So then it can apply that like it doesn't know anything about the stapler at all. It might have learned that behavior on the stapler because it observed it on there first, but there's no connection right now between the two models.

It doesn't know it's a stapler, but it knows, I'm sorry, these, the, relative locations is what's confusing me because I feel like we are building associative connections between the relative locations, which I know we're not storing any features there, but they are still defining how the stapler looks like, Because they are, the, movements are stored at these relative locations. If the relative locations are changing, for example, you change from a stapler to a laptop, the hinge is it's becoming a, different kind of hinge. but it's the same behavior. they don't tell you how the stapler looks. They tell you maybe where the stapler exists, but they have no information about how the surface of the stapler looks like, what curvature it has, where the point noms are, what the color is. They don't store any information about how the stapler looks like only where it observes changes. Yeah. But, yeah, maybe places also on a different object. 'cause a different object would, have, different places where you want to, apply the same movements. May maybe to paraphrase, like I feel like it, it is, this gets more into kind of the outstanding open questions, which is like. If we apply a novel behavior or a behavior to a novel object, how do we predict the appearance of that object as it moves? and like we, we've talked about potential solutions, like maybe it's something about anchoring point to point and things like that. But, yeah, I'm not, I don't think the current model necessarily like solves all of that, so I think it's something we can talk more about, but, but just, I think that's, it's useful to have that framing so that it's clear okay, what, have we discussed and we at least think might be right? And what is more like open questions that we need to do that we can just brainstorm now and try and understand better? Yeah. I think I've, so it, it sounds like your, questions are, more about yeah. This open question rather than, 'cause yeah, I think your description. Was, really good and accurate of kind of the current, model. Okay. I, just wanna say I don't think I, I did a very good job in, my writeup in explaining what I was actually aiming for. But this exact point is what I was actually aiming for. When I say apply behavior on a different morphology, it is this, open question, this is what I'm trying to solve. and maybe in, in my presentation, I could do a better job of how to do that. Yeah. I think that's a good distinction to make because yeah, that's something we have not figured out yet. And yeah. Thanks Neil for pointing that out. Yeah, no, no worries. That, yeah, this proposal here is incomplete. It has some nice properties and the one that I, was focusing on is that the two models are really quite independent. But we haven't really, we need to make them a bit more dependent, and we haven't quite figured out how to do that yet, to actually predict, I've learned the hinge behavior on the stapler. I have this general hinge behavior model, but now how do I apply it to a different object and actually make predictions in the features, about the features on that object. and yeah, that's an open question and this makes total sense. yeah, I, just, I think that in my presentation I will, I'm not sure, but I, think that I will try and, Define maybe the, a behavior space where they might not be aligned in physical 3D space. so it might, deviate a little bit from what we have here, our understanding, but just maybe, just take it as a proposal, not as a, this is what I'm thinking. Just maybe, yeah, it might be, I feel like it might even be useful to almost do a spectrum. So maybe if you find it helpful, but maybe start with the Pacman behavior on the clock or stapler on a laptop or something. Like, where they are similar and then go from there because at least it's, I think it's more intuitive if nothing else. Obviously if what you're proposing can solve it in the more general case, that's great. But, but yeah, before jumping straight into the hardest ones, which is okay, can we apply, can we even apply a stapler behavior to a very different object like a sphere?

Or is that kind of learning a new behavior and, things like that. Okay. Yeah. And just one more point to make, And, if you scroll down to the lower figure, the one that's, much more complicated, so they are, the two reference frames are only really aligned in their space when we learn the new object and behavior. 'cause then we really just move through the two reference frames in Synchrony with the same input and we're laying down points and learning about it. But then when we recognize them, we can recognize them independently and we can recognize them at different locations and orientations. So for example, if you look at the yellow arrows that go back down to Theos the orientation layer six B. It might be a different one for the object model that we're recognizing than for the object behavior that we're recognizing. Like I might have recognized the hinge on the stapler and then I recognize the hinge on the door and it's like totally different orientation. and then will need to, modify the movement that goes in into the two different re reference frames in a different way. So it's not like we always, and there might also be different scales too, like you might apply the hinge to a smaller part of another object. so they, they're, not always aligned. they're not always exactly the same if, you're thinking of it in more physical terms. Yeah, no, they wouldn't be exactly the same because they also anchor differently. One is anchored to the behavior, the other is anchored to, an object. Exactly. Yeah. but they, but the movement will, move them in synchrony, but they'll be different representations. Yeah, exactly.

Yeah, this makes sense.

okay. Yeah. And then, yeah, I guess on this diagram, one thing we can discuss is yeah, something that ViiV and I were just discussing on the document a minute ago, which is whether L five might also work as a location for the behavioral model, which I, think we've also talked about at some point in the past. But, just because, L three and L five actually tend to have really strong reciprocal connections. Like some people almost think it's two parallel pathways in the brain, L four and L six and L three and L five, but then L five and L six have really strong reciprocal connections, so it fits with, and even if the movement in Cool. Yeah. Like even if the movement information is coming in at the border between the two, that also fits with both of them. Path integrating based on sensorimotor movement.

and then yeah, motor output fitting that, like if, we talk about goal states and the goal states matching the behavioral states Or using it to plan movements and yeah, I think mento paper, they talk about the two parallel systems, and the right L five B reciprocal connections. Yeah. So L five and a B, I always forget. So I think, so in primates and run, I'm just referring to the Archic paper. Yeah, they're reversed. So L five A are the large cell bodies, so that's intrinsically bursting. So in a, primate. So those are the goal outputs. And then, so I would imagine that it would be L five B in primates probably if, 'cause it would be like L five B is like doing the. Behavioral state space, and then, L five A is taking that information somehow and then proposing a goal state that gets sent out. but yeah, in case that helps with the, but then presentation, the, change that's coming here, these are, mag cellular, projections. Yeah. Okay. because from what I've been reading is that these are going to four C alpha or four C beta, something like that. so I'm, not sure if, because if we're talking about blobs, I also, from what I've been reading, these are coming from cellular, not from, but they don't, I don't know if they do, represent change. So yeah. Okay. we could still have, if we both, if we have both of them in six A, they could still be, making, associate connections with four C alpha, and four C beta.

Just, separate it in Sublayers, Yeah. I think that'd be interesting to discuss the, inputs was, yeah, like we could, I don't know if you have that paper.

yeah. Or, that was talking about the me just find it first one, one paper I thought would be interesting just to quickly show is, this, Gilbert etal from, or I think it's just Gilbert actually from 1977, but it's a good example of where, they looked at the kind of response properties across different layers of cortex and saw this pattern of these like really small, receptive, field movements, in the kind of shallower layers. And then much larger kinda receptive fields, for detecting movement in the deeper layers. but this is if you hadn't seen this before, like when we're talking about the L six is integrating like movement from the sensorimotor moving versus like the, superficial layers are detecting like the movement of a object feature. This is the kind of, stuff that comes from.

but yeah, as with anything, it's I guess, complicated in terms of which layers are actually doing what. Like here it's kind of everything between L three and four C have kinda some degree of movement detection, it seems.

let me share this. This was shared in one of the writeups, basically the. Magnus Cellular would go to four C Alpha and Parvis Cellular would go to four C Beta, which fits nicely. if we want to just have, social connections with layer six a, because I don't know. Yeah, six a, if it just goes into one of these, like I think, it should, it would just make a social connections with both. So maybe and, then would go into the inter blobs in, layer two three.

Yeah. I'm trying to see, lemme just indicate the latest copy of the paper. I don't know if it, you've struggled with this Viviane as well, but because the hierarchy paper is under our personal email addresses. I always have to log out relief.

Oh, I think I can, just invite you with your CVP one or, I don't know if Okay. I wasn't sure. I think we've hit the maximum 'cause and super tie is also like the owner of the document. Yeah. I'm gonna, move it to another document anyways to format it properly. Okay. Yeah. If it's possible to then move it to Yeah. TBP stuff. Sure. That would be amazing.

Yeah. Do you remember Viviane, the kind of sources or whatever on, Magnus Cellular input and I guess was that, what you call it, was that from the Cortex textbook? The, one you were showing?

no, that was from a paper that just talks about these, okay. Parallels. So it was tracking them from the retina, from the ganglian cells all the way to, this triad cortex.

Yeah. Okay. these are the ones I have here right now. I don't know if you mean those meals?

Yeah.

or what specifically? Oh, actually, let me look at your giant PDF Oh, it was just a question of, movement Yeah. Where that's actually coming in.

Yeah. My giant PPF has like several images from different papers that show different things, so I feel like kind doesn't necessarily give clarity. Yeah. I don't know. Here's one of those papers that I reference in the hetero key paper. but it just shows magnocellular two layer four C alpha paracellular. Yeah. Okay. So that's consistent with what you're saying, Rammi. Yeah. Then they also go to the blobs. there is a lot of, text about that. I think, they, so there's a lot of, controversy of whether the mag cellular and cellular, they stay separated on segregated even when they get into V two and there's, arguments for yes and no.

what is a blob? Sorry, I'm not familiar with that, term.

yeah, it's, I think Neil's had a nice failure for her. Yeah. Let me pull it back up. But, basically it's, this one, it tends to be cells that are sensitive. Oh. color stop. Sure. Yeah. There's a few different ones, visible there.

sure, yeah. Cells that are, particularly sensitive to color are detected here. And I think under certain stains they kind of form these like blob like structures, which is what they're name comes from, but they're in general, like when we talk about minicolumns and stuff like that, Jeff often pointed out that, so that's where you see so that's indicated here with the orientation. So like all the cells. L four at least, tend to respond to the same orientation, but maybe that kind of mini column structure is going throughout all the layers to ape like maybe they're detecting all motion in a certain direction as well and things like that. So this kind of fits with okay, these are all cells that are sensitive to a particular color. but it's interesting that they're kinda conspicuous that they're almost everywhere except for L four. So even though they're representing features something like color, they're actually outside of the classic like feature detection layer. which fits maybe with I guess where our thinking has been evolving, which is that like L four is more representing orientation and then it might just be these might just be neurons that kind of respond weekly to color and then bias this column when color information's there More likely to see a banana, if it's also yellow, and things like that. Which, yeah, from the corneal cell goes into these blobs and they represent, blue, yellow poncy, from the retinal gangan cells. So they might use some color, but I'm not sure if you got two pictures to the right. I think it shows that what Ramy just said. there's a interesting one. This one there actually extends to layer four A, but yeah, the, conci cells projecting to the blob and, magnocellular two, four, CB or a, yeah.

Yeah.

Yeah, they show inter blobs as like a blob shaped thing too. I thought it was just a space between blobs.

And there's another distinction in V two, which, I, don't know what to make off. I don't feel like I fully understand it. But these layers, the thick, thin, thick and pale layers and, projections from different parts of V one, they go to different, layers in V two, which, this, is the next version of blobs, I think. And then the V two, but don't understand them very well.

What, what book is this from? This figure? Is this from a paper?

Yes. I don't remember any paper, which paper, but it's, I've seen it in multiple ones. I could send you some references.

yeah, I'm just wondering if it was the book on color Vision or, no. maybe, I don't know. I'm not sure. I, can look it up. And I think it was trying to make the argument that these, pathways, they stay segregated even into V two.

But yeah, Viviane, that might be something worth us querying with. Jeff, I guess we wanna update those figures. 'cause the layout in general, it's. just, how we represent the movement information coming in, because often it's shown, at that border, but, between L three and L four, but, we'd obviously want like an actual citation for that.

Yeah.

here's the other one that I referenced there where we have, this is an interesting picture, with the retinal gang on cells going to the magnocellular cellular once in LGN and then again. Yeah. Again, here it seems like layer four B.

Yeah.

Even though.

they show micro for C, but then they show movement being extracted from that somehow. Here it's still in four B, yeah, it is, yeah. The B four C, but yeah.

Yeah. The, the dividing lines in the figure don't correspond that clearly to the labels on the right hand side.

It's yeah, it's four four A is written on like the border between one color and another color. So it's like, what does that mean? What is four eight? Yeah.

but maybe that's the point is that. There's like functional divisions and then there's maybe they're focusing on the functional ones. Yeah. This one is just about functional segregation.

The, movement, projection that goes into four C alpha or, whatever. This is different from the, behavior ID that gets pulled into, some like a more superficial layer. So you would still want the behavior ID to be in layer two, three layers. Two, three. Yeah. And this actually helps because one of the other issues I was worried is are we expecting too much of L three? Because it's is it gonna do behavior id, object ID and motion detection and, all this kinda stuff. And if it's doing motion detection, it's not that clear why it's then. Passing that information on to, the next cortical column in the hierarchy.

I think, yeah, we once thought like maybe that was like a form of skip connection or something, but, but, yeah, I think we said we can't have the behavioral model in layer four because the, like time matrix, projections don't reach to layer four, but like only the neurons and layer three, oh, have the apical. Yeah.

Interesting. Because, yeah, I also suggested maybe the behavior models in layer four, but at least that was the argument against it.

So I, I guess the high level behavior model could still be an L three, but the, If, that's the kind of pool representation, but I, don't know if that necessarily is. What needs the L one, the matrix L input? Does these apical dendrites, today's synapse on six A as well, or just, five one?

the, ones that come from the matrix, the L one.

I don't think six A think five. Yeah. I think L three and IL five are the ones that classically send Dingys and L two, but six and four or so, yeah, that's, yeah, my understanding at least.

The reason I'm asking is because of the, the reference frame is, as attached to or tied to the, changes. Then maybe there's a way to get this indirect signal of, overlaps through the reference frame.

Yeah, think it would have to get it through the associative connections.

Okay. Yeah, so I guess that's some. Some more neuroscience questions to think about and maybe look into.

but yeah, but it does feel like maybe we're narrowing the space where these things could exist and yeah. Yeah. I think it would be worth going a bit more into depth back into the literature on what we know about the anatomy and connectivity of especially our two three.

yeah, it's a shame that people just look at them combined in a lot of cases. But yeah, that would be interesting or useful to figure these questions out.

Maybe go through the, the open questions, one by one, read through them and see, where we're stuck.

yeah, I was, yeah, that's a good idea. yeah, sounds good. Just to get a high level overview of all the things we need to figure out, and then we can go away and take a long walk and figure them out.

yeah, but I briefly go over them. yeah, I guess just intersect if you have thoughts on any of them, but we can also just collect them. yeah, the, can we learn associative connections between the reference frames was mostly a question. It's a bit of a smaller question, but it might give us some insights into how, like, how they inform each other and how we can apply. a behavior on a term morphology, but mostly I was just thinking about if I recognize an objects model, I also know, and I've learned its behavior, I should be able to predict its behavior model already. Like I don't have to infer the behavior. Again. It like, there seems to be an association that we could learn. Like I see the stapler, it's not moving, but I know what behavior it can have 'cause I've been moving before.

But also that the behavior would also, could the behavior also inform the object? I, know you said not sure that other way would make sense, but why wouldn't it? Yeah. I guess I couldn't think of a good example where you see the behavior, but, I guess it could, maybe if you see like a shadow of something moving, it gives you some idea of what object it might be. yeah, I think it, it makes sense that it could at least bias the recognition of an object.

and I guess this would really be more an association between the ID of the behavior ID and object id.

as, oh, I was thinking of it like, if you recognize the behavior ID, it increases the likelihood of a certain object or the other way around.

so yeah, I don't see any reason why we can learn it the other way around. I guess the video that, will was sharing during the retreats with the, motion capture points, walking, that would be maybe some behavior, right? Performing the person.

Yeah. That's a good example.

this one, I don't know, Niels, I feel like this deserves to be its own point.

yeah, if Jeff joins it in 10 minutes, if he just didn't get the invite update, maybe we can ask him about this. yeah, he would think.

and then, yeah. And maybe revisit also, I'll look at, I dunno if there's anything on, the different sublayers of L four and what if some of them have more connectivity to L six versus L five? Yeah. depending on if there's any literature.

Yeah.

so yeah, let me quickly go over the other ones. This one is more of a smaller one, just can multiple behaviors be detected at the same time? guess more of a side questionnaire. Didn't bold that one. and the big one is are there compositional object behaviors? Like we have compositional objects, so basically I. For compositional objects, we have this very concrete idea that we have in the hierarchy paper of All right, the object ID gets sent to layer four of the higher level and becomes a feature on that model. And we have these backward projections and we calculate the relative orientation of the child, object to the parent object and send that up here. But is there an analog to that for the behavior model? Or do we not actually learn behavior models in a compositional way, but instead just recognize higher level behaviors here? yeah, that was the question we talked about the end of last week's research meeting. Yeah. And maybe I feel for that one, I don't know if it's useful to define what we mean by hierarchical be or conversational behavior.

like to me, the one that's open is like a. Behavior where the child's behavior directly impacts like the parent or vice versa, as opposed to where the behavior is gonna self-contained.

Yeah. So what I mean by it is where the behavior ID becomes a feature on a higher level behavior. instead of definitely you can learn behaviors in this higher level as well. that's why this purple part is here. Sure. Like you can learn a behavior model here for sure. But does this model and when, you have behavior IDs as, features coming in, I feel like there's lots of cases where that would be the case.

like yeah, for example, like something like a car door or like a car or something like, you have something that's a low level as like the handle on the door and then opening the door itself. Then you have turning on the car, you have moving it. these are all interrelated probably in some like higher compositional object and that higher compositional object can have behaviors like driving and stuff.

yeah, I mean you could argue that those are all behaviors applied at different locations on the car, but yeah, definitely see the point that it might be necessary to learn like causality between different behaviors or how they're co connected. Yeah. 'cause otherwise it gets really complicated. It's like trying to model like an entire object with one reference frame. Like we wanna Yeah. Split up.

and I don't see like a fatal issue or anything like problem with having nested behaviors. Yeah. Then I guess the second question would be, would the behavior, ID actually become a feature on the object model here because it's a static thing, or on the behavior model, because like how we define this so far is that the behavior model encodes changes. So it would, by that definition, only encode if the object ID or the behavior ID changes from one step to another, and then when it stays static, it would be actually part of the object model, which is confusing to think about.

yeah, it's, yeah. No, that's interesting.

Yeah. Then we had this question about applying these temporary masks, when we have that was a, an attempt at solving the problem of how to make predictions about the objects, like how to apply the object behavior to a new object. Morphology basically masking half of the stapler and just rotating that part of the stapler, for example.

yeah, I guess this is their open question.

and then I guess I should probably move that down 'cause the next one's pretty related to the previous one. So whether behavior ID is treated the same way as object ID in the lateral and backward connections, and also how we communicate timing in the behavior like. Do we only communicate the behavior id or do we communicate behavior ID plus where we are The sequence of the behavior?

Yeah. Yeah. Maybe. Yeah. We can write sequence, sequence, location or something like that. sequence point. just to clarify the difference between like seconds and Oh yeah. Sequence, sequence. Can we vote on just position like that?

sure. Yeah. Position sounds less weird. That sounds good.

And then these two. Yeah. Now these are better ordered. This one is related again to the temporary mask. The more general question of like, how do we predict morphology in the middle of a behavior, like what we talked about earlier, like a big unsolved question. also what of behavior and Yeah. And I think arguably it's, still unclear even in the, case of an object. We have learned it for like even with the stapler, it's not, and we, even if we learned the hinge behavior with the stapler, it's not obvious how we predict what the stapler is gonna look like, at a particular location, Let alone applying hinge to a new object. Yeah. So we basically, our proposal currently allows us to recognize behaviors and objects independent of each other, but it doesn't allow us to make predictions.

Yeah.

okay then, I guess a bit related to the temporary mask was this idea that maybe object behaviors can also help us segment objects into sub-components. if we see a part of an object move that tells us that, might be like a child object. which again, I think, fits well with compositional behaviors because it's like the more complex a behavior is, the more likely we are to segment it into or the more complex how an object changes is, the more likely we are to segment it into like child objects with their own behaviors. So I think Jeff often gives the example of a transformer model or something like that. But if, it's this thing that does like loads of stuff, you may kinda understand each of those components and then how they fit into the whole thing. Yeah, I mean to me, I would mo almost think of it as I don't think the segmentation part would necessarily require a compositional behavior model, but it requires hierarchy for sure, since we have child and parent objects. And basically how I would think of it here is we would recognize the behavior in the high level column.

I think we had this weird example of the chair where something hinges off in the back or, yeah, I dunno why that, where this example came from. but we see a mo, we recognize the behavior here and then that would somehow inform down here to split up the object into sub components that then become parts of a composition object here. Like the object that we are decomposing is the object model, not the behavior model.

maybe, but, or both, I don't know. Say it's a rocking chair and then it has a little button on it that does something lifts up or, I feel like the rocking chair is the behavior of the parent object. The, rocking is the behavior of the parent object. And, but then we may separate out this oh, on this location, the object, there's this other smaller object that has its own behavior, which is to flip up and then you can press a button on it or whatever.

yeah. So then that flip out button would be the behavior recognized down here and the down there. Yeah. recognized up here. and then to your point about yeah, is it the change that's passed? Is it the behavioral ID or the change of behavioral ID that's passed up? It's almost it almost seems to fit in with if the behavior influences the. Higher level. Higher level, it's because there's a change happening that's somehow interesting. So it's if they're totally independent, I don't know, the button flips up and you can press it and it turns red or something. That's just like a feature at a location that can be different at different times. But if it's like pressing the button, causes the chair to start spinning or something, then it's almost like when you get that, sorry, it's such a crazy example. But, then that change, the, fact that the behavioral state is actually changing is almost like informing the high level behavior. I don't know. Something Yeah. Yeah, of, a, keyboard that has maybe two behaviors. like the, you can type in query or you can type in the VRA or call Mac or something like that. And then there's a light on that, keyboard. if it's blinking, then the behavior of the keyboard is, this type of, or, if the lights is, if it's green or if it's red or whatever, it changes the behavior of the whole keyboard. I don't know if this would be just like a causal, thing or a compositional behavior because the, change of the light from red to green, is, a type of behavior for the light. and then the state of whether you're typing into Bo or V Mac, that's a behavior of the keyboard.

Yeah. Yeah. That kind of.

yeah, I don't wanna sidetrack what you just said too much, but it, reminds me again of this big open question of how do we predict morphology based on behavior? It almost seems like where we are in the behavioral sequence needs to give us like a state kind of thing. Like whether the light is on now or off tells us what the morphology model should expect.

yeah, I'm not phrasing it very well.

I guess in your case, I don't know if the letters x-ray change, when the light switch they change, or just one you see something else. The, order, the whole layout changes. So the delay, so the, position of, the whole behavior of the keyboard changes, but the. but yeah, just the, layout of the keys. So that would be completely different and you would, you just adjust to it. And if the light is on, I know that the way I'm going to use this keyboard is completely different. I'm gonna type in completely different layout. or you just, you can just change languages. You're typing in a different language.

Yeah. Yeah. That seems like a version of, predicting different features based on which stage in the behavioral sequence we're in.

Yeah. In terms of the, like hierarchy and predicting optic morphology and stuff, maybe we don't want to go down this route, but if you, let's say, represent a stapler as a compositional object with the upper arm and the bottom arm and the totality of the behavior of the upper arm is that it can rotate and move through space. But it cannot like, deform within that object. Then in some sense, that makes it easier because it's like the relative positions of objects does not change. It's just like the whole thing can move through space and reoriented space. And then that's like a changing, that's a, state that gets passed up to a higher level region, which then might model the, kind of actual, the, motion of that relative to the bottom one. And then, yeah, I don't know, something. And then if you have the child object, that can tell you what, given an orientation of that stapler arm, like we can see where, yeah, if that makes sense. But yeah, it, also feels like it would be constraining because. We, don't wanna have to break everything up into children and parents. And if we have a really complex object like a I know balloon that you can squeeze in any dimension and then it's how do you model that?

Yeah.

So what you're saying, yeah, definitely big. Yeah. Good. High level behavior can be decomposed into just a change of orientation if we just keep going all the, layers down. yeah. so that, like maybe the, yeah. but then I'm not sure actually that kind of works. 'cause in the, stapler object, there still has to be some sort of change.

like there has to be some change that's more than just the orientation and the position of the whole object. So I'm not sure it helps that much.

I, think it hints at it still feels like the solution to this, like predicting what morphology has something to do with associating locations between models. And it's like the more complex the behavior, the more you have to learn these associations to be able to predict what feature you would see. But if it's like a simple behavior, you can fairly easy, easily map on what you would expect to see after the behavior has happened in terms of the features at locations.

Yeah.

but yeah. Yeah, definitely a big topic to think more about. Yeah.

yeah, I guess I'll move on to the next question for now, just so we can go through them all. So yeah, this one is, so basically, movement within that behavior reference frames, path integratable. Like you can observe a behavior at different locations and it doesn't matter in which order you go through them. And this is like a reference frame, like we have the reference frame for the object, but we also have this sequence of states basically, or like sequence of changes. So the question is whether that is somehow path integratable or it's really just a sequence and you'll have to learn different sequences, for more complex things like a joystick, like for example the behavior of a joystick. Do you have to learn a bunch of different sequences of how you can move that joystick back and forth, or do you, can you learn like a more general space of how you can move through that? Like state space of the, joystick. yeah. And maybe those aren't, mutually exclusive in the sense that if you, can represent something as a composition of small sequences, that is basically a path to degradable space. as in if you are in, if you've learned an edge that like, oh, if I move the joystick up, it's gonna be like this. That was a sequence at the time you learned it. Just that simple transition. But if you're able to chain that together with another one and another one, you can probably do path integration. what we wanna avoid though, is you have to learn oh, I do, right? Two times up, five times left, two times, blah, blah, blah. that's one sequence. And then that's separately represented from a totally different sequence.

yeah. But yeah, so, they may not be as separate as.

Yeah. I like that's a, yeah, that's a good point that these sequences might, you might be able to combine them to, Hey Jeff. Hi there. I'm so sorry. I got told something this morning at the last second and I didn't forgot to tell everyone. I was like, anyway, sorry to join. No worries. So late. Sorry to join you so late. I can't tell if you guys can see me or not. yeah, we can see. All right. I'm just standing outside on my phone.

Keep on. Yeah, no worries. Yeah, we just had to, High level discussion, with some kind of neuroscience and different things. And then now we're just going through the existing open questions, okay. And doing a bit of discussion, but with the idea that it's just revisiting them so we can think more about them. All right. just keep going on and I'll join in. Okay. But yeah, actually the, we already, we went through the main questions around object behavior models. The remaining ones are a bit more longer term questions around like actions and goals, and a bit more about the representations and anatomy. But I think now that you hear it may be worth revisiting a couple of the topics we talked about. Oh, sorry. No, no, worries. but Niels had a pretty interesting proposal, so maybe Niels, if you wanna, is this the one, the layer five, behavior thing?

yeah, I, I, I was. I was not on the call doing something else. I actually wrote a response to that. Okay. okay, cool. I, wrote a lengthy response to it 'cause I was thinking about it.

I just had to meet this contractor person right away. anyway, so I, apologize. yeah, so I thought it was a, really interesting idea and, you'll see that I posted a really, a lengthy response to it.

yeah, there's a lot to, there's a lot to like about it. yeah. and I think we've often talked about, and like going back that L five would be where behavior would be represented because of Right. the motor out projections and stuff. But I dunno if maybe just over the hackathon, because we were so focused on the space being path integrable. It naturally what it would mean L six. But anyways, what it would mean is that in my mind, for the two reference frames, the morphology reference frame and the behavior reference frame, they would likely or almost certainly share mini column definitions in the sense that the, I'm always, I'm continuing to work on the idea that minicolumns are the basis of grid cells and that the cells in the new column all representing movement in the similar direction. And so you would want both the ha referencing and the morphology referencing to be updated simultaneously by the same movement vectors. And so in some sense, if we say layer five B is the minicolumns, there are the reference banks for the morphology model. the behavior model and layer six A are the, minicolumns are the reference banks or the, morphology model and the behavior model. I said that wrong. I'm sorry. They, would share, you would see the same. And so what, basically the difference is both those layer five B and layer six A would be updated simultaneously, but they just anchor separately, right. So you can imagine the input to the column goes between layer five. It's always, they always say between layer five and layer six. So you can imagine it goes in there and then it projects upward, and downward at the same time. 'cause it defines the same minicolumns, but they just get anchored separately. and then also, and then layer five B also we know has long range connections. So that would be voting on, behaviors. so that all makes a lot of sense. wouldn't it technically still be, different movement vectors for the two? If, for example, the behavior model is recognized in a different orientation than the object model, they are transformed in different ways in the thalamus since it's in the objects reference frame. At this point, I guess that's a possibility we discussed. I don't know if we know that there's enough down projections for that or Interesting. Like from, it would yeah, be nice. Nice if it has that flexibility. Interesting.

interesting. in some ways it fits with the, alignment of the behavior with the morphology that like you can't apply or you probably can't apply like a behavior to an arbitrary morphology if there's no way that they align. In some ways the orientation also has to be aligned in order for them to match. does it, as in like the hinge has to be aligned with, I could have a ver a hinged vertical on a, on an object and hinge a horizontal on an object, in one case. Yeah. But so in that case, aren't both the morphology that is doing the hinge behavior and the behavior itself oriented together. But you might have learned a stapler model and the hinge behavior on the stapler model in this orientation. But then you see a hinging, like a door in this orientation. You're not recognizing the stapler, you're recognizing the door. I guess what I'm saying is the morphology of the hinge on the door is also oriented. if it was a stapler, it would be oriented the same way, the behavior, it would be rotated. But I don't, I'm missing that news. You might be right, but I'm missing it. It seems to me like, let's say I have a a, light switch it old, classic old light switch with a little thing you flip up and down. now I mount that on, another object where it's horizontal. Okay.

the, so both the morphology and the behavior are rotated in that case, right? No, but the object that it's on is, I. I have two objects. It's on, I have a, little, I don't know, some toy whatever, and one toy has a switch horizontally and one toy has a switch vertically. wouldn't they require two different, so the behavior to turn on the switch would be different. It would be, I may, you might be right Neil. I'm just, it's not obvious. Yeah. I guess it, in that case, it feels like it's like a child object or whatever, like the switch, if that's represented as like an, object, then that, that can be oriented in different ways in space. that's true if it's a child object. but we can't say all behaviors are on child object because they have to exist in every column.

yeah. I, thought the nice thing about this proposal is you can recognize behaviors on a bunch of different locations and a bunch of different orientation and different scale on different objects. So it seems like that would require. Here's an idea behavior model to send separate hypotheses down to a thalamus to rotate into its, reference frame. Here's an idea.

let's assume what if they, what if there were two separate orientations? And, what's, what strikes me there is that one of the funny things about the, thalamus is it seems like these, layers in the thalamus come in pairs, this is a really half-baked idea, right? So don't, hold me to it. But I, think that's also what Viviane that's what you've been suggesting, right? That there was two different, movements. Yeah, exactly. Yeah. So this is what I drew here, that the two have the two different orientations that are recognized and they're projected to the th and they separately rotate the incoming movement that goes into, oh, I haven't seen this figure. This is a new one.

yeah, it's the complex version of the, oh, I but you, cleaned it up. oh, maybe I did see this. I can, yeah. Oh, I don't remember there being two different orientations. Yeah. That, was only in the complex version of it. Okay. Yeah. Oh, no, it's actually the two different orientations actually in this one as well. That yeah, those two supposed to be different here. but there's nothing indicating of the different there, right? Is it? Oh, I see. Oh, the little, oh, I didn't really pay attention to those.

but this more than that, it, basically, yeah, that says it, but it doesn't say what the mechanism is. I guess I didn't follow through on it. this would be, this would basically be saying it's two separate columns. if I had a two hierarchically arranged columns, they have different orientations and, a child orientation versus the parent orientation. And in this case we're saying that the behavioral model and the, and morphology model have, might have two different orientations.

and then you'd have to have two sort projections back to, to the Falmouth and the Thout would've to do two different transformations unless Niels is right. And I don't understand this guy understand his point. But no, I'm down to that. I was just thinking yeah, whether it's, necessary, but, it seems like it is, but I could be wrong. Hope. it's an extra complexity. We don't really love to have complexity but necessary, but I feel like that maybe simplifies the, idea of having one of them in layer five B that we don't, we don't have to assume that they get exactly the same movement in I'm okay. How are you? I think they have to be updated the same, don't they? Yeah. the, that goes into the salam is the same, but then it gets rotated in different, into their respective reference frames. Oh, I see. And for what it's worth, these could be separate out in time if needs be. Like, I don't know, even if there's, yeah. nothing is, they not only, they have different orientations, they can have different scales, right? it's an issue we've never really dealt with, but has to be dealt with something. yeah, so that would, I think given you're arguing and maybe convincingly so that, that these things really aren't tied together. Like I suggested that they're they have to be, they have to be driven from the same basic movement vector, as you say, going into the thalamus. But after that, they, have to get translated separately. movement in the behavior frame versus movement in the morphology frame, different orientations in different scales. anyway, that would then I said to myself, how's the Theos gonna do both of those things? And then I said, oh look, the thout comes in these layers and there seems to be two of every type.

So, maybe that's, explain wondering why wouldn't there be two layers of every type, what's the point of that?

and even the ones that are left and right eye, I believe there's two left, and two right eyes.

so anyway, that could explain why you have multiple layers in the thumb. Yeah. And actually the scale example, I think you've convinced me 'cause I that one you, we definitely need to, change it. So you're right. No, I think that makes sense. This, requires a bunch of other stuff too. We mean that the projections to the thalmus have to come from different places. There has to be two orientation projections to the thalmus. One goes to one layer, one goes to the other layer. that, that's not outta the question, it's just not something I know about. But maybe someone has observed that.

yeah. And then I guess on this kind of revisiting the micro circuit, Rami brought up the interesting point that if you actually look at a lot of the literature on the mag cellular input and the movement input. It tends to be, there's L four C, at least in V one, this kinda lower, part of L four, whereas we've often shown it and coming in as the border between L three and L four. I was just wondering, do you remember, was that kind of an indirect, because Yeah, if you look at the responsiveness of cells, i, v one is unique to primates. Yeah. And, and I have zero theory about what those extra layer four cells are doing. Yeah. So when you look at the, they're saying it comes in, first of all, there's three projections that come, they're typically not broken out as Magnus out or the par cell. Maybe the people know that. I don't know that. But there's the one that's like the typical see lower layer three, layer four in the border between layer five and layer six. That's what they say. I the, who knows, but that is typically, I imagine would be non primates and not, or not visioned. That could be whiskers, that could be, rat being cat, vision. so when it comes to the striate, therefore I have no idea what's going on. I've never heard a cohesive theory at all about what the hell's happening. And I've tried to, and I haven't thought about it myself. So, I don't know that impacts what you just said, but I just try to avoid that. Yeah. what the hell's going on and no one knows.

yeah. okay. Yeah. And by the way, some people have argued that the labeling of those striate layer four is incorrect. That they say, oh, do people say these multiple layer fours? That's not right. Some of 'em should be considered, not layer four, they're more like, layer three or something. I dunno, multiple layer three. So I heard that once argument made once. Okay. Dunno. Actually, I was just looking, I think there's this figure from Thompson at all is, this was Alex Thompson. This, is that like L six? Yeah. huge. Yeah. Paper. I dunno if maybe this was partly where the, some of this comes from, look interest because this seems to suggest, they, first of mores Yeah. They, the magnet size should drive the, in my mind it should drive lower and upper. Yeah. but, with different receptive, field size. It's, driving the, overall movement of the sensorimotor in layer six. And it's driving, and it's the, detecting the, movement of the object in layer three.

And, of course these don't show that Again, this is the striate layer for it. So all bets are off now, as to what these really are, it's hard to say. I wish, but I mean it's it's interesting 'cause this even seems to suggest that you get the harvest cellular input into Yeah, it does say that. plastic six as well, it could be, it seems they there's almost overlap in where they all project except for this slight breakdown look more into, there's so much stuff here. It just, sometimes it's mind boggling, right? I don't know what to make of that, and sometimes you have to look at the real details, are they just, are they following axons? Are they, could these be projecting to inhibitory cells? Are they. there's just a ton of stuff, that's unknown and there's multiple cell populations in each layer, and so which are they protecting to the same cell? I, just, it's crazy. I, put in my little note, I always feel more comfortable when we deduce the function must exist. Then when we propose where it exists, the where it exists is it's, half, it's guesswork based on guesswork, and you hope it's right, but, sometimes you find that the data you're working on is all screwy and it's hard to know. But, we can deduce logically that certain functions have to happen and therefore there must be a cell population that does it.

excuse not under.

It was interesting that Thompson image too, she didn't make any distinction between the two layers and the fal. The only saw the projections coming.

That was an interesting idea that, that might come out of this. there might be somebody who's got some evidence that this difference is between those two layers, that they're not just equivalent duplicated, which is typically not, you don't typically see things like that in the, in nature. Just duplicate something.

and while we're on the open questions, I, put it in my little, I like to remind everyone that, we're think layer six A is the reference frame for morphology, but we have no explanation for why layer six eight projects back to the thalmus, because I don't remember one.

and that's a major projection.

what do, why does thalmus need to know where we are in an object? that's a, I mean it's essentially, yeah. 'cause here the projections, doesn't this kind of fit with okay, this back projection is the orientation of the object. This back projection is the orientation of the behavior. that could be, and both are, that's a good, so they're separately applied to the mag cellular, but, what they say is the same cell in layer six A will, will bifurcate like it's shown here and it'll send a projection to layer, four. And again, this is the screwy dry cortex. Like I'm not gonna pay too much attention to all the details, but the general rule is the layer six, a cell will, will project to layer four and it also projects to the thalamus in the same cell. So if it's orientation, that's great, but then, but we're using that as the location signal for, for the, Ology.

but isn't it just isn't it just a lo like it is just a location, it's just like an association almost? but what, if I'm saying I can send, I can see sending the orientation to the, I don't know why I would send the location to the Thomas. this is, could it be something to do with scale maybe that the grid cells are somehow, detecting scale and Right. I thought about that because what it is, it's a very unique representation, right? It's, basically representing a unique point on a unique option. so there in the world, there's a gazillion of these things and, and it's a high burden to expect the thalamus to be able to recognize them, right? It's like an SDR, which are many, variations in the world. And, So if that's correct, it's hard to imagine that the Fal, which is a pretty small object, is gonna be able to learn to recognize, do something unique, but every location. But on the other hand, if you just point out that scale is one of those things, you might vary on location, location by location, just like orientation is something you vary by location, location by location.

maybe that's the answer right there. Yeah, I think that's something we've talked about before. I'm just, I'm still thinking, I just thought, did we, I should I, I think your concern at the time was that yeah, like the sdr r kind of being too complex or something like that. It's, just, too much to ask. I can't remember. I can't expect a thalmus to remember, every location and every object and do something about it. it's just not possible. but.

I, it could be, the idea that it's, I'm confused right now, but the idea that, there are some locations which are important to note, where you might have a different scale or you might have something you a different scale or a different orientation you have to note at this location. We have to remember this. but it can't be every location because it's just, it seems like there's just too much, to ask the thal to learn.

there aren't that many cells in the Thal compared to the cortex.

anyway, I, haven't been too worried about it. I just threw it in there. So just as you, as we were talking about things we don't understand, in, voting between sensors, like two hands, thing, idea you proposed before, but, we're talking about the projections to the S right? Yeah. So I don't know how that would help. The sensorimotor would need to know, where the other sensorimotor is to be able to Oh, that thing. Yeah. But I don't, I, I have trouble imagining that's happening in the Thalmus.

that to me would be, it just, it could, that has to occur someplace, but it, I have trouble imagining it being the thal.

it's not, it's that's a big open question, Robin. as to how it is that we know the relative locations of objects and, anyway. Yeah.

Yeah. Oh, good stopping. So I, just, we've had lots of good questions to think about. I, posted some text on the, that document just a little while ago. And, you, now that I, we've had this conversation, I'd like to retract some of the idea that I, argue that the two minicolumns in layers six, the two morphology and the behavioral model should be the same. And Viviane convinced me that's not true. So just I should retract that.

okay.

anyway, okay. If we're done,