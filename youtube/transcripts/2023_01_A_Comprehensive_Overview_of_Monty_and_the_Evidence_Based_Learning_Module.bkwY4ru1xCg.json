[
    {
        "text": "All right, can you guys see\nmy slide on the laser pointer?",
        "start": 9.284,
        "duration": 3.22
    },
    {
        "text": "Yes, yep.",
        "start": 12.934,
        "duration": 0.74
    },
    {
        "text": "All right, perfect.",
        "start": 14.884,
        "duration": 0.9
    },
    {
        "text": "Okay, yeah, so I'm going to try and\nexplain the evidence based learning",
        "start": 16.634,
        "duration": 4.45
    },
    {
        "text": "module in a bit more detail and hopefully\ngive you a bit of a better understanding",
        "start": 21.094,
        "duration": 6.71
    },
    {
        "text": "what it does and also how it works\nwithin the whole Monty framework.",
        "start": 28.294,
        "duration": 3.69
    },
    {
        "text": "Let me see.",
        "start": 32.154,
        "duration": 3.33
    },
    {
        "text": "Yeah.",
        "start": 35.964,
        "duration": 0.27
    },
    {
        "text": "I've felt like this for a long time\ntrying to explain it and I spend a",
        "start": 36.894,
        "duration": 4.53
    },
    {
        "text": "lot of time thinking about how to best\nexplain, how everything works and fits",
        "start": 41.424,
        "duration": 5.32
    },
    {
        "text": "together and how everything is connected.",
        "start": 46.744,
        "duration": 2.43
    },
    {
        "text": "And I hope I, Got it halfway\nunderstandable by now, but yeah, feel",
        "start": 49.914,
        "duration": 7.715
    },
    {
        "text": "free to interrupt and ask questions\nand also let me know if there may",
        "start": 57.629,
        "duration": 4.92
    },
    {
        "text": "be better ways to explain things.",
        "start": 62.549,
        "duration": 1.67
    },
    {
        "text": "but yeah, let's go ahead.",
        "start": 65.979,
        "duration": 1.36
    },
    {
        "text": "So I'll start with the\ngeneral framework first.",
        "start": 68.039,
        "duration": 2.81
    },
    {
        "text": "It's not specific to the\nlearning module, but.",
        "start": 70.989,
        "duration": 2.61
    },
    {
        "text": "yeah, first since, Jeff doesn't\nreally know the framework yet, and",
        "start": 74.954,
        "duration": 3.99
    },
    {
        "text": "also just as a short refresher.",
        "start": 78.944,
        "duration": 1.73
    },
    {
        "text": "yeah, we basically test object\nrecognition at the moment, object",
        "start": 84.754,
        "duration": 4.5
    },
    {
        "text": "and pose recognition, and we test\nthis on the YCB dataset, which are 77",
        "start": 89.254,
        "duration": 4.38
    },
    {
        "text": "different objects, and we test in test\nthese objects in different rotations",
        "start": 93.654,
        "duration": 6.685
    },
    {
        "text": "and locations in the environment.",
        "start": 101.099,
        "duration": 2.03
    },
    {
        "text": "and the objects are basically floating in\nempty space and there's only one object.",
        "start": 104.819,
        "duration": 6.77
    },
    {
        "text": "So we have the object in Habitat\nin an empty space and we have a",
        "start": 113.069,
        "duration": 4.41
    },
    {
        "text": "sensor patch which always only\nperceives a small part of the object.",
        "start": 117.479,
        "duration": 4.08
    },
    {
        "text": "usually it's a RGBD camera and then\nfrom this little patch we can extract,",
        "start": 123.599,
        "duration": 6.52
    },
    {
        "text": "three dimensional patch, which\nare XYZ coordinates of where each",
        "start": 133.859,
        "duration": 7.2
    },
    {
        "text": "pixel in the patch would be in\nspace using the depth image and the",
        "start": 141.089,
        "duration": 5.02
    },
    {
        "text": "location of the agent and sensor.",
        "start": 146.109,
        "duration": 1.82
    },
    {
        "text": "And then from this patch,\nwe can extract a pose.",
        "start": 149.359,
        "duration": 3.81
    },
    {
        "text": "So a location in space and a, an\norientation, and the orientation",
        "start": 153.399,
        "duration": 5.91
    },
    {
        "text": "is defined by the point normal.",
        "start": 159.309,
        "duration": 2.04
    },
    {
        "text": "that's a vector that points out of\nthe surface, basically, and the first",
        "start": 162.154,
        "duration": 4.61
    },
    {
        "text": "curvature direction, which, in this\ncase, for example, would point to the",
        "start": 166.764,
        "duration": 5.34
    },
    {
        "text": "side of the cup, and then the second\ncurvature direction would point upwards.",
        "start": 172.214,
        "duration": 3.34
    },
    {
        "text": "So the largest and, direction of the\nlargest and smallest curvature, and then",
        "start": 175.674,
        "duration": 5.82
    },
    {
        "text": "we can also extract pose independent\nfeatures, so features that don't",
        "start": 181.884,
        "duration": 4.3
    },
    {
        "text": "change if the object rotates or moves.",
        "start": 186.184,
        "duration": 2.97
    },
    {
        "text": "For example, color at a location\nor the magnitude of the curvature.",
        "start": 189.819,
        "duration": 4.91
    },
    {
        "text": "And this is the general format.",
        "start": 198.139,
        "duration": 2.19
    },
    {
        "text": "Everything inside of Monty\nhappens in this format poses, with",
        "start": 200.439,
        "duration": 5.03
    },
    {
        "text": "features or features at poses.",
        "start": 205.469,
        "duration": 2.2
    },
    {
        "text": "we currently have two different\ntypes of action spaces.",
        "start": 210.784,
        "duration": 2.88
    },
    {
        "text": "One is the vision action space, where we\nhave the agent fixed in one location, and",
        "start": 213.924,
        "duration": 6.12
    },
    {
        "text": "it can tilt up, down, left, and right.",
        "start": 220.044,
        "duration": 1.84
    },
    {
        "text": "And the second one is the touch\naction space, where the agent",
        "start": 222.364,
        "duration": 5.01
    },
    {
        "text": "moves close to the surface, always\nperpendicular to the surface, and it",
        "start": 227.514,
        "duration": 4.86
    },
    {
        "text": "can move around the entire object.",
        "start": 232.374,
        "duration": 1.68
    },
    {
        "text": "And just to visualize, so this is how\nthe vision action would look like.",
        "start": 234.819,
        "duration": 3.99
    },
    {
        "text": "So we just tilt, we never see the\nobject from the other side, but",
        "start": 238.809,
        "duration": 3.91
    },
    {
        "text": "we see it from one viewpoint and\nwe can, yeah, explore it here.",
        "start": 242.719,
        "duration": 4.39
    },
    {
        "text": "This is the viewfinder\njust for visualization.",
        "start": 247.109,
        "duration": 2.11
    },
    {
        "text": "And then this is the patch.",
        "start": 249.219,
        "duration": 1.18
    },
    {
        "text": "That would get sent to the learning\nmodule or the sensor module as well.",
        "start": 251.029,
        "duration": 4.27
    },
    {
        "text": "And then this is how the\ntouch agent would look.",
        "start": 256.219,
        "duration": 2.37
    },
    {
        "text": "It basically can move\naround the entire object.",
        "start": 259.049,
        "duration": 2.77
    },
    {
        "text": "It moves a little slower because it\nwants to stay, on the surface of the",
        "start": 262.709,
        "duration": 4.91
    },
    {
        "text": "object and not fall off the object.",
        "start": 267.619,
        "duration": 2.17
    },
    {
        "text": "But yeah, it looks like the object\nis rotating, but it's just the",
        "start": 270.719,
        "duration": 4.98
    },
    {
        "text": "sensor moving around the object.",
        "start": 275.739,
        "duration": 1.81
    },
    {
        "text": "Okay.",
        "start": 282.389,
        "duration": 0.33
    },
    {
        "text": "So then there's the distinction\nbetween agent and sensors.",
        "start": 282.729,
        "duration": 3.09
    },
    {
        "text": "An agent is basically whatever moves in\nthe environment and whatever, the policy",
        "start": 287.424,
        "duration": 6.92
    },
    {
        "text": "use it, what the agent uses, the policy\nthat we define to move in the environment.",
        "start": 295.084,
        "duration": 4.6
    },
    {
        "text": "And then we can have a variable\nnumber of sensors attached to",
        "start": 300.214,
        "duration": 4.12
    },
    {
        "text": "an agent and all the sensors\nattached to an agent move together.",
        "start": 304.334,
        "duration": 4.2
    },
    {
        "text": "So for example, like.",
        "start": 308.584,
        "duration": 1.08
    },
    {
        "text": "patches of skin on a finger would be\nmultiple sensors attached to one agent,",
        "start": 310.579,
        "duration": 4.61
    },
    {
        "text": "or patches on the retina would be, yeah,\nmultiple sensors attached to one agent.",
        "start": 315.209,
        "duration": 6.95
    },
    {
        "text": "And then we can have different policies.",
        "start": 324.459,
        "duration": 2.49
    },
    {
        "text": "So we can have a completely random\npolicy, like this orange one that",
        "start": 327.319,
        "duration": 4.64
    },
    {
        "text": "just randomly moves along the object.",
        "start": 331.959,
        "duration": 2.8
    },
    {
        "text": "Then we can have bottom up policies.",
        "start": 335.269,
        "duration": 2.24
    },
    {
        "text": "That means we use the sensed\nfeatures to decide the next action.",
        "start": 337.909,
        "duration": 4.25
    },
    {
        "text": "So here we use the sensed curvature\ndirections, and we just follow",
        "start": 342.469,
        "duration": 4.19
    },
    {
        "text": "these curvature directions and\nswitch at some points, and then we",
        "start": 346.659,
        "duration": 4.69
    },
    {
        "text": "can have top down policies, which\nmeans we use the models that we have",
        "start": 351.349,
        "duration": 5.09
    },
    {
        "text": "learned to decide the next action.",
        "start": 356.439,
        "duration": 2.02
    },
    {
        "text": "Typically the learning module\nsuggests a motor command.",
        "start": 359.059,
        "duration": 2.7
    },
    {
        "text": "And then that gets executed by the agent.",
        "start": 362.254,
        "duration": 3.12
    },
    {
        "text": "So that would be the green line we move.",
        "start": 365.384,
        "duration": 2.54
    },
    {
        "text": "And then the learning model could\nsuggest to move to the handle.",
        "start": 367.974,
        "duration": 3.14
    },
    {
        "text": "And then we keep moving there.",
        "start": 371.854,
        "duration": 1.62
    },
    {
        "text": "Hey Vivian, quick question\nwith the previous slide.",
        "start": 375.844,
        "duration": 2.24
    },
    {
        "text": "you said an agent can have multiple\nsensors associated with it.",
        "start": 380.744,
        "duration": 3.04
    },
    {
        "text": "and in, have we ever used\nthat in any such scenario?",
        "start": 385.004,
        "duration": 4.29
    },
    {
        "text": "Or is it always one sensor\nper agent right now?",
        "start": 389.314,
        "duration": 2.58
    },
    {
        "text": "for example, all of the voting experiments\nuse, one agent and multiple sensors.",
        "start": 393.314,
        "duration": 5.65
    },
    {
        "text": "okay, got it.",
        "start": 400.454,
        "duration": 0.68
    },
    {
        "text": "So yeah, I will show some examples\nlater where we use one agent and",
        "start": 403.644,
        "duration": 4.52
    },
    {
        "text": "five sensor patches, for example.",
        "start": 408.774,
        "duration": 1.915
    },
    {
        "text": "Okay, so in that case, the voting\nmodule uses sensors that are",
        "start": 411.629,
        "duration": 3.24
    },
    {
        "text": "near, very close to one another.",
        "start": 415.059,
        "duration": 3.28
    },
    {
        "text": "It's not using patches that are quite very\ndifferent in very different locations.",
        "start": 418.599,
        "duration": 4.53
    },
    {
        "text": "Yeah, exactly.",
        "start": 423.839,
        "duration": 0.83
    },
    {
        "text": "Okay, so that's actually impressive that\nthe voting works as well as it does.",
        "start": 425.164,
        "duration": 4.06
    },
    {
        "text": "You would expect to get a lot\nmore disambiguating information",
        "start": 430.024,
        "duration": 3.94
    },
    {
        "text": "if they're further away than if\nthey're right next to one another.",
        "start": 433.964,
        "duration": 2.87
    },
    {
        "text": "yeah, I mean they're not like,\nmillimeters next to each other.",
        "start": 444.334,
        "duration": 3.92
    },
    {
        "text": "They can still cover",
        "start": 448.254,
        "duration": 1.18
    },
    {
        "text": "further away parts of the object depending\non the perspective, but Yeah, we haven't",
        "start": 452.144,
        "duration": 7.21
    },
    {
        "text": "really tested yet with multiple agents\nthat completely independently move around",
        "start": 459.364,
        "duration": 4.58
    },
    {
        "text": "the object and can see like opposite\nsides of the object at the same time.",
        "start": 463.964,
        "duration": 4.25
    },
    {
        "text": "Were you about to say something, Jeff?",
        "start": 474.294,
        "duration": 1.33
    },
    {
        "text": "No.",
        "start": 476.914,
        "duration": 0.35
    },
    {
        "text": "Okay.",
        "start": 479.594,
        "duration": 0.35
    },
    {
        "text": "All right.",
        "start": 481.024,
        "duration": 0.34
    },
    {
        "text": "I'll go on then.",
        "start": 482.524,
        "duration": 0.87
    },
    {
        "text": "we have to discretize,\ndiscretize time in a way.",
        "start": 486.554,
        "duration": 3.81
    },
    {
        "text": "So there are three ways\nin which we do that.",
        "start": 490.684,
        "duration": 2.05
    },
    {
        "text": "First is steps.",
        "start": 493.184,
        "duration": 0.96
    },
    {
        "text": "That's the smallest interval.",
        "start": 495.014,
        "duration": 1.51
    },
    {
        "text": "So a step is taking one\naction and observing a new",
        "start": 496.664,
        "duration": 5.17
    },
    {
        "text": "observation in the environment.",
        "start": 501.914,
        "duration": 1.71
    },
    {
        "text": "then the second one is the episode.",
        "start": 505.784,
        "duration": 1.94
    },
    {
        "text": "So we can take a variable number\nof steps until an episode ends.",
        "start": 508.444,
        "duration": 5.02
    },
    {
        "text": "that happens, for example,\nwhen we recognize the object.",
        "start": 515.454,
        "duration": 2.54
    },
    {
        "text": "And then when the episode ends, we\ninitialize the environment new, we",
        "start": 519.074,
        "duration": 5.32
    },
    {
        "text": "reset all the hypotheses in the learning\nmodule and we show a different object.",
        "start": 524.404,
        "duration": 6.45
    },
    {
        "text": "And then the last one is the epoch.",
        "start": 532.184,
        "duration": 2.26
    },
    {
        "text": "basically this happens once we cycle\nthrough all of the objects, a new",
        "start": 536.564,
        "duration": 4.41
    },
    {
        "text": "epoch starts, and we then start\nagain with the first object, and then",
        "start": 541.044,
        "duration": 3.27
    },
    {
        "text": "usually we show it in a new rotation.",
        "start": 544.324,
        "duration": 1.96
    },
    {
        "text": "that's yeah, the testing\nset up at the moment.",
        "start": 548.304,
        "duration": 2.67
    },
    {
        "text": "And then.",
        "start": 554.214,
        "duration": 0.36
    },
    {
        "text": "Yeah, the whole system is\ndesigned to work, from scratch.",
        "start": 555.449,
        "duration": 6.53
    },
    {
        "text": "So it is designed to be able\nto learn starting with no",
        "start": 561.979,
        "duration": 4.19
    },
    {
        "text": "knowledge about the world.",
        "start": 566.169,
        "duration": 1.14
    },
    {
        "text": "So nothing is in memory yet.",
        "start": 567.309,
        "duration": 1.4
    },
    {
        "text": "The sensor moves on the object.",
        "start": 569.429,
        "duration": 1.49
    },
    {
        "text": "It recognizes, I don't know this object.",
        "start": 570.919,
        "duration": 2.95
    },
    {
        "text": "And then it starts exploring and collect\nsome information about this object",
        "start": 573.959,
        "duration": 3.53
    },
    {
        "text": "and then builds a graph out of these\nobservations and stores it in memory.",
        "start": 578.249,
        "duration": 3.9
    },
    {
        "text": "And then when we have a new episode,\nthe sensor moves again on the object.",
        "start": 582.899,
        "duration": 5.34
    },
    {
        "text": "it might recognize the object as this\ngraph that it previously built and",
        "start": 588.849,
        "duration": 6.43
    },
    {
        "text": "saved, and then it can again explore\nthe object further to collect some",
        "start": 595.279,
        "duration": 4.65
    },
    {
        "text": "more observations about it, and then\nuse all of these new observations",
        "start": 599.939,
        "duration": 3.68
    },
    {
        "text": "to update the graph in memory.",
        "start": 603.959,
        "duration": 1.67
    },
    {
        "text": "And this way it can gradually\nlearn complete graphs of objects,",
        "start": 605.999,
        "duration": 5.04
    },
    {
        "text": "complete models of objects.",
        "start": 613.579,
        "duration": 1.33
    },
    {
        "text": "And it can, or should ideally even\nbe able to do this without labels.",
        "start": 615.959,
        "duration": 5.72
    },
    {
        "text": "at the moment we usually do supervised\npre training where we provide",
        "start": 622.579,
        "duration": 3.78
    },
    {
        "text": "labels to learn a complete model.",
        "start": 626.359,
        "duration": 2.15
    },
    {
        "text": "And then we load these models into memory\nat the beginning of every experiment.",
        "start": 628.549,
        "duration": 5.65
    },
    {
        "text": "just so we don't have to run this\nfrom scratch and we can make sure",
        "start": 634.729,
        "duration": 3.08
    },
    {
        "text": "that these models are complete.",
        "start": 637.809,
        "duration": 1.48
    },
    {
        "text": "I",
        "start": 639.299,
        "duration": 0.01
    },
    {
        "text": "really like these slides.",
        "start": 641.809,
        "duration": 1.12
    },
    {
        "text": "The way you've done the\nslides are very clear.",
        "start": 642.929,
        "duration": 1.66
    },
    {
        "text": "Cool.",
        "start": 645.954,
        "duration": 0.36
    },
    {
        "text": "Thanks.",
        "start": 646.314,
        "duration": 0.42
    },
    {
        "text": "Yeah, I was trying to think about how\nto explain these things, in a good way.",
        "start": 647.774,
        "duration": 3.9
    },
    {
        "text": "Yeah, they're very nice.",
        "start": 652.864,
        "duration": 1.2
    },
    {
        "text": "I have a question.",
        "start": 654.624,
        "duration": 0.69
    },
    {
        "text": "Yeah.",
        "start": 655.314,
        "duration": 0.06
    },
    {
        "text": "So there's a difficult period when\nyou're, when you're confronted with an",
        "start": 655.864,
        "duration": 5.1
    },
    {
        "text": "unknown object and you have to decide\nwhether you're learning a new object",
        "start": 660.964,
        "duration": 2.85
    },
    {
        "text": "or you're updating an existing one.",
        "start": 663.874,
        "duration": 2.37
    },
    {
        "text": "yeah.",
        "start": 667.474,
        "duration": 0.27
    },
    {
        "text": "how do you handle that?",
        "start": 668.164,
        "duration": 0.99
    },
    {
        "text": "Yeah, so basically every,\nepisode has two phases.",
        "start": 672.239,
        "duration": 4.87
    },
    {
        "text": "One is matching and the\nsecond one is exploration.",
        "start": 677.119,
        "duration": 2.54
    },
    {
        "text": "And if during the matching phase,",
        "start": 679.659,
        "duration": 2.94
    },
    {
        "text": "none of the models and memory match the\nobservations, then we create a new graph.",
        "start": 684.699,
        "duration": 5.23
    },
    {
        "text": "And if during the matching\nphase, we recognize the object.",
        "start": 690.989,
        "duration": 3.58
    },
    {
        "text": "So we do match it to a graph\nthat we have stored in memory.",
        "start": 694.569,
        "duration": 3.0
    },
    {
        "text": "Then we extend the graph\nwith the new observations.",
        "start": 698.159,
        "duration": 2.97
    },
    {
        "text": "of course it can happen, for example,\nif in the second episode I would have",
        "start": 702.609,
        "duration": 3.4
    },
    {
        "text": "started like somewhere on the bottom\nof the cup or something that's not",
        "start": 706.019,
        "duration": 3.34
    },
    {
        "text": "in my graph yet, then I would create\na new graph for this object, even",
        "start": 709.389,
        "duration": 4.15
    },
    {
        "text": "though it should be the same graph.",
        "start": 713.539,
        "duration": 1.53
    },
    {
        "text": "But it's just because I've seen a\ncompletely different side of the cup",
        "start": 715.479,
        "duration": 3.63
    },
    {
        "text": "that I don't have in my model yet.",
        "start": 719.109,
        "duration": 1.79
    },
    {
        "text": "So there, in the future, we\ncould do some kind of graph",
        "start": 721.649,
        "duration": 2.99
    },
    {
        "text": "consolidation later on or something.",
        "start": 724.669,
        "duration": 2.11
    },
    {
        "text": "But, Yeah, this is how it is right now.",
        "start": 726.779,
        "duration": 3.545
    },
    {
        "text": "Or you could extend the exploration\nphase to actually, try and make sure",
        "start": 730.704,
        "duration": 3.82
    },
    {
        "text": "you explore the entire object when you\nbuild the graph in the first place.",
        "start": 734.524,
        "duration": 3.48
    },
    {
        "text": "Yeah, no, I think it's a good approach.",
        "start": 738.534,
        "duration": 1.36
    },
    {
        "text": "And this was something we dealt with on\nsequence memory, and it was very tricky.",
        "start": 739.924,
        "duration": 4.61
    },
    {
        "text": "and so I think it's very practical the\nway you're going about it, dividing",
        "start": 745.784,
        "duration": 4.02
    },
    {
        "text": "it into two, like an exploration\ninference and a learning phase.",
        "start": 749.904,
        "duration": 3.83
    },
    {
        "text": "yeah.",
        "start": 756.874,
        "duration": 0.25
    },
    {
        "text": "theoretically during exploration, you\ncould also try to match, but we just",
        "start": 757.884,
        "duration": 4.25
    },
    {
        "text": "leave this out to save computational time\nand just collect a lot of observations",
        "start": 763.464,
        "duration": 5.28
    },
    {
        "text": "to be able to build a good graph.",
        "start": 769.334,
        "duration": 2.2
    },
    {
        "text": "okay.",
        "start": 776.824,
        "duration": 0.34
    },
    {
        "text": "So yeah, this is the supervised learning.",
        "start": 777.164,
        "duration": 2.11
    },
    {
        "text": "So that's what we use at the moment.",
        "start": 779.274,
        "duration": 1.59
    },
    {
        "text": "Most of the time we basically present\nthe object in a bunch of different",
        "start": 780.894,
        "duration": 4.1
    },
    {
        "text": "orientations and we tell the model\nwhat is the object ID and pose, and",
        "start": 785.004,
        "duration": 5.5
    },
    {
        "text": "then it can learn a very complete\nand perfect graph of the object.",
        "start": 790.504,
        "duration": 3.7
    },
    {
        "text": "Which is, yeah, a bit of an aid\nthat we're using right now, but we",
        "start": 797.034,
        "duration": 3.55
    },
    {
        "text": "do also run some experiments with\nlearning from scratch to test it.",
        "start": 800.584,
        "duration": 4.3
    },
    {
        "text": "Okay.",
        "start": 807.104,
        "duration": 0.3
    },
    {
        "text": "So now the Monty model\non a very abstract level.",
        "start": 807.404,
        "duration": 4.06
    },
    {
        "text": "So we basically have an environment\nand we have agents with sensors",
        "start": 812.144,
        "duration": 4.06
    },
    {
        "text": "that perceive this environment.",
        "start": 816.254,
        "duration": 1.88
    },
    {
        "text": "And every sensor patch, since it's raw\nsensory information to a sensor module,",
        "start": 818.884,
        "duration": 5.72
    },
    {
        "text": "the sensor module.",
        "start": 827.124,
        "duration": 1.13
    },
    {
        "text": "Turns this raw sensory information\ninto the common communication protocol.",
        "start": 828.849,
        "duration": 4.54
    },
    {
        "text": "And that is features at a pose.",
        "start": 833.939,
        "duration": 2.69
    },
    {
        "text": "A pose is a 3D location and, rotation.",
        "start": 836.889,
        "duration": 5.13
    },
    {
        "text": "Or these pose features like the point\nnormal and the curvature directions.",
        "start": 842.269,
        "duration": 4.01
    },
    {
        "text": "this gets sent as input\nto the learning modules.",
        "start": 848.519,
        "duration": 2.66
    },
    {
        "text": "learning modules have these,\nlateral connections so they",
        "start": 853.129,
        "duration": 3.48
    },
    {
        "text": "can vote with each other.",
        "start": 856.609,
        "duration": 1.18
    },
    {
        "text": "And they can also output their most\nlikely hypothesis at every step,",
        "start": 858.624,
        "duration": 4.21
    },
    {
        "text": "which is again, features at a pose,\nand features in this case can be",
        "start": 862.974,
        "duration": 4.72
    },
    {
        "text": "the ID of an entire object model.",
        "start": 868.064,
        "duration": 2.64
    },
    {
        "text": "And then this is, so you can see the\ninput and the output of a learning",
        "start": 872.374,
        "duration": 3.44
    },
    {
        "text": "module is the same format, so you\ncan easily stack them on top of each",
        "start": 875.814,
        "duration": 3.75
    },
    {
        "text": "other, and then those can recognize\nsuccessively more complex objects.",
        "start": 879.564,
        "duration": 5.0
    },
    {
        "text": "And the third output from learning\nmodules is a suggested motor command, so",
        "start": 885.489,
        "duration": 5.7
    },
    {
        "text": "a suggested location in space, that can be\nthen translated into the action space of",
        "start": 891.199,
        "duration": 6.26
    },
    {
        "text": "the agent and executed in the environment.",
        "start": 897.519,
        "duration": 3.07
    },
    {
        "text": "Does this make sense?",
        "start": 902.649,
        "duration": 1.14
    },
    {
        "text": "Some things of those are not nailed in\nstone yet, like the hierarchy aspect.",
        "start": 905.619,
        "duration": 4.08
    },
    {
        "text": "We haven't implemented yet and\nwe're still thinking about it",
        "start": 910.104,
        "duration": 3.35
    },
    {
        "text": "and brainstorming, but this is",
        "start": 913.454,
        "duration": 1.98
    },
    {
        "text": "how it is set up right now.",
        "start": 917.644,
        "duration": 1.59
    },
    {
        "text": "You're going to talk more\nabout, the motor output, right?",
        "start": 924.024,
        "duration": 2.57
    },
    {
        "text": "not too much this time.",
        "start": 929.454,
        "duration": 1.65
    },
    {
        "text": "So the motor output is basically.",
        "start": 931.114,
        "duration": 2.32
    },
    {
        "text": "the learning module suggests a location\nrelative to the body and then the motor",
        "start": 934.534,
        "duration": 7.51
    },
    {
        "text": "system can translate that into this\nagent's action space and execute it and",
        "start": 942.044,
        "duration": 6.28
    },
    {
        "text": "the learning module, the location that\nthe learning module suggests depends",
        "start": 948.324,
        "duration": 4.33
    },
    {
        "text": "on if it is matching or exploring.",
        "start": 952.654,
        "duration": 2.385
    },
    {
        "text": "So if it is matching, it would want to\nlocate somewhere that, can disambiguate",
        "start": 955.059,
        "duration": 5.43
    },
    {
        "text": "two hypotheses from each other.",
        "start": 960.859,
        "duration": 1.69
    },
    {
        "text": "if it's exploring, it would\nwant to go into areas where the",
        "start": 964.069,
        "duration": 3.27
    },
    {
        "text": "model is not very complete yet.",
        "start": 967.339,
        "duration": 1.76
    },
    {
        "text": "So high uncertainty in\nthe model, basically.",
        "start": 969.559,
        "duration": 2.61
    },
    {
        "text": "Sometimes we'll have to think about,\nimplementing, goal oriented behavior.",
        "start": 973.349,
        "duration": 4.77
    },
    {
        "text": "where the learning model is\ntrying to achieve something.",
        "start": 978.984,
        "duration": 2.06
    },
    {
        "text": "yeah.",
        "start": 982.214,
        "duration": 0.46
    },
    {
        "text": "Yeah, so we haven't really implemented\nany goal condition policies yet, except",
        "start": 983.774,
        "duration": 5.7
    },
    {
        "text": "for the goal of recognizing the object.",
        "start": 989.624,
        "duration": 2.15
    },
    {
        "text": "it seems like the framework\nwe have would work for that.",
        "start": 993.544,
        "duration": 2.66
    },
    {
        "text": "A goal is basically to get\nthis object into a particular",
        "start": 996.804,
        "duration": 3.69
    },
    {
        "text": "state, or give me a particular\ncondition or something like that.",
        "start": 1000.494,
        "duration": 4.67
    },
    {
        "text": "We can do it later.",
        "start": 1005.574,
        "duration": 0.83
    },
    {
        "text": "yeah.",
        "start": 1007.969,
        "duration": 0.29
    },
    {
        "text": "So yeah, all the components\nto do that are there.",
        "start": 1008.259,
        "duration": 3.92
    },
    {
        "text": "So since the learning module has a 3D\nmodel of the object, if it has like a goal",
        "start": 1012.189,
        "duration": 5.11
    },
    {
        "text": "pose of the object, for example, it can,",
        "start": 1017.309,
        "duration": 1.98
    },
    {
        "text": "yeah, pretty easily output a\nsuggested motor command for that.",
        "start": 1021.369,
        "duration": 4.81
    },
    {
        "text": "We just haven't really needed it yet\nfor what we're trying to achieve.",
        "start": 1028.639,
        "duration": 3.424
    },
    {
        "text": "We didn't implement it.",
        "start": 1032.669,
        "duration": 0.94
    },
    {
        "text": "but yeah, so today I'm going to focus\non the learning module and the evidence",
        "start": 1038.489,
        "duration": 3.64
    },
    {
        "text": "based learning module specifically.",
        "start": 1042.149,
        "duration": 1.95
    },
    {
        "text": "Any questions about the general\nframework before I go to that?",
        "start": 1045.859,
        "duration": 4.21
    },
    {
        "text": "Okay.",
        "start": 1054.649,
        "duration": 0.34
    },
    {
        "text": "so at each stage in the, hierarchy,\nthere's an SDR that's being generated",
        "start": 1055.919,
        "duration": 4.59
    },
    {
        "text": "for the representing it or when you\nhave poses and features coming from",
        "start": 1060.589,
        "duration": 4.23
    },
    {
        "text": "the sensory modules, but I'm assuming\nthe learning modules are doing some",
        "start": 1064.819,
        "duration": 2.77
    },
    {
        "text": "kind of an encoding of the features.",
        "start": 1067.589,
        "duration": 1.92
    },
    {
        "text": "Right now we're not using SDRs, we're\nthinking about doing that at some point",
        "start": 1070.859,
        "duration": 4.14
    },
    {
        "text": "but right now it is like a explicit.",
        "start": 1075.009,
        "duration": 2.55
    },
    {
        "text": "Explicitly X, Y, Z coordinates,\nand then features out like a list",
        "start": 1079.364,
        "duration": 4.68
    },
    {
        "text": "of continuous numbers, basically.",
        "start": 1084.044,
        "duration": 3.5
    },
    {
        "text": "At some point you assign an object ID or\nwhen you think you've identified it, or",
        "start": 1087.544,
        "duration": 3.94
    },
    {
        "text": "maybe of candidate IDs, is that right?",
        "start": 1091.484,
        "duration": 1.48
    },
    {
        "text": "Yeah.",
        "start": 1093.734,
        "duration": 0.36
    },
    {
        "text": "Yeah.",
        "start": 1094.094,
        "duration": 0.34
    },
    {
        "text": "So here at the output level, right\nnow, object ID is just like a label.",
        "start": 1094.564,
        "duration": 6.17
    },
    {
        "text": "Either if it was supervised, that's\nthe actual name of the object,",
        "start": 1101.394,
        "duration": 3.35
    },
    {
        "text": "or it's just like a number, the\nsixth object that I learned.",
        "start": 1104.984,
        "duration": 5.15
    },
    {
        "text": "but it's, yeah, we are thinking about\nturning this into an SDR at some",
        "start": 1112.624,
        "duration": 3.91
    },
    {
        "text": "point, but it doesn't right now.",
        "start": 1116.534,
        "duration": 2.3
    },
    {
        "text": "Okay, so just to quickly recap, there\nare right now three different graph based",
        "start": 1124.159,
        "duration": 4.52
    },
    {
        "text": "learning modules that we've implemented.",
        "start": 1128.679,
        "duration": 1.72
    },
    {
        "text": "The displacement based model that\nbasically matches, incoming displacement",
        "start": 1131.369,
        "duration": 6.62
    },
    {
        "text": "to the edges that are stored in the graph.",
        "start": 1138.159,
        "duration": 2.37
    },
    {
        "text": "the learning module that uses features\nat location, so it basically matches to",
        "start": 1142.479,
        "duration": 3.49
    },
    {
        "text": "the nodes that are stored in the graph.",
        "start": 1145.969,
        "duration": 1.7
    },
    {
        "text": "And then the evidence based learning\nmodule, which also matches to",
        "start": 1148.449,
        "duration": 2.57
    },
    {
        "text": "the nodes, but it uses evidence\ncolumns for each hypothesis.",
        "start": 1151.019,
        "duration": 4.575
    },
    {
        "text": "And so the displacement learning mode,\nall of them are location invariant,",
        "start": 1156.804,
        "duration": 5.55
    },
    {
        "text": "so the object can be anywhere in\nspace, you can still detect it,",
        "start": 1162.374,
        "duration": 2.99
    },
    {
        "text": "it doesn't matter where it is.",
        "start": 1165.364,
        "duration": 1.9
    },
    {
        "text": "all of them are rotation invariant,\nhowever, the node based ones",
        "start": 1167.724,
        "duration": 3.86
    },
    {
        "text": "have to explicitly cycle through\ntesting different rotations.",
        "start": 1171.964,
        "duration": 4.33
    },
    {
        "text": "this comes naturally with the\ndisplacement learning module.",
        "start": 1176.954,
        "duration": 3.06
    },
    {
        "text": "And then only the displacement module\nis scale invariant at the moment, the",
        "start": 1180.949,
        "duration": 3.55
    },
    {
        "text": "other two not yet, even though it's\nnot logically impossible to do this.",
        "start": 1184.499,
        "duration": 5.06
    },
    {
        "text": "and then the downside of the\ndisplacement module is that we have",
        "start": 1192.059,
        "duration": 3.68
    },
    {
        "text": "to sample the displacements that\nare stored in the graph as edges.",
        "start": 1195.739,
        "duration": 3.7
    },
    {
        "text": "We can't sample newer displacements.",
        "start": 1199.719,
        "duration": 1.09
    },
    {
        "text": "which we can do with the other two.",
        "start": 1202.469,
        "duration": 1.75
    },
    {
        "text": "we can also not sample any new locations\nthat are not stored in the graph.",
        "start": 1207.209,
        "duration": 3.98
    },
    {
        "text": "we can do this with the\nfeatured location module, but",
        "start": 1212.169,
        "duration": 4.04
    },
    {
        "text": "it decreases performance a bit.",
        "start": 1216.229,
        "duration": 1.56
    },
    {
        "text": "With the evidence module,\nit works quite well.",
        "start": 1218.279,
        "duration": 1.98
    },
    {
        "text": "with this one, we can also deal\nwith noise quite reasonably well.",
        "start": 1221.769,
        "duration": 5.06
    },
    {
        "text": "And then another advantage of the\nevidence based module is that we have",
        "start": 1227.619,
        "duration": 4.53
    },
    {
        "text": "a most likely hypothesis at every step.",
        "start": 1232.149,
        "duration": 2.69
    },
    {
        "text": "So knowing what is the most likely object\nand pose helps us to, one, communicate",
        "start": 1235.989,
        "duration": 7.815
    },
    {
        "text": "this further up the hierarchy at every\nstep, and two, to use the motor policy",
        "start": 1243.804,
        "duration": 6.39
    },
    {
        "text": "more efficiently, to test this hypothesis.",
        "start": 1250.404,
        "duration": 3.74
    },
    {
        "text": "So we'll look at this one right\nnow, and that's the, yeah?",
        "start": 1257.004,
        "duration": 3.8
    },
    {
        "text": "Could you just explain again the\ndownsides, the new displacement",
        "start": 1261.434,
        "duration": 4.27
    },
    {
        "text": "from the new locations?",
        "start": 1265.704,
        "duration": 0.99
    },
    {
        "text": "I didn't quite follow that.",
        "start": 1267.064,
        "duration": 0.75
    },
    {
        "text": "Why, does the displacement\nmodule can't deal with this?",
        "start": 1273.444,
        "duration": 3.346
    },
    {
        "text": "I don't, I'm not sure, I'm not\nsure what they actually mean",
        "start": 1276.79,
        "duration": 4.814
    },
    {
        "text": "by sampling new locations.",
        "start": 1281.604,
        "duration": 1.375
    },
    {
        "text": "Is it sampling joint learning, inference?",
        "start": 1282.979,
        "duration": 2.063
    },
    {
        "text": "I'm, confused by that.",
        "start": 1285.73,
        "duration": 1.375
    },
    {
        "text": "sorry.",
        "start": 1287.449,
        "duration": 0.344
    },
    {
        "text": "Yeah, so basically if we learn a graph\nand we store a discrete, number of nodes",
        "start": 1287.793,
        "duration": 6.19
    },
    {
        "text": "and connections between those nodes,\nand if we use this displacement module,",
        "start": 1293.983,
        "duration": 4.126
    },
    {
        "text": "in order to recognize this graph, we have\nto sample pretty much exactly the same",
        "start": 1300.739,
        "duration": 6.43
    },
    {
        "text": "edges that we've stored in the graph.",
        "start": 1307.749,
        "duration": 1.7
    },
    {
        "text": "I remember that from before, I just\ndidn't connect that with the world here.",
        "start": 1309.759,
        "duration": 3.29
    },
    {
        "text": "Okay, thank you, that's sufficient.",
        "start": 1313.259,
        "duration": 2.45
    },
    {
        "text": "Cool, nice.",
        "start": 1316.899,
        "duration": 0.92
    },
    {
        "text": "Okay,",
        "start": 1320.259,
        "duration": 0.39
    },
    {
        "text": "so this is the general structure\nof the learning module.",
        "start": 1322.849,
        "duration": 2.52
    },
    {
        "text": "We have the pose and the\nfeature coming into the module.",
        "start": 1326.259,
        "duration": 3.74
    },
    {
        "text": "It has a memory of graphs\nthat it has learned before.",
        "start": 1331.589,
        "duration": 3.4
    },
    {
        "text": "this memory is used to\ninitialize its hypotheses.",
        "start": 1336.899,
        "duration": 2.94
    },
    {
        "text": "And then we use the displacement\nbetween the current pose and the",
        "start": 1341.069,
        "duration": 4.46
    },
    {
        "text": "previous pose and the current\nfeatures to update the hypotheses.",
        "start": 1345.529,
        "duration": 5.58
    },
    {
        "text": "So each hypothesis has a evidence\ncount assigned to it, which I try",
        "start": 1352.849,
        "duration": 6.87
    },
    {
        "text": "to visualize here with colors.",
        "start": 1359.759,
        "duration": 1.4
    },
    {
        "text": "So some of those locations on the\nobjects are more or less likely and",
        "start": 1361.714,
        "duration": 4.25
    },
    {
        "text": "also rotations of the objects and\nthen with an incoming displacement and",
        "start": 1365.964,
        "duration": 5.73
    },
    {
        "text": "feature we update these hypotheses.",
        "start": 1371.694,
        "duration": 1.57
    },
    {
        "text": "Then we can send out, votes and we can\nalso receive votes and use the votes",
        "start": 1375.254,
        "duration": 5.44
    },
    {
        "text": "to update the evidence counts again.",
        "start": 1380.694,
        "duration": 2.35
    },
    {
        "text": "And you can see each learning\nmodule has three types of outputs.",
        "start": 1384.834,
        "duration": 3.54
    },
    {
        "text": "One is the vote.",
        "start": 1388.374,
        "duration": 0.86
    },
    {
        "text": "One is the current most likely hypothesis.",
        "start": 1389.854,
        "duration": 2.35
    },
    {
        "text": "So what's the most likely\nobject and its pose?",
        "start": 1392.274,
        "duration": 2.51
    },
    {
        "text": "and one is an action suggestion.",
        "start": 1396.039,
        "duration": 2.27
    },
    {
        "text": "A quick question when, could you\nremind me again, you might have",
        "start": 1400.369,
        "duration": 3.24
    },
    {
        "text": "already mentioned this, but what\nreference frame is the pose in?",
        "start": 1403.679,
        "duration": 2.88
    },
    {
        "text": "Is it relative to the body or to\nthe, it's relative to the model",
        "start": 1408.589,
        "duration": 6.76
    },
    {
        "text": "and to the body in the sense.",
        "start": 1415.409,
        "duration": 1.87
    },
    {
        "text": "So basically we have a location in the\nmodel reference frame, and together",
        "start": 1417.779,
        "duration": 6.75
    },
    {
        "text": "with the location of the sensor, we can\ntransform it into a location in the world.",
        "start": 1424.539,
        "duration": 4.65
    },
    {
        "text": "And then the rotation of the object\nis relative to the learned model.",
        "start": 1431.194,
        "duration": 4.21
    },
    {
        "text": "okay.",
        "start": 1436.164,
        "duration": 0.76
    },
    {
        "text": "how is the best pose and feature\ndifferent than the output of a vote?",
        "start": 1439.944,
        "duration": 3.79
    },
    {
        "text": "Votes output all the possible, all\npossible locations and rotations.",
        "start": 1447.594,
        "duration": 5.73
    },
    {
        "text": "So all possible poses.",
        "start": 1453.424,
        "duration": 1.25
    },
    {
        "text": "And then this one is just one\npose, the most likely pose.",
        "start": 1455.794,
        "duration": 3.67
    },
    {
        "text": "And why do you have them separate?",
        "start": 1462.994,
        "duration": 1.09
    },
    {
        "text": "Do you need one on the\nright for action policy?",
        "start": 1464.084,
        "duration": 2.23
    },
    {
        "text": "so the most likely pose and idea is this\nis the same format as the input, so this",
        "start": 1469.584,
        "duration": 7.06
    },
    {
        "text": "can be sent to the next higher level\nup learning module, but the votes they",
        "start": 1476.644,
        "duration": 4.97
    },
    {
        "text": "go laterally to other learning modules.",
        "start": 1481.614,
        "duration": 2.15
    },
    {
        "text": "And they are used to\nupdate the hypotheses.",
        "start": 1484.844,
        "duration": 3.16
    },
    {
        "text": "so it's a list of possible poses.",
        "start": 1489.654,
        "duration": 2.26
    },
    {
        "text": "here we just have one.",
        "start": 1492.624,
        "duration": 1.12
    },
    {
        "text": "So here, this pose, we can calculate\na displacement to the previous one,",
        "start": 1493.874,
        "duration": 3.42
    },
    {
        "text": "same as we do here in the beginning.",
        "start": 1497.294,
        "duration": 1.66
    },
    {
        "text": "but here we have a list that gets\ndirectly sent to the hypotheses, and",
        "start": 1501.374,
        "duration": 3.93
    },
    {
        "text": "it's a different type of, different\nway of updating the hypotheses.",
        "start": 1506.164,
        "duration": 4.31
    },
    {
        "text": "In my mind, I've always thought of\nthe, And they vote the collection of",
        "start": 1512.154,
        "duration": 4.99
    },
    {
        "text": "possibilities of what's being passed off.",
        "start": 1517.144,
        "duration": 1.94
    },
    {
        "text": "But you're saying there's a set\nof possible objects, which is",
        "start": 1519.184,
        "duration": 5.56
    },
    {
        "text": "what's voted on, and then we only\npass off the most likely, correct?",
        "start": 1524.784,
        "duration": 4.12
    },
    {
        "text": "Yeah, since we haven't really implemented\nhierarchy yet, this is not set in stone.",
        "start": 1530.614,
        "duration": 5.79
    },
    {
        "text": "We could also pass all the possible\nposes to the next learning module.",
        "start": 1536.474,
        "duration": 3.98
    },
    {
        "text": "But I was trying to have the\noutput the same format as the",
        "start": 1541.054,
        "duration": 3.03
    },
    {
        "text": "input, so it's easily compatible.",
        "start": 1544.084,
        "duration": 2.07
    },
    {
        "text": "But, yeah, it's, right now this is\njust used for, logging, basically,",
        "start": 1546.794,
        "duration": 5.89
    },
    {
        "text": "for seeing if we detect the object.",
        "start": 1552.704,
        "duration": 1.72
    },
    {
        "text": "But, yeah.",
        "start": 1554.444,
        "duration": 0.92
    },
    {
        "text": "With an SDR, you could have, you could\nrepresent a union of these things.",
        "start": 1555.934,
        "duration": 3.83
    },
    {
        "text": "We could, yeah.",
        "start": 1560.804,
        "duration": 0.74
    },
    {
        "text": "Then you wouldn't have the\nrepresentation problem.",
        "start": 1561.594,
        "duration": 1.85
    },
    {
        "text": "But it's still an interesting idea.",
        "start": 1563.484,
        "duration": 1.28
    },
    {
        "text": "it's still a very interesting idea\nthat you don't pass up the union.",
        "start": 1565.564,
        "duration": 3.13
    },
    {
        "text": "You only pass up the one.",
        "start": 1568.694,
        "duration": 1.4
    },
    {
        "text": "Yeah, I think with a union it would\nbe a bit more difficult to calculate",
        "start": 1570.979,
        "duration": 3.56
    },
    {
        "text": "the displacement to the previous pose.",
        "start": 1574.539,
        "duration": 2.47
    },
    {
        "text": "Yeah, you start getting a little bit\nof a combinatorial explosion there.",
        "start": 1579.019,
        "duration": 3.22
    },
    {
        "text": "Yeah, that's why this is\na very interesting idea",
        "start": 1583.329,
        "duration": 2.27
    },
    {
        "text": "that never occurred to me.",
        "start": 1585.599,
        "duration": 1.04
    },
    {
        "text": "This will of course require two different\nsets of neurons, one set representing",
        "start": 1588.149,
        "duration": 4.67
    },
    {
        "text": "the union, one set representing the\nhypothesis, which is quite believable,",
        "start": 1592.829,
        "duration": 5.42
    },
    {
        "text": "I just never thought of it, and\nit's worth thinking about some more.",
        "start": 1598.379,
        "duration": 2.23
    },
    {
        "text": "yeah.",
        "start": 1602.674,
        "duration": 0.29
    },
    {
        "text": "And yeah, like I said, it's not\ndo this right now because we're",
        "start": 1602.964,
        "duration": 5.55
    },
    {
        "text": "not, using hierarchy right now.",
        "start": 1608.514,
        "duration": 1.33
    },
    {
        "text": "And, yeah, actually Niels and I\nwere thinking maybe during the, by",
        "start": 1609.844,
        "duration": 4.12
    },
    {
        "text": "the Bay Week, we can do some more\nbrainstorming and, narrow down the",
        "start": 1613.974,
        "duration": 3.79
    },
    {
        "text": "hierarchy and all of this some more,\nand yeah, decide on these things.",
        "start": 1617.774,
        "duration": 5.24
    },
    {
        "text": "But yeah, that's just how I've\nbeen thinking about it so far.",
        "start": 1623.014,
        "duration": 3.11
    },
    {
        "text": "Yeah.",
        "start": 1626.124,
        "duration": 0.04
    },
    {
        "text": "Yeah, and I mean we, we might pass\nup both to the next to level, there",
        "start": 1636.004,
        "duration": 5.39
    },
    {
        "text": "could be two channels passed up.",
        "start": 1641.394,
        "duration": 1.44
    },
    {
        "text": "yeah.",
        "start": 1646.524,
        "duration": 0.36
    },
    {
        "text": "The most likely one could be through\nthe thalamus, potentially, the layer",
        "start": 1646.884,
        "duration": 3.75
    },
    {
        "text": "five path and the other one, the voting\none could be potentially the layer two,",
        "start": 1650.634,
        "duration": 6.03
    },
    {
        "text": "three, up to the layer four pathway.",
        "start": 1656.664,
        "duration": 2.55
    },
    {
        "text": "Yeah.",
        "start": 1660.654,
        "duration": 0.15
    },
    {
        "text": "Or the, or There are distinctions\nmaybe between layer 2 cells layer",
        "start": 1660.804,
        "duration": 3.63
    },
    {
        "text": "three cells and subdivisions of them.",
        "start": 1664.434,
        "duration": 1.74
    },
    {
        "text": "And, I think that's\nmore likely what occur.",
        "start": 1666.234,
        "duration": 3.21
    },
    {
        "text": "I think the five pathways, there's\nstill gonna be a motion pathway.",
        "start": 1670.274,
        "duration": 3.12
    },
    {
        "text": "anyway, it's very interesting.",
        "start": 1675.404,
        "duration": 0.93
    },
    {
        "text": "It's interesting to think about a new idea\nthat I don't think I've mentioned before.",
        "start": 1676.339,
        "duration": 3.995
    },
    {
        "text": "Yeah.",
        "start": 1681.134,
        "duration": 0.3
    },
    {
        "text": "The main reason I did it like this is,\nbecause yeah, that way the learning",
        "start": 1681.434,
        "duration": 7.41
    },
    {
        "text": "module to keep this modularity\nof the learning module so we can.",
        "start": 1688.844,
        "duration": 3.615
    },
    {
        "text": "have the exact same structure and\nwe can easily just stack them on top",
        "start": 1693.429,
        "duration": 2.94
    },
    {
        "text": "of each other because the input and\noutput formats is exactly the same.",
        "start": 1696.369,
        "duration": 4.04
    },
    {
        "text": "And then the inner workings can\nalso always be the same no matter",
        "start": 1700.839,
        "duration": 3.01
    },
    {
        "text": "where in the hierarchy it is.",
        "start": 1703.849,
        "duration": 1.32
    },
    {
        "text": "okay, are there any\nmore questions for now?",
        "start": 1710.699,
        "duration": 2.13
    },
    {
        "text": "Okay.",
        "start": 1716.129,
        "duration": 0.36
    },
    {
        "text": "yeah, real quick, what is a graph?",
        "start": 1718.789,
        "duration": 2.89
    },
    {
        "text": "How do we represent the models\ninside the learning module?",
        "start": 1721.719,
        "duration": 3.08
    },
    {
        "text": "So we have the 3D object that we\nexplore with the sensor, and then we",
        "start": 1725.439,
        "duration": 4.51
    },
    {
        "text": "turn that into a graph where nodes\nin the graph represent 3D locations",
        "start": 1729.949,
        "duration": 5.03
    },
    {
        "text": "in space, and edges represent the\ndisplacements between these locations.",
        "start": 1734.979,
        "duration": 4.39
    },
    {
        "text": "And then nodes can also store\nfeatures at these locations, so",
        "start": 1740.279,
        "duration": 4.2
    },
    {
        "text": "for example color and curvature.",
        "start": 1744.479,
        "duration": 1.72
    },
    {
        "text": "And then additionally we define\nthe morphology with point",
        "start": 1746.959,
        "duration": 2.83
    },
    {
        "text": "normals and curvature directions.",
        "start": 1749.789,
        "duration": 2.15
    },
    {
        "text": "These help us with, the rotation of it.",
        "start": 1753.319,
        "duration": 3.09
    },
    {
        "text": "show later why.",
        "start": 1756.944,
        "duration": 1.06
    },
    {
        "text": "Point normals basically, they, like you\nsee here, point out of the surface and",
        "start": 1758.314,
        "duration": 4.9
    },
    {
        "text": "then curvature directions point towards\nthe minimum and maximum curvature.",
        "start": 1763.214,
        "duration": 3.97
    },
    {
        "text": "And in the evidence learning module, we\ndon't make use of the edges of the graph.",
        "start": 1769.014,
        "duration": 4.65
    },
    {
        "text": "So theoretically, we could\nalso just store a point cloud.",
        "start": 1773.864,
        "duration": 2.65
    },
    {
        "text": "Okay, now to how the\nmatching process works.",
        "start": 1781.539,
        "duration": 4.35
    },
    {
        "text": "This, might be a bit complicated.",
        "start": 1786.779,
        "duration": 3.82
    },
    {
        "text": "I hope this example helps.",
        "start": 1790.599,
        "duration": 1.5
    },
    {
        "text": "So in this example, we have a cylinder,\nwhich is mostly red, but has this",
        "start": 1792.799,
        "duration": 5.64
    },
    {
        "text": "little blue corner, and we start.",
        "start": 1798.439,
        "duration": 2.03
    },
    {
        "text": "collecting one sensation down here.",
        "start": 1801.619,
        "duration": 1.82
    },
    {
        "text": "We haven't moved yet, so we just collected\nthe first observation, and we use this",
        "start": 1803.459,
        "duration": 5.29
    },
    {
        "text": "to initialize our hypothesis space.",
        "start": 1808.819,
        "duration": 2.49
    },
    {
        "text": "So this is the model of the cylinder,\neach point is a node in the graph, and",
        "start": 1812.689,
        "duration": 5.69
    },
    {
        "text": "then at each location in the graph, we\nstored the point normal and curvature",
        "start": 1818.379,
        "duration": 4.25
    },
    {
        "text": "direction, and then we sensed a\nlocation in space that doesn't help us",
        "start": 1822.629,
        "duration": 4.765
    },
    {
        "text": "any yet, but we also sense the point\nnormal and a curvature direction.",
        "start": 1827.394,
        "duration": 4.87
    },
    {
        "text": "since the object could be anywhere in\nspace, the location doesn't help us.",
        "start": 1836.404,
        "duration": 3.17
    },
    {
        "text": "We could be anywhere on the object,\nbut we can use the blue and the",
        "start": 1839.574,
        "duration": 5.15
    },
    {
        "text": "red line already to narrow down\nthe rotations of the object.",
        "start": 1844.724,
        "duration": 4.3
    },
    {
        "text": "if I would be on this specific\nlocation, the object can only",
        "start": 1851.079,
        "duration": 4.25
    },
    {
        "text": "be in two different rotations.",
        "start": 1855.329,
        "duration": 1.85
    },
    {
        "text": "The cylinder can only be\nstanding upright or upside down.",
        "start": 1857.229,
        "duration": 2.92
    },
    {
        "text": "If I would be on the edge of the\ncylinder can only, given the point",
        "start": 1861.569,
        "duration": 4.02
    },
    {
        "text": "normal and curvature direction,\nthere are only two options of how",
        "start": 1865.599,
        "duration": 3.55
    },
    {
        "text": "the cylinder might be rotated.",
        "start": 1869.149,
        "duration": 1.5
    },
    {
        "text": "And these are different for\nevery location on the cylinder.",
        "start": 1871.499,
        "duration": 2.95
    },
    {
        "text": "And in some cases, like in the, on\nthe flat top of the cylinder, we",
        "start": 1875.679,
        "duration": 3.97
    },
    {
        "text": "actually have to sample more than\ntwo possible rotations, because the",
        "start": 1879.649,
        "duration": 4.125
    },
    {
        "text": "curvature direction is meaningless.",
        "start": 1883.774,
        "duration": 1.79
    },
    {
        "text": "So if we're on a completely flat surface,\nwe don't have curvature directions.",
        "start": 1885.754,
        "duration": 3.91
    },
    {
        "text": "So here we just sample a\ncouple of possible rotations",
        "start": 1890.464,
        "duration": 3.56
    },
    {
        "text": "perpendicular to the point normal.",
        "start": 1894.644,
        "duration": 1.59
    },
    {
        "text": "And we do this for all objects.",
        "start": 1897.834,
        "duration": 1.46
    },
    {
        "text": "Here you can see it again, this\nis just colored by the rotation.",
        "start": 1899.824,
        "duration": 3.33
    },
    {
        "text": "I'm sorry, can you, on the rotation, are\nwe dealing with just two three dimensional",
        "start": 1903.774,
        "duration": 3.59
    },
    {
        "text": "rotations or three dimensional rotations?",
        "start": 1907.384,
        "duration": 1.42
    },
    {
        "text": "three dimensional rotations.",
        "start": 1909.964,
        "duration": 1.35
    },
    {
        "text": "Okay, so basically any change in\nthe orientation of the object today.",
        "start": 1911.354,
        "duration": 4.29
    },
    {
        "text": "Sorry, what was the last part?",
        "start": 1920.084,
        "duration": 1.06
    },
    {
        "text": "It's good, three\ndimensional, I got it, Okay.",
        "start": 1921.524,
        "duration": 2.86
    },
    {
        "text": "On the object, what is the gray?",
        "start": 1925.914,
        "duration": 2.02
    },
    {
        "text": "What do the gray up arrow,\ngray arrows mean exactly?",
        "start": 1928.519,
        "duration": 3.27
    },
    {
        "text": "Is that, you said that's the two, oh,\nthat's the two rotations of the object.",
        "start": 1931.799,
        "duration": 3.79
    },
    {
        "text": "it could be upright or upside down, right?",
        "start": 1936.209,
        "duration": 2.46
    },
    {
        "text": "Yeah, exactly.",
        "start": 1938.669,
        "duration": 0.76
    },
    {
        "text": "Okay.",
        "start": 1939.529,
        "duration": 0.28
    },
    {
        "text": "And then at the edge?",
        "start": 1940.619,
        "duration": 1.27
    },
    {
        "text": "For example, okay, so for example,\nhere on this point here, where's my",
        "start": 1943.299,
        "duration": 4.74
    },
    {
        "text": "pointer, in the model, we have this\npoint normal that points out like that.",
        "start": 1948.039,
        "duration": 4.17
    },
    {
        "text": "So if we align the observation with\nthis, stored point normal in curvature",
        "start": 1953.109,
        "duration": 5.585
    },
    {
        "text": "direction, it means the cylinder would\nhave to be tilted like this or like",
        "start": 1958.694,
        "duration": 5.49
    },
    {
        "text": "that, like it would have to be tilted\nfor the 45 degree or minus 45 degrees.",
        "start": 1964.524,
        "duration": 6.272
    },
    {
        "text": "But wouldn't we have a, that's just\nlooking at the pose, but wouldn't",
        "start": 1970.796,
        "duration": 3.838
    },
    {
        "text": "we normally have a feature also that\nwould be, the feature would be very",
        "start": 1974.684,
        "duration": 3.974
    },
    {
        "text": "different there and we actually,\nwe could not be there at all.",
        "start": 1978.658,
        "duration": 2.928
    },
    {
        "text": "Yeah, I'll get to that in a moment.",
        "start": 1981.586,
        "duration": 1.952
    },
    {
        "text": "This is just the pose hypothesis.",
        "start": 1983.538,
        "duration": 2.546
    },
    {
        "text": "we're not looking at the\nfeature in this step yet.",
        "start": 1988.149,
        "duration": 3.68
    },
    {
        "text": "yeah, so this is just possible\nlocations and rotations initializing.",
        "start": 1993.639,
        "duration": 4.52
    },
    {
        "text": "And then, yeah, as you can see here,\nlike the top of the cylinder would have",
        "start": 1999.699,
        "duration": 4.36
    },
    {
        "text": "exactly 180 degree rotated pose of all\nthe points on the bottom of the cylinder.",
        "start": 2004.099,
        "duration": 5.01
    },
    {
        "text": "And then the sides would be\n90 degrees rotated from that.",
        "start": 2010.109,
        "duration": 4.34
    },
    {
        "text": "along one axis.",
        "start": 2014.979,
        "duration": 0.99
    },
    {
        "text": "And now this is the second\npart what you mentioned.",
        "start": 2017.899,
        "duration": 2.19
    },
    {
        "text": "Now we also observe a feature.",
        "start": 2020.089,
        "duration": 2.19
    },
    {
        "text": "So our model also stores the color\nand curvature at these locations.",
        "start": 2022.899,
        "duration": 4.09
    },
    {
        "text": "And we observe with the finger up here,\nwe observe a red color and a curved,",
        "start": 2027.729,
        "duration": 5.0
    },
    {
        "text": "convex curvature.",
        "start": 2034.949,
        "duration": 1.7
    },
    {
        "text": "so now we can actually update the\nevidence for these poses and locations.",
        "start": 2039.739,
        "duration": 4.82
    },
    {
        "text": "So at points where all the features\nmatch, we have the highest evidence.",
        "start": 2045.424,
        "duration": 4.79
    },
    {
        "text": "So here where the cylinder is red and\ncurved in this amount of curvature,",
        "start": 2050.224,
        "duration": 5.77
    },
    {
        "text": "in places where only one of the two\nmatches, we have medium high evidence.",
        "start": 2057.104,
        "duration": 4.33
    },
    {
        "text": "So for example, here we have a\nred feature, but the curvature",
        "start": 2061.444,
        "duration": 4.25
    },
    {
        "text": "is different because we're on the\nedge or here the curvature matches,",
        "start": 2065.694,
        "duration": 3.65
    },
    {
        "text": "but the color doesn't match.",
        "start": 2069.374,
        "duration": 1.29
    },
    {
        "text": "And then wherever we neither, none of the\nfeatures match, We have zero evidence.",
        "start": 2071.974,
        "duration": 6.07
    },
    {
        "text": "Does that make sense?",
        "start": 2079.304,
        "duration": 0.58
    },
    {
        "text": "Why do you say the color doesn't,\noh, because the object has a blues?",
        "start": 2082.274,
        "duration": 4.88
    },
    {
        "text": "patch.",
        "start": 2087.644,
        "duration": 0.65
    },
    {
        "text": "Yeah, exactly.",
        "start": 2088.874,
        "duration": 0.91
    },
    {
        "text": "So all the points here in the model\nstore blue as a feature layer.",
        "start": 2090.224,
        "duration": 3.98
    },
    {
        "text": "Now in a real vision case, the color would\nbe, could be quite different, even though",
        "start": 2096.914,
        "duration": 5.71
    },
    {
        "text": "the actual color is the same and the\nperceived color could be quite different.",
        "start": 2102.624,
        "duration": 4.36
    },
    {
        "text": "So we're not addressing that here.",
        "start": 2106.994,
        "duration": 3.17
    },
    {
        "text": "Yeah.",
        "start": 2110.794,
        "duration": 0.46
    },
    {
        "text": "So for example, we\nusually look at the hue.",
        "start": 2111.254,
        "duration": 2.89
    },
    {
        "text": "So the hue isn't that much influenced\nby like brightness and stuff like that.",
        "start": 2114.434,
        "duration": 4.62
    },
    {
        "text": "But yeah, we don't really\naccount for that at the moment.",
        "start": 2121.064,
        "duration": 2.94
    },
    {
        "text": "But also the evidence value is\nnot like a one or zero value.",
        "start": 2124.504,
        "duration": 4.88
    },
    {
        "text": "Like I like it seems like in this\nexample, but it's like a continuous value.",
        "start": 2129.384,
        "duration": 5.26
    },
    {
        "text": "So what's the distance between\nthe perceived observation and",
        "start": 2134.644,
        "duration": 3.77
    },
    {
        "text": "the one stored in the model?",
        "start": 2138.424,
        "duration": 2.24
    },
    {
        "text": "So if the red is just a little off,\nit's like a still quite high evidence,",
        "start": 2141.204,
        "duration": 4.1
    },
    {
        "text": "but if it's like a completely different\nhue, like blue, then it's low evidence.",
        "start": 2145.304,
        "duration": 4.17
    },
    {
        "text": "And then another thing is\nFeatures can only add evidence.",
        "start": 2150.724,
        "duration": 4.145
    },
    {
        "text": "They cannot subtract evidence.",
        "start": 2154.989,
        "duration": 1.6
    },
    {
        "text": "So even if the features do not match\nat all, it's still zero evidence.",
        "start": 2158.519,
        "duration": 5.12
    },
    {
        "text": "We don't subtract evidence like\nwe will with the morphology.",
        "start": 2163.639,
        "duration": 3.56
    },
    {
        "text": "So that way we hopefully should still be\nable to recognize the morphology of the",
        "start": 2167.539,
        "duration": 5.43
    },
    {
        "text": "object, even if the features don't match.",
        "start": 2172.969,
        "duration": 2.35
    },
    {
        "text": "That's an important consideration.",
        "start": 2175.489,
        "duration": 1.85
    },
    {
        "text": "So I think it's great.",
        "start": 2177.379,
        "duration": 1.38
    },
    {
        "text": "I, just remind me a basic thing, the\nmodel, these are discrete nodes in",
        "start": 2178.979,
        "duration": 4.32
    },
    {
        "text": "the model, and then we are able to\ninterpolate between them later, or do we",
        "start": 2183.299,
        "duration": 4.04
    },
    {
        "text": "have to sample the discrete nodes again?",
        "start": 2187.349,
        "duration": 1.37
    },
    {
        "text": "I'm sorry for that basic question.",
        "start": 2188.719,
        "duration": 1.42
    },
    {
        "text": "Yeah, so these are the discrete nodes,\nyes, and that means we will initialize",
        "start": 2191.069,
        "duration": 6.7
    },
    {
        "text": "a discrete number of hypotheses.",
        "start": 2197.859,
        "duration": 1.18
    },
    {
        "text": "every following step will\nhappen in continuous space.",
        "start": 2201.589,
        "duration": 4.31
    },
    {
        "text": "But we still initialize a discrete number\nof hypotheses, and that is defined by",
        "start": 2206.439,
        "duration": 5.46
    },
    {
        "text": "how many points are stored in the model.",
        "start": 2211.919,
        "duration": 1.9
    },
    {
        "text": "Just as the model itself is a set\nof discrete points, and then when",
        "start": 2214.599,
        "duration": 5.75
    },
    {
        "text": "I'm doing, when I'm sampling during\ninference, I'm not assuming that",
        "start": 2220.349,
        "duration": 4.32
    },
    {
        "text": "I'm on those discrete points, or am\nI assuming I'm on a discrete point?",
        "start": 2224.669,
        "duration": 3.07
    },
    {
        "text": "yeah, you're assuming it, but if you're\nnot on one of these discrete points,",
        "start": 2231.039,
        "duration": 4.04
    },
    {
        "text": "we have slack variables in the system\nso you can deal with starting somewhere",
        "start": 2235.639,
        "duration": 4.65
    },
    {
        "text": "that's not that point so even if i start\nlike somewhere over here and then i move",
        "start": 2240.349,
        "duration": 4.79
    },
    {
        "text": "up the next observation will still be\nsimilar and close by enough to the other",
        "start": 2245.179,
        "duration": 5.35
    },
    {
        "text": "point to the next point that I should\nstill be able to recognize the object.",
        "start": 2250.529,
        "duration": 4.54
    },
    {
        "text": "So from experiments, it seems\nlike that isn't a big issue.",
        "start": 2255.069,
        "duration": 4.09
    },
    {
        "text": "I don't know how it, so our\nmodels are much more dense than",
        "start": 2260.699,
        "duration": 4.17
    },
    {
        "text": "the one I show in this example.",
        "start": 2264.869,
        "duration": 1.72
    },
    {
        "text": "So if we would have a model that's\nthis sparse with so few points in it,",
        "start": 2266.619,
        "duration": 3.6
    },
    {
        "text": "that might have an effect on it, but\nwith our models, it's not a big deal.",
        "start": 2270.239,
        "duration": 4.59
    },
    {
        "text": "Is your evidence stored only on the nodes?",
        "start": 2277.609,
        "duration": 2.46
    },
    {
        "text": "Do you have any other evidence other\nthan displacement stored on the edges?",
        "start": 2280.419,
        "duration": 3.24
    },
    {
        "text": "yeah.",
        "start": 2286.859,
        "duration": 0.3
    },
    {
        "text": "So evidence is for the hypothesis,\nand that will move around the space.",
        "start": 2287.159,
        "duration": 4.38
    },
    {
        "text": "I'll show in a moment.",
        "start": 2291.539,
        "duration": 1.02
    },
    {
        "text": "it's not gonna be stored\nin the graph at any point.",
        "start": 2293.279,
        "duration": 3.27
    },
    {
        "text": "oh, you're not storing like\ncolor or, other in information",
        "start": 2298.239,
        "duration": 3.685
    },
    {
        "text": "at the nodes that's part of that.",
        "start": 2301.944,
        "duration": 2.725
    },
    {
        "text": "Oh, yeah.",
        "start": 2304.669,
        "duration": 0.15
    },
    {
        "text": "Features are stored at the nodes, yes.",
        "start": 2304.819,
        "duration": 2.43
    },
    {
        "text": "Okay.",
        "start": 2307.514,
        "duration": 0.29
    },
    {
        "text": "But you don't store like a\ntransition, like when you're going",
        "start": 2308.319,
        "duration": 2.46
    },
    {
        "text": "from one node to another node.",
        "start": 2310.779,
        "duration": 1.35
    },
    {
        "text": "Either the color changes or the\ncurvature changes in a specific way.",
        "start": 2312.579,
        "duration": 2.7
    },
    {
        "text": "No, it's only like the way we built\nthe models if between, if in a small",
        "start": 2317.214,
        "duration": 6.48
    },
    {
        "text": "space features change a lot, we\nwill store more points in the model.",
        "start": 2323.694,
        "duration": 3.69
    },
    {
        "text": "If features change a little,\nwe don't store many points",
        "start": 2327.984,
        "duration": 3.39
    },
    {
        "text": "in that area of the model.",
        "start": 2331.734,
        "duration": 1.29
    },
    {
        "text": "okay.",
        "start": 2340.384,
        "duration": 0.57
    },
    {
        "text": "Any more questions before I\ngo to the evidence update?",
        "start": 2343.024,
        "duration": 2.58
    },
    {
        "text": "Okay.",
        "start": 2349.274,
        "duration": 0.4
    },
    {
        "text": "So now we move the finger.",
        "start": 2350.364,
        "duration": 1.94
    },
    {
        "text": "So we move from down here,",
        "start": 2352.544,
        "duration": 1.69
    },
    {
        "text": "up on the model up here.",
        "start": 2356.284,
        "duration": 1.68
    },
    {
        "text": "Again, we sense red and curved.",
        "start": 2358.779,
        "duration": 1.72
    },
    {
        "text": "so we get on displacement that is\na certain length and direction.",
        "start": 2362.279,
        "duration": 3.8
    },
    {
        "text": "We have all these hypotheses that I\nshowed before, and then we basically",
        "start": 2367.829,
        "duration": 7.89
    },
    {
        "text": "calculate search locations by taking\neach of these location and rotation",
        "start": 2376.339,
        "duration": 6.26
    },
    {
        "text": "hypotheses and We start at the possible\nlocation, we rotate the displacement",
        "start": 2382.609,
        "duration": 8.255
    },
    {
        "text": "by the hypothesis pose, and then\nwherever this rotated displacement",
        "start": 2391.774,
        "duration": 5.02
    },
    {
        "text": "ends up is our new search location.",
        "start": 2396.814,
        "duration": 2.28
    },
    {
        "text": "So for example, up here, we,",
        "start": 2400.074,
        "duration": 3.01
    },
    {
        "text": "let's see, yeah, let's\ntake this point here.",
        "start": 2406.634,
        "duration": 3.35
    },
    {
        "text": "We start at this location, we rotate\nthe displacement by this possible",
        "start": 2411.259,
        "duration": 5.05
    },
    {
        "text": "pose, and then the search location\nwould end up over here, and then the",
        "start": 2416.329,
        "duration": 4.44
    },
    {
        "text": "other arrow would end up over here.",
        "start": 2420.779,
        "duration": 1.75
    },
    {
        "text": "Same with all of these arrows\nhere, the search locations end",
        "start": 2423.159,
        "duration": 2.74
    },
    {
        "text": "up in a circle around this point.",
        "start": 2425.899,
        "duration": 2.72
    },
    {
        "text": "Down here, they end up like down\nthere, and then inside the curve.",
        "start": 2429.839,
        "duration": 3.91
    },
    {
        "text": "It's a bit difficult to draw this in 3D,",
        "start": 2434.499,
        "duration": 2.22
    },
    {
        "text": "but yeah, that's the procedure.",
        "start": 2438.749,
        "duration": 1.725
    },
    {
        "text": "So we have one search location\nfor each hypothesis now,",
        "start": 2440.474,
        "duration": 4.15
    },
    {
        "text": "and now I'm just going to\ntake a short detour into a few",
        "start": 2447.414,
        "duration": 3.87
    },
    {
        "text": "details, just one hypothesis now.",
        "start": 2451.284,
        "duration": 2.88
    },
    {
        "text": "So again, in this example, we\nwould have a sideways displacement,",
        "start": 2455.264,
        "duration": 4.8
    },
    {
        "text": "just to make it a bit more clear.",
        "start": 2460.064,
        "duration": 1.48
    },
    {
        "text": "We have this location and the\npose hypotheses are either the",
        "start": 2461.544,
        "duration": 3.86
    },
    {
        "text": "cylinders upright or upside down.",
        "start": 2465.444,
        "duration": 2.2
    },
    {
        "text": "We rotate the displacement\nand apply it to this location.",
        "start": 2470.204,
        "duration": 2.97
    },
    {
        "text": "So we get this search location, this one.",
        "start": 2473.184,
        "duration": 3.04
    },
    {
        "text": "Sorry?",
        "start": 2477.454,
        "duration": 0.28
    },
    {
        "text": "Oh, okay.",
        "start": 2480.914,
        "duration": 0.49
    },
    {
        "text": "So we would get these\ntwo search locations.",
        "start": 2481.944,
        "duration": 2.62
    },
    {
        "text": "If we now look at this one, for\nexample, this is zoomed in there now.",
        "start": 2484.624,
        "duration": 4.72
    },
    {
        "text": "We draw a search radius around\nthis search location, look at the",
        "start": 2490.194,
        "duration": 3.55
    },
    {
        "text": "nearest neighbors in this radius.",
        "start": 2493.744,
        "duration": 2.78
    },
    {
        "text": "For each of the nearest neighbors,\nwe then calculate the evidence.",
        "start": 2498.654,
        "duration": 3.45
    },
    {
        "text": "So we take the observed features\nthere, both the curvature direction.",
        "start": 2503.444,
        "duration": 7.82
    },
    {
        "text": "and pose independent features, so\ncolor and curvature, in this case.",
        "start": 2512.149,
        "duration": 3.77
    },
    {
        "text": "And we calculate the evidence,\nthat is for the pose features,",
        "start": 2516.599,
        "duration": 4.78
    },
    {
        "text": "it's the angle between them.",
        "start": 2521.379,
        "duration": 1.26
    },
    {
        "text": "for the other features, it's\njust the real value difference.",
        "start": 2523.789,
        "duration": 2.92
    },
    {
        "text": "So how different are the\ncolors and curvatures?",
        "start": 2526.719,
        "duration": 2.24
    },
    {
        "text": "And we weigh this by the\ndistance to the search location.",
        "start": 2530.199,
        "duration": 3.21
    },
    {
        "text": "So if the point is far away\nfrom it, it's, less evidence.",
        "start": 2533.449,
        "duration": 3.87
    },
    {
        "text": "If it's really close, it's more evidence.",
        "start": 2537.339,
        "duration": 1.87
    },
    {
        "text": "Why is that?",
        "start": 2539.949,
        "duration": 0.55
    },
    {
        "text": "just to Yeah, make sure we stay on\nthe model surface and if it's like",
        "start": 2543.169,
        "duration": 7.135
    },
    {
        "text": "an, if it is a point right where\nwe're looking, then it's more certain",
        "start": 2550.304,
        "duration": 5.38
    },
    {
        "text": "that this is the one we want to look\nat than if it is one that's like far",
        "start": 2555.684,
        "duration": 4.33
    },
    {
        "text": "on the outside of the search radius.",
        "start": 2560.014,
        "duration": 1.78
    },
    {
        "text": "So you're saying you might\nbe on a different object?",
        "start": 2562.214,
        "duration": 1.81
    },
    {
        "text": "Yeah, you might be off the object or\nyour pose hypothesis might be wrong,",
        "start": 2567.214,
        "duration": 3.99
    },
    {
        "text": "like you might just have rotate\nthe displacement in a way that's",
        "start": 2571.214,
        "duration": 3.345
    },
    {
        "text": "going off the object, for example.",
        "start": 2574.669,
        "duration": 2.04
    },
    {
        "text": "But if you went off the object, you\nwouldn't have an index observation.",
        "start": 2577.299,
        "duration": 2.7
    },
    {
        "text": "No, we didn't really go off the\nobject, but if our hypothesis of the",
        "start": 2579.999,
        "duration": 5.89
    },
    {
        "text": "object rotation is wrong, then if we\ntest this displacement with the wrong",
        "start": 2585.889,
        "duration": 6.03
    },
    {
        "text": "hypothesis, it will end up outside\nof the model, in the model space.",
        "start": 2591.929,
        "duration": 4.09
    },
    {
        "text": "All right, so you're relying on the fact\nthat if you move it just a little bit,",
        "start": 2598.069,
        "duration": 3.37
    },
    {
        "text": "then even if your orientation is wrong,\nyou'll have some useful information.",
        "start": 2601.869,
        "duration": 3.92
    },
    {
        "text": "Yeah,",
        "start": 2605.789,
        "duration": 5.39
    },
    {
        "text": "it works also with large displacements.",
        "start": 2613.289,
        "duration": 2.5
    },
    {
        "text": "It's just generally, most of\nthe hypotheses will be wrong.",
        "start": 2615.809,
        "duration": 5.26
    },
    {
        "text": "So most of the search locations\nwill end up somewhere outside",
        "start": 2621.679,
        "duration": 3.86
    },
    {
        "text": "of where the object actually is.",
        "start": 2625.539,
        "duration": 1.79
    },
    {
        "text": "in the model space.",
        "start": 2629.054,
        "duration": 1.05
    },
    {
        "text": "So we don't want to consider these\nhypotheses anymore, or we want to",
        "start": 2630.264,
        "duration": 4.58
    },
    {
        "text": "at least decrease their evidence.",
        "start": 2634.864,
        "duration": 1.51
    },
    {
        "text": "Yeah, earlier you had mentioned that in\nplaces where things are pretty constant",
        "start": 2637.314,
        "duration": 3.34
    },
    {
        "text": "you store fewer points in the model.",
        "start": 2640.694,
        "duration": 2.27
    },
    {
        "text": "Yeah.",
        "start": 2644.014,
        "duration": 0.33
    },
    {
        "text": "And it seems like there you'll just,\nit's much more likely to just have lower",
        "start": 2644.384,
        "duration": 6.23
    },
    {
        "text": "weights because, just because there's The\ndensity of stored points is fewer, right?",
        "start": 2650.614,
        "duration": 5.67
    },
    {
        "text": "But actually it's not really,\nthat's, it should be more dependent.",
        "start": 2656.284,
        "duration": 6.02
    },
    {
        "text": "I don't know.",
        "start": 2663.234,
        "duration": 0.3
    },
    {
        "text": "I don't know how you\ntake that into account.",
        "start": 2663.544,
        "duration": 1.41
    },
    {
        "text": "Yeah.",
        "start": 2666.174,
        "duration": 0.2
    },
    {
        "text": "Yeah.",
        "start": 2667.874,
        "duration": 0.47
    },
    {
        "text": "it might be that this weight\nfactor doesn't actually",
        "start": 2670.484,
        "duration": 2.36
    },
    {
        "text": "help a lot with performance.",
        "start": 2672.844,
        "duration": 1.37
    },
    {
        "text": "I would have to test that.",
        "start": 2674.214,
        "duration": 1.04
    },
    {
        "text": "I just thought intuitively we would\nwant to weigh that, but you're right.",
        "start": 2676.664,
        "duration": 4.41
    },
    {
        "text": "If we have a lot of noise, for example,\nor we don't store a lot of points in",
        "start": 2681.084,
        "duration": 3.35
    },
    {
        "text": "that area, it might just be a hindrance.",
        "start": 2684.434,
        "duration": 3.775
    },
    {
        "text": "So yeah, maybe I'll do an experiment\nwithout this weight factor.",
        "start": 2688.619,
        "duration": 4.375
    },
    {
        "text": "Or maybe different parts of the\nobject could have different weighting",
        "start": 2698.104,
        "duration": 2.6
    },
    {
        "text": "factors if you have to put it in.",
        "start": 2700.704,
        "duration": 1.4
    },
    {
        "text": "Yeah.",
        "start": 2703.124,
        "duration": 0.56
    },
    {
        "text": "But that's more complexity.",
        "start": 2704.174,
        "duration": 1.32
    },
    {
        "text": "Yeah, definitely.",
        "start": 2706.544,
        "duration": 0.8
    },
    {
        "text": "but yeah, that's a good point.",
        "start": 2708.644,
        "duration": 1.18
    },
    {
        "text": "Maybe I'll just try that.",
        "start": 2709.834,
        "duration": 1.65
    },
    {
        "text": "Maybe it's not even really\nnecessary to weigh that, weigh this.",
        "start": 2711.514,
        "duration": 3.36
    },
    {
        "text": "yeah, anyways, so We basically calculate\nthe, how well each of the points in the",
        "start": 2718.964,
        "duration": 5.95
    },
    {
        "text": "radius matches the observed features,\nand then we take the best match to",
        "start": 2724.914,
        "duration": 5.35
    },
    {
        "text": "update the evidence for the hypothesis.",
        "start": 2730.394,
        "duration": 2.5
    },
    {
        "text": "So even if, for example, one of these\ndoesn't match well, like if we're here",
        "start": 2735.194,
        "duration": 4.0
    },
    {
        "text": "up on the corner, we do have a red\ncolor, but everything else doesn't",
        "start": 2739.194,
        "duration": 4.45
    },
    {
        "text": "match, the point normal doesn't\nmatch, the curvature doesn't match.",
        "start": 2743.664,
        "duration": 2.98
    },
    {
        "text": "so that one would have a pretty low\nevidence, but that doesn't matter.",
        "start": 2747.969,
        "duration": 2.75
    },
    {
        "text": "It's just a another point in the model.",
        "start": 2750.719,
        "duration": 2.42
    },
    {
        "text": "As long as there's one good match in this\nradius, we get a high evidence update.",
        "start": 2753.189,
        "duration": 5.33
    },
    {
        "text": "and evidence update basically\nmeans we add this evidence to",
        "start": 2760.559,
        "duration": 4.68
    },
    {
        "text": "the accumulated evidence so far.",
        "start": 2765.239,
        "duration": 1.98
    },
    {
        "text": "and then as another\ndetail, the search radius.",
        "start": 2770.289,
        "duration": 3.58
    },
    {
        "text": "is not exactly circular, but\nit's a bit, it's spherical",
        "start": 2774.389,
        "duration": 6.25
    },
    {
        "text": "influenced by the point normal.",
        "start": 2780.709,
        "duration": 1.61
    },
    {
        "text": "So basically it's the notion that we want\nto search far along the surface of the",
        "start": 2782.999,
        "duration": 7.28
    },
    {
        "text": "object, but not far out of the surface\nof the object or inside the object.",
        "start": 2790.279,
        "duration": 4.29
    },
    {
        "text": "So basically in this example, the\npoint normal would be pointing upwards.",
        "start": 2795.179,
        "duration": 4.41
    },
    {
        "text": "Search location is in the center of this.",
        "start": 2799.669,
        "duration": 1.76
    },
    {
        "text": "And then color represents distance, so\npoints that go in the direction of the",
        "start": 2802.224,
        "duration": 4.27
    },
    {
        "text": "point normal or down into the object,\nthere the distance increases much faster",
        "start": 2806.494,
        "duration": 6.95
    },
    {
        "text": "than if we go along the surface of\nthe object in any of these directions.",
        "start": 2813.544,
        "duration": 3.81
    },
    {
        "text": "And that's, I'm sorry, earlier we\nwere talking about the idea that,",
        "start": 2817.444,
        "duration": 5.81
    },
    {
        "text": "you have an action policy which\njust follows the surface, and it",
        "start": 2824.144,
        "duration": 4.25
    },
    {
        "text": "sounds like you're not doing that.",
        "start": 2828.394,
        "duration": 0.91
    },
    {
        "text": "I hear you're doing an action which\nis independent of following the",
        "start": 2829.404,
        "duration": 3.54
    },
    {
        "text": "surface, it could be off the object\nat some point, but wouldn't you",
        "start": 2832.944,
        "duration": 3.38
    },
    {
        "text": "normally be following the surface?",
        "start": 2836.324,
        "duration": 1.34
    },
    {
        "text": "In which case you wouldn't.",
        "start": 2837.664,
        "duration": 0.92
    },
    {
        "text": "I guess I'm trying to\nunderstand why is that?",
        "start": 2839.764,
        "duration": 3.19
    },
    {
        "text": "It wouldn't be on the object.",
        "start": 2842.954,
        "duration": 0.96
    },
    {
        "text": "No, so these are not actions, these\nare just, we sense the displacement.",
        "start": 2845.494,
        "duration": 5.63
    },
    {
        "text": "There was an action that was performed\nin the environment, but then we add this",
        "start": 2851.124,
        "duration": 4.01
    },
    {
        "text": "displacement to all of our hypotheses,\nso for every hypothesis that we have.",
        "start": 2855.134,
        "duration": 5.13
    },
    {
        "text": "Where did the displacement come from?",
        "start": 2860.584,
        "duration": 1.3
    },
    {
        "text": "This is what we, this is the\naction that we performed.",
        "start": 2863.114,
        "duration": 2.78
    },
    {
        "text": "so why wouldn't the action be\nconstrained by the object versus",
        "start": 2866.654,
        "duration": 2.84
    },
    {
        "text": "just, not constrained by that?",
        "start": 2869.494,
        "duration": 4.633
    },
    {
        "text": "we could only take actions which\nkeep us on the object, like the",
        "start": 2876.214,
        "duration": 2.35
    },
    {
        "text": "fingers following one another.",
        "start": 2878.564,
        "duration": 1.48
    },
    {
        "text": "Yeah, that is the constraint.",
        "start": 2880.549,
        "duration": 1.7
    },
    {
        "text": "But then your points will\nall be on the object.",
        "start": 2882.679,
        "duration": 2.58
    },
    {
        "text": "You were just describing how the points\ncould be off the object or in the object.",
        "start": 2885.299,
        "duration": 3.43
    },
    {
        "text": "I don't understand how that could be.",
        "start": 2888.729,
        "duration": 1.04
    },
    {
        "text": "No, this is just for the\nsearch inside the model space.",
        "start": 2891.009,
        "duration": 4.24
    },
    {
        "text": "So we have the displacement applied to\nthe, applied inside the model space.",
        "start": 2895.839,
        "duration": 4.92
    },
    {
        "text": "This is not an actual movement.",
        "start": 2900.759,
        "duration": 1.54
    },
    {
        "text": "We look up here, we look down here.",
        "start": 2902.769,
        "duration": 1.69
    },
    {
        "text": "We do this for all the hypothesis in here.",
        "start": 2904.769,
        "duration": 2.11
    },
    {
        "text": "And then we want to search\nhere on the model hypothesis.",
        "start": 2907.269,
        "duration": 4.06
    },
    {
        "text": "We don't move here.",
        "start": 2911.349,
        "duration": 1.88
    },
    {
        "text": "It's just looking at all the points on\nthe surface in this area, basically.",
        "start": 2913.259,
        "duration": 4.11
    },
    {
        "text": "That's a, that's not an observation\nin feature space and in object space.",
        "start": 2922.369,
        "duration": 4.38
    },
    {
        "text": "That's a prediction made by the model.",
        "start": 2927.059,
        "duration": 1.93
    },
    {
        "text": "Yeah.",
        "start": 2929.869,
        "duration": 0.39
    },
    {
        "text": "Yeah.",
        "start": 2931.859,
        "duration": 0.16
    },
    {
        "text": "It's a simple example.",
        "start": 2932.149,
        "duration": 0.93
    },
    {
        "text": "I mentioned the following, let's\nsay this is the object we have in",
        "start": 2933.079,
        "duration": 3.65
    },
    {
        "text": "memory and we also have serving.",
        "start": 2936.729,
        "duration": 1.52
    },
    {
        "text": "Let's say I'm touching it here,\nbut I'm actually thinking one of my",
        "start": 2938.799,
        "duration": 5.92
    },
    {
        "text": "hypothesis is I'm touching it over here.",
        "start": 2944.719,
        "duration": 2.57
    },
    {
        "text": "So now I make a displacement\ngoing from here to here.",
        "start": 2948.289,
        "duration": 3.34
    },
    {
        "text": "If my hypothesis was I originally\ntouched here, then I should have",
        "start": 2953.089,
        "duration": 4.04
    },
    {
        "text": "expect something over there.",
        "start": 2957.129,
        "duration": 1.32
    },
    {
        "text": "But now we're outside the object.",
        "start": 2960.289,
        "duration": 1.77
    },
    {
        "text": "And then, so this is the one\nwe're considering here, this",
        "start": 2963.789,
        "duration": 2.76
    },
    {
        "text": "just being outside the object\nbecause my hypothesis was wrong.",
        "start": 2967.174,
        "duration": 2.78
    },
    {
        "text": "I was at the wrong location.",
        "start": 2970.734,
        "duration": 1.13
    },
    {
        "text": "I should have thought I was here.",
        "start": 2972.904,
        "duration": 2.26
    },
    {
        "text": "If I think of it like, like you're making\na prediction, like you're doing like",
        "start": 2975.814,
        "duration": 4.4
    },
    {
        "text": "counterfactuals, what, if I moved in this\ndirection, what would I expect to see?",
        "start": 2980.224,
        "duration": 3.59
    },
    {
        "text": "And if that's not consistent with\nmy current evidence, then I'm going",
        "start": 2984.284,
        "duration": 2.83
    },
    {
        "text": "to discard that as a counterfactual\nthat's not likely to be happening.",
        "start": 2987.114,
        "duration": 2.66
    },
    {
        "text": "Is that right?",
        "start": 2990.264,
        "duration": 0.4
    },
    {
        "text": "Yeah.",
        "start": 2990.684,
        "duration": 0.45
    },
    {
        "text": "Yeah.",
        "start": 2991.474,
        "duration": 0.27
    },
    {
        "text": "Yeah.",
        "start": 2991.744,
        "duration": 0.25
    },
    {
        "text": "Let me go to the slide.",
        "start": 2991.994,
        "duration": 0.99
    },
    {
        "text": "Actually that.",
        "start": 2992.984,
        "duration": 0.52
    },
    {
        "text": "Maybe it visualizes it better, maybe\nI should have put that one first.",
        "start": 2993.799,
        "duration": 2.83
    },
    {
        "text": "So basically,",
        "start": 2996.639,
        "duration": 0.83
    },
    {
        "text": "yeah, so for example, if we test the\nhypothesis that we were down here on",
        "start": 3001.319,
        "duration": 5.11
    },
    {
        "text": "the bottom of the cup, and we sense\nthis displacement, we would say, if I",
        "start": 3006.429,
        "duration": 4.96
    },
    {
        "text": "would have been here in this hypothesis\nrotation, then now I should be here.",
        "start": 3011.389,
        "duration": 4.8
    },
    {
        "text": "But then if we do a search\nradius around here, there are",
        "start": 3016.869,
        "duration": 2.43
    },
    {
        "text": "no nearby points in the model.",
        "start": 3019.299,
        "duration": 2.03
    },
    {
        "text": "So it's, we want to decrease the evidence.",
        "start": 3021.349,
        "duration": 2.39
    },
    {
        "text": "for this hypothesis, because we're\nnot on the model surface anymore,",
        "start": 3024.689,
        "duration": 3.685
    },
    {
        "text": "if we would follow this hypothesis.",
        "start": 3029.214,
        "duration": 1.8
    },
    {
        "text": "Is the displacement an actual movement\nof the sensor in our hypothesis space?",
        "start": 3031.294,
        "duration": 5.985
    },
    {
        "text": "We have one displacement with the sensor.",
        "start": 3037.464,
        "duration": 2.34
    },
    {
        "text": "This is the actual displacement that\nwe sensed, but then we test all our",
        "start": 3039.864,
        "duration": 6.04
    },
    {
        "text": "hypotheses given that displacement.",
        "start": 3045.904,
        "duration": 2.51
    },
    {
        "text": "I think it's like a trial,\nthe trial displacement, it's",
        "start": 3048.414,
        "duration": 4.29
    },
    {
        "text": "not an actual displacement.",
        "start": 3052.704,
        "duration": 1.13
    },
    {
        "text": "It's a, like a mental manipulation\nwhere you're, I don't understand.",
        "start": 3053.834,
        "duration": 4.46
    },
    {
        "text": "If it's not an actual displacement,\nthen I have no data on which to say, oh,",
        "start": 3060.664,
        "duration": 4.22
    },
    {
        "text": "it's off the object or it's not right.",
        "start": 3065.274,
        "duration": 1.87
    },
    {
        "text": "How can I understand\nif it's just imagining?",
        "start": 3067.344,
        "duration": 2.51
    },
    {
        "text": "No, there is an actual, where it says\ndisplacement, that's an actual movement.",
        "start": 3072.694,
        "duration": 4.63
    },
    {
        "text": "Yeah, but that's what they're saying.",
        "start": 3078.119,
        "duration": 3.79
    },
    {
        "text": "But then I was told that it wasn't.",
        "start": 3081.909,
        "duration": 1.19
    },
    {
        "text": "no, that is the actual.",
        "start": 3084.079,
        "duration": 0.7
    },
    {
        "text": "So there is one movement,\nwhich is that displacement.",
        "start": 3085.529,
        "duration": 2.8
    },
    {
        "text": "But depending on your hypothesis,\nthat one movement can lead to",
        "start": 3088.459,
        "duration": 3.98
    },
    {
        "text": "very different predictions.",
        "start": 3092.439,
        "duration": 1.03
    },
    {
        "text": "And so that's what's being\nchecked for every point for",
        "start": 3094.119,
        "duration": 3.79
    },
    {
        "text": "every possible, pose hypothesis.",
        "start": 3097.909,
        "duration": 3.9
    },
    {
        "text": "You try that movement out.",
        "start": 3102.169,
        "duration": 1.7
    },
    {
        "text": "So make it out of predictions.",
        "start": 3106.214,
        "duration": 1.16
    },
    {
        "text": "In that case, back to my earlier point,\nwhich I'm saying, like, why would I try",
        "start": 3108.364,
        "duration": 3.28
    },
    {
        "text": "a movement that takes me off the object?",
        "start": 3111.704,
        "duration": 2.2
    },
    {
        "text": "I just require my action policy\nto keep me on the object.",
        "start": 3114.324,
        "duration": 2.72
    },
    {
        "text": "I never test.",
        "start": 3117.044,
        "duration": 0.94
    },
    {
        "text": "I have a displacement that\ntakes me off the object.",
        "start": 3117.984,
        "duration": 2.9
    },
    {
        "text": "No, we stay on the object so our\nmovement in this example is we",
        "start": 3121.634,
        "duration": 3.57
    },
    {
        "text": "were down here with how my laser\npointer up on the top right corner.",
        "start": 3125.204,
        "duration": 4.56
    },
    {
        "text": "So we were down here, we\nmoved the finger up here.",
        "start": 3130.034,
        "duration": 2.32
    },
    {
        "text": "That is an actual movement in the world.",
        "start": 3132.394,
        "duration": 1.81
    },
    {
        "text": "We stayed on the object surface.",
        "start": 3134.234,
        "duration": 1.71
    },
    {
        "text": "So this is the displacement\nwe're sensing from year up here.",
        "start": 3136.604,
        "duration": 3.78
    },
    {
        "text": "And then we take that actual sense\nmovement along the surface of the object.",
        "start": 3141.474,
        "duration": 4.35
    },
    {
        "text": "And we compare it to all the\nhypotheses we would have.",
        "start": 3147.234,
        "duration": 2.89
    },
    {
        "text": "And with a lot of the hypotheses,\nthis is not going to match.",
        "start": 3150.954,
        "duration": 3.16
    },
    {
        "text": "I think, I'm sorry, it's\npretty basic and that's it.",
        "start": 3154.464,
        "duration": 2.97
    },
    {
        "text": "Thank you.",
        "start": 3157.544,
        "duration": 0.51
    },
    {
        "text": "Yeah, but Vivian, it's also, but isn't\nit the case that you can't guarantee",
        "start": 3158.054,
        "duration": 4.61
    },
    {
        "text": "that the movement is going to keep\nyou on the object because you don't",
        "start": 3162.664,
        "duration": 3.29
    },
    {
        "text": "know where on the object you are.",
        "start": 3165.964,
        "duration": 1.54
    },
    {
        "text": "You just have a whole bunch of hypotheses.",
        "start": 3168.004,
        "duration": 1.29
    },
    {
        "text": "You can take your best guess, but you\ndon't, you can't guarantee that it's",
        "start": 3170.394,
        "duration": 3.81
    },
    {
        "text": "going to keep you on the object, can you?",
        "start": 3174.204,
        "duration": 2.04
    },
    {
        "text": "So in the real world, we're\ngoing to stay on the object.",
        "start": 3178.964,
        "duration": 3.14
    },
    {
        "text": "The policy makes sure that we\nstay on the object for all the",
        "start": 3182.614,
        "duration": 3.99
    },
    {
        "text": "actual movements of the agent.",
        "start": 3186.644,
        "duration": 1.95
    },
    {
        "text": "But then for testing hypotheses,\nif I have a wrong hypothesis, this",
        "start": 3189.574,
        "duration": 7.99
    },
    {
        "text": "actual displacement that was actually\non the surface is going to end up",
        "start": 3197.764,
        "duration": 3.79
    },
    {
        "text": "somewhere out here in model space.",
        "start": 3201.554,
        "duration": 2.14
    },
    {
        "text": "out here in model space, not\non the model surface anymore.",
        "start": 3203.784,
        "duration": 2.78
    },
    {
        "text": "Yeah, no, I understand that piece of it.",
        "start": 3206.964,
        "duration": 1.7
    },
    {
        "text": "I'm just wondering how can you guarantee\nthat the original movement is going",
        "start": 3208.714,
        "duration": 4.37
    },
    {
        "text": "to keep you on the object if you don't\nknow where on the object you are?",
        "start": 3213.084,
        "duration": 3.62
    },
    {
        "text": "that could be a low level action\npolicy, just as, keeping contact.",
        "start": 3217.274,
        "duration": 4.77
    },
    {
        "text": "Your finger just never comes off the\nsurface when you're touching an object.",
        "start": 3222.044,
        "duration": 4.26
    },
    {
        "text": "It just, it tracks on the server.",
        "start": 3226.854,
        "duration": 1.91
    },
    {
        "text": "I don't know how it does it.",
        "start": 3228.764,
        "duration": 2.34
    },
    {
        "text": "Yeah, so for example, in, in\nthe implementation side, we",
        "start": 3231.104,
        "duration": 2.93
    },
    {
        "text": "have some simple heuristics.",
        "start": 3234.034,
        "duration": 1.47
    },
    {
        "text": "And for example, if we do go off\nthe object, We don't send those",
        "start": 3235.534,
        "duration": 3.76
    },
    {
        "text": "observations to the learning module.",
        "start": 3239.334,
        "duration": 1.88
    },
    {
        "text": "We just perform some corrective\nmovements to go back on the surface.",
        "start": 3241.504,
        "duration": 3.34
    },
    {
        "text": "And then when we're there, we send\nit back to the learning module.",
        "start": 3244.864,
        "duration": 2.72
    },
    {
        "text": "Okay.",
        "start": 3248.014,
        "duration": 0.36
    },
    {
        "text": "Okay.",
        "start": 3248.464,
        "duration": 0.24
    },
    {
        "text": "Got it.",
        "start": 3248.754,
        "duration": 0.35
    },
    {
        "text": "I have a question.",
        "start": 3251.094,
        "duration": 1.11
    },
    {
        "text": "And how do you know that you're correctly\ntranslating this displacement from",
        "start": 3252.284,
        "duration": 4.46
    },
    {
        "text": "the real world objects to your graph?",
        "start": 3256.744,
        "duration": 1.96
    },
    {
        "text": "is this the reason why we're\nnot, invariant to scale now?",
        "start": 3259.424,
        "duration": 4.48
    },
    {
        "text": "I hope I understand the question.",
        "start": 3270.934,
        "duration": 1.95
    },
    {
        "text": "So we basically learned from a\nsmaller, cup of coffee and now you're",
        "start": 3274.374,
        "duration": 9.33
    },
    {
        "text": "traveling through a bigger one.",
        "start": 3283.704,
        "duration": 1.47
    },
    {
        "text": "So the displacement, It's\ngoing to be different.",
        "start": 3285.574,
        "duration": 3.68
    },
    {
        "text": "Yeah.",
        "start": 3290.194,
        "duration": 0.25
    },
    {
        "text": "yeah.",
        "start": 3291.464,
        "duration": 0.3
    },
    {
        "text": "So that's not going to work if\nthe cup now has a different size,",
        "start": 3291.764,
        "duration": 3.41
    },
    {
        "text": "we wouldn't recognize it only\nif it's a very similar size.",
        "start": 3295.204,
        "duration": 3.38
    },
    {
        "text": "but yeah.",
        "start": 3300.454,
        "duration": 0.75
    },
    {
        "text": "So the length of the\ndisplacement is fixed.",
        "start": 3301.204,
        "duration": 4.06
    },
    {
        "text": "And we're not going to test\nlike different lengths of it.",
        "start": 3305.739,
        "duration": 2.97
    },
    {
        "text": "I'm going to get to why I was, thinking\nbefore, if you'd also stored like the",
        "start": 3313.319,
        "duration": 4.7
    },
    {
        "text": "rate that the properties are changing\nalong the edges and you can basically,",
        "start": 3318.019,
        "duration": 2.59
    },
    {
        "text": "you can decide, of all the nodes that\nyou're at, it's which directions can",
        "start": 3320.619,
        "duration": 4.97
    },
    {
        "text": "you go in that graph that correspond\nto the actual change that you saw when",
        "start": 3325.589,
        "duration": 5.63
    },
    {
        "text": "you made your displacement, right?",
        "start": 3331.219,
        "duration": 1.8
    },
    {
        "text": "there's a matching.",
        "start": 3333.179,
        "duration": 0.94
    },
    {
        "text": "Delta in the properties that\nwill correspond to the transition",
        "start": 3335.629,
        "duration": 4.44
    },
    {
        "text": "from one node to another.",
        "start": 3340.069,
        "duration": 1.28
    },
    {
        "text": "Yeah.",
        "start": 3343.019,
        "duration": 0.39
    },
    {
        "text": "Yeah.",
        "start": 3343.409,
        "duration": 0.21
    },
    {
        "text": "That could be an idea.",
        "start": 3343.619,
        "duration": 2.65
    },
    {
        "text": "Yeah.",
        "start": 3346.289,
        "duration": 0.42
    },
    {
        "text": "Yeah.",
        "start": 3348.339,
        "duration": 0.25
    },
    {
        "text": "So scale here still, an open\nissue, how to best do it.",
        "start": 3348.589,
        "duration": 5.72
    },
    {
        "text": "Yeah.",
        "start": 3354.349,
        "duration": 0.2
    },
    {
        "text": "We could do the change in features.",
        "start": 3354.549,
        "duration": 2.55
    },
    {
        "text": "Yeah.",
        "start": 3357.099,
        "duration": 4.07
    },
    {
        "text": "Yeah.",
        "start": 3362.729,
        "duration": 0.29
    },
    {
        "text": "So in a lot of places, features\ndon't really change much.",
        "start": 3363.019,
        "duration": 5.1
    },
    {
        "text": "except for the point normals.",
        "start": 3368.509,
        "duration": 2.12
    },
    {
        "text": "But,",
        "start": 3371.299,
        "duration": 0.37
    },
    {
        "text": "yeah, one option, for example, is to re\nanchor the hypotheses and then use that to",
        "start": 3374.269,
        "duration": 7.98
    },
    {
        "text": "re scale how we scale the displacements.",
        "start": 3382.279,
        "duration": 2.52
    },
    {
        "text": "But yeah, we haven't\nreally figured it out.",
        "start": 3385.759,
        "duration": 3.2
    },
    {
        "text": "Another option could just be\nto learn models of different",
        "start": 3389.289,
        "duration": 2.85
    },
    {
        "text": "scales, separate models.",
        "start": 3392.139,
        "duration": 1.52
    },
    {
        "text": "And then if the scale is similar,\nit would still work because we",
        "start": 3396.469,
        "duration": 3.49
    },
    {
        "text": "have some slack, but yeah, we would\nhave to store separate models.",
        "start": 3399.969,
        "duration": 3.42
    },
    {
        "text": "not necessarily, because what you do\nis if you're moving along the evidence",
        "start": 3404.069,
        "duration": 3.63
    },
    {
        "text": "that your observation says that's\nproperty changed by this much, right?",
        "start": 3407.749,
        "duration": 4.36
    },
    {
        "text": "Then you could basically do a rescaling\nin the model saying, okay, if I were",
        "start": 3412.579,
        "duration": 3.77
    },
    {
        "text": "to go in this direction along the,\nthe graph, then, and I'm expecting a",
        "start": 3416.349,
        "duration": 4.11
    },
    {
        "text": "change this much in that direction, I\ncould actually, I could predict how far",
        "start": 3420.459,
        "duration": 5.0
    },
    {
        "text": "along the graph I'm actually moving.",
        "start": 3425.459,
        "duration": 1.48
    },
    {
        "text": "I may not be going one node.",
        "start": 3426.959,
        "duration": 1.5
    },
    {
        "text": "I may be going like two or three\nnodes along because I have more of",
        "start": 3428.459,
        "duration": 2.87
    },
    {
        "text": "a change in the feature than I was\nexpecting just going by one node.",
        "start": 3431.329,
        "duration": 4.12
    },
    {
        "text": "You can do some sort of auto\nalimentation or something like that.",
        "start": 3436.214,
        "duration": 3.45
    },
    {
        "text": "Yeah, I'd have to think about that one.",
        "start": 3442.304,
        "duration": 1.62
    },
    {
        "text": "I guess the question would be if\nit also works if we don't move",
        "start": 3444.674,
        "duration": 3.22
    },
    {
        "text": "continuously, but if we do, saccades\nfrom one location to another, for",
        "start": 3448.014,
        "duration": 4.95
    },
    {
        "text": "example, that would also work with it?",
        "start": 3452.964,
        "duration": 2.98
    },
    {
        "text": "it's interesting, with physical\nobjects, I'm not sure the",
        "start": 3457.684,
        "duration": 2.67
    },
    {
        "text": "scaling issue actually comes up.",
        "start": 3460.484,
        "duration": 3.19
    },
    {
        "text": "If you're always in real, coordinates,\nif it's a larger coffee cup, it's",
        "start": 3464.759,
        "duration": 5.0
    },
    {
        "text": "actually a different coffee cup.",
        "start": 3469.759,
        "duration": 1.2
    },
    {
        "text": "It's not the same coffee cup anymore, but\nit's more to the generalization that gets",
        "start": 3471.639,
        "duration": 5.21
    },
    {
        "text": "more to the generalization question of\nhow can we recognize similar morphologies.",
        "start": 3476.849,
        "duration": 4.57
    },
    {
        "text": "or something like that.",
        "start": 3482.074,
        "duration": 0.96
    },
    {
        "text": "But if it's the exact same, the coffee\ncup never changes in size, right?",
        "start": 3483.034,
        "duration": 5.89
    },
    {
        "text": "with the perception on our sensor may\nbe different, but as long as we're",
        "start": 3490.174,
        "duration": 2.76
    },
    {
        "text": "translating back into, real body\ncoordinates or real world coordinates,",
        "start": 3492.934,
        "duration": 5.16
    },
    {
        "text": "you're never actually going to see.",
        "start": 3498.714,
        "duration": 1.57
    },
    {
        "text": "a scaling issue.",
        "start": 3500.694,
        "duration": 1.0
    },
    {
        "text": "you argued it's a generalization issue.",
        "start": 3502.774,
        "duration": 1.63
    },
    {
        "text": "I think I understand that, but on the\nother hand, if I do see a miniature coffee",
        "start": 3504.424,
        "duration": 4.01
    },
    {
        "text": "cup, then I can make predictions based on\nmy previous model of a larger coffee cup.",
        "start": 3508.464,
        "duration": 4.97
    },
    {
        "text": "So somehow I'm able to bring in\na model that was learned at one",
        "start": 3513.434,
        "duration": 2.97
    },
    {
        "text": "scale to help me generalize.",
        "start": 3516.444,
        "duration": 2.45
    },
    {
        "text": "Yes, yeah, I think it's more of a\ngeneralization question rather than",
        "start": 3518.894,
        "duration": 4.13
    },
    {
        "text": "just recognizing the same object.",
        "start": 3523.424,
        "duration": 1.64
    },
    {
        "text": "Yeah, we could, you're still able to use\na model that was learned at one scale to",
        "start": 3525.929,
        "duration": 6.4
    },
    {
        "text": "inform a new model on a different scale.",
        "start": 3532.429,
        "duration": 2.72
    },
    {
        "text": "So they're not completely independent.",
        "start": 3535.959,
        "duration": 1.35
    },
    {
        "text": "Yeah, no, they're not.",
        "start": 3538.149,
        "duration": 0.99
    },
    {
        "text": "Yeah, exactly.",
        "start": 3539.139,
        "duration": 0.71
    },
    {
        "text": "And we have this goal of trying to\nrecognize morphologically similar",
        "start": 3539.889,
        "duration": 4.39
    },
    {
        "text": "objects and that when we think about\nit that way, it's not just scale, it",
        "start": 3544.799,
        "duration": 3.4
    },
    {
        "text": "could be other, small, distortions,\nthe, the top could be a little bit",
        "start": 3548.199,
        "duration": 4.88
    },
    {
        "text": "narrower, the bottom could be wider.",
        "start": 3553.139,
        "duration": 1.66
    },
    {
        "text": "It could be curved a little bit.",
        "start": 3555.239,
        "duration": 1.38
    },
    {
        "text": "There's all these other things that\ndefine similar quote unquote similarity,",
        "start": 3556.619,
        "duration": 4.29
    },
    {
        "text": "and scale is just one of those things.",
        "start": 3560.909,
        "duration": 1.77
    },
    {
        "text": "You know what, maybe it's obvious.",
        "start": 3562.889,
        "duration": 2.22
    },
    {
        "text": "It's not obvious to me.",
        "start": 3565.119,
        "duration": 2.2
    },
    {
        "text": "In vision, of course, we see\nthings at different scales all",
        "start": 3567.319,
        "duration": 2.3
    },
    {
        "text": "the time, different distances.",
        "start": 3569.619,
        "duration": 1.26
    },
    {
        "text": "And, That's automatically, we\nnever get confused by that.",
        "start": 3572.069,
        "duration": 4.05
    },
    {
        "text": "it was a small coffee shop.",
        "start": 3576.229,
        "duration": 1.25
    },
    {
        "text": "The coffee shop is just further away.",
        "start": 3577.479,
        "duration": 2.33
    },
    {
        "text": "I've never really quite understood that.",
        "start": 3580.439,
        "duration": 1.61
    },
    {
        "text": "So I'm just throwing that out here.",
        "start": 3582.079,
        "duration": 0.99
    },
    {
        "text": "That seems like it's going to be part of\nthe solution that we have to think about.",
        "start": 3583.069,
        "duration": 3.0
    },
    {
        "text": "That scale invariance can be actually\nthe actual size of the object.",
        "start": 3586.569,
        "duration": 3.03
    },
    {
        "text": "It's just your view behind scale, at\nleast when it comes to the vision.",
        "start": 3589.659,
        "duration": 2.65
    },
    {
        "text": "for like distance, for example, we\ndon't have that issue with the system",
        "start": 3594.154,
        "duration": 3.76
    },
    {
        "text": "because just from the depth image,\nit will just convert it to different",
        "start": 3597.914,
        "duration": 4.29
    },
    {
        "text": "X, Y, Z coordinates, but the scale in\nlike 3D space will still be the same.",
        "start": 3602.214,
        "duration": 5.22
    },
    {
        "text": "But yeah, exactly.",
        "start": 3607.894,
        "duration": 1.01
    },
    {
        "text": "Actually, what I was thinking is we could\nalso solve the scale issue with hierarchy.",
        "start": 3609.304,
        "duration": 4.3
    },
    {
        "text": "For example, if we learn models of\nmultiple size cylinders, separate models,",
        "start": 3613.604,
        "duration": 6.51
    },
    {
        "text": "but then we encode them with similar SDRs.",
        "start": 3620.114,
        "duration": 2.42
    },
    {
        "text": "And then a higher level model\ncan learn that a cylinder",
        "start": 3623.304,
        "duration": 3.75
    },
    {
        "text": "plus a handle is a coffee cup.",
        "start": 3627.084,
        "duration": 1.7
    },
    {
        "text": "It can get the SDR for small\ncylinder or larger cylinder.",
        "start": 3629.084,
        "duration": 3.27
    },
    {
        "text": "And both of them could be, if it gets\nthat plus the SDR for a handle, it could",
        "start": 3632.944,
        "duration": 6.11
    },
    {
        "text": "recognize small and big cups, for example.",
        "start": 3639.144,
        "duration": 3.16
    },
    {
        "text": "The problem with my argument is\nthat after the holidays, I think my",
        "start": 3651.169,
        "duration": 3.27
    },
    {
        "text": "dimensions have definitely changed.",
        "start": 3654.439,
        "duration": 1.71
    },
    {
        "text": "too much.",
        "start": 3659.264,
        "duration": 0.34
    },
    {
        "text": "My, my fail have increased",
        "start": 3660.384,
        "duration": 2.06
    },
    {
        "text": "okay.",
        "start": 3670.949,
        "duration": 0.21
    },
    {
        "text": "Should I go on with this for now?",
        "start": 3671.159,
        "duration": 2.25
    },
    {
        "text": "Yeah, Let's go.",
        "start": 3673.604,
        "duration": 0.975
    },
    {
        "text": "Okay, so now let's move again.",
        "start": 3675.559,
        "duration": 2.63
    },
    {
        "text": "So now we move to the right,\ninto the blue part of the model.",
        "start": 3678.249,
        "duration": 4.29
    },
    {
        "text": "So we got a different displacement\nthat points to the, right now",
        "start": 3683.319,
        "duration": 3.02
    },
    {
        "text": "our previous.",
        "start": 3688.779,
        "duration": 0.96
    },
    {
        "text": "where our previous hypothesis ended up.",
        "start": 3690.234,
        "duration": 2.5
    },
    {
        "text": "So at the end of all of these rotated\ndisplacements, this is now where we start.",
        "start": 3693.084,
        "duration": 5.53
    },
    {
        "text": "So we start at the end of the previous\ndisplacement for every hypothesis.",
        "start": 3699.724,
        "duration": 3.89
    },
    {
        "text": "And again, we do the same thing.",
        "start": 3704.444,
        "duration": 1.52
    },
    {
        "text": "We apply the displacement to, the\nrotation of all the hypotheses",
        "start": 3705.964,
        "duration": 4.83
    },
    {
        "text": "to the sense displacement.",
        "start": 3710.824,
        "duration": 1.44
    },
    {
        "text": "We again, get new search\nlocations in the model space.",
        "start": 3712.774,
        "duration": 3.6
    },
    {
        "text": "We compare the points in the model\nspace that are around the search",
        "start": 3718.564,
        "duration": 4.23
    },
    {
        "text": "locations to the sensed rotations and\nfeatures, and we update the evidence.",
        "start": 3722.794,
        "duration": 5.295
    },
    {
        "text": "And now we can already see that we\nhave a most likely hypothesis, which",
        "start": 3729.039,
        "duration": 4.13
    },
    {
        "text": "now is this having moved from here to\nhere, because only this sequence of",
        "start": 3733.199,
        "duration": 7.22
    },
    {
        "text": "starting here, moving upwards here,\nand then moving right here, matches",
        "start": 3740.749,
        "duration": 4.32
    },
    {
        "text": "with all the features that we have\nsensed, namely red, blue, and also the",
        "start": 3745.079,
        "duration": 5.28
    },
    {
        "text": "curvature staying constant, the convex.",
        "start": 3751.119,
        "duration": 2.88
    },
    {
        "text": "And then a lot of the other hypotheses,\nlike all of the ones that are",
        "start": 3754.629,
        "duration": 3.83
    },
    {
        "text": "completely off the object already, are\nvery, have very low evidence counts.",
        "start": 3758.989,
        "duration": 5.11
    },
    {
        "text": "And then some, like the ones that kind of\ngo around the object, are still likely.",
        "start": 3765.009,
        "duration": 5.42
    },
    {
        "text": "It might have been that we just sensed\none blue observation due to noise or",
        "start": 3770.789,
        "duration": 4.4
    },
    {
        "text": "whatever, so we might still be here, or\nthe cylinder might be upside down, we",
        "start": 3775.189,
        "duration": 5.47
    },
    {
        "text": "might have moved down, and then here,",
        "start": 3780.659,
        "duration": 2.42
    },
    {
        "text": "But yeah, we basically just\nadd the new evidence from this",
        "start": 3786.614,
        "duration": 3.59
    },
    {
        "text": "displacement and features to the\nexisting hypothesis evidence counts.",
        "start": 3790.244,
        "duration": 4.41
    },
    {
        "text": "Does that make sense?",
        "start": 3795.784,
        "duration": 1.4
    },
    {
        "text": "And you're exhaustively testing\nall the nodes in the graph as",
        "start": 3801.234,
        "duration": 3.62
    },
    {
        "text": "hypotheses for all of them.",
        "start": 3804.884,
        "duration": 1.39
    },
    {
        "text": "You're not like discarding like the ones\nthat are like completely implausible.",
        "start": 3806.284,
        "duration": 3.72
    },
    {
        "text": "Not right now.",
        "start": 3811.034,
        "duration": 0.82
    },
    {
        "text": "So since we can do this all with a\nsingle matrix multiplication, we just",
        "start": 3811.854,
        "duration": 6.28
    },
    {
        "text": "do it for all hypotheses every time.",
        "start": 3818.174,
        "duration": 2.34
    },
    {
        "text": "But There is an option in the\ncode to, say, we only want to",
        "start": 3820.794,
        "duration": 4.005
    },
    {
        "text": "test the n most likely ones, so\nonly the ones that have a positive",
        "start": 3824.799,
        "duration": 3.46
    },
    {
        "text": "evidence count or stuff like that.",
        "start": 3828.299,
        "duration": 1.95
    },
    {
        "text": "And we might actually do that and\ntry to use, some sparse matrix",
        "start": 3830.759,
        "duration": 3.95
    },
    {
        "text": "multiplications or something then.",
        "start": 3834.729,
        "duration": 1.64
    },
    {
        "text": "But, yeah, for now it's fast enough\nto just update all of them every time.",
        "start": 3836.829,
        "duration": 6.34
    },
    {
        "text": "In this matrix, is it, is, what\nis, what are the rows and columns?",
        "start": 3849.849,
        "duration": 4.16
    },
    {
        "text": "I",
        "start": 3858.599,
        "duration": 0.16
    },
    {
        "text": "mean, it seems like you\nget the reason I'm asking.",
        "start": 3861.079,
        "duration": 2.41
    },
    {
        "text": "It seems like it's not\nreally a sparse matrix.",
        "start": 3863.489,
        "duration": 2.47
    },
    {
        "text": "You might be just eliminating rows and\ncolumns as you eliminate hypotheses.",
        "start": 3865.959,
        "duration": 5.58
    },
    {
        "text": "Or are you actually eliminating\nindividual cells within the matrix?",
        "start": 3872.069,
        "duration": 4.35
    },
    {
        "text": "Because if you're eliminating full\nrows, it's a much easier optimization.",
        "start": 3877.549,
        "duration": 4.235
    },
    {
        "text": "You don't need to worry about\nsparse matrix optimizations.",
        "start": 3881.784,
        "duration": 1.83
    },
    {
        "text": "Yeah.",
        "start": 3887.324,
        "duration": 0.6
    },
    {
        "text": "let me get back on to you on that.",
        "start": 3890.404,
        "duration": 2.43
    },
    {
        "text": "I don't have it on, up off the top of my\nhead what the dimensions are right now.",
        "start": 3894.564,
        "duration": 4.71
    },
    {
        "text": "Okay.",
        "start": 3900.004,
        "duration": 0.33
    },
    {
        "text": "That's all right.",
        "start": 3900.424,
        "duration": 0.39
    },
    {
        "text": "Yeah, figure.",
        "start": 3900.814,
        "duration": 1.23
    },
    {
        "text": "Yeah, I, my, my guess is you're\neliminating rose or columns",
        "start": 3902.254,
        "duration": 3.45
    },
    {
        "text": "and in that case it's much\neasier to optimize that, right?",
        "start": 3906.924,
        "duration": 4.99
    },
    {
        "text": "Yeah.",
        "start": 3911.914,
        "duration": 0.3
    },
    {
        "text": "Yeah, so basically this\nprocedure gets repeated at",
        "start": 3918.309,
        "duration": 2.98
    },
    {
        "text": "every step after every movement.",
        "start": 3921.309,
        "duration": 1.84
    },
    {
        "text": "We look at the displacement, we\napply the hypothesized rotations",
        "start": 3924.079,
        "duration": 4.62
    },
    {
        "text": "to it, and we check the sensed\nfeatures with the features stored in",
        "start": 3928.699,
        "duration": 4.94
    },
    {
        "text": "the model and update the evidence.",
        "start": 3933.639,
        "duration": 1.63
    },
    {
        "text": "Yeah, and this is how it looks in reality.",
        "start": 3938.329,
        "duration": 2.05
    },
    {
        "text": "So here we see the displacements\nthat we sensed up here.",
        "start": 3940.389,
        "duration": 4.8
    },
    {
        "text": "This is the viewfinder, this is the\nsensor patch, so what we actually use.",
        "start": 3945.489,
        "duration": 3.07
    },
    {
        "text": "And then these are three,\nfour models in memory.",
        "start": 3949.059,
        "duration": 2.46
    },
    {
        "text": "and how the evidence gets updated.",
        "start": 3952.244,
        "duration": 2.08
    },
    {
        "text": "And for example, for the dice,\nwhich is a small object, all",
        "start": 3954.414,
        "duration": 4.14
    },
    {
        "text": "the hypotheses are already far\noff the model and very unlikely.",
        "start": 3958.554,
        "duration": 3.46
    },
    {
        "text": "Also, after moving down the mug and\nthen on the bottom, we also already",
        "start": 3962.504,
        "duration": 6.32
    },
    {
        "text": "made almost all hypotheses on the\nbowl and on the banana very unlikely.",
        "start": 3969.474,
        "duration": 3.89
    },
    {
        "text": "and then on the mug, since it's pretty\nsymmetrical, we have a red ring of likely",
        "start": 3975.014,
        "duration": 6.72
    },
    {
        "text": "places, that kind of moves up, up, up\nthe cup as we are moving up the cup.",
        "start": 3981.744,
        "duration": 5.57
    },
    {
        "text": "and we have a most likely\nhypothesis at every step.",
        "start": 3989.754,
        "duration": 3.59
    },
    {
        "text": "Which right now is already\nthe correct hypothesis.",
        "start": 3994.114,
        "duration": 2.5
    },
    {
        "text": "I'm just letting it run for a\nwhile to have this visualization.",
        "start": 3996.614,
        "duration": 4.5
    },
    {
        "text": "and yeah, we just move and after\nevery movement, we update these,",
        "start": 4004.604,
        "duration": 3.56
    },
    {
        "text": "locations and evidence counts",
        "start": 4009.854,
        "duration": 2.06
    },
    {
        "text": "until we recognize the object.",
        "start": 4014.754,
        "duration": 2.19
    },
    {
        "text": "And then another example is the dice.",
        "start": 4017.454,
        "duration": 3.02
    },
    {
        "text": "So we move on the dice.",
        "start": 4021.114,
        "duration": 1.39
    },
    {
        "text": "here's the sensor patch.",
        "start": 4022.994,
        "duration": 1.47
    },
    {
        "text": "That's what the sensor module sees.",
        "start": 4024.544,
        "duration": 2.29
    },
    {
        "text": "The model never sees this wide view that\nis here, it's just for visualization.",
        "start": 4027.474,
        "duration": 3.98
    },
    {
        "text": "And then already after a few moves, the\nlarge objects are pretty much excluded.",
        "start": 4032.144,
        "duration": 4.5
    },
    {
        "text": "And then the dice is quite\nsymmetrical, so we have a lot of,",
        "start": 4037.074,
        "duration": 5.52
    },
    {
        "text": "positive evidence on\neach side of the dice.",
        "start": 4044.614,
        "duration": 3.29
    },
    {
        "text": "But we also already have a pretty stable,\nmost likely hypothesis after a few steps.",
        "start": 4048.224,
        "duration": 4.38
    },
    {
        "text": "And you can see it's not the correct one\nactually, the target is 90, 0, 180, but",
        "start": 4053.384,
        "duration": 5.01
    },
    {
        "text": "the most likely one is, minus 90, 0, 0.",
        "start": 4058.654,
        "duration": 4.44
    },
    {
        "text": "And if we look how this one would look\nlike, it's, yeah, over here, it's, it",
        "start": 4063.474,
        "duration": 5.95
    },
    {
        "text": "basically looks the same, it's, and,\nin this episode, the learning module",
        "start": 4069.434,
        "duration": 4.77
    },
    {
        "text": "actually detects symmetry, so it, reach\nthe terminal condition, by detecting",
        "start": 4074.224,
        "duration": 5.675
    },
    {
        "text": "symmetry between those two poses.",
        "start": 4079.909,
        "duration": 2.61
    },
    {
        "text": "So then it, it says actually this one\nis the most likely one, but, yeah,",
        "start": 4082.529,
        "duration": 5.33
    },
    {
        "text": "notice this, it is a symmetrical object.",
        "start": 4088.239,
        "duration": 2.25
    },
    {
        "text": "Okay.",
        "start": 4095.139,
        "duration": 0.22
    },
    {
        "text": "Does that make sense before\nI go to multiple patches?",
        "start": 4095.359,
        "duration": 2.66
    },
    {
        "text": "Yeah, can we, is there a notion of,\nuncertainty that if you have a couple",
        "start": 4099.169,
        "duration": 5.92
    },
    {
        "text": "of hypotheses that are really high\nand everything else is low, then it",
        "start": 4105.089,
        "duration": 2.96
    },
    {
        "text": "can be a little more certain, but\nif everything is close to equal,",
        "start": 4108.049,
        "duration": 3.76
    },
    {
        "text": "then the most likely hypothesis is\nnot going to be very likely, right?",
        "start": 4112.439,
        "duration": 5.6
    },
    {
        "text": "Yeah, We do use so we have a list of\nwhat is all still possible and I'm",
        "start": 4120.089,
        "duration": 8.125
    },
    {
        "text": "going to get to that a bit later.",
        "start": 4128.214,
        "duration": 1.47
    },
    {
        "text": "So in this case it would still\nconsider we still have a lot of",
        "start": 4129.684,
        "duration": 3.43
    },
    {
        "text": "possible locations on this dice.",
        "start": 4133.134,
        "duration": 1.94
    },
    {
        "text": "it doesn't only look\nat the most likely one.",
        "start": 4138.864,
        "duration": 2.71
    },
    {
        "text": "it's, we still look at all the ones\nthat are, that have the highest",
        "start": 4141.764,
        "duration": 3.975
    },
    {
        "text": "evidence counts, and that kind of gives\nthe notion of uncertainty in a way.",
        "start": 4145.749,
        "duration": 5.29
    },
    {
        "text": "Does that make sense?",
        "start": 4151.429,
        "duration": 0.62
    },
    {
        "text": "yeah, I was just thinking more in a\npractical scenario, you have to make",
        "start": 4156.859,
        "duration": 3.61
    },
    {
        "text": "some decision, so you'll want to use the\nmost likely hypothesis, but there may be",
        "start": 4160.479,
        "duration": 6.03
    },
    {
        "text": "cases where you're not very confident,\nother cases where you are more confident.",
        "start": 4166.509,
        "duration": 3.9
    },
    {
        "text": "Yeah, so you could just look at how many\nother possible hypotheses do we have.",
        "start": 4171.399,
        "duration": 4.43
    },
    {
        "text": "Yeah, and then if that's a lot,\nthen it might be less confidence",
        "start": 4176.189,
        "duration": 6.68
    },
    {
        "text": "in the most likely hypothesis.",
        "start": 4182.869,
        "duration": 1.55
    },
    {
        "text": "That's what we use as the terminal\ncondition, that we need to have",
        "start": 4186.559,
        "duration": 3.86
    },
    {
        "text": "very few possible, only one possible\nhypothesis or very few similar ones",
        "start": 4190.709,
        "duration": 4.04
    },
    {
        "text": "to say, to actually classify the\nobject and end the matching procedure.",
        "start": 4195.189,
        "duration": 4.51
    },
    {
        "text": "yeah, oh yeah, let me move on\nfor the company meeting starts.",
        "start": 4206.109,
        "duration": 4.21
    },
    {
        "text": "So yeah, this is a multiple\nsensor patches now.",
        "start": 4211.109,
        "duration": 2.79
    },
    {
        "text": "here we have one agent, and it has five\npatches attached to it, and the patches",
        "start": 4214.804,
        "duration": 5.56
    },
    {
        "text": "can have different locations, they can\nhave different zoom values, so they can",
        "start": 4220.364,
        "duration": 5.48
    },
    {
        "text": "be larger or smaller, and they can have\ndifferent resolutions, for example.",
        "start": 4225.844,
        "duration": 3.13
    },
    {
        "text": "And, yeah, they all move together.",
        "start": 4230.904,
        "duration": 2.21
    },
    {
        "text": "So the agent moves, all those sensor\npatches move together and sync, even",
        "start": 4233.439,
        "duration": 5.82
    },
    {
        "text": "though where they are in 3d space can\nvary radically since yeah, some can be",
        "start": 4239.259,
        "duration": 5.57
    },
    {
        "text": "like here on the rim and then others can\nbe on the inside of the cup, which in 3d",
        "start": 4244.829,
        "duration": 3.61
    },
    {
        "text": "space can be far apart from each other.",
        "start": 4248.439,
        "duration": 2.305
    },
    {
        "text": "And then, yeah, each sensor patch sends\nits raw observations to the sensor",
        "start": 4254.024,
        "duration": 4.83
    },
    {
        "text": "module, which again turns it into\nfeatures and a pose that gets sent to",
        "start": 4258.954,
        "duration": 5.01
    },
    {
        "text": "the learning modules and learning modules\noutput a most likely object and pose",
        "start": 4263.964,
        "duration": 4.79
    },
    {
        "text": "at every step and then have lateral\nvoting connections between each other.",
        "start": 4268.874,
        "duration": 4.87
    },
    {
        "text": "And those voting connections\ncan speed up object recognition.",
        "start": 4274.054,
        "duration": 3.92
    },
    {
        "text": "So how does the voting work?",
        "start": 4279.674,
        "duration": 1.58
    },
    {
        "text": "in this example we have two sensors.",
        "start": 4283.484,
        "duration": 2.575
    },
    {
        "text": "One senses the rim of the cup here and the\nother one senses the handle of the cup.",
        "start": 4286.229,
        "duration": 3.98
    },
    {
        "text": "They send their features and poses\nto the learning modules and then",
        "start": 4290.839,
        "duration": 3.93
    },
    {
        "text": "have their first evidence counts.",
        "start": 4294.859,
        "duration": 3.96
    },
    {
        "text": "So now this one would think it's most\nlikely that we are either on the top",
        "start": 4298.844,
        "duration": 4.08
    },
    {
        "text": "of the cup or on the bottom of the cup,\ngiven the sensed color and curvature.",
        "start": 4303.384,
        "duration": 6.64
    },
    {
        "text": "And then this one would say it's\nmost likely that we're either on",
        "start": 4311.044,
        "duration": 3.28
    },
    {
        "text": "the top or on the bottom corner\nof the handle, given the color and",
        "start": 4314.324,
        "duration": 5.14
    },
    {
        "text": "curvature that we're sensing here.",
        "start": 4319.654,
        "duration": 1.84
    },
    {
        "text": "And now we're going to do an example\nof the first learning module,",
        "start": 4322.474,
        "duration": 4.03
    },
    {
        "text": "sending a vote to the second one.",
        "start": 4326.534,
        "duration": 2.41
    },
    {
        "text": "So in order to do that, we first have\nto transform all the hypotheses from",
        "start": 4331.944,
        "duration": 6.7
    },
    {
        "text": "this learning module space into this\nlearning module space, and for that",
        "start": 4338.644,
        "duration": 5.02
    },
    {
        "text": "we calculate the sensor displacement\nbetween this finger and this finger.",
        "start": 4343.704,
        "duration": 5.41
    },
    {
        "text": "So what's the displacement between\nthis sensed pose and this sensed pose?",
        "start": 4349.544,
        "duration": 4.81
    },
    {
        "text": "And then that displacement gets\napplied to all of these points.",
        "start": 4355.344,
        "duration": 3.53
    },
    {
        "text": "and we have them in this model space.",
        "start": 4359.509,
        "duration": 2.08
    },
    {
        "text": "That basically says, for every\nhypothesis here, if we say, okay,",
        "start": 4362.299,
        "duration": 5.59
    },
    {
        "text": "it says, if I would be here, then\ngiven our sensor displacement,",
        "start": 4367.889,
        "duration": 5.93
    },
    {
        "text": "your sensor should be over here.",
        "start": 4374.199,
        "duration": 2.43
    },
    {
        "text": "And then it sends a\nvote for this location.",
        "start": 4376.949,
        "duration": 2.42
    },
    {
        "text": "And it does that for\nall of its hypothesis.",
        "start": 4380.239,
        "duration": 1.99
    },
    {
        "text": "And for most of them, it will be\nfar off the model in this case.",
        "start": 4382.249,
        "duration": 4.37
    },
    {
        "text": "So if it says, if I would start here,\nthen your sensor should be over here.",
        "start": 4386.629,
        "duration": 5.465
    },
    {
        "text": "It would expect a handle on the\nother side of the cup, for example.",
        "start": 4393.194,
        "duration": 2.75
    },
    {
        "text": "Does that make sense?",
        "start": 4396.764,
        "duration": 0.79
    },
    {
        "text": "I'm a bit confused.",
        "start": 4401.134,
        "duration": 0.71
    },
    {
        "text": "What is actually being sent?",
        "start": 4401.884,
        "duration": 1.99
    },
    {
        "text": "The",
        "start": 4405.294,
        "duration": 1.83
    },
    {
        "text": "possible poses are being\nsent and the evidence.",
        "start": 4409.484,
        "duration": 3.62
    },
    {
        "text": "Bottom arrow.",
        "start": 4413.514,
        "duration": 0.73
    },
    {
        "text": "Where is the sensor displacement?",
        "start": 4415.524,
        "duration": 2.38
    },
    {
        "text": "So we take all the possible poses\nand their evidence and we transform",
        "start": 4422.994,
        "duration": 5.32
    },
    {
        "text": "the poses by the sensor displacement.",
        "start": 4428.314,
        "duration": 2.38
    },
    {
        "text": "And who had, but the learning module\non the left does not know the sensor",
        "start": 4432.484,
        "duration": 5.21
    },
    {
        "text": "displacement of the learning module\non the right, or where is the sensor",
        "start": 4437.694,
        "duration": 3.6
    },
    {
        "text": "displacement, in this case it's\nfixed right this is like to pass",
        "start": 4441.294,
        "duration": 3.89
    },
    {
        "text": "it on the retina so they're fixed\nright displacement into the sensor.",
        "start": 4445.184,
        "duration": 4.17
    },
    {
        "text": "It's not.",
        "start": 4450.564,
        "duration": 0.65
    },
    {
        "text": "No, it's not fixed because We are\nlooking at locations in space, so one",
        "start": 4451.634,
        "duration": 6.345
    },
    {
        "text": "patch might be like offset like we\nsaw in this example here, one might",
        "start": 4457.979,
        "duration": 4.44
    },
    {
        "text": "be inside the cup, So you're, oh maybe\nyou're just saying that we know, you're",
        "start": 4462.419,
        "duration": 4.11
    },
    {
        "text": "just giving, we assume we know the\ndisplacement between the sensors, is that?",
        "start": 4466.529,
        "duration": 3.32
    },
    {
        "text": "Yeah, the system knows, it's clear\nthe system knows, but I'm wondering",
        "start": 4470.399,
        "duration": 3.74
    },
    {
        "text": "where is that in the learning module,\nYeah, the learning modules don't know",
        "start": 4475.369,
        "duration": 4.61
    },
    {
        "text": "this, but the Monty model knows this.",
        "start": 4479.979,
        "duration": 2.31
    },
    {
        "text": "So Monty basically handles the vote, like\nMonty handles all the communication and",
        "start": 4482.869,
        "duration": 5.8
    },
    {
        "text": "it handles transforming the vote from\nhere to here and Monty just calculates the",
        "start": 4488.669,
        "duration": 5.96
    },
    {
        "text": "sensor displacement from the difference\nbetween this pose and this pose.",
        "start": 4494.629,
        "duration": 4.89
    },
    {
        "text": "Okay.",
        "start": 4500.839,
        "duration": 0.28
    },
    {
        "text": "Yeah.",
        "start": 4501.119,
        "duration": 0.18
    },
    {
        "text": "I think that was my confusion.",
        "start": 4501.299,
        "duration": 1.31
    },
    {
        "text": "in the brain, it would be within\nthe cortical column somewhere.",
        "start": 4504.289,
        "duration": 2.62
    },
    {
        "text": "It wouldn't be some,",
        "start": 4506.909,
        "duration": 0.86
    },
    {
        "text": "it wouldn't be some external system,\nit's interesting question about that.",
        "start": 4510.019,
        "duration": 4.31
    },
    {
        "text": "It's not clear.",
        "start": 4515.319,
        "duration": 0.83
    },
    {
        "text": "there's all kinds of\nevidence that there's,",
        "start": 4516.419,
        "duration": 3.25
    },
    {
        "text": "there might be certain intermediaries\ndetermining this stuff, but I don't",
        "start": 4522.964,
        "duration": 3.88
    },
    {
        "text": "know if we have to talk about it here.",
        "start": 4526.844,
        "duration": 1.902
    },
    {
        "text": "No, because if you have 100, 000\ncortical columns, there's 100, 000",
        "start": 4528.746,
        "duration": 3.298
    },
    {
        "text": "squared relative displacements.",
        "start": 4532.044,
        "duration": 2.95
    },
    {
        "text": "Yeah, but actually It's a huge number, but\nRight, but Actually, let me correct this.",
        "start": 4535.304,
        "duration": 5.41
    },
    {
        "text": "in the implementation, actually,\nthis learning module, when it sends",
        "start": 4542.204,
        "duration": 2.98
    },
    {
        "text": "the vote, it also sends its pose.",
        "start": 4545.184,
        "duration": 2.45
    },
    {
        "text": "So it sends all of those Plus this,\nand then the receiving learning",
        "start": 4548.524,
        "duration": 3.865
    },
    {
        "text": "module can use, the pose of that one.",
        "start": 4552.389,
        "duration": 3.4
    },
    {
        "text": "It communicates to it to\ncalculate the displacement.",
        "start": 4555.789,
        "duration": 2.82
    },
    {
        "text": "okay.",
        "start": 4559.169,
        "duration": 0.06
    },
    {
        "text": "Yeah, that makes sense.",
        "start": 4559.499,
        "duration": 0.78
    },
    {
        "text": "That makes sense.",
        "start": 4560.279,
        "duration": 0.51
    },
    {
        "text": "Yeah.",
        "start": 4561.354,
        "duration": 0.29
    },
    {
        "text": "Yeah.",
        "start": 4561.649,
        "duration": 0.07
    },
    {
        "text": "That, that would work.",
        "start": 4561.719,
        "duration": 0.72
    },
    {
        "text": "I'm sorry.",
        "start": 4563.044,
        "duration": 0.3
    },
    {
        "text": "That sense?",
        "start": 4563.344,
        "duration": 0.6
    },
    {
        "text": "Okay.",
        "start": 4565.289,
        "duration": 0.18
    },
    {
        "text": "Yeah.",
        "start": 4565.469,
        "duration": 0.18
    },
    {
        "text": "Sorry about that.",
        "start": 4565.649,
        "duration": 0.75
    },
    {
        "text": "yeah, and so the receiving learning\nmodule is the one that then transforms",
        "start": 4569.219,
        "duration": 4.05
    },
    {
        "text": "all of the other cortical other learning\nmodules, hypotheses into its own,",
        "start": 4573.269,
        "duration": 7.595
    },
    {
        "text": "reference in own models.",
        "start": 4584.384,
        "duration": 1.525
    },
    {
        "text": "Reference is not the right word, but yeah.",
        "start": 4586.594,
        "duration": 2.78
    },
    {
        "text": "Its own model, reference frame.",
        "start": 4589.874,
        "duration": 1.865
    },
    {
        "text": "Yeah.",
        "start": 4591.739,
        "duration": 0.21
    },
    {
        "text": "Yeah.",
        "start": 4592.084,
        "duration": 0.29
    },
    {
        "text": "Okay.",
        "start": 4592.374,
        "duration": 0.001
    },
    {
        "text": "Yeah.",
        "start": 4595.269,
        "duration": 0.24
    },
    {
        "text": "Sorry.",
        "start": 4595.509,
        "duration": 0.3
    },
    {
        "text": "Sometimes I also forget these details.",
        "start": 4595.809,
        "duration": 2.1
    },
    {
        "text": "yeah.",
        "start": 4601.309,
        "duration": 0.18
    },
    {
        "text": "And yeah, so this displacement is also\ndifferent if it gets a vote now from a",
        "start": 4601.489,
        "duration": 4.14
    },
    {
        "text": "different learning module, for example.",
        "start": 4605.629,
        "duration": 1.74
    },
    {
        "text": "Then it has to apply a different\ntransform to those votes to",
        "start": 4609.209,
        "duration": 4.55
    },
    {
        "text": "get them in the same space.",
        "start": 4613.759,
        "duration": 1.3
    },
    {
        "text": "yeah, and then we have all these votes\nhere in the models reference frame and",
        "start": 4619.839,
        "duration": 4.1
    },
    {
        "text": "we can use them to update the hypotheses.",
        "start": 4623.939,
        "duration": 1.98
    },
    {
        "text": "So basically to do that, we go through\nall these points that are stored in",
        "start": 4626.349,
        "duration": 5.25
    },
    {
        "text": "the receiving learning modules model.",
        "start": 4631.599,
        "duration": 2.07
    },
    {
        "text": "And we again use a search\nradius same way as before.",
        "start": 4633.669,
        "duration": 4.81
    },
    {
        "text": "We look at all the points in\nthe search radius and then take",
        "start": 4638.529,
        "duration": 4.5
    },
    {
        "text": "the weighted average of them.",
        "start": 4643.029,
        "duration": 1.36
    },
    {
        "text": "To add evidence here.",
        "start": 4645.434,
        "duration": 1.31
    },
    {
        "text": "And we scaled this to\nrange of minus one to one.",
        "start": 4646.744,
        "duration": 3.42
    },
    {
        "text": "and yeah, just add that\nto the evidence count.",
        "start": 4652.644,
        "duration": 2.41
    },
    {
        "text": "And then now after this voting update,\nin this case, we would have the",
        "start": 4655.084,
        "duration": 4.1
    },
    {
        "text": "highest evidence for the top panel\nbecause only that is getting high",
        "start": 4659.184,
        "duration": 7.24
    },
    {
        "text": "evidence from the voting connections\nand had high evidence before.",
        "start": 4666.424,
        "duration": 3.45
    },
    {
        "text": "Does that make sense?",
        "start": 4674.324,
        "duration": 1.03
    },
    {
        "text": "Yeah.",
        "start": 4677.764,
        "duration": 0.37
    },
    {
        "text": "Okay, cool.",
        "start": 4681.454,
        "duration": 0.64
    },
    {
        "text": "yeah.",
        "start": 4682.734,
        "duration": 0.46
    },
    {
        "text": "Okay.",
        "start": 4683.304,
        "duration": 0.4
    },
    {
        "text": "Almost done.",
        "start": 4684.944,
        "duration": 0.55
    },
    {
        "text": "So now,",
        "start": 4686.174,
        "duration": 0.67
    },
    {
        "text": "most likely hypothesis\nand possible matches.",
        "start": 4689.044,
        "duration": 2.21
    },
    {
        "text": "We already mentioned that before.",
        "start": 4691.264,
        "duration": 1.75
    },
    {
        "text": "So basically we have the evidence for\nall the possible poses of an object, and",
        "start": 4695.064,
        "duration": 4.76
    },
    {
        "text": "then from this, if we take the maximum\nout of that is the object's evidence,",
        "start": 4699.824,
        "duration": 4.47
    },
    {
        "text": "and the maximum of that would be the\nmost likely object, in this case the",
        "start": 4705.724,
        "duration": 3.46
    },
    {
        "text": "mug, and then the maximum of the poses\nwithin that would be the most likely pose.",
        "start": 4709.184,
        "duration": 5.02
    },
    {
        "text": "And then to get the possible matches\nwe can threshold this, So we say",
        "start": 4715.854,
        "duration": 5.44
    },
    {
        "text": "everything, so we look at the maximum\nevidence here, and then everything",
        "start": 4721.934,
        "duration": 5.73
    },
    {
        "text": "that's the maximum evidence minus x\npercent of it, for example, minus 20",
        "start": 4727.664,
        "duration": 4.94
    },
    {
        "text": "percent of it, is considered possible.",
        "start": 4732.604,
        "duration": 2.46
    },
    {
        "text": "So everything that is very similar\nto the highest evidence count",
        "start": 4736.149,
        "duration": 3.05
    },
    {
        "text": "is also considered possible.",
        "start": 4739.209,
        "duration": 1.81
    },
    {
        "text": "In this case, for example, we\nwould say the mug and this larger",
        "start": 4741.959,
        "duration": 4.61
    },
    {
        "text": "cylinder are still possible.",
        "start": 4746.569,
        "duration": 1.69
    },
    {
        "text": "And then also for the poles, we can apply\nthe same thresholding, saying everything",
        "start": 4749.029,
        "duration": 5.87
    },
    {
        "text": "20 percent below the maximum is possible.",
        "start": 4754.979,
        "duration": 2.39
    },
    {
        "text": "And as you might see here, orange is, so\nboth of these are orange, but in the mug,",
        "start": 4757.989,
        "duration": 8.38
    },
    {
        "text": "all of these points are not considered\npossible anymore because They're too",
        "start": 4766.679,
        "duration": 4.12
    },
    {
        "text": "far off from the maximum evidence count,\nso here we would only consider these.",
        "start": 4770.799,
        "duration": 3.97
    },
    {
        "text": "I don't know how well you can see\nthe colors, those are darker red,",
        "start": 4775.209,
        "duration": 3.1
    },
    {
        "text": "dark red, and those are orange.",
        "start": 4778.489,
        "duration": 1.46
    },
    {
        "text": "While in the cylinders, all the orange\npoints are all considered possible",
        "start": 4780.719,
        "duration": 3.78
    },
    {
        "text": "because they're all about equally likely.",
        "start": 4784.519,
        "duration": 2.1
    },
    {
        "text": "And then if there are no positive\nevidence values on an object, it is",
        "start": 4788.419,
        "duration": 5.56
    },
    {
        "text": "generally not considered possible.",
        "start": 4793.979,
        "duration": 1.79
    },
    {
        "text": "does that make sense?",
        "start": 4799.289,
        "duration": 0.88
    },
    {
        "text": "Oh, yeah.",
        "start": 4801.599,
        "duration": 0.66
    },
    {
        "text": "Yeah, and this threshold is that\nyou said is a dynamic threshold.",
        "start": 4802.299,
        "duration": 3.36
    },
    {
        "text": "It's based on the max evidence.",
        "start": 4805.759,
        "duration": 2.09
    },
    {
        "text": "Yes, based on the maximum evidence.",
        "start": 4807.889,
        "duration": 1.98
    },
    {
        "text": "And then we, it's like a parameter\nwhere you sent the percentage",
        "start": 4809.909,
        "duration": 3.49
    },
    {
        "text": "below the maximum that is allowed.",
        "start": 4814.169,
        "duration": 1.71
    },
    {
        "text": "So the larger you set this percentage\nvalue, the more certain you need to be",
        "start": 4816.379,
        "duration": 4.0
    },
    {
        "text": "an object to reach a terminal condition.",
        "start": 4820.399,
        "duration": 2.11
    },
    {
        "text": "Basically to say there's only one possible\nobject because it's so much significantly",
        "start": 4822.509,
        "duration": 5.11
    },
    {
        "text": "more likely than all the other objects.",
        "start": 4827.629,
        "duration": 2.2
    },
    {
        "text": "Seems like there are a few things\nthere, but it seems like a bunch",
        "start": 4839.234,
        "duration": 3.91
    },
    {
        "text": "of choices there which potentially\ncould investigate a little bit more.",
        "start": 4843.144,
        "duration": 4.28
    },
    {
        "text": "yeah, definitely.",
        "start": 4848.794,
        "duration": 1.02
    },
    {
        "text": "and there's also, yeah,\nso there are two versions.",
        "start": 4850.224,
        "duration": 2.69
    },
    {
        "text": "One is where the evidence value can\ngrow infinitely, and then there's",
        "start": 4852.914,
        "duration": 4.01
    },
    {
        "text": "another option where we can, we have\nthe evidence bounded by weighing the",
        "start": 4856.924,
        "duration": 5.25
    },
    {
        "text": "past compared to the previous evidence.",
        "start": 4862.174,
        "duration": 2.66
    },
    {
        "text": "Okay.",
        "start": 4864.834,
        "duration": 0.08
    },
    {
        "text": "compared to the current evidence.",
        "start": 4865.304,
        "duration": 1.31
    },
    {
        "text": "And if the evidence is bounded in\na certain range, we can also just",
        "start": 4866.904,
        "duration": 2.96
    },
    {
        "text": "use a fixed value threshold, for\nexample, instead of having to,",
        "start": 4869.864,
        "duration": 3.85
    },
    {
        "text": "make it dependent on the maximum.",
        "start": 4873.954,
        "duration": 1.54
    },
    {
        "text": "Yeah.",
        "start": 4876.154,
        "duration": 0.44
    },
    {
        "text": "Or maybe use a softmax or something.",
        "start": 4876.964,
        "duration": 1.66
    },
    {
        "text": "Yeah.",
        "start": 4879.404,
        "duration": 0.31
    },
    {
        "text": "Okay.",
        "start": 4883.484,
        "duration": 0.21
    },
    {
        "text": "Lastly, real quick, we also\nneed to define a terminal state.",
        "start": 4883.734,
        "duration": 4.54
    },
    {
        "text": "So when do we end an episode?",
        "start": 4888.274,
        "duration": 2.07
    },
    {
        "text": "and we have three\ndifferent terminal states.",
        "start": 4892.434,
        "duration": 2.86
    },
    {
        "text": "One is timeout.",
        "start": 4895.294,
        "duration": 0.79
    },
    {
        "text": "We took too many steps.",
        "start": 4896.154,
        "duration": 1.48
    },
    {
        "text": "one is no match and one is match.",
        "start": 4898.414,
        "duration": 1.57
    },
    {
        "text": "So if.",
        "start": 4900.914,
        "duration": 0.63
    },
    {
        "text": "We have no possible matches anymore, so\nall of the evidence counts are negative,",
        "start": 4902.684,
        "duration": 5.37
    },
    {
        "text": "we say no match, and we create a new\ngraph in memory and learn a new object.",
        "start": 4908.844,
        "duration": 3.69
    },
    {
        "text": "If we do have possible matches,\nand we look at all of the learning",
        "start": 4914.064,
        "duration": 4.85
    },
    {
        "text": "modules, so this check is now done for\nall learning modules in the system,",
        "start": 4918.924,
        "duration": 3.19
    },
    {
        "text": "we check if the number of\npossible matches is one, so do",
        "start": 4924.714,
        "duration": 3.34
    },
    {
        "text": "we only have one possible object?",
        "start": 4928.054,
        "duration": 1.95
    },
    {
        "text": "If no, we set pose to none,\nI'll get back to that later.",
        "start": 4931.434,
        "duration": 3.88
    },
    {
        "text": "If we do have only one possible object,\nWe look at if the evidence for this object",
        "start": 4935.834,
        "duration": 4.92
    },
    {
        "text": "is above the minimum required evidence.",
        "start": 4940.754,
        "duration": 2.74
    },
    {
        "text": "If yes, we look at all the possible\nposes within that object, and",
        "start": 4944.694,
        "duration": 4.76
    },
    {
        "text": "we see how many possible poses\ndo we have within that object.",
        "start": 4949.454,
        "duration": 3.14
    },
    {
        "text": "if all of the possible poses\nhave a very similar location,",
        "start": 4956.364,
        "duration": 4.52
    },
    {
        "text": "we say the location is unique.",
        "start": 4961.324,
        "duration": 1.58
    },
    {
        "text": "If all the possible poses have\na similar rotation, we say",
        "start": 4963.594,
        "duration": 2.65
    },
    {
        "text": "that the rotation is unique.",
        "start": 4966.244,
        "duration": 1.31
    },
    {
        "text": "And we can also, we also\nhave a check for symmetry.",
        "start": 4969.194,
        "duration": 3.08
    },
    {
        "text": "I'm not going to go into\ntoo much detail right now.",
        "start": 4972.664,
        "duration": 1.8
    },
    {
        "text": "but basically we say we determined the\npose of either location and rotation",
        "start": 4975.344,
        "duration": 4.7
    },
    {
        "text": "is unique, or if we detected symmetry.",
        "start": 4980.044,
        "duration": 2.95
    },
    {
        "text": "And then we set the pose to the\nmost likely hypothesis pose,",
        "start": 4983.794,
        "duration": 3.64
    },
    {
        "text": "otherwise again pose is none.",
        "start": 4988.364,
        "duration": 1.64
    },
    {
        "text": "and then after we did this for all\nlearning modules, we concatenate",
        "start": 4992.404,
        "duration": 3.53
    },
    {
        "text": "all the predicted poses for\nall of the learning modules.",
        "start": 4995.964,
        "duration": 3.12
    },
    {
        "text": "And if we have actually decided the pose\nfor enough learning modules, this is again",
        "start": 5000.839,
        "duration": 7.03
    },
    {
        "text": "a parameter we can set how many learning\nmodules need to be sure of their pose,",
        "start": 5007.869,
        "duration": 4.15
    },
    {
        "text": "then we check if all of the learning\nmodules agree on the object and pose.",
        "start": 5013.719,
        "duration": 6.29
    },
    {
        "text": "If yes, we say it's a match.",
        "start": 5020.269,
        "duration": 1.83
    },
    {
        "text": "If no, we say we take another\nstep and continue matching.",
        "start": 5023.569,
        "duration": 3.75
    },
    {
        "text": "That's the terminal slide.",
        "start": 5031.414,
        "duration": 1.3
    },
    {
        "text": "Very",
        "start": 5032.714,
        "duration": 7.7
    },
    {
        "text": "nice.",
        "start": 5042.454,
        "duration": 0.05
    },
    {
        "text": "Just in time.",
        "start": 5044.144,
        "duration": 1.04
    },
    {
        "text": "Thanks.",
        "start": 5045.764,
        "duration": 0.14
    },
    {
        "text": "Did you do all the lettering yourself.",
        "start": 5047.824,
        "duration": 2.68
    },
    {
        "text": "Yeah.",
        "start": 5051.944,
        "duration": 0.44
    },
    {
        "text": "That's amazing.",
        "start": 5055.384,
        "duration": 0.86
    },
    {
        "text": "Really great.",
        "start": 5056.394,
        "duration": 0.53
    },
    {
        "text": "Yeah, I tried to try something new.",
        "start": 5058.564,
        "duration": 1.77
    },
    {
        "text": "I liked it.",
        "start": 5061.959,
        "duration": 0.77
    },
    {
        "text": "It's good.",
        "start": 5063.239,
        "duration": 0.39
    },
    {
        "text": "Great.",
        "start": 5064.239,
        "duration": 0.24
    },
    {
        "text": "Thank you.",
        "start": 5064.489,
        "duration": 0.18
    },
    {
        "text": "Yeah.",
        "start": 5068.089,
        "duration": 0.31
    },
    {
        "text": "And there's a lot in there.",
        "start": 5068.739,
        "duration": 1.52
    },
    {
        "text": "And, I know we talked about this\nstuff before, but, going through",
        "start": 5070.359,
        "duration": 3.86
    },
    {
        "text": "the holidays, I forget things.",
        "start": 5074.219,
        "duration": 1.39
    },
    {
        "text": "anyway, there's a lot of big ideas.",
        "start": 5077.089,
        "duration": 1.79
    },
    {
        "text": "I think that was a very clear explanation.",
        "start": 5078.969,
        "duration": 1.97
    },
    {
        "text": "Have you run simulations of this\nand the performance and how slow",
        "start": 5080.939,
        "duration": 7.61
    },
    {
        "text": "it is and all that kind of stuff.",
        "start": 5088.549,
        "duration": 0.99
    },
    {
        "text": "Thank you.",
        "start": 5089.599,
        "duration": 0.06
    },
    {
        "text": "Yeah.",
        "start": 5090.874,
        "duration": 0.26
    },
    {
        "text": "Yeah.",
        "start": 5091.134,
        "duration": 0.37
    },
    {
        "text": "yeah, that's, basically the results that\nI showed before the Christmas break.",
        "start": 5092.244,
        "duration": 4.18
    },
    {
        "text": "So this is all just a review of the\nstuff you showed before the break.",
        "start": 5096.534,
        "duration": 2.63
    },
    {
        "text": "Yeah.",
        "start": 5099.874,
        "duration": 0.31
    },
    {
        "text": "Yeah.",
        "start": 5100.184,
        "duration": 0.23
    },
    {
        "text": "It's not.",
        "start": 5100.414,
        "duration": 0.36
    },
    {
        "text": "No.",
        "start": 5100.824,
        "duration": 0.36
    },
    {
        "text": "Okay.",
        "start": 5101.604,
        "duration": 0.31
    },
    {
        "text": "I don't know.",
        "start": 5101.994,
        "duration": 0.6
    },
    {
        "text": "It looks good because you have new\ndiagrams or maybe new language.",
        "start": 5102.594,
        "duration": 2.34
    },
    {
        "text": "Yeah.",
        "start": 5104.954,
        "duration": 0.33
    },
    {
        "text": "Yeah.",
        "start": 5105.284,
        "duration": 0.41
    },
    {
        "text": "I just couldn't remember if all\nthis was done before or not.",
        "start": 5107.464,
        "duration": 2.48
    },
    {
        "text": "and you're getting reasonably good\nperformance speed up if I recall.",
        "start": 5111.204,
        "duration": 3.54
    },
    {
        "text": "Is that right?",
        "start": 5115.204,
        "duration": 0.48
    },
    {
        "text": "Yeah.",
        "start": 5115.794,
        "duration": 0.45
    },
    {
        "text": "Yeah.",
        "start": 5116.774,
        "duration": 0.3
    },
    {
        "text": "Yeah.",
        "start": 5118.784,
        "duration": 0.27
    },
    {
        "text": "So detecting one object takes",
        "start": 5119.054,
        "duration": 1.66
    },
    {
        "text": "One second or so, usually, depending\non how many models we have in memory.",
        "start": 5122.744,
        "duration": 5.8
    },
    {
        "text": "Yeah.",
        "start": 5129.274,
        "duration": 0.25
    },
    {
        "text": "Nice presentation.",
        "start": 5131.144,
        "duration": 0.97
    },
    {
        "text": "Yeah, really nice.",
        "start": 5132.444,
        "duration": 0.98
    },
    {
        "text": "Yeah, thanks and thanks\nfor all your questions.",
        "start": 5134.274,
        "duration": 2.07
    },
    {
        "text": "Yeah, I'm always trying to figure\nout how to explain these things best.",
        "start": 5136.864,
        "duration": 3.09
    }
]