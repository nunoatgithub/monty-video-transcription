[
    {
        "text": "I thought just a little preface here,",
        "start": 9.191,
        "duration": 1.81
    },
    {
        "text": "the brain has all this\ncomplicated anatomy.",
        "start": 13.751,
        "duration": 2.66
    },
    {
        "text": "It's been documented for decades\nand decades for over 100 years.",
        "start": 16.701,
        "duration": 3.18
    },
    {
        "text": "it's really messy.",
        "start": 20.946,
        "duration": 1.03
    },
    {
        "text": "there are different terms that\nare used for the same things.",
        "start": 23.316,
        "duration": 3.72
    },
    {
        "text": "There's different reports,\nreported empirical results",
        "start": 27.036,
        "duration": 2.51
    },
    {
        "text": "that conflict with one another.",
        "start": 29.546,
        "duration": 1.27
    },
    {
        "text": "There are empirical results that\nare on the same topic, but because",
        "start": 31.496,
        "duration": 4.34
    },
    {
        "text": "of the different techniques and\nanimals and so on, they just They're",
        "start": 35.836,
        "duration": 2.835
    },
    {
        "text": "talking about the same thing, but\nthere's no overlap between them.",
        "start": 38.701,
        "duration": 2.59
    },
    {
        "text": "and I've said this many times, if you\nwant to know anything about the brain,",
        "start": 43.161,
        "duration": 3.3
    },
    {
        "text": "you have to read at least seven papers\nbefore you start getting a gist of,",
        "start": 46.461,
        "duration": 4.0
    },
    {
        "text": "okay, what's really happening here?",
        "start": 50.461,
        "duration": 1.62
    },
    {
        "text": "because any individual paper can\nbe very misleading, not wrong,",
        "start": 53.141,
        "duration": 3.32
    },
    {
        "text": "not incorrect, but just not.",
        "start": 56.471,
        "duration": 1.4
    },
    {
        "text": "Using the same language, the same things,\nwhatever, you just get different answers.",
        "start": 58.331,
        "duration": 2.9
    },
    {
        "text": "it's also true that the anatomy itself\nis not like a circuit diagram you can",
        "start": 62.241,
        "duration": 3.76
    },
    {
        "text": "look at and deduce what is going on.",
        "start": 66.001,
        "duration": 2.25
    },
    {
        "text": "You just can't do that.",
        "start": 68.311,
        "duration": 1.0
    },
    {
        "text": "It's just too many unknowns,\ntoo much complication.",
        "start": 69.721,
        "duration": 2.62
    },
    {
        "text": "It's not possible, so\ngive up on that idea.",
        "start": 72.671,
        "duration": 2.49
    },
    {
        "text": "That you could look at and\ngo, Oh, I could do this.",
        "start": 76.076,
        "duration": 1.47
    },
    {
        "text": "What's going on.",
        "start": 77.666,
        "duration": 0.6
    },
    {
        "text": "There's a few simple circuits and\nbiological neural circuits and that",
        "start": 78.546,
        "duration": 4.55
    },
    {
        "text": "people have been able to do that with\nbut not anything close to in your cortex.",
        "start": 83.246,
        "duration": 2.79
    },
    {
        "text": "It's just crazy.",
        "start": 86.176,
        "duration": 0.66
    },
    {
        "text": "And there's so many, this was\nstill discovering how the neocortex",
        "start": 88.306,
        "duration": 3.55
    },
    {
        "text": "represents information and so on.",
        "start": 91.876,
        "duration": 1.37
    },
    {
        "text": "So it's You can't do that.",
        "start": 93.246,
        "duration": 1.32
    },
    {
        "text": "So what good is this studying anatomy?",
        "start": 94.566,
        "duration": 1.56
    },
    {
        "text": "The good of studying anatomy is\nthat it's a classic science problem.",
        "start": 96.656,
        "duration": 3.35
    },
    {
        "text": "you have top down theoretical constraints,\nwhich you, say, okay, the theory and",
        "start": 100.456,
        "duration": 5.62
    },
    {
        "text": "deduction says, this has to happen.",
        "start": 106.076,
        "duration": 2.18
    },
    {
        "text": "And then you can look at the anatomy\nand say, can that thing that has",
        "start": 108.856,
        "duration": 3.66
    },
    {
        "text": "to happen match up here at all?",
        "start": 112.516,
        "duration": 1.83
    },
    {
        "text": "And how would it match up?",
        "start": 114.646,
        "duration": 1.33
    },
    {
        "text": "And maybe there's one,\nonly one way to do it.",
        "start": 115.976,
        "duration": 1.59
    },
    {
        "text": "Maybe there's multiple ways\nto do it, but at least.",
        "start": 117.616,
        "duration": 1.35
    },
    {
        "text": "It's this interaction back and\nforth, and then you say, Oh, I",
        "start": 119.551,
        "duration": 2.64
    },
    {
        "text": "wish I knew more about the anatomy\nbecause that may prove this theory.",
        "start": 122.191,
        "duration": 2.72
    },
    {
        "text": "Then you dig and you find out more about\nthe anatomy and physiology, and maybe it",
        "start": 125.111,
        "duration": 2.75
    },
    {
        "text": "just proves it So my point is, on its own,\nthe cortical anatomy and physiology, and",
        "start": 127.881,
        "duration": 5.28
    },
    {
        "text": "with brain anatomy and physiology, isn't,\nit can't do anything with it on its own.",
        "start": 133.161,
        "duration": 3.49
    },
    {
        "text": "You have to match it with,\nwith, with, deductive and top",
        "start": 136.651,
        "duration": 4.57
    },
    {
        "text": "down theoretical constraints.",
        "start": 141.221,
        "duration": 1.42
    },
    {
        "text": "so that's the process we've gone through.",
        "start": 143.631,
        "duration": 1.92
    },
    {
        "text": "any questions about that before\nI dive into it any further?",
        "start": 146.631,
        "duration": 2.72
    },
    {
        "text": "All right.",
        "start": 149.351,
        "duration": 1.32
    },
    {
        "text": "There's one axiom.",
        "start": 150.761,
        "duration": 1.1
    },
    {
        "text": "That, that, we follow, or I follow, and\nwe all follow here, and actually this is",
        "start": 152.801,
        "duration": 6.38
    },
    {
        "text": "something you just take as a truth, right?",
        "start": 159.181,
        "duration": 2.24
    },
    {
        "text": "It's a ground base, you just\nhave to accept this, and this",
        "start": 161.421,
        "duration": 2.05
    },
    {
        "text": "is Mountcastle's proposal,",
        "start": 163.471,
        "duration": 1.3
    },
    {
        "text": "and, this is the cortical\ncolumn hypothesis.",
        "start": 166.971,
        "duration": 3.51
    },
    {
        "text": "which is at the cortex, which is\nthis big sheet of neural tissue is",
        "start": 172.726,
        "duration": 2.89
    },
    {
        "text": "divided up into these columns, and\nthey're all basically doing the same",
        "start": 175.626,
        "duration": 2.45
    },
    {
        "text": "thing, and it's not purely made up.",
        "start": 178.076,
        "duration": 3.81
    },
    {
        "text": "There's a lot of evidence for it, but\nit's the one thing I don't question",
        "start": 181.926,
        "duration": 4.77
    },
    {
        "text": "as we're going through our work.",
        "start": 187.176,
        "duration": 1.01
    },
    {
        "text": "I never go back and say, I wonder if my\ncustomer was wrong about this, because we",
        "start": 188.186,
        "duration": 2.71
    },
    {
        "text": "could come up with some, the consciousness\ncircuit over here or something like that.",
        "start": 190.896,
        "duration": 3.99
    },
    {
        "text": "I just don't go there.",
        "start": 195.366,
        "duration": 1.12
    },
    {
        "text": "this is the, there's the one\nsort of axiom that we stick with.",
        "start": 197.136,
        "duration": 3.36
    },
    {
        "text": "And so it's underlying everything,\nand hopefully it's right, because",
        "start": 200.926,
        "duration": 2.67
    },
    {
        "text": "if it's not, then we're all screwed.",
        "start": 203.606,
        "duration": 2.54
    },
    {
        "text": "But so far, there's a lot of evidence\nfor it, and I think it's fairly safe.",
        "start": 206.326,
        "duration": 3.23
    },
    {
        "text": "One thing maybe on this is, in terms of\nhow you define the extent of a column.",
        "start": 211.116,
        "duration": 4.47
    },
    {
        "text": "Because I think sometimes there's more\nlike a histological point of view,",
        "start": 216.036,
        "duration": 3.04
    },
    {
        "text": "and then numenta has a little shift.",
        "start": 219.076,
        "duration": 2.04
    },
    {
        "text": "so part of Mountcastle's\nproposal, it talks about what",
        "start": 223.346,
        "duration": 5.24
    },
    {
        "text": "is the extent of a column.",
        "start": 228.606,
        "duration": 0.99
    },
    {
        "text": "So this is your, neocortex.",
        "start": 230.046,
        "duration": 2.53
    },
    {
        "text": "It's about three millimeters in\nthickness, and it's big sheet, right?",
        "start": 233.156,
        "duration": 5.15
    },
    {
        "text": "And different parts do different things.",
        "start": 238.316,
        "duration": 1.47
    },
    {
        "text": "And, and when they first observed\nit, under a microscope back for",
        "start": 240.426,
        "duration": 4.56
    },
    {
        "text": "Cajal, they saw that the predominant\narchitectural figures feature with layers.",
        "start": 244.986,
        "duration": 7.585
    },
    {
        "text": "So they and you've seen the picture,\nhopefully of the picture that,",
        "start": 252.581,
        "duration": 3.63
    },
    {
        "text": "that, the hollow draw June, but\nyou could see this different cell",
        "start": 257.271,
        "duration": 4.23
    },
    {
        "text": "densities and different cell types.",
        "start": 261.501,
        "duration": 1.83
    },
    {
        "text": "And it looked like these layers of\ncells and these extend across the whole.",
        "start": 263.331,
        "duration": 4.62
    },
    {
        "text": "The cortex continues like this, and they\ncame up with 6 layers that is incorrect.",
        "start": 268.391,
        "duration": 4.9
    },
    {
        "text": "We aren't 6 layers.",
        "start": 273.291,
        "duration": 1.1
    },
    {
        "text": "There are different cell types\nand different densities, and",
        "start": 274.781,
        "duration": 3.21
    },
    {
        "text": "they just made up the number 6.",
        "start": 277.991,
        "duration": 1.36
    },
    {
        "text": "and, and for example, today, generally,\nlayers, some layers are grouped together.",
        "start": 280.996,
        "duration": 6.07
    },
    {
        "text": "Layers 2 and layers 3 are often\njust referred to as layer 2 3.",
        "start": 287.066,
        "duration": 3.08
    },
    {
        "text": "Some people don't make a distinction.",
        "start": 290.146,
        "duration": 1.12
    },
    {
        "text": "There are papers that talk about layer\n2 A and 2 B and, if I write correctly,",
        "start": 291.876,
        "duration": 4.62
    },
    {
        "text": "and layer 3 A and 3 B. Well, who's right?",
        "start": 296.536,
        "duration": 3.29
    },
    {
        "text": "I don't know.",
        "start": 300.326,
        "duration": 0.36
    },
    {
        "text": "Depends on how you judge it, right?",
        "start": 300.706,
        "duration": 1.02
    },
    {
        "text": "You can look at cells and say, oh,\nin between two and three, their",
        "start": 302.796,
        "duration": 3.05
    },
    {
        "text": "cell types are a little bit smaller.",
        "start": 305.846,
        "duration": 1.34
    },
    {
        "text": "They make slightly different projections.",
        "start": 307.186,
        "duration": 1.18
    },
    {
        "text": "You say, okay, I think those are\nreally separate, even though sometimes",
        "start": 308.366,
        "duration": 2.69
    },
    {
        "text": "people don't talk about it separately.",
        "start": 311.056,
        "duration": 1.2
    },
    {
        "text": "layer five, it's often there's\ntwo types of cells in layer five.",
        "start": 313.336,
        "duration": 3.29
    },
    {
        "text": "Now there's actually a third type of\npimple margain valve that connects",
        "start": 317.026,
        "duration": 3.19
    },
    {
        "text": "to the striatum or something.",
        "start": 320.216,
        "duration": 1.5
    },
    {
        "text": "And then layer six, it's got\na half a dozen different types",
        "start": 322.286,
        "duration": 3.09
    },
    {
        "text": "of cells in it, at least.",
        "start": 325.376,
        "duration": 1.08
    },
    {
        "text": "So these layers, visually, you could\nsee them, maybe you could count six, but",
        "start": 327.151,
        "duration": 5.4
    },
    {
        "text": "they're just placeholders that help you\nlocate cell types relative to each other.",
        "start": 332.581,
        "duration": 4.66
    },
    {
        "text": "But we often fall into the habit of\nsaying, oh, layer 6a connects to here.",
        "start": 337.531,
        "duration": 3.3
    },
    {
        "text": "even in layer 6a, there's more than\none cell type, so we have to be really",
        "start": 341.241,
        "duration": 2.73
    },
    {
        "text": "conscious about in the back of your mind.",
        "start": 344.301,
        "duration": 1.36
    },
    {
        "text": "the next thing is that these cells\nalmost all, the next thing is that,",
        "start": 347.991,
        "duration": 4.8
    },
    {
        "text": "the general rule is that if you look at\ninformation that comes into the cortex,",
        "start": 352.881,
        "duration": 4.07
    },
    {
        "text": "Information flows up and down vertically.",
        "start": 358.241,
        "duration": 2.61
    },
    {
        "text": "You see a lot more vertical connections\nthan horizontal connections.",
        "start": 360.861,
        "duration": 2.65
    },
    {
        "text": "So there's a lot of, there's\nclearly a lot of information",
        "start": 363.741,
        "duration": 2.19
    },
    {
        "text": "going back and forth, up and down.",
        "start": 365.951,
        "duration": 1.52
    },
    {
        "text": "And then there are connections\nin some layers that go small",
        "start": 367.981,
        "duration": 4.43
    },
    {
        "text": "distances or long distances.",
        "start": 372.411,
        "duration": 1.54
    },
    {
        "text": "Sometimes they exit and\ngo out and back in again.",
        "start": 374.286,
        "duration": 1.99
    },
    {
        "text": "So there's a very heavy connectivity\nvertically oriented, and then",
        "start": 376.656,
        "duration": 4.22
    },
    {
        "text": "a sparse of connectivity, but\nstill a lot, going elsewhere.",
        "start": 380.906,
        "duration": 3.05
    },
    {
        "text": "this is the first suggestion that there\nmight be columns because it seems like",
        "start": 385.446,
        "duration": 2.89
    },
    {
        "text": "the information is first and foremost\nprocessed in a sort of vertical fashion.",
        "start": 388.336,
        "duration": 3.64
    },
    {
        "text": "And then Mountcastle made the argument\nthat, that if you look at the cortex",
        "start": 392.976,
        "duration": 7.42
    },
    {
        "text": "and you, look at, what might, you\nmight call a column, That these",
        "start": 400.896,
        "duration": 3.995
    },
    {
        "text": "what distinguishes things return.",
        "start": 405.531,
        "duration": 1.54
    },
    {
        "text": "There's no visual market demarcation\nbetween column and column, but",
        "start": 407.311,
        "duration": 3.24
    },
    {
        "text": "you can't see a line between them.",
        "start": 410.551,
        "duration": 1.51
    },
    {
        "text": "It just looks like layers, but he made\nthe argument that a column is defined",
        "start": 413.231,
        "duration": 4.93
    },
    {
        "text": "by where it's getting input from.",
        "start": 418.161,
        "duration": 1.55
    },
    {
        "text": "So if it was like on your hand.",
        "start": 420.271,
        "duration": 2.22
    },
    {
        "text": "He's a famous picture",
        "start": 422.961,
        "duration": 1.2
    },
    {
        "text": "where this is on the hand of a monkey,\nthe skin of the monkey, and these columns.",
        "start": 427.001,
        "duration": 4.92
    },
    {
        "text": "Are getting input from a patch of\nthe skin, but it's not continuous.",
        "start": 432.986,
        "duration": 5.89
    },
    {
        "text": "That is all the cells within a column\nare getting input from this patch here.",
        "start": 439.306,
        "duration": 5.22
    },
    {
        "text": "But if you skip over to the next\ncolumn, just move a little bit further.",
        "start": 445.046,
        "duration": 2.82
    },
    {
        "text": "They're all getting input from here.",
        "start": 448.206,
        "duration": 1.5
    },
    {
        "text": "And of course, sometimes in the cortex,\nyou go from one region to another or one",
        "start": 449.726,
        "duration": 6.83
    },
    {
        "text": "modality this might be a somatosensory\ncolumn, this might be a visual",
        "start": 456.556,
        "duration": 3.3
    },
    {
        "text": "column, and they're getting it from\na completely different sensory order.",
        "start": 459.856,
        "duration": 3.04
    },
    {
        "text": "It's completely some part of the\nAre these sensory patches not",
        "start": 463.106,
        "duration": 3.31
    },
    {
        "text": "overlapping, or do they overlap?",
        "start": 466.416,
        "duration": 1.14
    },
    {
        "text": "The sensory patches do overlap a bit.",
        "start": 468.586,
        "duration": 1.87
    },
    {
        "text": "If they didn't over yeah, but The\nbut not a lot, not completely.",
        "start": 471.026,
        "duration": 3.695
    },
    {
        "text": "And this is his argument.",
        "start": 475.251,
        "duration": 1.34
    },
    {
        "text": "He gave evidence for this.",
        "start": 476.621,
        "duration": 1.31
    },
    {
        "text": "But the most important thing\nis, it's not about the overlap.",
        "start": 478.691,
        "duration": 3.55
    },
    {
        "text": "It's the fact that all these cells\nin from here to here all driven",
        "start": 482.241,
        "duration": 4.63
    },
    {
        "text": "by the same area and as soon as\nyou jump a little bit, they're all",
        "start": 486.871,
        "duration": 3.92
    },
    {
        "text": "driven by a different set of things.",
        "start": 490.891,
        "duration": 1.87
    },
    {
        "text": "It's a it's not a continuous thing.",
        "start": 492.771,
        "duration": 2.49
    },
    {
        "text": "It's a sudden jump.",
        "start": 495.281,
        "duration": 1.12
    },
    {
        "text": "so he said that instead of his proof\nthat these are separate processing",
        "start": 498.241,
        "duration": 4.65
    },
    {
        "text": "units, this thing here processes\nall the information from this patch.",
        "start": 502.891,
        "duration": 3.325
    },
    {
        "text": "This comp, it's only getting\ninformation from this patch and so on.",
        "start": 506.586,
        "duration": 2.91
    },
    {
        "text": "And the same thing, it happens in vision\nand touch and some, in auditory and he",
        "start": 509.986,
        "duration": 5.0
    },
    {
        "text": "gave evidence for that and all those.",
        "start": 514.986,
        "duration": 2.09
    },
    {
        "text": "so this is his proposal about columns.",
        "start": 518.246,
        "duration": 3.29
    },
    {
        "text": "And then he said, since they all\nlook identical, pretty much, then",
        "start": 522.066,
        "duration": 5.98
    },
    {
        "text": "they're all doing the same thing.",
        "start": 528.046,
        "duration": 0.77
    },
    {
        "text": "They're just processing a\ndifferent part of the world.",
        "start": 529.801,
        "duration": 2.13
    },
    {
        "text": "And again, remember, I could have a\nvision column right here next to a, somato",
        "start": 531.931,
        "duration": 3.56
    },
    {
        "text": "centric column, or I can have a V one\ncolumn boarding a, they're not intermixed,",
        "start": 535.491,
        "duration": 3.09
    },
    {
        "text": "but they're points in the cortex where\nthey are boundaries between these regions.",
        "start": 538.581,
        "duration": 3.0
    },
    {
        "text": "And if you just slip, jump over a\nlittle bit over the hoop here, all of a",
        "start": 541.821,
        "duration": 2.43
    },
    {
        "text": "sudden you're in a different modality.",
        "start": 544.251,
        "duration": 1.02
    },
    {
        "text": "In fact, it was, what's his name, who\nproposed that, synesthesia is a cause,",
        "start": 546.141,
        "duration": 6.6
    },
    {
        "text": "is caused by, cells incorrectly making\nconnections across modalities like that.",
        "start": 552.831,
        "duration": 5.06
    },
    {
        "text": "what's his name?",
        "start": 559.266,
        "duration": 0.58
    },
    {
        "text": "The famous,",
        "start": 559.846,
        "duration": 1.55
    },
    {
        "text": "anyway.",
        "start": 564.006,
        "duration": 0.39
    },
    {
        "text": "that was, again, evidence, yeah, there's\nthese, there's these hard boundaries",
        "start": 566.036,
        "duration": 3.71
    },
    {
        "text": "sometimes, but then even here within a\nsingle modality there's these boundaries.",
        "start": 569.766,
        "duration": 3.71
    },
    {
        "text": "So then you just think, okay, a\ncolumn is just, it's just looking",
        "start": 574.246,
        "duration": 2.89
    },
    {
        "text": "at a patch, it's getting input from\nthat patch, and that's all it does.",
        "start": 577.136,
        "duration": 3.1
    },
    {
        "text": "And then it processes it.",
        "start": 581.156,
        "duration": 1.05
    },
    {
        "text": "there is a, there is another\nconfusing element called minicolumns.",
        "start": 583.286,
        "duration": 2.9
    },
    {
        "text": "if you're not familiar with\nthat, a minicolumn is again,",
        "start": 588.096,
        "duration": 5.2
    },
    {
        "text": "columns you can't see.",
        "start": 593.296,
        "duration": 1.15
    },
    {
        "text": "You can't see them in the cortex, right?",
        "start": 594.526,
        "duration": 1.29
    },
    {
        "text": "the only example that's different\nis the rat barrel cortex.",
        "start": 596.156,
        "duration": 2.46
    },
    {
        "text": "Rats have a column for each whisker\nand that you can actually see those,",
        "start": 598.916,
        "duration": 3.73
    },
    {
        "text": "But generally you can't see columns.",
        "start": 603.426,
        "duration": 1.58
    },
    {
        "text": "And, but there is something you\ncan see called the minicolumn.",
        "start": 605.666,
        "duration": 3.68
    },
    {
        "text": "and now I'll just draw it like this.",
        "start": 611.746,
        "duration": 1.53
    },
    {
        "text": "And the minicolumn is much, much smaller.",
        "start": 616.816,
        "duration": 1.69
    },
    {
        "text": "Where a regular column can be anywhere\nbetween a third of a millimeter",
        "start": 618.846,
        "duration": 4.79
    },
    {
        "text": "and a millimeter in dimension.",
        "start": 623.756,
        "duration": 1.73
    },
    {
        "text": "Minicoms are much more smaller,\nthat may be like 30 to 60",
        "start": 625.746,
        "duration": 2.75
    },
    {
        "text": "microns or something like that.",
        "start": 628.586,
        "duration": 1.75
    },
    {
        "text": "and they typically, it's typically\nreported, each minicom is like",
        "start": 631.526,
        "duration": 3.43
    },
    {
        "text": "a little stack of neurons.",
        "start": 635.066,
        "duration": 1.24
    },
    {
        "text": "that go across all the layers.",
        "start": 637.046,
        "duration": 1.43
    },
    {
        "text": "So the general idea is that all the\ndifferent types of cells that exist",
        "start": 639.096,
        "duration": 2.8
    },
    {
        "text": "in a column, exist in a mini column.",
        "start": 641.896,
        "duration": 1.56
    },
    {
        "text": "And, and so a typical number,\nyou'll see different numbers, but",
        "start": 644.016,
        "duration": 4.24
    },
    {
        "text": "a hundred, 120 cells is a typical\nnumber you'll see for a mini column.",
        "start": 648.266,
        "duration": 4.75
    },
    {
        "text": "and they come about when the, when\nyou're in utero and you're developing",
        "start": 654.796,
        "duration": 5.25
    },
    {
        "text": "your brain, the way the brain develops,\nthe cortex develops, there's a sheet",
        "start": 660.046,
        "duration": 2.94
    },
    {
        "text": "of neural tissue, just a single layer.",
        "start": 662.986,
        "duration": 3.16
    },
    {
        "text": "And then the cells start replicating,\nand they move vertically,",
        "start": 666.581,
        "duration": 3.99
    },
    {
        "text": "they move in this direction.",
        "start": 671.401,
        "duration": 1.22
    },
    {
        "text": "and so the, essentially\na single progenitor cell",
        "start": 673.621,
        "duration": 2.57
    },
    {
        "text": "ends up creating 120 cells.",
        "start": 676.241,
        "duration": 1.65
    },
    {
        "text": "And they, grow up vertically like that.",
        "start": 678.441,
        "duration": 1.73
    },
    {
        "text": "So that's how they come about.",
        "start": 680.181,
        "duration": 1.11
    },
    {
        "text": "So the minicom is a real thing,\nbecause that's how the cortex develops.",
        "start": 681.291,
        "duration": 4.54
    },
    {
        "text": "And, you can often see\nthem under a microscope.",
        "start": 687.261,
        "duration": 3.07
    },
    {
        "text": "There's these great pictures, you\nsee these little skinny little",
        "start": 690.331,
        "duration": 1.89
    },
    {
        "text": "things, cells, and then a little\ngap and other skinny little cells.",
        "start": 692.221,
        "duration": 2.35
    },
    {
        "text": "They're not always visible.",
        "start": 695.601,
        "duration": 1.38
    },
    {
        "text": "So, in some animals, like in rats\nand mice, it's hard to see them,",
        "start": 698.141,
        "duration": 3.91
    },
    {
        "text": "or they don't look like they exist.",
        "start": 702.911,
        "duration": 1.23
    },
    {
        "text": "And people say, they don't really exist.",
        "start": 704.141,
        "duration": 1.34
    },
    {
        "text": "They say, they were there when you\nbrain grew, but they're not there now.",
        "start": 705.521,
        "duration": 4.23
    },
    {
        "text": "And other people say, even if they\nare there, they're not functional.",
        "start": 709.951,
        "duration": 3.04
    },
    {
        "text": "what do they do?",
        "start": 713.736,
        "duration": 0.87
    },
    {
        "text": "maybe it doesn't matter,\nit's just the way they grow.",
        "start": 715.191,
        "duration": 2.265
    },
    {
        "text": "Malkin has argued that this actually\nwas the most important replicable",
        "start": 718.076,
        "duration": 3.79
    },
    {
        "text": "unit of computation, but he had\nno hypothesis of what it was.",
        "start": 721.876,
        "duration": 4.39
    },
    {
        "text": "He said that is the unit of\nreplication of the brain, the minicom.",
        "start": 727.006,
        "duration": 3.62
    },
    {
        "text": "And he said if you take a bunch of\nminicoms, several hundred minicoms, you",
        "start": 730.826,
        "duration": 3.18
    },
    {
        "text": "put them together, they form a column.",
        "start": 734.006,
        "duration": 1.36
    },
    {
        "text": "And they work together.",
        "start": 736.116,
        "duration": 0.78
    },
    {
        "text": "So this is the two levels of\norganization that you see in the cortex.",
        "start": 736.916,
        "duration": 3.56
    },
    {
        "text": "I have a theory about minicoms.",
        "start": 740.486,
        "duration": 1.29
    },
    {
        "text": "I've never really shared it\ncompletely with everybody.",
        "start": 741.776,
        "duration": 2.08
    },
    {
        "text": "We can get into that later.",
        "start": 744.196,
        "duration": 1.14
    },
    {
        "text": "but I have, I'm developing a,\npartial understanding of how would I",
        "start": 746.456,
        "duration": 3.58
    },
    {
        "text": "think about what does a minicom do?",
        "start": 750.066,
        "duration": 1.64
    },
    {
        "text": "as an independent unit, obviously\nyou can't do too much, right?",
        "start": 753.056,
        "duration": 2.52
    },
    {
        "text": "Because.",
        "start": 755.606,
        "duration": 0.26
    },
    {
        "text": "It's just 120 cells, and obviously\nyou can't do, they have to work",
        "start": 756.291,
        "duration": 3.71
    },
    {
        "text": "together as a group, but can\nyou understand what they do?",
        "start": 760.001,
        "duration": 2.19
    },
    {
        "text": "I think you can.",
        "start": 762.641,
        "duration": 0.61
    },
    {
        "text": "so that tells you, if, you said, oh,\nthere are six layers of cells and you",
        "start": 765.621,
        "duration": 3.97
    },
    {
        "text": "might say, there's 20 layers per cell, 20\ncells per layer or something like that.",
        "start": 769.591,
        "duration": 3.71
    },
    {
        "text": "But, we've already seen that,\nthat's, that's not really",
        "start": 773.301,
        "duration": 6.08
    },
    {
        "text": "true that there's six layers.",
        "start": 779.381,
        "duration": 1.22
    },
    {
        "text": "In terms of the lateral extent, so\nI think sometimes when I've read",
        "start": 781.316,
        "duration": 3.37
    },
    {
        "text": "about a column, it's suggested\nit's like around 10, 000 neurons.",
        "start": 784.686,
        "duration": 4.5
    },
    {
        "text": "my understanding is, Oh,\nthey're much bigger than that.",
        "start": 790.556,
        "duration": 1.97
    },
    {
        "text": "Yeah.",
        "start": 792.616,
        "duration": 0.29
    },
    {
        "text": "It's more like a hundred thousand\nat least, but I thought that",
        "start": 792.906,
        "duration": 2.3
    },
    {
        "text": "was arrived at and you mentioned\nstuff through some other logic.",
        "start": 795.206,
        "duration": 3.28
    },
    {
        "text": "If you look at the cats, the hyper\ncolumns that Hubel and Wiesel",
        "start": 798.776,
        "duration": 3.23
    },
    {
        "text": "talked about in cats, those are\nabout a millimeter square in area.",
        "start": 802.006,
        "duration": 4.55
    },
    {
        "text": "And basically just do the math.",
        "start": 806.916,
        "duration": 1.66
    },
    {
        "text": "In a hundred and a square millimeter,\nyou'll have about 100, 000 neurons.",
        "start": 808.931,
        "duration": 3.22
    },
    {
        "text": "Okay.",
        "start": 813.021,
        "duration": 0.42
    },
    {
        "text": "now that's arguably the\nhyper column in a cat.",
        "start": 814.731,
        "duration": 2.98
    },
    {
        "text": "No one, I haven't really gotten\ndefinitive answers on it.",
        "start": 818.011,
        "duration": 2.62
    },
    {
        "text": "Is that a column or is\nthat multiple columns?",
        "start": 820.641,
        "duration": 2.06
    },
    {
        "text": "It's debatable.",
        "start": 822.701,
        "duration": 1.58
    },
    {
        "text": "but at least at the high end, you\nmight have a column, which is a square",
        "start": 825.491,
        "duration": 3.58
    },
    {
        "text": "millimeter, a millimeter in area.",
        "start": 829.071,
        "duration": 1.21
    },
    {
        "text": "100, 000 cells.",
        "start": 830.431,
        "duration": 1.47
    },
    {
        "text": "If you, if your column was,",
        "start": 832.181,
        "duration": 1.76
    },
    {
        "text": "smaller than that, it was, let's say\nit was 300 microns by 300 microns,",
        "start": 836.331,
        "duration": 4.56
    },
    {
        "text": "that would be like a tenth of that.",
        "start": 841.951,
        "duration": 1.56
    },
    {
        "text": "There'd be like, maybe,\n10, 000 cells like that.",
        "start": 843.521,
        "duration": 3.02
    },
    {
        "text": "the numbers generally work out\nwell, that is you cross correlate",
        "start": 847.876,
        "duration": 4.44
    },
    {
        "text": "them, but they're not always,\nthey don't always fit properly.",
        "start": 852.316,
        "duration": 3.54
    },
    {
        "text": "there's also evidence, people\nargue that some of the cells in",
        "start": 857.226,
        "duration": 2.61
    },
    {
        "text": "the cortex do not start minicombs.",
        "start": 859.836,
        "duration": 1.75
    },
    {
        "text": "Some of the inhibitory cells\ngenerate through a separate process.",
        "start": 861.586,
        "duration": 3.9
    },
    {
        "text": "So there's more cells than in minicombs,\nthat, it's not, it's complicated.",
        "start": 865.496,
        "duration": 3.4
    },
    {
        "text": "It doesn't have to be a question.",
        "start": 868.896,
        "duration": 1.5
    },
    {
        "text": "The minicombs make up all the neurons\nin a column, and you just said it.",
        "start": 871.386,
        "duration": 2.84
    },
    {
        "text": "Yes, but maybe no.",
        "start": 874.711,
        "duration": 2.43
    },
    {
        "text": "no one really knows.",
        "start": 880.421,
        "duration": 1.06
    },
    {
        "text": "If people argue different things,\nbut the general answer is yes.",
        "start": 882.401,
        "duration": 3.29
    },
    {
        "text": "the general answer, there\nare, other cells that are not.",
        "start": 886.441,
        "duration": 3.36
    },
    {
        "text": "So if you look at the cortex, about 75\npercent of the cells are excitatory cells.",
        "start": 890.201,
        "duration": 4.8
    },
    {
        "text": "These are cells that you input.",
        "start": 895.011,
        "duration": 1.48
    },
    {
        "text": "They have a positive, they affect\nother cells in a positive way.",
        "start": 896.491,
        "duration": 3.79
    },
    {
        "text": "They make other cells fire.",
        "start": 900.321,
        "duration": 1.01
    },
    {
        "text": "And then roughly 20 to 25 percent\nare inhibitory cells, which make",
        "start": 901.666,
        "duration": 3.71
    },
    {
        "text": "other cells less likely to follow.",
        "start": 905.386,
        "duration": 1.52
    },
    {
        "text": "The definitely all the excitatory\ncells, I believe, are in mini columns.",
        "start": 908.116,
        "duration": 3.29
    },
    {
        "text": "Some of the inhibitory cells are weird.",
        "start": 911.796,
        "duration": 2.08
    },
    {
        "text": "there's these ones in layer one, which\nhardly anyone ever talks about, that",
        "start": 914.866,
        "duration": 4.1
    },
    {
        "text": "are really weird and schlong things\nand, they don't really fit one per",
        "start": 918.966,
        "duration": 3.43
    },
    {
        "text": "mini column, that kind of thing.",
        "start": 922.396,
        "duration": 1.21
    },
    {
        "text": "So who knows?",
        "start": 923.606,
        "duration": 1.01
    },
    {
        "text": "one of the rules I have about\nneuroscience is that for every rule,",
        "start": 925.726,
        "duration": 2.62
    },
    {
        "text": "There are exceptions, every single one.",
        "start": 928.756,
        "duration": 1.57
    },
    {
        "text": "And so I could say, oh,\nthe cells are there.",
        "start": 930.806,
        "duration": 1.28
    },
    {
        "text": "And then someone said, no, they're not.",
        "start": 932.086,
        "duration": 1.05
    },
    {
        "text": "And I could say, oh, these\nare all excitatory cells.",
        "start": 933.136,
        "duration": 2.48
    },
    {
        "text": "And they said, oh, no, here's one,",
        "start": 935.616,
        "duration": 1.04
    },
    {
        "text": "never ending about that.",
        "start": 940.886,
        "duration": 1.14
    },
    {
        "text": "Okay, so that's the general layout\nof this common algorithm, divided",
        "start": 942.396,
        "duration": 5.04
    },
    {
        "text": "into columns, each one getting a\npatch, an input from someplace.",
        "start": 947.466,
        "duration": 4.27
    },
    {
        "text": "And the next column processing input\nfrom someplace else, and then, that",
        "start": 952.196,
        "duration": 4.91
    },
    {
        "text": "being divided into many columns, which\nour theories generally don't talk about,",
        "start": 957.106,
        "duration": 3.11
    },
    {
        "text": "but if you look at our, if you look\nat the, the temporal memory algorithm,",
        "start": 960.216,
        "duration": 3.75
    },
    {
        "text": "it's really relying on many columns,\nthe whole, so, we do take advantage",
        "start": 963.966,
        "duration": 5.34
    },
    {
        "text": "of it, but, in, in our, Montage, I\ndon't think we do anything with any",
        "start": 969.306,
        "duration": 4.19
    },
    {
        "text": "columns, we just take the concept of it.",
        "start": 973.496,
        "duration": 1.68
    },
    {
        "text": "So this is, any questions\nabout this now, Aaron?",
        "start": 976.636,
        "duration": 2.799
    },
    {
        "text": "So the proximity of the sensory\npatches, is that mapped into",
        "start": 979.435,
        "duration": 3.071
    },
    {
        "text": "the proximity between cosmos?",
        "start": 982.506,
        "duration": 1.82
    },
    {
        "text": "They're generally,",
        "start": 986.146,
        "duration": 0.61
    },
    {
        "text": "except, when you get to borders.",
        "start": 989.606,
        "duration": 1.4
    },
    {
        "text": "If you switch from one modality\nor one region to another,",
        "start": 992.206,
        "duration": 2.27
    },
    {
        "text": "there's a discontinuity.",
        "start": 994.476,
        "duration": 1.03
    },
    {
        "text": "yeah.",
        "start": 998.546,
        "duration": 0.35
    },
    {
        "text": "cortical computational unit, minicolumns\ncomputational unit, how, in the",
        "start": 1001.716,
        "duration": 4.71
    },
    {
        "text": "standard architecture, different\nareas, different Brodmann areas,",
        "start": 1006.426,
        "duration": 2.96
    },
    {
        "text": "will have different looking layers?",
        "start": 1009.426,
        "duration": 2.13
    },
    {
        "text": "No, the same layers, the differences\nwould be that you mentioned Brodmann.",
        "start": 1011.566,
        "duration": 5.28
    },
    {
        "text": "Brodmann is a guy who tried to define\nregions by looking at the visual",
        "start": 1016.876,
        "duration": 4.32
    },
    {
        "text": "differences between parts of the cortex.",
        "start": 1021.196,
        "duration": 1.735
    },
    {
        "text": "So the typical variation is the cells, the\nnumber of cells in each layer can vary.",
        "start": 1023.311,
        "duration": 7.08
    },
    {
        "text": "You might, one region might have\nmore layer three cells, one region",
        "start": 1030.391,
        "duration": 3.05
    },
    {
        "text": "have more layers, five cells.",
        "start": 1033.441,
        "duration": 2.03
    },
    {
        "text": "they, cell types may vary in size.",
        "start": 1037.111,
        "duration": 2.32
    },
    {
        "text": "So like the, what people classically\ncall the motor cortex, Which have",
        "start": 1039.441,
        "duration": 4.0
    },
    {
        "text": "neurons of which project to your spine,\nthose cells are really big because",
        "start": 1043.491,
        "duration": 4.19
    },
    {
        "text": "they have to project a long way, but\nthe same cells exist in other regions,",
        "start": 1047.691,
        "duration": 3.59
    },
    {
        "text": "but they're smaller, even though the\nsame cells, they're just smaller cells",
        "start": 1051.431,
        "duration": 4.05
    },
    {
        "text": "because they don't project very far.",
        "start": 1055.481,
        "duration": 1.72
    },
    {
        "text": "Maybe they only project to\nanother part of the brain.",
        "start": 1057.261,
        "duration": 1.76
    },
    {
        "text": "There's all motor output cells.",
        "start": 1059.041,
        "duration": 1.765
    },
    {
        "text": "They're all LaFe5A cells, but someone\nwill look at the, they'll look at the",
        "start": 1060.956,
        "duration": 3.83
    },
    {
        "text": "motor, quote, motor cartridge, it's\nreally somatosensory cartridge, will",
        "start": 1064.786,
        "duration": 3.12
    },
    {
        "text": "say, oh, those cells are different,\nthey're bigger, so we can define the",
        "start": 1067.906,
        "duration": 2.64
    },
    {
        "text": "motor region because it's got these\nbig cells in it, but functionally it's",
        "start": 1070.556,
        "duration": 3.43
    },
    {
        "text": "not really any different than regions\nof smaller cells in the same place.",
        "start": 1073.986,
        "duration": 3.1
    },
    {
        "text": "That was going to be my question, so that\ndistribution, that doesn't mean anything",
        "start": 1077.146,
        "duration": 4.66
    },
    {
        "text": "that maybe for motor system, they have\nto optimize for different No, it doesn't,",
        "start": 1081.816,
        "duration": 4.2
    },
    {
        "text": "it could be, and it almost certainly is.",
        "start": 1086.016,
        "duration": 2.21
    },
    {
        "text": "Okay.",
        "start": 1088.286,
        "duration": 0.27
    },
    {
        "text": "So there are the classic big\nexceptions to this common algorithm.",
        "start": 1088.746,
        "duration": 6.515
    },
    {
        "text": "One is motor cortex, these big cells.",
        "start": 1095.271,
        "duration": 2.4
    },
    {
        "text": "which people at the time didn't\nrealize are the same as the",
        "start": 1098.706,
        "duration": 2.26
    },
    {
        "text": "little cells in other regions.",
        "start": 1100.966,
        "duration": 1.16
    },
    {
        "text": "And the other classic difference is the\nprimary visual cortex, V1, which as we",
        "start": 1102.566,
        "duration": 5.12
    },
    {
        "text": "see is the first region that gets input\nfrom the retina, has some extra layers.",
        "start": 1107.686,
        "duration": 4.97
    },
    {
        "text": "In fact, a classic V1 in a primate has\nabout twice as many cells per minicom.",
        "start": 1113.366,
        "duration": 4.74
    },
    {
        "text": "and, but it's only in the, they\ncall it extra layer four cells.",
        "start": 1120.226,
        "duration": 3.81
    },
    {
        "text": "So they have an extra\nfew extra layers there.",
        "start": 1124.416,
        "duration": 1.62
    },
    {
        "text": "Now, here's the thing about that.",
        "start": 1126.276,
        "duration": 1.07
    },
    {
        "text": "So obviously that is an optimization\non vision that works better, but",
        "start": 1127.346,
        "duration": 4.06
    },
    {
        "text": "many mammals don't have that.",
        "start": 1131.406,
        "duration": 1.6
    },
    {
        "text": "Dogs and cats do not have what\nthey call a striate layer 4.",
        "start": 1133.586,
        "duration": 3.16
    },
    {
        "text": "They don't have those extra layers.",
        "start": 1136.756,
        "duration": 1.53
    },
    {
        "text": "So presumably this is something that\nprimates have evolved to have something",
        "start": 1138.726,
        "duration": 5.04
    },
    {
        "text": "a better vision somehow different\nthan the vision of dogs and cats.",
        "start": 1143.766,
        "duration": 3.75
    },
    {
        "text": "but dogs and cats still see.",
        "start": 1148.736,
        "duration": 1.55
    },
    {
        "text": "so how do we handle that?",
        "start": 1151.496,
        "duration": 1.09
    },
    {
        "text": "The way I handle that from a theorist\npoint of view is I say, okay, clearly",
        "start": 1152.656,
        "duration": 2.96
    },
    {
        "text": "these are important, these extra\nlayers, but they're not essential for",
        "start": 1155.616,
        "duration": 3.81
    },
    {
        "text": "the basic algorithm of the cortex.",
        "start": 1159.436,
        "duration": 1.89
    },
    {
        "text": "They don't, exist in touch, they don't\nexist in hearing, they don't exist",
        "start": 1162.246,
        "duration": 2.82
    },
    {
        "text": "anywhere else in the cortex, only in V1.",
        "start": 1165.066,
        "duration": 2.04
    },
    {
        "text": "And not all animals with eyes that\nsee have a striated cortex, so",
        "start": 1167.406,
        "duration": 4.03
    },
    {
        "text": "it's important, but it's not, it\ndoesn't overthrow mountain R axiom.",
        "start": 1171.686,
        "duration": 4.73
    },
    {
        "text": "It's and so the general idea I've\nalways said is we can just focus",
        "start": 1177.346,
        "duration": 4.1
    },
    {
        "text": "on the core, commonality across\nall modalities, because there seems",
        "start": 1181.466,
        "duration": 5.875
    },
    {
        "text": "to be the same basic arrangement\nof cell types in all modalities.",
        "start": 1187.341,
        "duration": 3.18
    },
    {
        "text": "And then the variations we see, whether\nit's an extra few layers or extra bigger",
        "start": 1190.841,
        "duration": 4.23
    },
    {
        "text": "cells or more of these cells and less\nof these cells, they're all tweaks that,",
        "start": 1195.071,
        "duration": 4.2
    },
    {
        "text": "and so we don't want to focus on those.",
        "start": 1199.961,
        "duration": 1.23
    },
    {
        "text": "We want to focus on the core algorithms\nfirst, what's going on common to all",
        "start": 1201.496,
        "duration": 3.67
    },
    {
        "text": "of these things, and then later we\nmight say, even in our work, we're",
        "start": 1205.176,
        "duration": 3.73
    },
    {
        "text": "a learning module, we might say,\nhey, you know what, we're going to",
        "start": 1209.216,
        "duration": 1.85
    },
    {
        "text": "tweak the learning module for LiDAR.",
        "start": 1211.146,
        "duration": 2.16
    },
    {
        "text": "Here's how we could do it.",
        "start": 1213.646,
        "duration": 0.89
    },
    {
        "text": "We can add a little extra twist here\nand put some more of these things here.",
        "start": 1214.576,
        "duration": 3.39
    },
    {
        "text": "I don't know.",
        "start": 1218.616,
        "duration": 0.45
    },
    {
        "text": "we can do that, but\nlet's not focus on that.",
        "start": 1220.116,
        "duration": 1.8
    },
    {
        "text": "So don't, get hung up on that.",
        "start": 1221.916,
        "duration": 1.26
    },
    {
        "text": "A good question.",
        "start": 1225.156,
        "duration": 0.72
    },
    {
        "text": "Any other questions before I go on?",
        "start": 1226.416,
        "duration": 1.26
    },
    {
        "text": "Alright.",
        "start": 1230.406,
        "duration": 0.36
    },
    {
        "text": "I know some of this, for some\nof you, this is all review.",
        "start": 1231.206,
        "duration": 1.98
    },
    {
        "text": "Some of it may not be.",
        "start": 1233.186,
        "duration": 0.93
    },
    {
        "text": "I'm now an erase if I can or\nshould I just turn it around?",
        "start": 1235.356,
        "duration": 3.06
    },
    {
        "text": "Go other side?",
        "start": 1238.686,
        "duration": 0.39
    },
    {
        "text": "Sure.",
        "start": 1239.786,
        "duration": 0.18
    },
    {
        "text": "I doesn't turn.",
        "start": 1239.966,
        "duration": 1.26
    },
    {
        "text": "Maybe you can flip it.",
        "start": 1241.706,
        "duration": 0.63
    },
    {
        "text": "Oh, second footboard over there.",
        "start": 1242.756,
        "duration": 2.22
    },
    {
        "text": "We flip it.",
        "start": 1245.336,
        "duration": 0.99
    },
    {
        "text": "Oh, I see.",
        "start": 1246.506,
        "duration": 0.54
    },
    {
        "text": "Oh, this clever, the wheel locked there.",
        "start": 1247.046,
        "duration": 2.53
    },
    {
        "text": "Okay.",
        "start": 1251.506,
        "duration": 0.31
    },
    {
        "text": "Great.",
        "start": 1251.846,
        "duration": 0.07
    },
    {
        "text": "All right.",
        "start": 1251.916,
        "duration": 1.93
    },
    {
        "text": "This is a classic example.",
        "start": 1253.846,
        "duration": 1.93
    },
    {
        "text": "If you were to go to a neuroscience\none on one class in any university,",
        "start": 1256.076,
        "duration": 5.18
    },
    {
        "text": "and you're talking about the brain,\nand they would say, here's the cortex,",
        "start": 1261.606,
        "duration": 3.37
    },
    {
        "text": "and here's a column, and, and they\nwould say, okay, what's going on here?",
        "start": 1265.206,
        "duration": 5.22
    },
    {
        "text": "they would say the following.",
        "start": 1270.726,
        "duration": 0.81
    },
    {
        "text": "They say, okay, there's layer\nfour is the input layer.",
        "start": 1271.536,
        "duration": 4.99
    },
    {
        "text": "So it comes from some, I'm going to draw\nit as if it was coming from the outside.",
        "start": 1276.606,
        "duration": 3.61
    },
    {
        "text": "And you're like, oh.",
        "start": 1280.216,
        "duration": 0.47
    },
    {
        "text": "this, okay?",
        "start": 1281.426,
        "duration": 0.79
    },
    {
        "text": "Layer four is the input layer, because\nthis is where the eye projects to,",
        "start": 1282.436,
        "duration": 2.95
    },
    {
        "text": "or the skin projects to, or the\nhearing, it gets pre processed, vision",
        "start": 1285.396,
        "duration": 4.54
    },
    {
        "text": "doesn't really get pre processed.",
        "start": 1289.936,
        "duration": 1.3
    },
    {
        "text": "Vision goes on right from, I haven't\ntalked about thalamus yet, but it",
        "start": 1291.306,
        "duration": 2.4
    },
    {
        "text": "goes right from the eye, right from\nthe eye to the visual cortex, but,",
        "start": 1294.006,
        "duration": 3.05
    },
    {
        "text": "when you, your touch sensors in\nyour hearing get pre processed a",
        "start": 1297.746,
        "duration": 3.74
    },
    {
        "text": "bit, but it ends up coming up here.",
        "start": 1301.606,
        "duration": 2.3
    },
    {
        "text": "Then layer three is considered\nthe output layer and layer",
        "start": 1304.536,
        "duration": 3.58
    },
    {
        "text": "four projects to layer three.",
        "start": 1308.116,
        "duration": 1.56
    },
    {
        "text": "And then layer three is the\noutput layer, and then the next",
        "start": 1309.826,
        "duration": 2.88
    },
    {
        "text": "column over, or hierarchical.",
        "start": 1312.706,
        "duration": 2.71
    },
    {
        "text": "So now we're going , say V one to V two.",
        "start": 1315.416,
        "duration": 3.0
    },
    {
        "text": "Then this input goes into layer four of,",
        "start": 1319.666,
        "duration": 4.34
    },
    {
        "text": "of, of, the next guy.",
        "start": 1327.276,
        "duration": 1.71
    },
    {
        "text": "So you see this and this goes up to\nlayer three again, and then it just",
        "start": 1329.216,
        "duration": 4.31
    },
    {
        "text": "repeats as you go up the hierarchy.",
        "start": 1333.526,
        "duration": 1.335
    },
    {
        "text": "So this is your classic view that\ninformation enters layer four, gets",
        "start": 1335.376,
        "duration": 3.61
    },
    {
        "text": "processed, somehow goes to layer\nthree, becomes input to layer four,",
        "start": 1338.996,
        "duration": 3.18
    },
    {
        "text": "gets processed to layer three, gets\ninput to layer four, and so on.",
        "start": 1342.326,
        "duration": 2.59
    },
    {
        "text": "Your classic hierarchy.",
        "start": 1345.086,
        "duration": 1.55
    },
    {
        "text": "Of course, this ignores a lot of stuff,\nlike what's everything else doing?",
        "start": 1347.006,
        "duration": 5.6
    },
    {
        "text": "And, but this is your classic view.",
        "start": 1353.306,
        "duration": 2.62
    },
    {
        "text": "we under, we think we understand\nthis pretty well right now.",
        "start": 1357.126,
        "duration": 2.04
    },
    {
        "text": "I do want to point out something\nthat all inference is a matter of",
        "start": 1360.466,
        "duration": 4.695
    },
    {
        "text": "mapping many inputs to fewer outputs.",
        "start": 1365.201,
        "duration": 2.33
    },
    {
        "text": "It's if I'm going to label an image,\nthere's millions of images that I might",
        "start": 1367.771,
        "duration": 3.65
    },
    {
        "text": "call cat, and millions of images that\nI might call dog, or this is true of,",
        "start": 1371.421,
        "duration": 3.45
    },
    {
        "text": "millions of different patterns, I'm like,\nso that's this song, that's that song.",
        "start": 1375.171,
        "duration": 3.19
    },
    {
        "text": "Inference, if this isn't obvious to\nyou, I'll expand on it, but inference",
        "start": 1378.881,
        "duration": 3.05
    },
    {
        "text": "is always a many to one mapping, and\nif that's, oh, I should mention here",
        "start": 1381.941,
        "duration": 4.45
    },
    {
        "text": "too, Mountcastle said that every\ncolumn in the neocortex is doing the",
        "start": 1386.391,
        "duration": 4.38
    },
    {
        "text": "same thing, the correlative to that.",
        "start": 1390.771,
        "duration": 2.26
    },
    {
        "text": "is that every column does what\nthe neocortex does as a whole.",
        "start": 1393.891,
        "duration": 3.74
    },
    {
        "text": "You can't really escape that.",
        "start": 1398.621,
        "duration": 1.1
    },
    {
        "text": "If something's going to happen\nin the neocortex, it's going",
        "start": 1401.131,
        "duration": 3.27
    },
    {
        "text": "to happen in every column.",
        "start": 1404.401,
        "duration": 0.69
    },
    {
        "text": "Because, and I, it doesn't mean\nevery column processes vision.",
        "start": 1405.641,
        "duration": 3.21
    },
    {
        "text": "It means whatever processing elements that\nare going on are happening everywhere.",
        "start": 1408.881,
        "duration": 3.44
    },
    {
        "text": "I just, that's the background to this.",
        "start": 1413.781,
        "duration": 1.15
    },
    {
        "text": "So I'm assuming that anything\nthat happens in the cortex is",
        "start": 1414.941,
        "duration": 2.24
    },
    {
        "text": "going to happen in every column.",
        "start": 1417.181,
        "duration": 0.74
    },
    {
        "text": "Inference is going to happen in\nevery column, and mapping from",
        "start": 1418.601,
        "duration": 3.4
    },
    {
        "text": "many inputs to one output is\ngoing to happen in every column.",
        "start": 1422.141,
        "duration": 2.72
    },
    {
        "text": "So this tells me, right off\nthe bat, there is a many to one",
        "start": 1425.131,
        "duration": 3.38
    },
    {
        "text": "mapping between layer 4 and layer\n3, if I follow that group, right?",
        "start": 1428.521,
        "duration": 3.57
    },
    {
        "text": "And many to one mapping, the term\nwe use for that is temporal pooling.",
        "start": 1432.541,
        "duration": 2.69
    },
    {
        "text": "It means that different\npatterns over time, they get",
        "start": 1435.621,
        "duration": 2.29
    },
    {
        "text": "mapped into a single output.",
        "start": 1437.911,
        "duration": 1.24
    },
    {
        "text": "And I can state that even\nbefore I understand anything",
        "start": 1439.811,
        "duration": 2.82
    },
    {
        "text": "about sensorimotor inference.",
        "start": 1442.641,
        "duration": 1.02
    },
    {
        "text": "It was just like, that's\nlike a fact, it has to be.",
        "start": 1443.741,
        "duration": 2.16
    },
    {
        "text": "if you're gonna, if you're gonna put a\nbunch of patterns and say it's one thing,",
        "start": 1447.036,
        "duration": 3.34
    },
    {
        "text": "then it has to occur, and there's, if\nthis is the way I go up the hierarchy,",
        "start": 1450.776,
        "duration": 3.72
    },
    {
        "text": "then it has to occur from here to here.",
        "start": 1454.536,
        "duration": 1.26
    },
    {
        "text": "So this is a, and our current\ntheory is that temporal pooling",
        "start": 1455.816,
        "duration": 3.19
    },
    {
        "text": "is that, is a term for that.",
        "start": 1459.006,
        "duration": 1.29
    },
    {
        "text": "so as your eyes move or your fingers\nmove, this thing is going to be changing,",
        "start": 1461.286,
        "duration": 3.47
    },
    {
        "text": "but this is going to be more stable.",
        "start": 1464.936,
        "duration": 1.33
    },
    {
        "text": "And it just has to be.",
        "start": 1467.136,
        "duration": 1.13
    },
    {
        "text": "There's nowhere else for it to occur.",
        "start": 1468.566,
        "duration": 1.42
    },
    {
        "text": "Okay.",
        "start": 1470.391,
        "duration": 0.38
    },
    {
        "text": "so that was that.",
        "start": 1472.251,
        "duration": 0.73
    },
    {
        "text": "Then we, said, okay,\nso we could state that.",
        "start": 1473.601,
        "duration": 2.16
    },
    {
        "text": "then we came up with a theory for\nhow the brain could learn sequences",
        "start": 1476.591,
        "duration": 4.19
    },
    {
        "text": "and make predictions of higher order\nsequences like melodies and so on.",
        "start": 1480.971,
        "duration": 2.86
    },
    {
        "text": "It's a really challenging problem.",
        "start": 1483.831,
        "duration": 1.33
    },
    {
        "text": "And we realized we could do that\neven in a single layer, like layer",
        "start": 1485.481,
        "duration": 3.15
    },
    {
        "text": "four, and we use many columns.",
        "start": 1488.631,
        "duration": 1.65
    },
    {
        "text": "I won't go through that algorithm\nnow unless someone wants me to.",
        "start": 1490.301,
        "duration": 2.2
    },
    {
        "text": "But this is the temporal memory algorithm.",
        "start": 1492.846,
        "duration": 1.61
    },
    {
        "text": "We said, okay, so I could have a series,\nif I was listening to a melody, I could",
        "start": 1494.716,
        "duration": 3.0
    },
    {
        "text": "have a series of patterns here, using\nthese mini columns, and then, then, I",
        "start": 1497.716,
        "duration": 5.79
    },
    {
        "text": "map all those patterns to layer 3, and\nthat would be the name of the melody.",
        "start": 1503.556,
        "duration": 2.58
    },
    {
        "text": "So that's the temporal memory algorithm.",
        "start": 1507.496,
        "duration": 1.48
    },
    {
        "text": "And it's very important.",
        "start": 1509.946,
        "duration": 0.83
    },
    {
        "text": "There's a lot of, there's a lot of really\nimportant ideas and how that works.",
        "start": 1510.776,
        "duration": 4.33
    },
    {
        "text": "And it's challenging\npeople to get it in person.",
        "start": 1515.116,
        "duration": 2.04
    },
    {
        "text": "So that was great, but he didn't do\nanything about sensory motor inference.",
        "start": 1518.366,
        "duration": 3.25
    },
    {
        "text": "And, I avoided talking about, I knew\nthat most of the changes occurred to",
        "start": 1521.956,
        "duration": 3.72
    },
    {
        "text": "the branch because we move our bodies.",
        "start": 1525.676,
        "duration": 1.37
    },
    {
        "text": "We move our eyes, we move\nour fingers, we tone.",
        "start": 1527.571,
        "duration": 1.77
    },
    {
        "text": "That's why most of these\nchanges are occurring.",
        "start": 1529.351,
        "duration": 1.91
    },
    {
        "text": "It's not like melody.",
        "start": 1531.271,
        "duration": 0.74
    },
    {
        "text": "Melody happens on its own, but most of\nthe changes are coming into our brains",
        "start": 1532.011,
        "duration": 3.49
    },
    {
        "text": "because I'm moving my head right now.",
        "start": 1535.541,
        "duration": 1.23
    },
    {
        "text": "Everything's moving around\nrapidly, and these are leading",
        "start": 1536.951,
        "duration": 1.91
    },
    {
        "text": "to different changes constantly.",
        "start": 1538.861,
        "duration": 1.27
    },
    {
        "text": "Think about the flood of information\nthat's coming in right now as",
        "start": 1540.491,
        "duration": 2.07
    },
    {
        "text": "I touch things and look at you.",
        "start": 1542.561,
        "duration": 1.7
    },
    {
        "text": "so I didn't understand how that could\nhappen from a sensory motor point of view",
        "start": 1545.591,
        "duration": 3.52
    },
    {
        "text": "for a long time, so I just ignored it.",
        "start": 1549.201,
        "duration": 1.55
    },
    {
        "text": "and I figured, we'll figure it out later.",
        "start": 1551.941,
        "duration": 1.08
    },
    {
        "text": "we did figure it out.",
        "start": 1553.181,
        "duration": 0.71
    },
    {
        "text": "and the answer, it turns out to be,\nthat there's another layer of cells,",
        "start": 1554.861,
        "duration": 4.2
    },
    {
        "text": "which is representing a location\nand that layer cell is, there's, and",
        "start": 1559.071,
        "duration": 7.44
    },
    {
        "text": "we're going to call that layer 6A,",
        "start": 1566.511,
        "duration": 1.76
    },
    {
        "text": "and there is a bi directional\nconnection between layer 6A and layer",
        "start": 1571.881,
        "duration": 4.88
    },
    {
        "text": "4, this is a very major connection,\nand what's happening here is that,",
        "start": 1576.761,
        "duration": 5.32
    },
    {
        "text": "this is keeping track of where the\nsensor is on the objects in the world.",
        "start": 1584.041,
        "duration": 3.94
    },
    {
        "text": "And, therefore it says the\nlocation I've sensed this thing,",
        "start": 1588.886,
        "duration": 3.34
    },
    {
        "text": "and if I know the location, I can\npredict what I'm going to sense.",
        "start": 1592.616,
        "duration": 2.43
    },
    {
        "text": "And if I know what I sense, it can\nhelp me narrow down the location.",
        "start": 1595.426,
        "duration": 3.32
    },
    {
        "text": "And so this pairing of sensations\nAnd, or features and location is",
        "start": 1599.666,
        "duration": 5.735
    },
    {
        "text": "the foundation of basic model.",
        "start": 1605.411,
        "duration": 2.09
    },
    {
        "text": "It's like it's that's the\nfoundation of the model.",
        "start": 1607.551,
        "duration": 1.73
    },
    {
        "text": "and so this was the idea that neurons\nin a column could keep track of a",
        "start": 1610.621,
        "duration": 3.5
    },
    {
        "text": "location of the sensor seemed crazy.",
        "start": 1614.121,
        "duration": 1.96
    },
    {
        "text": "How could that be, but we\ncouldn't deduce it had to happen.",
        "start": 1616.571,
        "duration": 2.59
    },
    {
        "text": "That's the only way your finger can\npredict what it's going to sense.",
        "start": 1619.781,
        "duration": 2.86
    },
    {
        "text": "If the finger is, if this thing's\ngetting input from the tip of your",
        "start": 1622.901,
        "duration": 2.34
    },
    {
        "text": "finger, and you can predict what you're\ngoing to sense, it needs to know what",
        "start": 1625.241,
        "duration": 3.51
    },
    {
        "text": "it's sensing, like what object, and it\nneeds to know where it is on the object.",
        "start": 1628.751,
        "duration": 2.65
    },
    {
        "text": "There's no other way around it.",
        "start": 1631.401,
        "duration": 0.98
    },
    {
        "text": "And and then we realized, oh, this is,\nit seemed crazy at first, but then we",
        "start": 1633.131,
        "duration": 4.8
    },
    {
        "text": "said, oh, no, we found these things.",
        "start": 1637.931,
        "duration": 1.15
    },
    {
        "text": "We didn't find them.",
        "start": 1639.201,
        "duration": 0.58
    },
    {
        "text": "We know about these other cells\nin part of the rainbow grid",
        "start": 1639.801,
        "duration": 2.07
    },
    {
        "text": "cells, which acts like a location.",
        "start": 1641.871,
        "duration": 2.17
    },
    {
        "text": "So we speculated the,\nsonic grid cells here.",
        "start": 1644.041,
        "duration": 2.83
    },
    {
        "text": "grid cells exist in the antelope cortex,\nbut they, were like a reference frame.",
        "start": 1647.646,
        "duration": 3.8
    },
    {
        "text": "And, and they tell you, they tell\nyou where you are on the object.",
        "start": 1651.856,
        "duration": 3.92
    },
    {
        "text": "And of course, then you\nneed something else.",
        "start": 1656.046,
        "duration": 1.62
    },
    {
        "text": "how does this thing work?",
        "start": 1658.966,
        "duration": 1.24
    },
    {
        "text": "we know a lot about grid cells\nbecause it's a field of study.",
        "start": 1660.466,
        "duration": 3.32
    },
    {
        "text": "And so the basic idea here is that\nthere's a second input coming into",
        "start": 1664.296,
        "duration": 3.61
    },
    {
        "text": "the, into each column, a movement\ninput, and as opposed to a sort of.",
        "start": 1668.076,
        "duration": 5.84
    },
    {
        "text": "feature input or sense thing.",
        "start": 1674.411,
        "duration": 1.91
    },
    {
        "text": "it can be a feature, it can be more\nthan, it doesn't have to come from a",
        "start": 1678.441,
        "duration": 2.6
    },
    {
        "text": "sensory organ, it comes from the cells.",
        "start": 1681.041,
        "duration": 1.39
    },
    {
        "text": "So now we have two inputs to our column.",
        "start": 1682.771,
        "duration": 1.6
    },
    {
        "text": "One is updating where the location is,\nI know I'm moving in this direction,",
        "start": 1684.371,
        "duration": 3.62
    },
    {
        "text": "therefore I can calculate where I\nwill be over time, and grid cells do",
        "start": 1688.401,
        "duration": 3.25
    },
    {
        "text": "that, we know that, it's well proven,\nit's incredible data on grid cells.",
        "start": 1691.651,
        "duration": 3.78
    },
    {
        "text": "We speculated it happens in\nthe cortex, but it's known to",
        "start": 1695.831,
        "duration": 3.02
    },
    {
        "text": "exist in the entorhinal cortex.",
        "start": 1698.851,
        "duration": 1.278
    },
    {
        "text": "So you have a movement information, which\nupdates the location and therefore now",
        "start": 1700.616,
        "duration": 3.67
    },
    {
        "text": "you send something at a new location\nand it doesn't matter what kind of I'm",
        "start": 1704.286,
        "duration": 3.74
    },
    {
        "text": "going to learn how something feels.",
        "start": 1708.026,
        "duration": 1.68
    },
    {
        "text": "It doesn't matter what\norder I go around it.",
        "start": 1709.896,
        "duration": 1.57
    },
    {
        "text": "It doesn't really matter as long\nas I cover different locations.",
        "start": 1711.516,
        "duration": 2.27
    },
    {
        "text": "In any pattern, in any order, it'll\nkeep track of where I am, and then,",
        "start": 1714.106,
        "duration": 3.66
    },
    {
        "text": "and then I can build this model.",
        "start": 1718.126,
        "duration": 1.13
    },
    {
        "text": "And you need to develop this, if\nyou don't already, this image in",
        "start": 1719.256,
        "duration": 3.45
    },
    {
        "text": "your head of a model of a three\ndimensional structure where each",
        "start": 1722.706,
        "duration": 3.06
    },
    {
        "text": "location you have some knowledge about,\nthat's what Monte does, about what",
        "start": 1725.766,
        "duration": 3.19
    },
    {
        "text": "is there, what was observed there.",
        "start": 1728.986,
        "duration": 1.26
    },
    {
        "text": "And so that is the basic of how\nmodels are built, sensory motor",
        "start": 1731.156,
        "duration": 3.09
    },
    {
        "text": "models are built in the cortex.",
        "start": 1734.246,
        "duration": 1.74
    },
    {
        "text": "And so we only, we guessing what these\nlayers mean, but you can see how how",
        "start": 1736.226,
        "duration": 6.765
    },
    {
        "text": "they, how you forced to say, layer\nthree must be doing something like that.",
        "start": 1742.991,
        "duration": 5.39
    },
    {
        "text": "And layer six, eight, because of\nthese bidirectional connections",
        "start": 1748.381,
        "duration": 2.12
    },
    {
        "text": "must be doing location.",
        "start": 1750.501,
        "duration": 1.02
    },
    {
        "text": "And, so now you can deduce these things.",
        "start": 1752.121,
        "duration": 1.89
    },
    {
        "text": "We might still get it wrong, but.",
        "start": 1754.011,
        "duration": 1.01
    },
    {
        "text": "I, think the actual layer, layers is\nnot as important as the functional",
        "start": 1756.206,
        "duration": 4.33
    },
    {
        "text": "role that must be done, but it's\na pretty good guess what the",
        "start": 1760.536,
        "duration": 2.82
    },
    {
        "text": "layers are, at this point in time.",
        "start": 1763.356,
        "duration": 1.71
    },
    {
        "text": "Is there any, physiological\nevidence of layer 3 being more",
        "start": 1765.076,
        "duration": 3.85
    },
    {
        "text": "stable as we look at the subject?",
        "start": 1768.926,
        "duration": 2.25
    },
    {
        "text": "no, but I, don't, I'm not aware of it.",
        "start": 1772.086,
        "duration": 2.88
    },
    {
        "text": "But they haven't looked for it because\nthey don't want to look for it.",
        "start": 1775.316,
        "duration": 3.27
    },
    {
        "text": "this is a great question.",
        "start": 1780.376,
        "duration": 1.37
    },
    {
        "text": "So let's just talk about how, a\nlayer of cells represents something.",
        "start": 1782.246,
        "duration": 3.67
    },
    {
        "text": "If you look at layer 3, maybe it has\n5, 000 cells in it, maybe 10, 000.",
        "start": 1786.876,
        "duration": 5.75
    },
    {
        "text": "I don't know, something like that, right?",
        "start": 1792.646,
        "duration": 1.39
    },
    {
        "text": "and, and it may be, it's very sparse.",
        "start": 1795.586,
        "duration": 5.03
    },
    {
        "text": "We know that.",
        "start": 1800.646,
        "duration": 0.64
    },
    {
        "text": "There are very few neurons that\nare active at any point in time.",
        "start": 1801.836,
        "duration": 2.07
    },
    {
        "text": "So you might say, let's\nsay 2 cells are active.",
        "start": 1803.906,
        "duration": 2.765
    },
    {
        "text": "So maybe you have 100 cells\nthat are active, right?",
        "start": 1806.951,
        "duration": 3.43
    },
    {
        "text": "What is stable is that\npattern of 100 cells.",
        "start": 1810.571,
        "duration": 3.6
    },
    {
        "text": "Any particular cell, by the way,\nit's only stable if the animal is",
        "start": 1814.611,
        "duration": 4.08
    },
    {
        "text": "observing an object that it knows.",
        "start": 1818.691,
        "duration": 1.56
    },
    {
        "text": "so an animal has to be awake, it has\nto be observing an object that it",
        "start": 1821.151,
        "duration": 3.09
    },
    {
        "text": "knows, it has to be continually to\nobserve that same object and alert,",
        "start": 1824.241,
        "duration": 4.33
    },
    {
        "text": "and then you would expect to see\na stability of this hundred cells.",
        "start": 1829.671,
        "duration": 3.38
    },
    {
        "text": "Any particular cell will become active\none, two percent of the time, so on",
        "start": 1834.501,
        "duration": 4.11
    },
    {
        "text": "one out of fifty presentations, right?",
        "start": 1838.621,
        "duration": 1.64
    },
    {
        "text": "So if you look at the experimental\nparadigms that people typically do,",
        "start": 1840.971,
        "duration": 3.34
    },
    {
        "text": "most of those conditions are not met.",
        "start": 1844.891,
        "duration": 1.45
    },
    {
        "text": "The animal's anesthetized, they're\nshowing sinusoidal gratings, They're",
        "start": 1846.401,
        "duration": 4.735
    },
    {
        "text": "doing all kinds of stuff where the animal\nis not awake and alert and looking at",
        "start": 1851.146,
        "duration": 3.42
    },
    {
        "text": "something, and they're not, and they'll\nsay, the cell, it fired on this image,",
        "start": 1854.566,
        "duration": 4.49
    },
    {
        "text": "but it didn't fire on that image, and,\nand get back to the work that you and",
        "start": 1859.056,
        "duration": 4.31
    },
    {
        "text": "Niels are doing, are these SDRs with\nthese sparse distributed representations.",
        "start": 1863.366,
        "duration": 3.26
    },
    {
        "text": "Do they have semantic overlap?",
        "start": 1866.936,
        "duration": 1.28
    },
    {
        "text": "If they have no semantic overlap,\nmeaning one SDR is randomly chosen",
        "start": 1868.496,
        "duration": 3.76
    },
    {
        "text": "for another one, then you won't\nlook, you won't be able to see",
        "start": 1872.256,
        "duration": 2.59
    },
    {
        "text": "a cell assign any meaning to it.",
        "start": 1874.846,
        "duration": 1.76
    },
    {
        "text": "One moment it might be a cat,\nand next it might be, a bicycle.",
        "start": 1876.616,
        "duration": 3.75
    },
    {
        "text": "it's just meaningless.",
        "start": 1880.686,
        "duration": 1.23
    },
    {
        "text": "it's the step that matters.",
        "start": 1883.136,
        "duration": 1.01
    },
    {
        "text": "it's very difficult to\nknow what to look for.",
        "start": 1885.791,
        "duration": 1.89
    },
    {
        "text": "Now they have techniques that\nthey might be able to do this.",
        "start": 1887.961,
        "duration": 2.46
    },
    {
        "text": "But again, it's very\ndifficult experiments.",
        "start": 1890.741,
        "duration": 1.5
    },
    {
        "text": "Animal has learned an object, recognizes\nthe object, is fixated, moving on that",
        "start": 1892.551,
        "duration": 4.15
    },
    {
        "text": "object, is alert, and they're licking a\nwhole bunch of neurons at the same time.",
        "start": 1896.701,
        "duration": 3.2
    },
    {
        "text": "Hard to do.",
        "start": 1901.391,
        "duration": 0.5
    },
    {
        "text": "But there's evidence that It's more\nsparse, in that layer, Yes, And",
        "start": 1905.441,
        "duration": 5.78
    },
    {
        "text": "has electrical connectivity, which,\nas I said before, fits with it.",
        "start": 1911.221,
        "duration": 5.23
    },
    {
        "text": "You've got these 10, 000 cells, and\nwhat you really want to do is you want",
        "start": 1917.221,
        "duration": 2.93
    },
    {
        "text": "the SDR, the sparse distributor, the\n100 active cells to self reinforce.",
        "start": 1920.151,
        "duration": 4.0
    },
    {
        "text": "and then another pattern of\n100 self reinforced, and so on.",
        "start": 1925.806,
        "duration": 2.81
    },
    {
        "text": "The whole, the whole, the sort of\nmathematics of sparse distributed",
        "start": 1928.956,
        "duration": 3.52
    },
    {
        "text": "representations is really interesting.",
        "start": 1932.476,
        "duration": 1.44
    },
    {
        "text": "We're not using that\nat all in Monte today.",
        "start": 1934.106,
        "duration": 1.52
    },
    {
        "text": "It's not clear if we have\nto, but brains do it.",
        "start": 1935.756,
        "duration": 2.9
    },
    {
        "text": "All right, other, questions.",
        "start": 1939.766,
        "duration": 2.08
    },
    {
        "text": "I'm going to fill in a few\nmore pieces here, and then,",
        "start": 1942.036,
        "duration": 1.88
    },
    {
        "text": "is this helpful?",
        "start": 1946.776,
        "duration": 0.71
    },
    {
        "text": "Yes.",
        "start": 1947.776,
        "duration": 0.39
    },
    {
        "text": "I'm talking a lot, so I don't know.",
        "start": 1948.286,
        "duration": 1.27
    },
    {
        "text": "One thing we didn't understand\nat first is that there needs",
        "start": 1951.126,
        "duration": 2.86
    },
    {
        "text": "to be a concept of orientation.",
        "start": 1953.986,
        "duration": 1.73
    },
    {
        "text": "it's insufficient just to know where\nlike, where the patch of the eye is on the",
        "start": 1956.536,
        "duration": 3.7
    },
    {
        "text": "object or the fingertip is on the object.",
        "start": 1960.356,
        "duration": 1.53
    },
    {
        "text": "You have to know the\norientation of the patch.",
        "start": 1962.116,
        "duration": 2.21
    },
    {
        "text": "Like I tilt my head left or\nright, the whole image is on",
        "start": 1964.626,
        "duration": 2.95
    },
    {
        "text": "my, the patch is all rotated.",
        "start": 1967.576,
        "duration": 1.39
    },
    {
        "text": "Or if I take my finger\nand I rotate it like this.",
        "start": 1969.176,
        "duration": 1.83
    },
    {
        "text": "My perception isn't changing.",
        "start": 1971.511,
        "duration": 1.43
    },
    {
        "text": "I perceive, it doesn't matter if I\nrun my finger this way or this way, I",
        "start": 1972.941,
        "duration": 3.58
    },
    {
        "text": "perceive the same object, but it's very\ndifferent patterns coming in my finger.",
        "start": 1976.541,
        "duration": 2.91
    },
    {
        "text": "And so the orientation has to\nbe compensated for in many ways.",
        "start": 1980.231,
        "duration": 3.84
    },
    {
        "text": "So there has to be another signal\nwhich represents orientation.",
        "start": 1984.551,
        "duration": 3.74
    },
    {
        "text": "This is equivalent to head\ndirection cells in the hippocampal",
        "start": 1988.291,
        "duration": 2.92
    },
    {
        "text": "complex, if you, or elsewhere.",
        "start": 1991.211,
        "duration": 1.28
    },
    {
        "text": "So we have an orientation signal,\na location and an orientation,",
        "start": 1993.096,
        "duration": 3.25
    },
    {
        "text": "and both of those will be updated by\nmovement, like when I have a, if the",
        "start": 1999.736,
        "duration": 4.49
    },
    {
        "text": "cortex is being told my finger or hand\nis moving and my fingers moving some",
        "start": 2004.296,
        "duration": 3.57
    },
    {
        "text": "way, it could change the orientation,\nit could change its location.",
        "start": 2007.866,
        "duration": 2.71
    },
    {
        "text": "So we have this input coming in here.",
        "start": 2010.576,
        "duration": 2.03
    },
    {
        "text": "Both of these can be updated by movement.",
        "start": 2012.906,
        "duration": 1.77
    },
    {
        "text": "So now we know the orientation,\nthe center to the object, we",
        "start": 2015.066,
        "duration": 2.9
    },
    {
        "text": "know the location on the object.",
        "start": 2017.966,
        "duration": 1.06
    },
    {
        "text": "Now, this is something we figured\nout fairly recently, I don't know,",
        "start": 2020.176,
        "duration": 3.68
    },
    {
        "text": "I don't know how many years ago,\ntwo years ago, I don't know, how is",
        "start": 2024.096,
        "duration": 4.61
    },
    {
        "text": "orientation taken advantage of here?",
        "start": 2028.706,
        "duration": 1.57
    },
    {
        "text": "what we want to do is we want\nto change, we want to basically",
        "start": 2032.156,
        "duration": 2.86
    },
    {
        "text": "We want to remove the input.",
        "start": 2035.551,
        "duration": 1.98
    },
    {
        "text": "Imagine if I'm touching\nan object with my finger.",
        "start": 2038.171,
        "duration": 1.71
    },
    {
        "text": "I don't want the orientation to matter.",
        "start": 2039.911,
        "duration": 1.37
    },
    {
        "text": "It should matter what\nthe orientation might be.",
        "start": 2041.281,
        "duration": 2.29
    },
    {
        "text": "I want to get the same result regardless.",
        "start": 2043.811,
        "duration": 1.9
    },
    {
        "text": "Or if the object is rotated, I'm looking\nat it this way or this way, or I tilt",
        "start": 2046.601,
        "duration": 3.34
    },
    {
        "text": "my head, it should be the same thing.",
        "start": 2049.941,
        "duration": 1.75
    },
    {
        "text": "I don't want to have, it can't change it.",
        "start": 2051.691,
        "duration": 2.83
    },
    {
        "text": "So here's something we\nfigured out fairly recently.",
        "start": 2054.911,
        "duration": 2.28
    },
    {
        "text": "It's in the,",
        "start": 2057.611,
        "duration": 0.74
    },
    {
        "text": "something we, figured out, I dunno how,",
        "start": 2067.551,
        "duration": 1.68
    },
    {
        "text": "okay, so we look at the\ncortex, we've got columns.",
        "start": 2071.721,
        "duration": 4.7
    },
    {
        "text": "There's another part of the\nbrain, which is absolutely",
        "start": 2078.161,
        "duration": 1.92
    },
    {
        "text": "essential how the cortex works.",
        "start": 2080.081,
        "duration": 1.29
    },
    {
        "text": "it's intimately tied to\neverything in the cortex.",
        "start": 2082.231,
        "duration": 2.04
    },
    {
        "text": "That is the th",
        "start": 2084.741,
        "duration": 0.63
    },
    {
        "text": "the thal is like a, it looks\nlike a little bird egg.",
        "start": 2087.661,
        "duration": 2.58
    },
    {
        "text": "There's two of on each side of your head\nin the center of the brain, and every",
        "start": 2090.391,
        "duration": 3.75
    },
    {
        "text": "part of the cortex connects to Thalamus\nand every part, and, and Thalamus",
        "start": 2094.141,
        "duration": 2.68
    },
    {
        "text": "connects back to every part of the.",
        "start": 2096.821,
        "duration": 0.92
    },
    {
        "text": "it's intimately connected, and in\nfact, if you have an eye or finger",
        "start": 2099.696,
        "duration": 6.1
    },
    {
        "text": "or whatever, any input to the cortex\nfirst goes through the thalamus and",
        "start": 2105.796,
        "duration": 4.36
    },
    {
        "text": "then goes up to layer four, right?",
        "start": 2110.156,
        "duration": 2.76
    },
    {
        "text": "And it stops at these\nthings called relay cells.",
        "start": 2113.276,
        "duration": 2.27
    },
    {
        "text": "And then the cortex projects\nback to the thalamus,",
        "start": 2116.486,
        "duration": 2.33
    },
    {
        "text": "and in a major way, lots of details\nknown about these series of connections,",
        "start": 2121.646,
        "duration": 4.59
    },
    {
        "text": "but all inputs to the cortex go\nthrough relay cells in the thalamus.",
        "start": 2126.826,
        "duration": 4.14
    },
    {
        "text": "And if you look at a lot of\nthe literature, they don't",
        "start": 2131.526,
        "duration": 3.38
    },
    {
        "text": "always talk about this.",
        "start": 2134.916,
        "duration": 1.05
    },
    {
        "text": "They'll say, Projects to, to\nthe thalamus, a thing called",
        "start": 2136.196,
        "duration": 5.635
    },
    {
        "text": "LGN, which is lateral nucleus.",
        "start": 2141.831,
        "duration": 2.25
    },
    {
        "text": "Then it goes to V one, then V\none projects to V two and V two",
        "start": 2144.321,
        "duration": 3.75
    },
    {
        "text": "projects to V four in the cortex.",
        "start": 2148.071,
        "duration": 2.13
    },
    {
        "text": "this is just how you get into the\ncortex and the information flows",
        "start": 2150.681,
        "duration": 2.64
    },
    {
        "text": "from region to region, which is true.",
        "start": 2153.321,
        "duration": 2.63
    },
    {
        "text": "But then, what is also known that every\nregion, the cortex gets input from",
        "start": 2156.221,
        "duration": 5.31
    },
    {
        "text": "the th every region and every column.",
        "start": 2161.531,
        "duration": 3.55
    },
    {
        "text": "So this is where the heterarchy\npaper comes about, right?",
        "start": 2165.351,
        "duration": 3.57
    },
    {
        "text": "There's clearly a hierarchy\nof, projections in B4,",
        "start": 2169.931,
        "duration": 4.93
    },
    {
        "text": "but it's also in parallel.",
        "start": 2175.061,
        "duration": 1.29
    },
    {
        "text": "so sometimes these, regions are\nworking in parallel, and they're",
        "start": 2178.391,
        "duration": 3.55
    },
    {
        "text": "also working hierarchically.",
        "start": 2181.941,
        "duration": 1.64
    },
    {
        "text": "And what we now believe is in the\nwhole heterarchy paper is that",
        "start": 2183.581,
        "duration": 3.26
    },
    {
        "text": "Each region is learning objects.",
        "start": 2187.111,
        "duration": 2.18
    },
    {
        "text": "Each region is, or each column in\neach region is modeling objects.",
        "start": 2189.291,
        "duration": 3.85
    },
    {
        "text": "Each one has to have a complete\ncentri motor interface to",
        "start": 2193.731,
        "duration": 3.12
    },
    {
        "text": "the world in some sense.",
        "start": 2196.851,
        "duration": 1.07
    },
    {
        "text": "but then these connections are\nfor hierarchical composition,",
        "start": 2198.841,
        "duration": 3.32
    },
    {
        "text": "objects composed of objects.",
        "start": 2202.181,
        "duration": 1.36
    },
    {
        "text": "So you don't have to, the classic\nview is that V1 just detects little",
        "start": 2204.081,
        "duration": 3.01
    },
    {
        "text": "features and you have to bing\nand fence to get objects up here.",
        "start": 2207.091,
        "duration": 3.12
    },
    {
        "text": "But what we think is going on is\nthat everything is recognizing",
        "start": 2210.641,
        "duration": 2.78
    },
    {
        "text": "objects, they just, people didn't\nknow it, they couldn't, they",
        "start": 2213.451,
        "duration": 1.9
    },
    {
        "text": "didn't know how to observe it.",
        "start": 2215.351,
        "duration": 1.18
    },
    {
        "text": "and these connections are like saying\nthat the object in V2 has a, feature",
        "start": 2217.581,
        "duration": 5.21
    },
    {
        "text": "which is an object in V1, with the\nclassic coffee mug with the logo.",
        "start": 2222.791,
        "duration": 4.09
    },
    {
        "text": "The logo would be here, the coffee\nmug would be here, therefore the",
        "start": 2227.336,
        "duration": 2.49
    },
    {
        "text": "logo is part of the coffee mug.",
        "start": 2229.826,
        "duration": 0.84
    },
    {
        "text": "but this is recognizing the mug\nand this is representing the logo.",
        "start": 2231.866,
        "duration": 2.48
    },
    {
        "text": "it's not, and, I'm virtually\ncertain that's what's happening.",
        "start": 2235.876,
        "duration": 2.84
    },
    {
        "text": "Higher level input, does\nit also go to layer four?",
        "start": 2239.406,
        "duration": 2.04
    },
    {
        "text": "higher layer, what do you mean?",
        "start": 2243.346,
        "duration": 0.88
    },
    {
        "text": "what's going to be two and three?",
        "start": 2244.876,
        "duration": 1.35
    },
    {
        "text": "this is, going back to the layer\nthree projects to layer four, like",
        "start": 2246.776,
        "duration": 3.15
    },
    {
        "text": "layer three projects to layer four,\nlayer three projects to layer four.",
        "start": 2249.966,
        "duration": 2.43
    },
    {
        "text": "Oh, okay.",
        "start": 2253.086,
        "duration": 1.04
    },
    {
        "text": "there's some more details\nthere that I didn't tell you.",
        "start": 2255.596,
        "duration": 1.71
    },
    {
        "text": "People talk about the\nmain input to a quark.",
        "start": 2258.406,
        "duration": 2.24
    },
    {
        "text": "com going to layer 3.",
        "start": 2260.646,
        "duration": 1.26
    },
    {
        "text": "excuse me, layer 4.",
        "start": 2262.956,
        "duration": 0.69
    },
    {
        "text": "Layer 4.",
        "start": 2263.646,
        "duration": 0.49
    },
    {
        "text": "That's not really completely true.",
        "start": 2265.866,
        "duration": 1.23
    },
    {
        "text": "there's another input that\ngoes to lower layers, 3.",
        "start": 2268.106,
        "duration": 2.61
    },
    {
        "text": "And there's another input that goes\nto, the layer 5, layer 6 border.",
        "start": 2271.386,
        "duration": 5.74
    },
    {
        "text": "this could arguably be\nlayer 3, layer 4 border.",
        "start": 2278.436,
        "duration": 2.0
    },
    {
        "text": "It depends on how you look at it.",
        "start": 2280.436,
        "duration": 1.49
    },
    {
        "text": "So there's actually three different\ninputs to the, to a column.",
        "start": 2282.501,
        "duration": 2.62
    },
    {
        "text": "Both people talk about layer\nfour as the main input.",
        "start": 2285.661,
        "duration": 1.96
    },
    {
        "text": "what I think is going on here, and I\nthink this is the motor input, the layer",
        "start": 2288.571,
        "duration": 3.19
    },
    {
        "text": "five plus layer three, layer six one.",
        "start": 2291.761,
        "duration": 2.18
    },
    {
        "text": "It's basically saying, here's, I'm\ngoing to drive these guys to, to path",
        "start": 2294.241,
        "duration": 5.8
    },
    {
        "text": "integrate and update the location.",
        "start": 2300.141,
        "duration": 1.72
    },
    {
        "text": "And, I think what's going on up here\nis this is actually related to object",
        "start": 2302.611,
        "duration": 4.53
    },
    {
        "text": "behaviors and movement, it's movement\nrelated to the object as opposed to",
        "start": 2307.161,
        "duration": 3.57
    },
    {
        "text": "this is movement related to the sensor.",
        "start": 2310.731,
        "duration": 1.36
    },
    {
        "text": "The object is moving\nsomething on the object.",
        "start": 2312.621,
        "duration": 1.59
    },
    {
        "text": "So we can come back to that maybe\nwhen we talk about object behaviors.",
        "start": 2314.231,
        "duration": 3.22
    },
    {
        "text": "now your, did I answer your question?",
        "start": 2318.511,
        "duration": 1.73
    },
    {
        "text": "Yeah, so it's the same for v1, v2, and v4.",
        "start": 2320.411,
        "duration": 2.42
    },
    {
        "text": "They all get the same composition.",
        "start": 2322.881,
        "duration": 1.73
    },
    {
        "text": "This is basically all look\nlike this as far as we know.",
        "start": 2324.671,
        "duration": 2.25
    },
    {
        "text": "As Murray Sherman has told me\nseveral times, he says, everywhere",
        "start": 2327.981,
        "duration": 2.92
    },
    {
        "text": "we've looked, we've seen this.",
        "start": 2330.901,
        "duration": 1.465
    },
    {
        "text": "But we haven't looked at it",
        "start": 2332.806,
        "duration": 0.76
    },
    {
        "text": "yet.",
        "start": 2336.206,
        "duration": 0.13
    },
    {
        "text": "And these inputs from\nthe THALMOS II lead to",
        "start": 2336.336,
        "duration": 2.85
    },
    {
        "text": "nuclear, and so the THALMOS is,\nseparate, divided into many different",
        "start": 2342.306,
        "duration": 6.75
    },
    {
        "text": "nuclei, and they get different inputs.",
        "start": 2349.056,
        "duration": 2.04
    },
    {
        "text": "Each region has its own nuclei, right?",
        "start": 2351.596,
        "duration": 3.14
    },
    {
        "text": "And by the way, the, not only do the\nsensory input go to it, but the, oops,",
        "start": 2355.396,
        "duration": 5.16
    },
    {
        "text": "the motor input goes to the THALMOS\nII, or the, there's a separate,",
        "start": 2360.966,
        "duration": 3.67
    },
    {
        "text": "there's, two pathways to the thalamus.",
        "start": 2365.626,
        "duration": 1.62
    },
    {
        "text": "They don't call it motor,\nbut we know it's motor.",
        "start": 2367.666,
        "duration": 1.85
    },
    {
        "text": "there are these parallel\npathways to the thalamus.",
        "start": 2371.426,
        "duration": 2.28
    },
    {
        "text": "And, from the eye, they're related\nto the magnus side and parvus",
        "start": 2374.076,
        "duration": 4.35
    },
    {
        "text": "side of the pathways from the eye.",
        "start": 2378.426,
        "duration": 1.7
    },
    {
        "text": "So there's two pathways from the eye.",
        "start": 2380.126,
        "duration": 1.47
    },
    {
        "text": "And one represents movement.",
        "start": 2382.056,
        "duration": 1.64
    },
    {
        "text": "We're pretty certain about this.",
        "start": 2384.396,
        "duration": 1.07
    },
    {
        "text": "And the other represents features.",
        "start": 2385.486,
        "duration": 1.27
    },
    {
        "text": "so you have the movement goes\nto the thalamus and the sensory",
        "start": 2387.466,
        "duration": 3.1
    },
    {
        "text": "input goes to the thalamus.",
        "start": 2390.566,
        "duration": 0.72
    },
    {
        "text": "What is one of the things, one of the\nmajor things that Thalmus is doing, is",
        "start": 2392.236,
        "duration": 3.45
    },
    {
        "text": "part of our theories, they call these\nrelay cells because they look like one",
        "start": 2395.716,
        "duration": 4.49
    },
    {
        "text": "spike comes in and one spike comes out.",
        "start": 2400.206,
        "duration": 1.81
    },
    {
        "text": "great, what's that for?",
        "start": 2403.506,
        "duration": 0.88
    },
    {
        "text": "Not very useful, is it?",
        "start": 2404.856,
        "duration": 0.82
    },
    {
        "text": "So they're like, oh, it might be a delay,\nbut these cells are really complicated.",
        "start": 2406.326,
        "duration": 2.8
    },
    {
        "text": "They have 6, 000 synapses and\nvery complex architecture.",
        "start": 2409.166,
        "duration": 3.6
    },
    {
        "text": "It's a huge amount of\ncomplication down here we can",
        "start": 2413.576,
        "duration": 1.63
    },
    {
        "text": "get into if you want to know it.",
        "start": 2415.206,
        "duration": 1.01
    },
    {
        "text": "But what's the point of this?",
        "start": 2417.426,
        "duration": 1.92
    },
    {
        "text": "If it's a relay cell,\nwhat the hell is it doing?",
        "start": 2419.376,
        "duration": 1.61
    },
    {
        "text": "that doesn't get useful.",
        "start": 2421.246,
        "duration": 0.83
    },
    {
        "text": "No one really knows.",
        "start": 2422.496,
        "duration": 0.68
    },
    {
        "text": "We now know.",
        "start": 2423.216,
        "duration": 0.85
    },
    {
        "text": "We're pretty certain what it is.",
        "start": 2424.116,
        "duration": 1.41
    },
    {
        "text": "They're remapping.",
        "start": 2425.896,
        "duration": 0.95
    },
    {
        "text": "So what spike output\nturns out that can vary.",
        "start": 2427.306,
        "duration": 4.53
    },
    {
        "text": "That is, cells, they\nget more than one input.",
        "start": 2431.876,
        "duration": 2.26
    },
    {
        "text": "They have more snaps in some parts of\ndifferent parts of the, the retina.",
        "start": 2434.136,
        "duration": 3.62
    },
    {
        "text": "And so they're like multiplexers.",
        "start": 2437.886,
        "duration": 1.83
    },
    {
        "text": "They can basically take an input,\nremap it and send it to the cortex.",
        "start": 2439.776,
        "duration": 3.21
    },
    {
        "text": "That's the basic idea.",
        "start": 2443.846,
        "duration": 1.02
    },
    {
        "text": "There's a lot of salty and confused about\nhow it does that, but there's a lot of",
        "start": 2445.126,
        "duration": 3.03
    },
    {
        "text": "suggestions that's what they're doing.",
        "start": 2448.156,
        "duration": 1.23
    },
    {
        "text": "And theoretically, it makes sense,\nbecause what we think is going on is,",
        "start": 2449.716,
        "duration": 4.64
    },
    {
        "text": "one of the, one of the major projections\nyou have going down there is layer",
        "start": 2455.536,
        "duration": 3.84
    },
    {
        "text": "5A, which we think is orientation,",
        "start": 2459.376,
        "duration": 2.48
    },
    {
        "text": "and that projects down here, and it says,\nbasically, given my current orientation",
        "start": 2465.076,
        "duration": 5.48
    },
    {
        "text": "of the center to the object, remember\nthis is the orientation of the sensor,",
        "start": 2470.566,
        "duration": 3.31
    },
    {
        "text": "like a sensor patch, like your eye, if\nI tilt my head, the orientation changes.",
        "start": 2473.886,
        "duration": 3.09
    },
    {
        "text": "Oh, if I rotate my finger,\nthe orientation changes.",
        "start": 2478.096,
        "duration": 1.96
    },
    {
        "text": "That orientation comes down here and\ntells this guy how to compensate for it.",
        "start": 2480.786,
        "duration": 3.35
    },
    {
        "text": "It says, rotate the input!",
        "start": 2484.136,
        "duration": 1.91
    },
    {
        "text": "and it has to do that for motor too,\nbecause if I'm reading text and I",
        "start": 2487.866,
        "duration": 2.77
    },
    {
        "text": "rotate my page like this, which you\ndo all the time, your eyes have to",
        "start": 2490.646,
        "duration": 3.14
    },
    {
        "text": "move diagonally to read the text.",
        "start": 2493.786,
        "duration": 1.3
    },
    {
        "text": "So your motor behavior changes based\non the orientation and the, what you",
        "start": 2495.616,
        "duration": 3.47
    },
    {
        "text": "sense changes based on the orientation,\nand this is compensating for it.",
        "start": 2499.096,
        "duration": 3.29
    },
    {
        "text": "So now we have the complete system.",
        "start": 2503.386,
        "duration": 1.47
    },
    {
        "text": "You've got a system with movement coming\nin, features coming in, there's a,",
        "start": 2504.886,
        "duration": 5.2
    },
    {
        "text": "there's a location, objects are modeled\nby pairing locations with features.",
        "start": 2510.506,
        "duration": 5.045
    },
    {
        "text": "the orientation is used to make\nsure that movements in the, the,",
        "start": 2516.581,
        "duration": 4.34
    },
    {
        "text": "features are rotated properly.",
        "start": 2521.601,
        "duration": 1.4
    },
    {
        "text": "We do temporal pooling, and now\nthis is the object coming out.",
        "start": 2523.111,
        "duration": 2.89
    },
    {
        "text": "And the reason it goes into Lay\n4 in this region is saying this",
        "start": 2526.341,
        "duration": 2.54
    },
    {
        "text": "feature on this, column is the\nentire object of this column.",
        "start": 2529.111,
        "duration": 3.7
    },
    {
        "text": "It's this is the logo, this is the column.",
        "start": 2533.446,
        "duration": 1.83
    },
    {
        "text": "I'm going to stop soon.",
        "start": 2537.786,
        "duration": 0.76
    },
    {
        "text": "And you have one column to one column,\nbut just for completeness, like",
        "start": 2540.876,
        "duration": 4.74
    },
    {
        "text": "the V2 column, will we see L4 input\nfrom a whole bunch of other columns?",
        "start": 2545.766,
        "duration": 3.97
    },
    {
        "text": "not clear, actually.",
        "start": 2550.476,
        "duration": 1.13
    },
    {
        "text": "I didn't talk about columns to columns.",
        "start": 2553.186,
        "duration": 1.99
    },
    {
        "text": "The way I've always viewed this is we\nneed to understand a single column first.",
        "start": 2555.646,
        "duration": 3.19
    },
    {
        "text": "Because that was Mountcastle's\naxiom, and then we have to understand",
        "start": 2560.031,
        "duration": 3.98
    },
    {
        "text": "how single columns work together\nhierarchically, like one column",
        "start": 2564.011,
        "duration": 2.55
    },
    {
        "text": "here, one column there, and don't get\ndistracted by all those other columns,",
        "start": 2566.561,
        "duration": 4.96
    },
    {
        "text": "but now the question is,\nis there convergence onto",
        "start": 2573.711,
        "duration": 3.27
    },
    {
        "text": "V2 or something like that?",
        "start": 2577.011,
        "duration": 1.22
    },
    {
        "text": "I don't actually know the\nanswer to that question.",
        "start": 2582.671,
        "duration": 1.57
    },
    {
        "text": "There's evidence that there is,\nbut is, but that convergence,",
        "start": 2585.021,
        "duration": 3.54
    },
    {
        "text": "it's, I'm hesitant because I\nthink it can be interpreted wrong.",
        "start": 2588.881,
        "duration": 3.15
    },
    {
        "text": "Isn't it's often physiological, as in\nif you measure the response in B2, it's",
        "start": 2594.811,
        "duration": 5.68
    },
    {
        "text": "oh, this is getting, this can see a\nlot, but it's, not necessarily the case",
        "start": 2600.631,
        "duration": 5.2
    },
    {
        "text": "that's because of convergence of input.",
        "start": 2605.931,
        "duration": 1.82
    },
    {
        "text": "It could be more.",
        "start": 2608.261,
        "duration": 0.63
    },
    {
        "text": "imagine you have a visual column and\nyou're looking just like through a straw,",
        "start": 2609.481,
        "duration": 3.57
    },
    {
        "text": "like one column, and it sees a cat, right?",
        "start": 2613.191,
        "duration": 2.95
    },
    {
        "text": "And you can't only recognize the cat by\nmoving the straw around a little bit.",
        "start": 2616.401,
        "duration": 2.38
    },
    {
        "text": "Okay, I see there's a cat.",
        "start": 2618.851,
        "duration": 0.89
    },
    {
        "text": "If this is the thing, the\noutput will be cat, and this guy",
        "start": 2619.741,
        "duration": 5.42
    },
    {
        "text": "will be getting input for cat.",
        "start": 2625.161,
        "duration": 1.09
    },
    {
        "text": "And that looks like a broader\narea of the cortex, right?",
        "start": 2626.906,
        "duration": 3.04
    },
    {
        "text": "Because it is, it's everything that\nthis guy could see as moves around.",
        "start": 2629.946,
        "duration": 5.05
    },
    {
        "text": "so physiologically, as Neil said,\nthis would be broader area would",
        "start": 2635.886,
        "duration": 3.93
    },
    {
        "text": "respond to anywhere in the cat.",
        "start": 2639.816,
        "duration": 1.25
    },
    {
        "text": "And if you look at this layer,\nit's only going to respond",
        "start": 2641.546,
        "duration": 2.46
    },
    {
        "text": "to what's part of the cat.",
        "start": 2644.006,
        "duration": 1.2
    },
    {
        "text": "But if they knew how to look\nat this layer, they would",
        "start": 2645.546,
        "duration": 1.78
    },
    {
        "text": "see it was responding to cat.",
        "start": 2647.326,
        "duration": 1.13
    },
    {
        "text": "But as we said earlier, they don't really\nknow how to look at this layer, because",
        "start": 2650.286,
        "duration": 2.7
    },
    {
        "text": "it's sparse and there's all these things.",
        "start": 2652.986,
        "duration": 1.49
    },
    {
        "text": "And so these are testable hypotheses,\nbut it has to be like this in some sense.",
        "start": 2654.476,
        "duration": 5.57
    },
    {
        "text": "It's deduction.",
        "start": 2660.476,
        "duration": 0.82
    },
    {
        "text": "It just has to be.",
        "start": 2661.296,
        "duration": 0.64
    },
    {
        "text": "People get annoyed when I say\nthat, but that's the way I do it.",
        "start": 2662.176,
        "duration": 2.82
    },
    {
        "text": "The surface area is smaller,\nthough, as you go up.",
        "start": 2665.266,
        "duration": 2.44
    },
    {
        "text": "either the columns are getting\nsmaller, v2 and so on, or you're",
        "start": 2668.496,
        "duration": 5.74
    },
    {
        "text": "getting a conversion input.",
        "start": 2674.446,
        "duration": 0.86
    },
    {
        "text": "okay.",
        "start": 2675.866,
        "duration": 0.49
    },
    {
        "text": "Not necessarily either one of\nthose will have to be true.",
        "start": 2676.826,
        "duration": 1.69
    },
    {
        "text": "first of all, interesting going\nfrom v1 to v2, v2 is actually",
        "start": 2680.816,
        "duration": 2.74
    },
    {
        "text": "a little bit larger than v1.",
        "start": 2683.826,
        "duration": 1.4
    },
    {
        "text": "So you have the, you typically wouldn't\nsee the same with the S1 and S2.",
        "start": 2685.226,
        "duration": 2.79
    },
    {
        "text": "The first two regions are really large.",
        "start": 2688.216,
        "duration": 1.9
    },
    {
        "text": "Yeah.",
        "start": 2690.196,
        "duration": 0.28
    },
    {
        "text": "And then they start\ngetting smaller quickly.",
        "start": 2691.026,
        "duration": 1.5
    },
    {
        "text": "I interpret that as.",
        "start": 2693.536,
        "duration": 1.24
    },
    {
        "text": "Most vision actually occurs in V1\nand V2, and you only need two layers",
        "start": 2695.196,
        "duration": 4.43
    },
    {
        "text": "to learn a compositional structure.",
        "start": 2699.626,
        "duration": 2.7
    },
    {
        "text": "And so there's a huge amount\nof memory in V1 and V2.",
        "start": 2702.736,
        "duration": 2.88
    },
    {
        "text": "It's got to be learning\na lot of the world.",
        "start": 2705.616,
        "duration": 1.67
    },
    {
        "text": "And then these things get narrower,\nvery quickly and they become",
        "start": 2707.601,
        "duration": 3.1
    },
    {
        "text": "more multimodal and other things.",
        "start": 2710.701,
        "duration": 1.48
    },
    {
        "text": "so that's the number one thing.",
        "start": 2713.191,
        "duration": 0.9
    },
    {
        "text": "it's not a strict convergence going up.",
        "start": 2714.461,
        "duration": 1.75
    },
    {
        "text": "and there are multiple ways that a\nregion can get smaller with or without,",
        "start": 2717.681,
        "duration": 5.18
    },
    {
        "text": "I guess I want to avoid the word\nconvergence because that's essentially",
        "start": 2726.581,
        "duration": 3.83
    },
    {
        "text": "saying, Oh, this column can only\nunderstand something if it's looking",
        "start": 2730.411,
        "duration": 3.05
    },
    {
        "text": "at a larger part of the world.",
        "start": 2733.461,
        "duration": 0.95
    },
    {
        "text": "It can be physiological.",
        "start": 2734.791,
        "duration": 1.7
    },
    {
        "text": "It doesn't, I haven't worked at\nall, I don't like to, if you really",
        "start": 2736.846,
        "duration": 2.15
    },
    {
        "text": "want that we can spend some time\non this, but it, I don't think",
        "start": 2739.146,
        "duration": 2.53
    },
    {
        "text": "that's the right way to look at it.",
        "start": 2741.676,
        "duration": 0.82
    },
    {
        "text": "It's not, the right way to look at it\nisn't like I have to have convergence",
        "start": 2742.526,
        "duration": 2.39
    },
    {
        "text": "of columns, because I think the whole\nsystem can be built with a single",
        "start": 2744.916,
        "duration": 2.88
    },
    {
        "text": "module, single column on top of a\nsingle column on top of a single column.",
        "start": 2747.796,
        "duration": 2.58
    },
    {
        "text": "It won't be the most efficient\nsystem, but it would work.",
        "start": 2750.886,
        "duration": 2.13
    },
    {
        "text": "So you don't have to have convergence\nof columns for this to work.",
        "start": 2753.706,
        "duration": 2.66
    },
    {
        "text": "We can build our first oppositional\nobject with two learning",
        "start": 2756.896,
        "duration": 3.08
    },
    {
        "text": "modules if we want to do that.",
        "start": 2759.986,
        "duration": 2.48
    },
    {
        "text": "Yeah, I guess maybe one way of\nsaying it is like, it's not an",
        "start": 2762.706,
        "duration": 2.47
    },
    {
        "text": "issue if there is convergence.",
        "start": 2765.226,
        "duration": 1.41
    },
    {
        "text": "It can be accommodated.",
        "start": 2766.716,
        "duration": 2.39
    },
    {
        "text": "It's not necessary.",
        "start": 2769.666,
        "duration": 1.34
    },
    {
        "text": "That's a good way of putting it.",
        "start": 2771.466,
        "duration": 0.94
    },
    {
        "text": "Don't fool yourself and\nthink we have to have it.",
        "start": 2773.166,
        "duration": 1.72
    },
    {
        "text": "We don't.",
        "start": 2775.156,
        "duration": 0.33
    },
    {
        "text": "It can exist, but you\ndon't have to have it.",
        "start": 2776.356,
        "duration": 2.3
    },
    {
        "text": "In fact, the theory came up with\ncompositionality, is the following,",
        "start": 2782.206,
        "duration": 3.85
    },
    {
        "text": "you have, imagine this is v2.",
        "start": 2786.216,
        "duration": 2.01
    },
    {
        "text": "You have a bunch of columns here and\nhere's V one roughly the same size.",
        "start": 2789.586,
        "duration": 5.64
    },
    {
        "text": "the columns can be a little different,\nbut roughly the same size in the area.",
        "start": 2798.166,
        "duration": 2.28
    },
    {
        "text": "Maybe V two is a little\nbit larger, like I said.",
        "start": 2800.446,
        "duration": 1.71
    },
    {
        "text": "what we, what the, theory that we\nworked out, and this is the last time",
        "start": 2804.296,
        "duration": 3.24
    },
    {
        "text": "I, it was the first, we kind of piece\nthis together when Vivian was here",
        "start": 2807.536,
        "duration": 2.85
    },
    {
        "text": "about whenever it was, we're working\non this problem, is to understand",
        "start": 2810.386,
        "duration": 4.93
    },
    {
        "text": "that the way positionality works.",
        "start": 2815.316,
        "duration": 1.44
    },
    {
        "text": "It's on a location by location basis.",
        "start": 2817.336,
        "duration": 2.52
    },
    {
        "text": "So imagine this is getting input\nfrom some part of the retina.",
        "start": 2820.346,
        "duration": 3.16
    },
    {
        "text": "let's see here's eyeball.",
        "start": 2825.626,
        "duration": 1.52
    },
    {
        "text": "the retina is back here, right?",
        "start": 2829.826,
        "duration": 1.33
    },
    {
        "text": "Imagine we're getting input from\nthis little patch right here.",
        "start": 2831.996,
        "duration": 2.64
    },
    {
        "text": "Okay.",
        "start": 2834.876,
        "duration": 0.36
    },
    {
        "text": "This column is getting\ninput from that patch.",
        "start": 2835.686,
        "duration": 1.75
    },
    {
        "text": "And this column is also getting input\nfrom a patch that is co located with it.",
        "start": 2838.116,
        "duration": 3.77
    },
    {
        "text": "They're essentially pointing\nat the same point in space.",
        "start": 2841.916,
        "duration": 2.73
    },
    {
        "text": "V1 is looking at the retina, it gets\ninput from the retina, V2 gets input",
        "start": 2847.276,
        "duration": 3.34
    },
    {
        "text": "from the retina, and this column,\nthese columns are both centered",
        "start": 2850.666,
        "duration": 3.19
    },
    {
        "text": "on the same part of the retina.",
        "start": 2853.856,
        "duration": 1.05
    },
    {
        "text": "When, we learn computational structure,\nand this is all in the heterarchy",
        "start": 2856.666,
        "duration": 3.27
    },
    {
        "text": "paper, we're essentially saying\nthis, co alignment is essential.",
        "start": 2859.936,
        "duration": 4.55
    },
    {
        "text": "You learn what the system is doing.",
        "start": 2866.446,
        "duration": 2.96
    },
    {
        "text": "If I have a coffee cup\nwith the logo on it,",
        "start": 2869.406,
        "duration": 2.88
    },
    {
        "text": "it's basically saying, at this point\non the logo is also a point on the cup.",
        "start": 2877.156,
        "duration": 6.91
    },
    {
        "text": "And at that point in physical\nspace, I can assign this point on",
        "start": 2884.616,
        "duration": 3.97
    },
    {
        "text": "the logo to this point on the cup.",
        "start": 2888.586,
        "duration": 1.4
    },
    {
        "text": "It's on a location by location basis.",
        "start": 2890.026,
        "duration": 1.94
    },
    {
        "text": "So these two guys, as you move around,\nit says, oh, I'm going to, I'm going to",
        "start": 2893.076,
        "duration": 4.54
    },
    {
        "text": "learn to connect, basically this is a\nsort of a bidirectional connection here.",
        "start": 2897.616,
        "duration": 2.97
    },
    {
        "text": "I'm going to learn at this point of\nthe cup, I'm at this point of the logo,",
        "start": 2900.886,
        "duration": 2.49
    },
    {
        "text": "and I'm at this point of the cup, I'm\nat this point of the logo, and so on.",
        "start": 2903.416,
        "duration": 2.42
    },
    {
        "text": "And this allows the logo to be morphed\nand changed and rotated and all kinds",
        "start": 2906.646,
        "duration": 3.29
    },
    {
        "text": "of weird stuff and still learns it.",
        "start": 2909.936,
        "duration": 1.39
    },
    {
        "text": "so when we build compositional\nstructures, We can really do",
        "start": 2914.366,
        "duration": 5.035
    },
    {
        "text": "this with just two columns.",
        "start": 2919.401,
        "duration": 1.0
    },
    {
        "text": "that is efficient to do it.",
        "start": 2921.781,
        "duration": 1.39
    },
    {
        "text": "It's sufficient, not efficient.",
        "start": 2924.261,
        "duration": 1.95
    },
    {
        "text": "then less than theory tells us.",
        "start": 2927.851,
        "duration": 1.44
    },
    {
        "text": "And yeah, and that location\nby location also can store the",
        "start": 2930.011,
        "duration": 2.97
    },
    {
        "text": "orientation, which is why, yeah.",
        "start": 2933.021,
        "duration": 2.17
    },
    {
        "text": "But yeah, maybe it's worth checking that.",
        "start": 2937.671,
        "duration": 2.2
    },
    {
        "text": "It makes sense because that will\nbe important for the location",
        "start": 2939.881,
        "duration": 2.04
    },
    {
        "text": "by location for the behavior.",
        "start": 2941.951,
        "duration": 1.48
    },
    {
        "text": "It has to know the idea of the object.",
        "start": 2943.481,
        "duration": 1.51
    },
    {
        "text": "this is the logo on the cup.",
        "start": 2945.506,
        "duration": 1.53
    },
    {
        "text": "It has to know the\norientation of the object.",
        "start": 2947.426,
        "duration": 2.02
    },
    {
        "text": "like it's rotated here, and it needs\nto know the scale of the object",
        "start": 2950.691,
        "duration": 4.25
    },
    {
        "text": "because it could be bigger and smaller.",
        "start": 2955.401,
        "duration": 1.54
    },
    {
        "text": "We learn this stuff really quickly\nand instantly, so we need, we",
        "start": 2957.441,
        "duration": 3.11
    },
    {
        "text": "learn these things for everything.",
        "start": 2960.551,
        "duration": 1.25
    },
    {
        "text": "And the surprising thing was it has to be\ndone on a location by basis, but if you do",
        "start": 2961.971,
        "duration": 4.22
    },
    {
        "text": "that, then the logo can have distortions\nand be twisted and can do various things.",
        "start": 2966.191,
        "duration": 3.54
    },
    {
        "text": "So these are the three things we\nhave to learn as part of the model.",
        "start": 2970.461,
        "duration": 3.38
    },
    {
        "text": "We have to say the feature\ncoming into this guy.",
        "start": 2973.981,
        "duration": 2.77
    },
    {
        "text": "Is rotated in a certain scale at this\nlocation, and we're going through",
        "start": 2977.181,
        "duration": 5.21
    },
    {
        "text": "the circuitry for how this actually\nworks when it's in the paper, but",
        "start": 2982.391,
        "duration": 3.64
    },
    {
        "text": "you can see how this actually works.",
        "start": 2986.041,
        "duration": 1.65
    },
    {
        "text": "And then maybe it's with that.",
        "start": 2989.211,
        "duration": 1.724
    },
    {
        "text": "But just that like\nthat, informs inference.",
        "start": 2990.935,
        "duration": 4.985
    },
    {
        "text": "So If you've learned like a particular\nmug with a funny logo or whatever",
        "start": 2995.92,
        "duration": 5.546
    },
    {
        "text": "that information coming in about like\nwhat the pose at a particular location",
        "start": 3002.166,
        "duration": 3.38
    },
    {
        "text": "of the logo is can tell you, oh,\nthat was that mug that had the weird",
        "start": 3005.596,
        "duration": 3.61
    },
    {
        "text": "thing, but also you can, it can assist\nprediction and that let's say, because",
        "start": 3009.206,
        "duration": 6.59
    },
    {
        "text": "of the other side, you saw the mug.",
        "start": 3015.796,
        "duration": 1.275
    },
    {
        "text": "This is that weird mug\nwith the weird logo.",
        "start": 3017.411,
        "duration": 1.78
    },
    {
        "text": "You can predict at a location a\nparticular orientation scale of the logo.",
        "start": 3019.761,
        "duration": 5.76
    },
    {
        "text": "so yeah, I guess it's just\nthat the location by location",
        "start": 3028.541,
        "duration": 3.02
    },
    {
        "text": "base is important both for the\nfeedforward and for the feedback.",
        "start": 3031.561,
        "duration": 3.07
    },
    {
        "text": "Which comes into, the anatomy.",
        "start": 3035.001,
        "duration": 1.91
    },
    {
        "text": "and I'm just emphasizing it because when\nwe come to talking about the behaviors",
        "start": 3037.841,
        "duration": 3.77
    },
    {
        "text": "And that's the location by location.",
        "start": 3042.451,
        "duration": 2.1
    },
    {
        "text": "Yeah, it's helpful to understand that.",
        "start": 3044.841,
        "duration": 1.88
    },
    {
        "text": "And, I think when we talk about\nthat, we should project the images",
        "start": 3046.721,
        "duration": 4.1
    },
    {
        "text": "from the paper because they're\nreally not right in these papers.",
        "start": 3050.821,
        "duration": 2.64
    },
    {
        "text": "So are we saying that input to v2 is\nmore receptive field or is it the same",
        "start": 3055.041,
        "duration": 3.99
    },
    {
        "text": "receptive field as the input to v1?",
        "start": 3059.041,
        "duration": 1.64
    },
    {
        "text": "It could be a Typically it's a\nlarger receptive field, like from",
        "start": 3060.681,
        "duration": 3.575
    },
    {
        "text": "the retina itself, more ganglion\ncells in the retina converge onto",
        "start": 3064.256,
        "duration": 3.52
    },
    {
        "text": "V2, but that's not important.",
        "start": 3067.776,
        "duration": 2.84
    },
    {
        "text": "It gets it lowered out, right?",
        "start": 3072.346,
        "duration": 1.3
    },
    {
        "text": "it may be very efficient and useful,\nbut it's not theoretically essential.",
        "start": 3075.546,
        "duration": 3.85
    },
    {
        "text": "and yeah, and it would fit with this\nlearning, like a coarser model and this",
        "start": 3081.966,
        "duration": 4.42
    },
    {
        "text": "learning a more fine grained model.",
        "start": 3086.386,
        "duration": 1.33
    },
    {
        "text": "So there's only so much information\nthat any cortical column can store.",
        "start": 3087.746,
        "duration": 3.57
    },
    {
        "text": "So if it's getting small inputs,\nOr like kind of fine detail inputs.",
        "start": 3091.706,
        "duration": 4.13
    },
    {
        "text": "Realistically, it's going to learn a\nfairly small but like detailed model.",
        "start": 3095.846,
        "duration": 4.04
    },
    {
        "text": "This one, it's getting over a larger\nsurface area, so it cannot necessarily",
        "start": 3100.386,
        "duration": 3.44
    },
    {
        "text": "distinguish details as much.",
        "start": 3103.836,
        "duration": 1.42
    },
    {
        "text": "But it can build like a coarser\nI've always thought this part was I",
        "start": 3105.676,
        "duration": 3.22
    },
    {
        "text": "believe it's just in hierarchy and not\nI've made a good type of pool in the",
        "start": 3108.896,
        "duration": 4.15
    },
    {
        "text": "hierarchy to take care of that part.",
        "start": 3113.046,
        "duration": 1.54
    },
    {
        "text": "Because I can't Like how big can\nthis receptive field go, right?",
        "start": 3115.226,
        "duration": 3.8
    },
    {
        "text": "Because we get bigger, be one.",
        "start": 3119.026,
        "duration": 2.03
    },
    {
        "text": "They're really small.",
        "start": 3121.056,
        "duration": 0.66
    },
    {
        "text": "Yeah, before does it\ncover the whole object?",
        "start": 3122.286,
        "duration": 4.02
    },
    {
        "text": "it's not clear.",
        "start": 3126.476,
        "duration": 0.68
    },
    {
        "text": "It's V two definitely gets\ninput from the retina.",
        "start": 3127.166,
        "duration": 2.76
    },
    {
        "text": "I don't know about v4.",
        "start": 3130.476,
        "duration": 1.99
    },
    {
        "text": "so it cannot be that\nbig that can cover like.",
        "start": 3133.536,
        "duration": 2.57
    },
    {
        "text": "Larger objects, it would\nbe bigger than V one.",
        "start": 3137.126,
        "duration": 3.18
    },
    {
        "text": "I think there's a lot of evidence that\nthe, convergence from the retina onto",
        "start": 3141.026,
        "duration": 4.23
    },
    {
        "text": "the cell and V one and versus cell\nand V two V, there's more convergence",
        "start": 3145.436,
        "duration": 3.39
    },
    {
        "text": "onto V two, makes the broader area.",
        "start": 3148.826,
        "duration": 1.92
    },
    {
        "text": "that's a, that's also\nproperty and somato cortex.",
        "start": 3153.046,
        "duration": 3.12
    },
    {
        "text": "so it's, that's an empirical\nobservation in some sense.",
        "start": 3157.826,
        "duration": 2.52
    },
    {
        "text": "We accept it.",
        "start": 3160.346,
        "duration": 0.72
    },
    {
        "text": "I think Neil's, there's a couple\nadvantages that Neil's mentioned.",
        "start": 3161.956,
        "duration": 2.88
    },
    {
        "text": "One, it's the V1 is the\nhighest acuity you can get.",
        "start": 3164.836,
        "duration": 4.37
    },
    {
        "text": "There's nothing more refined than that.",
        "start": 3169.266,
        "duration": 1.99
    },
    {
        "text": "So if I wanted to, if I'm reading\nthe smallest print that I could",
        "start": 3171.856,
        "duration": 2.96
    },
    {
        "text": "possibly read and recognize, it's\nalmost certainly happening in V1,",
        "start": 3174.816,
        "duration": 2.62
    },
    {
        "text": "if I'm saying that's the smallest.",
        "start": 3177.436,
        "duration": 1.31
    },
    {
        "text": "And V2 would be too blurry, right?",
        "start": 3179.046,
        "duration": 2.51
    },
    {
        "text": "But if I have a very big letter,\nV1 is too small because you have to",
        "start": 3181.636,
        "duration": 5.095
    },
    {
        "text": "integrate over a huge amount of area\nand it's just not very useful, but V2",
        "start": 3186.951,
        "duration": 3.52
    },
    {
        "text": "could do it in a more reasonable way.",
        "start": 3190.471,
        "duration": 2.02
    },
    {
        "text": "So that makes sense, from\na just scale perspective.",
        "start": 3192.961,
        "duration": 4.01
    },
    {
        "text": "It also makes sense that when you have\ncomposite objects, it's really hard",
        "start": 3197.281,
        "duration": 4.24
    },
    {
        "text": "to come up with an example where a\nchild is bigger than the parent, right?",
        "start": 3201.521,
        "duration": 4.45
    },
    {
        "text": "It's almost always the child\nobject is smaller than the parent",
        "start": 3206.041,
        "duration": 2.69
    },
    {
        "text": "object, so that also makes sense.",
        "start": 3208.731,
        "duration": 1.38
    },
    {
        "text": "In fact, if it was bigger, then you\nwould probably flip around and say",
        "start": 3210.631,
        "duration": 2.29
    },
    {
        "text": "one of those, so So this will, but\nfrom a theory point of view, it's not",
        "start": 3212.921,
        "duration": 5.1
    },
    {
        "text": "essential, it's just that they have to\nbe two different objects, and they have",
        "start": 3218.051,
        "duration": 3.68
    },
    {
        "text": "to have the ability to have the same,\nat times, the, same, point on them.",
        "start": 3221.731,
        "duration": 6.37
    },
    {
        "text": "So they're looking at the same\npoint, but one is focused on the",
        "start": 3228.101,
        "duration": 2.602
    },
    {
        "text": "Right, one is attending to the\nlogo, and one, so when you see a",
        "start": 3230.703,
        "duration": 3.268
    },
    {
        "text": "new object, I picked that one up.",
        "start": 3233.971,
        "duration": 2.355
    },
    {
        "text": "It's got water in it.",
        "start": 3236.326,
        "duration": 0.7
    },
    {
        "text": "I don't know.",
        "start": 3239.006,
        "duration": 0.46
    },
    {
        "text": "that's not a great one, but it\ndoesn't have much of a logo.",
        "start": 3240.536,
        "duration": 2.33
    },
    {
        "text": "Oh, it's just Kirkland on it.",
        "start": 3242.916,
        "duration": 1.05
    },
    {
        "text": "when you see a new object, oh,\nthat's a bottle and then you tend",
        "start": 3247.226,
        "duration": 3.06
    },
    {
        "text": "to focus on the details and you\nstart saying, Oh, it's Kirkland.",
        "start": 3250.286,
        "duration": 2.77
    },
    {
        "text": "It says this and that.",
        "start": 3253.246,
        "duration": 1.09
    },
    {
        "text": "Oh, it's got this little\nfunny bottom to the cap.",
        "start": 3254.376,
        "duration": 1.71
    },
    {
        "text": "While you're doing that.",
        "start": 3256.326,
        "duration": 1.04
    },
    {
        "text": "I believe what's happening\nis there's a higher region.",
        "start": 3257.396,
        "duration": 2.62
    },
    {
        "text": "That's still saying this is the\nbottle and you're attending to",
        "start": 3260.026,
        "duration": 2.49
    },
    {
        "text": "all these components and in series\nbuilding up the model of the bottle.",
        "start": 3262.516,
        "duration": 3.69
    },
    {
        "text": "Yeah.",
        "start": 3266.206,
        "duration": 0.075
    },
    {
        "text": "So now I say, oh, yeah, I see this, the\nKirkland logo, and there's this thing,",
        "start": 3267.041,
        "duration": 3.27
    },
    {
        "text": "and then there's that thing, and there's\nthis thing, and I can look on the back,",
        "start": 3270.311,
        "duration": 2.42
    },
    {
        "text": "oh, there's this thing, and now I have\na model of this object, because I knew",
        "start": 3272.731,
        "duration": 3.47
    },
    {
        "text": "it was a bottle, and I'm looking at\nthe intended features one at a time.",
        "start": 3276.201,
        "duration": 2.76
    },
    {
        "text": "So that part of our, mechanism for doing\ncompositional structure is to keep,",
        "start": 3279.531,
        "duration": 3.65
    },
    {
        "text": "we were talking about this earlier,\nabout your unsupervised learning.",
        "start": 3283.191,
        "duration": 2.53
    },
    {
        "text": "One region or one column has to\nbe maintaining, I'm looking at",
        "start": 3286.491,
        "duration": 3.32
    },
    {
        "text": "this bottle, and the other one is\nsaying, I'm, no, I'm looking at",
        "start": 3289.811,
        "duration": 3.27
    },
    {
        "text": "the features on it individually.",
        "start": 3293.081,
        "duration": 1.69
    },
    {
        "text": "and recognizing them individually.",
        "start": 3295.351,
        "duration": 1.25
    },
    {
        "text": "How does the higher level know it's\na bottle without the lower level?",
        "start": 3296.951,
        "duration": 2.84
    },
    {
        "text": "Because the higher level also has,\nit basically has its own feature",
        "start": 3300.311,
        "duration": 3.34
    },
    {
        "text": "detections that come straight from\nthe retina in some sense, right?",
        "start": 3303.651,
        "duration": 3.23
    },
    {
        "text": "it's, the boundaries of\nthe bottle can be learned.",
        "start": 3308.251,
        "duration": 2.44
    },
    {
        "text": "these are grosser features.",
        "start": 3312.666,
        "duration": 1.67
    },
    {
        "text": "and, and then only when you, then\nyou basically attend to a subset",
        "start": 3315.176,
        "duration": 4.55
    },
    {
        "text": "does the bottle stay the same.",
        "start": 3320.086,
        "duration": 1.84
    },
    {
        "text": "I don't know how else it could work.",
        "start": 3322.466,
        "duration": 1.0
    },
    {
        "text": "it's like you deduce it has to do this.",
        "start": 3323.626,
        "duration": 1.95
    },
    {
        "text": "I, I can't, maybe I just failing\nin my brain, but it seems like",
        "start": 3325.576,
        "duration": 4.52
    },
    {
        "text": "this absolutely has to happen.",
        "start": 3330.376,
        "duration": 1.43
    },
    {
        "text": "Once you understand it, you're\nlike, there's no other doing this.",
        "start": 3331.806,
        "duration": 2.35
    },
    {
        "text": "You have to be able to sign these\nindividual components to a larger object.",
        "start": 3334.696,
        "duration": 3.63
    },
    {
        "text": "And you do that by moving around them.",
        "start": 3338.546,
        "duration": 1.77
    },
    {
        "text": "look at them one at a time.",
        "start": 3341.011,
        "duration": 0.94
    }
]