yesterday I said I had a few small things to talk about, which I can do, and I don't know how long it'll take, and, but we can, go into that, we're all thinking, some of us are thinking about, hierarchical actions and goal oriented behaviors, and, so I've been thinking myself, personally, I've been thinking about little pieces around that, oh, how would they, the thing that's really puzzling to me is, It's how does, how do we take, some sort of action I know how to do, or I might come up with, and I can implement it using different parts of my body, I might do it by using my right hand or my left hand, or I might implement the same behavior using my eyes, an eye tracker, or trying to get, Hojae to do it by talking to her, so there's all these different ways That, we are able to achieve a goal, even though the goals are the same, somehow we're able to decompose this in the hierarchy and figure out which part to do, how are we going to come about it, and we can overcome it. But if I'm trying to do something, trying to open the door and my right hand is occupied, then I might, transfer what I'm carrying or I might use my left hand. So these are, it's just puzzling how this all happens. And the good news is I think we're starting to have a real understanding about hierarchy, at least with, in terms of compositional objects. And as I said, I think that's the key insights they are going to apply here as well. So I have one small topic related to this, and it's, related, it may not be exactly obvious how it's related, but I'll just present it. And, I thought it was a, for me it was a nice little insight or at least a, clarity. can you, am I not sharing, I'm probably not sharing my screen. I'm going to have to share my screen. Yeah. Here we go. Share, share my screen.

And, there we go. All right. PowerPoint presentation here. Yep. All right. I guess I'm not helpful because I have two. this is, again, don't get your hopes up, this is a pretty simple little thing I put together here.

one of the things that, that is conventional neuroscience, dogma is if you look at two regions in the cortex, I just label them one and two, that can be V1, V2, S1, S2, whatever. Two hierarchical regions is that you start out, the first one you have like small receptive fields, meaning that the cells in that region don't, by the way I'm showing five columns here even though they're separated that doesn't mean anything, just just showing you some columns. that you have these small receptive fields, meaning the cells respond to a small part of the retina, a small part of the skin or something like that, a small part of the copia. And you have these simple features, this goes back to Hubel and Biesel, oh, look at the edges and so on. And then you go up the next level and you find cells that respond to a larger area of the sensory organ and the features that they detect are complex. Very quickly, it becomes very difficult to actually characterize these features. in the beginning, they say, oh, these are edges down here and on but then when they get up to here, they're like, oh, they're all kinds of weird stuff. And they try to spend a lot of time trying to figure out what they are. And the basic idea that was proposed a long time ago, the obvious way they thought this would occur is that somehow, these lower columns, which are each detecting some small feature, are converging onto cells in the upper column, therefore they're representing a larger area of the retina or a larger area of the skin, and they combine a bunch of simple features into more complex features. That is still, I believe, the standard dogma in neuroscience. But it never really worked for me. I had always these questions about it, because it looks really simple here. But in reality, if you draw in all the arrows, there's every column in R1 is projecting to lots of columns in R2, and every column in R2 is projecting back to lots of columns in R1. It's actually not even clear if it's diverging or converging. It's just a lot of problems. And this never made a lot of sense to me, and every time I tried to figure out how information would flow from a column to other columns, I always had difficulty with it. I, know this, I think this is similar to what's going on in deep learning networks and it works there, but it's not. What's going on? I don't think that's what's going on in the brain. So we, we, I, could never get this to work in a way like, oh, how to build this. So we, the thousand brains theory, our recent work on compositional objects, shows a very different, it shows a very different interpretation. In fact, you can get the same properties with just two columns. one in, one hierarchically above the other, and now the, theory here is that, the complex features in R2. are caused because in R1, there's spatial temporal integration. So you can look at those simple features in R1, they detect those, but they don't detect the output of R1, which is typically a more sparse distributed representation, and it's not easily characterized. But because R1 is combining inputs over multiple points in space and multiple points in time, R1 creates a more complex feature, which we would call our object output of the column. the increasing size of the receptive fields in R2, there's two possible reasons for that. One, obviously, R1 has already done most of the work. R1 has already said, okay, I've already integrated a bunch of stuff over a spatial area. I'm passing the result to that. But I think, but there's probably something else going on as well. I wrote the first one here, increasing RF in size in R2 is caused by spatial temple integration in R1. And then I said, and or changing scale.

I've always had this belief, and it's just belief, I have no proof of it whatsoever, but there's some evidence that the scale of R2 in terms of its reference frame is larger than R1. And we saw, we see this in the enthorhinal cortex where you have, adjacent grid cell modules that get larger and larger, meaning, what does it mean to get larger and larger? What it really means is the rate of change in the grid cells, relative to the movement vector changes. So if you're moving at some, constant velocity and the grid cells change slower, that would be a larger scale, right? The space, you have less resolution in your space, but you have a bigger space. I think that's going on here and I'm not sure if it's required, but I think it's going on. So I think. My first assumption is, okay, R2 is naturally going to be modeling larger spaces just because of its, the way this system is set up. It's not learned that, just like the entorhinal cortex and, but also, R1 is already passing things which are larger to R2.

now the important thing here in our, theory was that, The reason this works is because R2 and R1 are co located, they're looking at the same physical space in the world. So they're both modeling the same point in space. One is modeling a parent object, one is modeling a child object, and we can assign the child object to the parent object on a location by location basis. So as the sensor organ moves Both of these columns are moving with them, with the sensor organ. Interesting, R2 would be changing slower than R1, right? R2 might, the R1 location might change and R2's location might change less or not change at all. But I think that all works. but the point is the key to the whole discovery of getting all the coffee cup variations working was that we, these two guys are looking at the same point in space and therefore we can assign them. at any point on the cup, but the same point on the logo, something like that. and that was the key. So we can achieve all these, this larger RIFs and complex features and smaller RIFs and simple features just with two columns. we actually don't need, more than that, we don't need any convergence or divergence. I actually don't, we'll come back to the actual connections here, in a second. of course we don't just have two columns, we have multiple columns, and so we have this concept of voting, where voting, where these, columns in the two different regions are coming to a consensus. But I don't think that changes anything really. It just means that they get to, they get each of these columns in R2 and each of these columns in R1 are going to reach a consensus about what they're seeing, but still the learning occurs on a column by column basis. It's just that the horizontal voting is just to make sure that we get to R1 and R2 and what object they're looking at more quickly. But all along here, we see that the columns are still basically one to one voting on location to location. Now this doesn't mean this is happening in every column in V1 or V2, it just means in the fovea area at some point where these columns are looking at the same object it would be occurring. and, so that's basically our theory about how this is occurring, as opposed to the thing on the left, which is the conventional theory. And of course, the one on the right solves a huge number of problems that no one ever even tried to attempt on the left side. So we have great confidence that's correct. I thought it, this to me was a really great insight. It just means when we're talking about any kind of compositional structure, whether we're going down the hierarchy, especially if we're going down the hierarchy of the motor behavior, we should be thinking it like along these lines. now it's more complex than this, in a second here I'll show you. So this is a figure from the paper where you're supposedly going to finish sometime, and this is showing, the three, three, three columns in three different regions, R1, R2, and R3. and the feedback connections we were just talking about are these purple ones, just to review, where layer 6a, we believe that's the location in this space, in this column, in all these columns, and so the location in R3 is projected first to the location in R2, and we know that this is a very narrow projection, so by narrow I interpret that I mean that R3 and R2 are looking at the same point in space. and, so we are basically associating the location in, if you will, the coffee cup with the location on the logo. here, and we're learning, and we have all this worked out in a fair amount of detail, but we're associating at this point in the cup, you should be at this point in the logo with an orientation and scale, things like that. So that's going down here. Of course, we do have these long range connections in layer one, which don't fit what I just talked about. They go beyond this first column, so we have this very targeted projection layer six, one to one, that's what I showed in the previous slide, that's, this targeted connection here, yet, and, that's the forward one of this one, and yet we have, obviously, a broader spread, up in layer one that goes beyond that. That's a little bit harder to interpret actually, but it seems to be important, of course it's important. and so that's a, how do we, what do we make of that? Clearly R3 is able to tell multiple columns in R2 something about what's going on. I've always often wondered if, like, how do all the columns learn at the same time? I want all the columns, there's some capacity to hold the whole system, so I can't learn everything, but these three columns can't be just learning specific points. They have to, everyone has to be able to take the role of any point in space because the object can move around. So I always thought that maybe this is a learning signal. It's like saying, hey, you know what? I'm passing to you, to all the other guys, you could learn, if you're not getting any input, maybe I'll help you train or something like that. I don't really understand it.

it's, and it may play a very central role in how we do, how we are able to, model, and execute behaviors in different modalities and so on. Anyway, I'm just, reminding us, talking to myself here in some sense, okay, some of this we understand, some of it we don't understand. and, believe it or not, that's the end of my little presentation today. I think this, idea that, this, idea that we have in our theories is contrary to almost everyone thinks in neuroscience. and I just, I think it's really just, it was helpful for me to remind myself when I think about not just, compositional objects, but compositional behaviors that, that I have to think in this paradigm. And, and I have to, somehow we have to work with these connections. There are no other connections besides this that we know of. there are some, yes, there are. there's long range connections from other places, but these are the primary ones. And, so it's like somehow we have to make, we have to make this understandable. That's really it. We can talk about this. Maybe everyone got this and knew it already. but just writing it down like this was helpful for me. and just making clear, yeah, don't, because I was starting to think along these lines on the left here. I was starting to think along, how do I, spread from this column out to here? And I'm really, I got to look at it like this. and, like this, this, these are the way to think about it, where it's tempting to think about it this way, and I don't think that's right. Yeah, on, on this note, one thing I was just thinking about randomly while we were talking about this was, so yeah, I guess we know there's fan in connections to higher level columns, and we've accounted for this partially with the current setup where, sorry, on the previous slide, Do you want me to bring up a paper from the paper? I have the paper here.

I don't know if we actually had a, but maybe I can just, I can just go on this. Do you want me to stop sharing or do you want me to stop? no, this is great actually, because then I can write on this. Okay, I shouldn't interrupt you. Keep going. Oh, you're going to use your iPad? Yeah. I figured that we drew like, one and a half years ago or something. Yeah, I think you drew one, Viviane. If you want. Oh, no. Okay. I think this is You draw them off to the side there. Can you see? Oh, okay. It does come, but it's slow. Yeah, it's a little bit, Okay. You need to be patient. Okay.

I don't know if this really helps, but I'm just thinking, why is it so slow?

yeah, we, know there's fan in connections and, right now, yeah, we're, generally still assuming that there's some degree of, where do we, how do we know those fan in connections? What, are we talking about specifically there?

it's, so it's not just the receptive field. It's not just the physiological properties. It's actually the connectivity. I remember looking that up. it's funny, I was trying to, I was trying to remember whether that was, the details matter, just like in my neck side, there's, fan out, but they're not equivalent, right? There's a specific fan, there's a specific connection 101, and then there's a fan out, and so I was looking, I was trying to recall, I didn't do a literature search, but I was trying to recall, have I seen, what do we know about those actual connections like that? And all I can recall is that I know that people assume that they look like this. Based on these properties. Yeah, no, that's what I thought at first as well, but I'm pretty sure, I can maybe try and find it after this, but I'm pretty sure I eventually found the paper where they talk about the, the anatomy. But anyways, I guess just what I was going to get at was like, yeah, this co location assumption seems reasonable in a lot of cases, but I guess in some ways it might constrain us. But then it also just feels if we apply the same transformation we are doing for voting, then that's not really an issue anymore. the same kind of transformation we're doing for voting could also bring, could basically account for any difference in the pose of the sensor module for this one as this one. you know what's interesting about this, Niels, is that I think I can do the entire compositional model using two columns. And Yeah, so you potentially don't need it, but Right. So that tells me that the other stuff is, if it's there, It's not the requirement, it's somehow doing, it's helpful, so I, voting is one example. Another example I was trying to talk about is like, helping these columns learn, training columns that aren't actively involved in this. to, learn the model, so like we can, train multiple columns that aren't even being experiencing anything right now. So there could be others, there seems to be other reasons. it's not a fundamental requirement. If I can do the whole thing in two columns, then, I, it's, it puts it into this category like voted, it's like there's something else that's really got those connections, but it doesn't seem like they're required. But, by the way, I don't know if we can do the object behavior of two columns. I, I'm pretty sure we can do the compositional structure modeling with two columns, and I'm going to try to work on trying to get it to work with two columns because that would be the beautiful result, right? That would be the nice result. And I guess if nothing else, this was more an aside. I just thought it would be interesting to maybe quickly chat about that. I don't think this relates to the, hierarchical policies, because, yeah, ultimately those are going to depend a lot on the top down connections, and we know what those look and like you were saying, those are going to L1, so those kind of by definition cannot give some sort of location specific, except for the co located reference frame. they, it wouldn't be meaningful for the column, the co location wouldn't be meaningful if the columns were out there looking elsewhere, right? I don't really understand it. it's it's, I think it will become clear shortly, but right at the moment, I'm confused by it. at one point I said, oh, those projections to L1 could be just like, oh, what is the object that, you're supposed to be observing, but not the location. But if it's coming from layer 6A, it's the same cells, we believe those are specific locations. So I'm providing a specific location to L1 to a column that's not at that location. So okay, I don't know what that means.

here's an idea, oh, here's an idea, remember if R2, the space of R2 is larger than the space of R1, imagine it was quantized, so one location in R2 would correspond to multiple locations in R1, And, imagine R1 is looking at three different parts of the logo, but those all fit within the one location in R2, like R2 can't, doesn't have the resolution to distinguish those two. basically, R2 is saying, at my location, here I am at my location, as best I can resolve it. It's like saying, this is, this location. Yeah, that's what we're doing at the moment, I think, where it's yeah, R2 has a lower frequency, or yeah, like a more, a coarser model. Yeah, maybe I can share the figures that we took a while ago, if you don't mind, maybe that would be helpful. Sure, I probably forgot these things. Also, can I ask a question that I've been holding for three weeks? For three weeks, sure. since the last time you presented the hierarchical, or compositional objects, and I know, this is, going against quite a lot of literature, but does it have to be true that R2 always have a large interceptive field? No, I don't think it has to be. Yeah, as in, I, and the reason why I'm making that is, statement is, maybe R1 has, a general, sense, has actually the largest field. receptive field. but then as we go higher in R2, R3, when we're trying to do something, interesting, we need to focus on, I can be looking at this, laptop. I know that I'm still here, but actually, it's pretty, hard for me to, I can't pay attention to everything that's here. But the theory of that is that the higher level can say that it's a laptop and the lower levels can be taking care of all the details and you don't have to be conscious of it, right? I don't know, a couple other observations worth making here. One is, typically the first two regions of ending with central medulla are about the same size. Okay. V1 and V2. In fact, V2 is a slightly larger than V1, at least in some studies. And, but they're about the same size, so you don't, we don't see this, first of all, we don't see any kind of conversions in space size, right? In theory, you, logically, you might say, you have the same number of columns, which is interesting. I'm just separating out, that's a sort of separate piece. you do have convergence after V2, but I think you do have pretty significant convergence after V2. It does get smaller after. It does get a lot smaller after. What gets smaller? V4 would be smaller. Like just the number of neurons. Oh, okay. Presumably the number of columns. So maybe the walk away from that is, first of all, it's a tangent to your question, Hojae, but it seems like this works no matter how many columns you have in a particular region. Like somehow we can have small columns on top of bigger columns, and we probably get a bigger column on top of, small regions on top of bigger regions. We might be able to have B2, if B2 is larger than B1, we have a larger B1, slightly larger B2 over B1. So I'm just separating out the, that's a separate tangential to your question. I don't, I, it feels totally logical to me that, the, receptive field sizes get larger as you go up the hierarchy, that is the receptive field sizes of The inherent ones in the, in the grid cells. we know that actual, the actual cells themselves do that, but that could be just for, it could be integration, Right. and I asked myself that question, the same question you're asking, does it have to be larger, does R2, grid cell space have to be larger than R1? Not clear to me. And then I ask myself a different question, which is how do I, how would I feed in an R1 from one modality to an R2 of a different modality? Okay. because some point we have to, we're constantly combining modalities in ways here. And I haven't answered that question yet, but I have some interesting thoughts about it. it's oh, I have a movement. In a movement vector coming into R2 which represents movement of one sensor modality and a movement vector representing a different, an R1, a different sensor, what would we learn? I, I'm basically, I don't know yet, but anyway, I don't know, your question's a good one, my assumption is that these spaces get larger as you go up, seems to make sense to me, but maybe you can make the argument why it doesn't make sense to you. Yeah, or I guess I, just to keep in mind that when we build on top of this, that maybe there's some assumption, just to also think about it in the other way, where what would happen if the receptive field is closed? It's getting, not getting smaller, but I guess with the cup with the logo, maybe R1 can see the cup, but maybe the logo part, let's say, is the interesting part, so like I, I don't know. First of all, anything that's really small would benefit from a smaller space, right? So I've always felt like when I'm reading the smallest font I can possibly read.

that is, if I had two regions of different resolution, only the one that has the highest resolution that represents a small area of space would work, and I've always assumed that would be the lowest one down. It just, it makes sense to me. it fits what the cells look like. I see, yeah. and it just, also if you think about, behavior flowing down the hierarchy, I have some overall behavior which is maybe sign my name, But then, at some point, I have to actually move my fingers the smallest little amount to get the little ding, and, where, and I can do that with my hand, I can do it with another tool, I can do it with a pen, there's a lot of ways I can do that, but it feels like the large scale thing is at the top, and that the actual motions I have to make each letter or something like that would be at the bottom. It just feels, I just, it seems intuitive to me, which could be wrong, but it feels intuitive to me that we're going to go from large scale to smaller scale as we go down, but that's just an intuition. I'm giving hand waving arguments for it. Or maybe we can think about, the goal of, making coffee because, so the goal, Niels presented last week that comes from some sort of goal, Region. So it could also make sense that it goes from near the subcortical to the cortex. okay, sub some, somewhere in the subcortical is telling me, oh, like I want to get energized and, we make the decision to make coffee. And then, eventually that the kind of the, higher level kind of gets.

As information goes, a higher level figures out, okay, here's a plan. Yeah, but I think the plan gets executed differently as you go down the hierarchy, right? as I said earlier, I'm trying to open the door and I got something in my right hand, so I might just use my left hand, where I normally wouldn't do that. And the higher goal stays the same, open the door. But at any moment in time I have to adjust, so maybe my pen is a little bit longer and shorter in my hand as I'm writing, I have to adjust my movement space and that. It just feels naturally that you have a high level goal. That gets decomposed into lots of small pieces, those pieces, as you go down, those small pieces are, in some sense, optional, like you could have done it different ways, but the high level goal stays the same. And also But the high level goal is coming from the subcortex. not, maybe, we can just assume, we can just assume that somebody is assigned, remember I talked about maybe like a desired behavioral state. Yeah. And that could be subcortex, it could be, you talking to me, asking me to do something, which then isn't like I'm thirsty, it's oh, I want to do what Hojae asked me to do. so we just, from my point of view, I think we could just, for the starters here, just say, okay, we've assigned a goal to this thing. it could be an outer loop of Monty. and and now we want to decompose that into a series of actions, and that series of actions may vary, will vary almost every day, moment to moment, based on the circumstances. Yes. so it feels yeah, that just feels the opposite of going, compositional structure going up and, decomposing going down. I'm going to work on, you can think about it, but I'm not going to, I'm not going to spend too much time thinking about it. Fair enough. Yeah. so what were you, want to show something guys? Oh yeah. So I just took it down cause we were talking. so yeah, this was, what we drew up after some brainstorming by the Bay sessions, I think a year ago. basically, and this is how it's implemented right now. That the high level learning module has a larger receptive field. It also gets direct sensory input, or it can get direct sensory input from a lower resolution, larger receptive field, and then the columns or learning modules the assumptions from the lower level that it gets input from are the ones that have receptive fields co located within its larger receptive field, but they could be at different locations in there. Learning module 3 would not be able to distinguish these locations, but they can all feed into it. The assumption here, too, is that the three lower learning modules are modeling the same object, but at different locations. If they were the logo, they would all be saying, it's a logo, but they're at different locations on the logo. Yeah, and they might not send input at the same time to LearningWatchU3, they just have a connection. Why wouldn't they? like if they get noise, or they're, like, one of them is not sure about what it's sensing at the moment. Okay, maybe, but let's take the assumption that they're all modeling the logo. in that case, the inputs to learning model 3, even though there's three different learning modules, 1, 2, 1, 0, 0, 1, 2, that's odd, there's a lot of orders there, they're all basically saying the same thing. They're all saying, it's a logo, it's a logo, it's a logo. They're not saying anything about location, they're just saying it's a logo. there's no, those three inputs aren't really converging. you're not creating something new in Learning Module 3. They're just, they're all saying the same thing, and if any one of them dropped out, it would still work. Yeah, exactly. And that's the second picture that basically, it's like a rough drawing of that they would detach the different locations on the dendrite. And the one closest to the soma would be the one from, the one that's at the center co located of its receptive field from learning module one. So if that one It's certain about what it's sensing that can activate the cell, if otherwise it might look at the actual sensory input or, it can get input from the ones that are a bit more on the side of its receptive field, and it works with either of them, this one is the most confident one, if you want to think of it in these terms, but I guess it, to me, it is like a mechanism to add a bit more robustness into the system, versus Yeah, it's funny, I don't think you actually have to put them in order on the dendrite.

you could, but, it doesn't have to be because, obviously, as we look at different environments, the one that's most likely going to always be the correct one is zero. And on the other ones, sometimes it'll be the same object, sometimes it'll be something different. And you'll just naturally form more synapses to learning module zero than you would to one and two, unless one and two are consistently the same object, and in which case. You know what I'm saying? The neuron will naturally form synapses to the things that are the most consistent, whether you arrange them on the dendrite or not. It's just that if learning module 1 is sometimes the same as learning module 0 and sometimes not, maybe those synapses just won't form, or maybe there'll be fewer of them or something like that. yeah. The system is very dynamic. We have to and so it's not clear that they have to be on the, in an order on the dendrites. Otherwise, I would say the pictures, I just keep the picture the same. Yeah, I guess to me it was more the general idea. in Monty, we don't have dendrites anyways, but more on the idea that like, if it gets input from all of them, like this one is the most reliable one, learning module one or two could be actually on a different object, if it's on the border or might be noisy or something. And yeah. So I don't know, in Monty, I don't know how you do that. Do you, have different weightings or something like that?

yeah, so there are different options how you could select which input to use or how you want to weigh them.

yeah, so basically learning module can get input from all of these sources, but it could weigh them differently, and it's basically up to the person who implements it, how you want to weigh it, or if you want to just pick the winner or something like that. Yeah, Thanks. Yes, so I was thinking about motion, object motion, and where and when that's computed. And, one of the thoughts popped in my head is we've got these converging inputs from multiple LMs that are spatially distributed in one layer or of the, or one tier of the hierarchy. Could it be that even if a corresponding column in the second tier of the hierarchy has roughly the same receptive field area, it's using its Conversion, connections to, to compute object motion.

I think that's a good hand waving argument. I'm not sure how I would implement that. I guess maybe today, my, my proposition today is, I'd like to solve this problem without using converging inputs from multiple columns. I see. and, it's we solved sensorimotor input by ignoring, initially by ignoring the hierarchy and by ignoring voting. We said it has to happen in a column, and that led to success. and so now I'm arguing if we're going to feel, think about hierarchy, I want to first start with the case where you have one column in each region and then I can, and I should be able to get that to work and then all those other things become, then they'll become clearer later. that's my hope. Yeah. it seems like this is the whole principle of Monty, like it's the same as we don't feed the whole image to one learning module, we feed individual patches to each learning module, then they can vote with each other. So it's exactly the same principle, just one level up the hierarchy. so we, that's, it's a divide and conquer strategy, right? Solve this problem, now we're gonna, okay, all these years I resisted going to two columns. And, people kept saying, let's solve this problem with hierarchy, and I said, no, guys, you've got to figure out what a column does first. And, now I'm saying, okay, we're going to solve these problems with two columns. We're going to solve all, compositional behaviors with two columns, at least to get started. And then, once we understand the two columns, we can add some more.

Again, this is my, I'm just sharing my current brainstorming, my internal thoughts right now. This is nothing set in stone. As well, I can tell you what I'm thinking about. That's what I'm thinking about. I think it just up and down makes sense based on at least neuromorphology. So like a lot of the neuromorphology across the layers, like L1 and 2 are the most If you look at the direction, or the angle in which the axons and dendrites are pointing in lower layers, they're mostly, they're closer to the vertical orientation than out. I think that was the key to that image I showed from our paper. where the synapses are made in layer 6a and then they get to layer 1 and spread out. that was a, I hope that's true. But it was like, that was a key piece of evidence to explain all this to me.

so my point is, Hojae, it can fan in and fan out, but the key part is the one that's co located. That solves all the compositional structure problems, all the problems we were struggling with for years about how the lower can be curved and oriented and doing all these things, but it solves all of them.

it was like, oh, that's beautiful, it really is great. I'm not denying just fan in and fan out, I'm just saying, I think it's misleading. And we don't want to rely on it. If I can solve the problem of two columns, and then let's do that, then we can say, okay, how do we expand beyond that? Yeah, so I guess going to that question of two columns, and then this issue of, how do you do it essentially with arbitrary objects, like the whole point that, you can recruit, as you're saying, your elbow or whatever it needs to be. That's going to take more than two columns, right? Yeah, I was just going to say, sorry, go ahead. Yeah, what I would do in that case, I would say, okay, we start with two columns, and then, then we go to three, two in R1 and one in R2, that's okay. How do I, take this, the behavior I'm trying to do in R2 and not just decompose it in time? in R1, but also decompose it in space in the two R1 columns. just the whole problem of like how I, might write my name with my elbow or my hand or, or make the coffee cup, use, make, pour the coffee with my, different actions I could take. All that could be maybe expressed in just two columns in R1. in fact, don't even think of it as R1 because you have two columns in one level. They could even be two different modalities. Or two different parts of your body and say, how do I execute the behavior that's learned in R two in either R one or in either R one or R one A or R one B. so just start moving in that direction because that would, if I can understand that, if you understand how we could take, maybe a behavior that was learned in just one of those R one columns and now have it played back in the other R one column that gets at the core of the. the tasks we've been talking about where you can execute various tasks using different, different, methods. Yeah, and I guess I was just thinking that, one, maybe this won't help, but one thing that, seems like it would help is just if those goal states are in a appropriately abstract kind of representation in the sense that, if, for example, the goal state that you're passing down the hierarchy is apply pressure at this location, there are potentially lots of body parts that can answer that call and achieve that. And I'm just trying to think, like, how we can do it, with a body part, we've never used previously for, a specific task. Like pushing your computer mouse around, but we understand that we can do things with our elbow more generally And yeah, and so I don't know just something like that. but let's say, okay, imagine the two R1 columns, R1 and R1A and R1B, represent two parts of your body. And normally I'd push the button with my right hand, the right column. And but now, for whatever reason today, I have to use the other one, it's suggests that, Okay, this is where we, might start getting into things like, wear pathways, because I have to figure out how to move the, the, data around The sensor attached to R1B is in a different location and has to move to the location someplace else. I think by, yeah, I think by decomposing the problem into these simple two columns and then maybe three columns, it just feels like we could resolve all these issues.

and, that's what happened with compositional structure. We, we had to give up on doing with multiple columns and just settle on, like, how do two columns relate to each other? And that solved the problem. anyway, it's a suggestion on how to think about the problem. And I'm agreeing with you, Neil. I'm think we could, I think we can solve all those problems that, just adding one component at a time. Okay. Go from two columns and one column R, one to two columns, another that kind.

and it could be as simple as, we have, the goal is to have this, to get the object in R two. In some state, the button is press. How do we get that to happen?

Yeah. And I'm just thinking maybe like in those instances, like we might not have a learned association between, our left toe or her elbow or whatever, and doing that particular behavior. But as long as we have a learned association to some sufficiently abstract primitive, like applying pressure, for that body part, then yeah, then maybe It's just a bit easier to generalize in that kind of zero shot way. It seems like also Wouldn't the state be, I want the computer mouse to be in location X instead of Yeah, so I, I guess I was thinking like a couple steps down. So yeah, that would be a higher level one. And then at some point, I don't know, the learning module that maybe knows about computer mice or whatever. or as modeling where the computer mice is on the desk is okay, for the mouse to move, there needs to be pressure at this point on it. And then it's going to recruit something to apply that pressure. But rather than saying like left hand apply pressure or right hand apply pressure, like maybe it doesn't know anything about the body parts and the body parts don't know anything about mice. But so if the one that knows about mice and the desk just knows okay, there just needs to be pressure on here. And then the body parts just understand, okay, I need, one of us needs to apply pressure. Okay.

there is a, often the key to success here is picking the right problem to think about. and that's why I love the mug, the coffee cup with the logo on it, because it really exposed a lot of problems in a very simple example. The one I've been thinking about just yesterday and the day before is typing. And, it's really interesting because when I type, I actually, I don't think about the letters at all, right? You just don't think about the letters. In fact, I asked myself, do I even remember the layout of the keyboard, and I couldn't recall it all. Like, when you first learn to type, you have to learn where all the letters are on the keyboard, and now, when I'm typing, I'm like, can I just recite all the letters as I go? I can't do it, actually. I have to think really hard about it. But I can type any word instantaneously, right? And, but it requires that my hands are in the same position, right? That's why we have these little detents on the F and the J, it's so you can enter in the right position. And once you're in that position, it's all, to me, that's all low level memory. It's I'm now executing a low level motor command. And even maybe S1 or whatever, M1 is doing this. But as soon as I, if I try to do, moving my, moving my hands out or in, maybe I now I'm locating my hands on the G and the H, so they're not in the normal position. I can't type at all. I have to think really slowly, where's the letter, or if I was typing with a tooth, I'm trying to type with a, a stick or something, I have to think really carefully. So my point is, this is, I'm using this as my thinking example. The simplest version of this would be like, I have a single finger, it's located, my hand is located at some point relative to the keyboard, and the task of that finger is to move, to execute, certain, sequences. I type, I'm typing with one finger, but I can learn to really, I could learn to do it really quickly with one finger, just like I can do it with two hands. and then say, okay, so imagine I have two lower columns, one represents my right finger, one represents my left finger, and I've learned to type, with my right finger just by moving it from some, my palm is in some location, and I'm moving it to some ten keys, and I can quickly type. Okay. I can do that really quickly, but I haven't learned to do it with my left hand, my left finger. And so now I would have to pretend, if I was going to do it with my left finger, I'd have to attend very carefully with where is my left hand, where is it relative to the keys, that kind of stuff. I might have to use vision. I'm just suggesting this is the example I'm using right now where You could have a, you could have two very simple actuators, your two fingertips. One could learn in R1, could learn very complex, sort of sequences, because it practices over and over again, no thinking involved, and, but if I want to do it with the other one, I have to think about it and attend to it. So that was, I was, I'm just throwing this out as a potential sort of problem that exposes all the issues. that we might have come across, doing this compositional behavior. And the top R2 might say, oh, R2 tells R1, type this word, these letters, or just this word, and R1 plays it out. But if I have to go to the other R1 column, the one that hasn't practiced this, then it would be very slow, and I'd have to attend to it, and so these are the things that we have to deal with, in, in our insomniac goal oriented behaviors.

I'll just do that. Yeah, actually the keyboard example makes me think of an interesting thing. So I guess, as well as using arbitrary parts, like another challenge we've talked about is like coordinating systems, like how do you coordinate your fingers and things like that? But yeah, the keyboard example was just making me think.

yeah, we were talking recently on Slack about how, we, if we can do anything within a model based way, even if it's going to be really slow and use a lot of computational resources, then we can eventually then just Learn in a kind of subcortical model free place, how to do it in a more kind of finessed way with balance and, unconsciously and stuff like that. But I was just thinking we've struggled with thinking how we're going to just learn to even pincer grip or something like that, or let alone yeah, typing on a keyboard with both hands, but I guess, to a certain degree, those things do always, yeah, when you're doing them in the model based way, it's almost like one at a time, it's serial, right? Like, when you're first learning to type the keyboard, you have to type with one hand at a time. And even for a child, I think it's a fairly complex thing for them to learn the pincer grip. They're like, first they can move the thumb, and then they can move the finger, and then very slowly, maybe, then a model free policy takes over.

Yeah. And the example I just gave is simpler, it's really, it's just two movable sensor paths representing the tips of your fingers and, and, and there's no coordination between anything. It's I think, I think it might get to, like even the pincer grip, you're moving two things. yeah, I guess what I'm trying to say is what I was thinking about on Slack was that like, anything needs to be done at least slowly, it needs to be possible to do it slowly in a model based way so that we can learn to do it efficiently in a model free way. But it feels like coordination by definition is always going to be taken over by model free. Like we can do it. you can really slowly, okay, I'm going to move my thumb, and I'm going to move my finger, and I'm going to move my thumb, and then, okay, now I've got the object, and I can pick it up, but what you're really going to want to do is learn to do that in a model free way, and then it's okay, now I just need to execute the pincer grip. You're using the word model free again. I'm not sure where you're Okay. Or subcortical, if that helps. Why would you use subcortical? Why do I need it to be subcortical? Why can't I just learn this rote behavior in R1? I think I can. I guess you can do it slowly, but No, I feel like, yeah, we talked before that we want to have all, all, everything that happens in the neocortex will be like model based policies because why, otherwise, why would it be happening in the neocortex if it doesn't need a model to do it? But I like the idea how Niels formulated it, that when you do something using the model, it's always going to be a bit slow because you have to go through the model and calculate your movements. And, but then when you want to do motor coordination, I don't know, dancing or moving your hands, grasping something, whatever. That's all some stuff that you can initially do clunky using your models, and you can do it, you watch someone do the dance move, and you do it right afterwards, but it isn't smooth and not very coordinated, and then once you practice it multiple times, it gets smooth. A lot more coordinated and then turns more into a model free policy where we don't have to think about everything. I'm going to argue with that. I don't think it's a model free policy. it's, first of all, I don't deny that some of these things are learned subcortically. the cerebellum is really important and so the vagal ganglia and all this stuff. But I think the whole thing can be done in the cortex. so again, I imagine the R1 It has to be, if it's not done in the cortex then it's going to take you like a thousand years to learn to do it subcortically. so I think the cortex has to solve all these problems. yeah, I think the only thing I'm suggesting that the subcortex can do is just to help the coordination bit. we can coordinate it, using model base like cortically, but it's just going to be really slow. Maybe, but look, take my example of two fingers. One has learned to type and the other has not learned to type. And, the one that's learned to type could be, it's still model based, it's still going on in the learning module in layer, region one. but it's, it can be very fast. It's basically, it doesn't have to calculate trajectories. It just, it's learned the trajectories. It's like saying I can calculate how to go from point A to point B using my model, but I'm going to do it over and over again from the same spot. I don't have to calculate it. It's like a sequence. I just learn it. It's like a melody. I just learn it. And now I don't have to think about it. I just know, I've done this many times, it's just a sequence I've learned, so I don't, I just go follow the sequence and it's done. So I think the evidence we have from humans and other animals is that when we practice something, whether it's dance or whether it's typing, whatever, that the representations for those behaviors move down in the cortex. And, therefore it's faster, you don't have to regress multiple regions, there's no communications involved, these are learned sequences, and so they're essentially learned based on the model, they're still happening in the same learning module, but I don't have to do the calculation in the learning module, I just follow the sequence. Is there any reason why we would still need them to be happening within the learning module instead of, subcortically, if we're not using them anymore?

I suppose you, there's no reason to, but I need to, I want to solve it first in the cortex. The cortex has to solve these problems. I can't, take the cerebellum, it's obviously helpful for any kind of coordinated movements like this. if your cerebellum is damaged, then your movements are jerky. they're not smooth, we're relying on the cerebellum to really grease everything up and make it work better, but I, but you can still do these things about the cerebellum, it's just, they're just not as coordinated, it's just like clunkier, so I think, for me, I want to solve how the cortex does this first, that's our goal in mind, it's like cortical models. Then we can ask ourselves, okay, what kind of other stuff do we want to wrap around this that is engineered or works in a different way or helps, make things move quicker or whatever, but I don't think we can, I think we have to solve the problem in the cortex itself. Yeah, no, I think that's the point that Niels was making to us, especially on Slack, that, we need to be able to solve all these problems in the cortex. And then, but then once it's being practiced and getting really smooth and coordinated that those might be optimized subcortically. Oh, okay. so I think I, Yeah. Thumbs up. And so actually. I was thinking a little bit about this in like the, like a write up that I did in Google Doc, one, first, I agree that probably everything is model based, definitely during learning and even when we're doing FAST, I think the doing FAST, so when we're learning, I think, I'm thinking of it as okay, if, let's say, we're trying to pinch the finger, we need to think about, okay, move the left, move the thumb, move the index, move the thumb, move the index, and it takes a while, and, in the baby, and also in computation wise, because we need to consider a lot of things about the model to decide on this action, so there's some function that chooses that action, and it's, in the beginning, it needs to take a lot into consideration, but as we get used practice, I think that function computation can be faster, or even that function doesn't need to depend on any model, so it becomes like model free, which is, and then I think the faster, fastness comes from the probability of choosing the next action becomes faster. close to one. if I did move my thumb one way, then the other, the, probably choosing the next action, now I don't need to think because I have, that function has been optimized so that it's the next, we immediately know what the next action is. does that, like? The words all made sense, but I got lost. Okay. That's just me. I'll also probably try to like, Yeah, I think maybe to paraphrase, maybe yeah, I think the idea that in the, even in the model based policy or in the models, in the learning models, there can be probabilities associated with certain actions and that those can be learned and refined. And, yeah, I think that's interesting that, yeah, because. Yeah, I think that makes a lot of sense that you want to make coffee, okay, there's a 80 percent probability you're going to do it the usual way you do 20 percent you reach for the instant coffee or whatever, and whether that's by the strength of neural connections or some other thing. But, yeah, I think that makes sense. And then, as you're saying, maybe when you have high confidence, then you don't need to deliberate as much. And so you can navigate through that faster. Yeah, so I guess, yeah. If, I don't know if this is what you were saying to that, so that might be a case of like where a model based policy can also improve over time, like there are things which still require conscious involvement, like they're sufficiently complicated that they don't become just model free subcortical stuff, but they can still become faster through practice. yeah. I think I, this all can happen in a cortical region. Yeah. So I think the cortex is responsible for choosing the actions and I think the cortex has to learn the actions and the sub cortex is just the executor. Like I, I think we should just, yeah. Alright. I'm gonna keep, so this, I think we should totally ignore anything sub cortex from them. And we have to solve this problem in the cortex itself. I can see how the cortex itself, by learning these, I'm thinking through it in my head right now, how they can learn to do these things very rapidly. You could call a model free because there's no thinking involved, like when I'm typing, but that's still cortex. And it just means that I've learned a particular, given, if I, if my hand is in the correct position on the keyboard, then the behaviors I have to execute, are rote. They're not, I don't, there's, they've been learned. The first time I did them, I had to think how do I move my finger from the J key to the Y key? But after I've done that enough times, I don't have to think about it anymore. And it's just it's still, there's still a model in the, in that column, but I'm not using the model to execute the behavior. I'm just using a sequence that I've practiced over and over again, but it's still in the column. and that's how I think, that's personally I think how we have to attack this. And so that's essentially like a model free policy in Cortex? you can call it, it was, learned based on the model. And it becomes like a model free. It becomes model free only in the sense that because it's so practiced. I'm starting the same position, it's, think about it, really, my hand has to be in the exact same position on the keyboard, so we have to, that's why we locate the index figure on the J, and on the F, and once it's in that exact same position, then how do I move them to get to the correct keys, there's no ifs, ands, or buts about it, it's that there is a single direction you have to go, a certain distance, I remember early on in my career, I worked on laptops. And they were changing the scale of keys. From the original typewriters, to the IBM Selectric, to the laptops, because the laptop makers wanted to make the keyboard smaller. And they went from like a 13 millimeter spacing to a 12 millimeter spacing, okay? And initially, this caused havoc. People who had shown to type on typewriters couldn't type, because that millimeter was like, it just threw off everything. And so we had this huge amount of pressure to increase, to go back and go back to the 13 millimeter spacing. And by the way, I don't know what they are now. They're probably 10 millimeter now. but back then it was a lot, every keyboard was the same spacing until the laptops came along and they got, started to get smaller. And then people started complaining about them. And so people said, you have to go back to 13 millimeters. But people said, that makes our computers too big. We don't want to do that. So that was an interesting thing, how that rote learning got off. Of course, after you've used a laptop for a while, you, adjust. That was the right solution. my point was, it's very, precise, right? And so you've learned these rote behaviors. And at that point, you're just assuming that everything's the same. Once my finger's in the right position, that all the other keys are in the right position, I don't have to think about it. But it still could be happening in the learning model. It's just not using the, it's not learning, using the model anymore. It's just practice behaviors.

I'm just I think we're all agreeing on that this is going to need to happen and that we're going to need to be able to do everything model based and then be able to learn model free sequences from that. I think the only question that Niels and I raised was whether the model free sequences are still in the neocortex or whether they are then learned subcortically, but Mechanistically, I think we all agree that this will happen. It's just that maybe it doesn't really matter. I think, I can't, it's automatically, it'll be learned in the cortex as far as I'm concerned. all these layers of cells, this is another thing I was working on, I'll maybe open it another time, let's think about minicolumns, but I think all these layers of cells work on the same principle as the temporal memory, algorithm, which is, we have this sparsification in context, but that, those When you have a thing set up on minicolumns like that, it'll automatically learn sequences if it's presented to them over and over again. the temporal memory algorithm will learn sequences if it sees them over and over again, and then therefore doesn't have to calculate anything. So it's inherent in the way the neural mechanisms work, I believe. That if you practice something enough, it will become, quote, model free in the sense that it will just execute the sequence without having to calculate. so I don't think you need anything subcortical to do this, so you might want to think about subcortically transferring it there, but to me, I think it's a distraction. I would rather not, we can all agree it's cortex that has to solve this, but then you say, it has to transfer later to make it faster. I disagree with that. I don't want to do that. I think that's, we saw absolutely everything in the cortex. Then, obviously some mechanics in the body maybe, I don't know. But, yeah, from the implementation it's exactly the same. it's just whether we say, oh, this is what would be happening in the columns, or this is what would be happening in the cerebellum. So if I would implement this right now, I, this wouldn't influence how I imple implement it. But yeah, just a question of how we would map it to the brain, I think it's still cortex. I think the point. Or, the thing that I think about is just because we're not thinking about where to move to type, it's not, that doesn't mean that it's subcortex. I think it's just that we don't, just because we don't recognize that we're thinking about it, I think it's still cortex. It's just that, in predictive coding, because there's nothing, no change in the actions that we did before, we're not really recognizing it, but it's still cortex. I wrote about this on intelligence. there's a lot of things you do. I wrote a book. What's that? Talking about the book, Unintelligence. Unintelligence. Oh, your book. Sorry. My book. Sorry. I wrote about this thing, Unintelligence, where, and it's not my idea. other people come up with this idea too. that, imagine the cortex is executing a lot of stuff. As long as you can get process low down, like typing, it handles, it gets handled in the lower region. Only when something requires attention, there's an error, or there's something that requires attention, then it goes right all the way to the top. If you're attending to something, you, it's going to the hippocampus, you're able to remember it, you're, it's everything gets taken over for that. But that's so much of what we do in the world. It's handled by these rote behaviors in the cortex itself, even compositional behaviors are taken care of, and, and, so you're not aware of it. You're talking about attention, what you're conscious of. It only gets conscious when the rote behaviors don't work anymore. And then you, it bops up to the top and then you say, oh, I have to pay attention to this and think about it. so I think there's a lot of complex behaviors that are happening in the cortex, compositional behaviors, as long as they are. as long as they have been practiced enough. so even like typing on the keyboard, the first thing I have to do is get my hands onto the keyboard in the right position. my, I don't generally have to think about that, right? It just, you put your hands in it, you just, you've learned these behaviors from feelings and you just know where to put things. you put your palms down and then you adjust your palms to the right position and then you find the J and the H key and then, J and the F key. So there's a complex, hierarchical behavior going on that I'm not thinking about at all. and it's involving multiple regions in the cortex and, it doesn't, it, just because I'm not thinking about it doesn't mean it's subcortical. it's subcortical. Yeah. I guess it just seems like we don't have a very good model of the keyboard actually anymore Like you said, if I ask you now, where's the O key? It's really hard. You have to mentally type a word with an O in it and then you know where it's right. But when you, when I first started learning the type, I actually took a typing class when I was in school, at grade school, the first thing you had to do is memorize where all those letters are, and. And the whole keyboard layout. But now that we've been typing for so many years, I've forgotten it, right? I don't need that model anymore. It's amazing. I was trying to like, can I walk through all the keys on the keyboard? And I was struggling with it. We could do the QWERTY one, that's easy, and you can do the ASDF one, you can see that a lot. But then other places, what the hell? I can't remember. But I can type words, no problem. all right, we can, maybe we're in agreement, maybe we're not, I don't know. but that's how I'm going to be working on it. Yeah, I think as Viviane says, it maybe doesn't matter too much, and who knows if our language will change going forward. But yeah, I guess the main thing is that we agree that, yeah, some sort of model based deliberate conscious control is what comes first. or unconscious once, once you've learned it to work. Yeah, that's why I said comes first. Yeah. So I, it's, I'm gonna, the goal I would think about would be like, I've got two fingers, one has been practicing typing from some location, and it does it automatically, then I want to do it with another finger, which is not that finger, a different column, and says, oh, I haven't learned how to do this, so I'll have to think about each one. And that is a nice problem, perhaps, I don't know. Very simple. Two columns in R1, one column in R2. it's a behavior we can all think about. and, so I'm gonna, now that we're talking about it today, it seems like that's, my, I'm gonna try to see if that works as a good, that's the magnolobal equivalent for sensorimotor for goal oriented behaviors. It's an interesting sensory problem too, because you do the action, but you see the change somewhere else, like the letter appearing on your screen, and you have the tactile sensation, but then you. What the change actually affected is the visual input. on that note, it's also in English. Also, the other, it's in English when, what if my, hand is not in the right position, right? And, so I definitely use vision for that, right? I have to see where the laptop is, or maybe I look at the keyboard or something like that. so even, just getting your hand or your finger in the right sort of base position could require multiple modalities.

I think that's what you're talking about.

Yeah.

I think it's a rich problem in that it seems like the mug and the coffee cup, the mug and the logo is, it seems like a rich problem where very simple, a few columns can expose a lot of the issues, that we have. And I guess one thing. I feel it's potentially encouraging is because we're doing it in a model based kind of slow way, I feel like that just makes it easier that, yeah, if it's like an abstract goal state, like pressure at a location, I guess my first concern with that was like, okay, then how do you coordinate, pressure at multiple locations and stuff? But again, if we're not worrying about that right now, because, That only comes through lots of practice, then it's it's not that hard to imagine. Okay, first you send the goal state. Okay, something that, yeah, basically apply pressure at this location. And then, as you said, like if the hand's in the wrong location, then maybe the eye can see that. And then that's in some other goal state. But it does feel like we can serially break it down. and any task can just be like serially broken down. that's the goal, right? To come up with something where almost all tasks are combinations of the elements we solve in the simple test.

that would be the, that's the hope. I got mine, marching orders. I'm going to go think about typing with one finger and two fingers.

just to make it like a concrete hierarchical goal, just to, yeah, state it explicitly, so the highest level goal would, for example, be type the word Numenta, and then it would be broken down into get hands in location X, Y, Z, type N, type Y. You, and so on. I would start with, I would start with the hand being in the correct position and then have to figure out how do I move The finger to the correct key, that would be the first thing I would do. And then, that's a, that's an interesting, because that's, this would, it would ask us how do you calculate that, and then, and you could show that if you practice it enough, you can start doing it automatically. You don't have to calculate it again. I would start with there, and then later I would say, oh, now I have a problem of how to get the hands in the right position. Because I think that's going to be, that might be a wear problem, we might have to, this might be much more complex. Yeah, I was thinking it would be more like, yeah, you start with, you want to type Numenta, so then the next goal state is typing the letter N. Whatever knows about, a key says, okay, I need pressure here, so maybe it's there needs to be pressure at this location in body centric coordinates. Okay. And that's quite like a wide, widely sent goal state. That's like something that lots of things can answer. And then the learning module associated with a hand is maybe okay, I know I can apply a pressure, but I'm all the way over here. So I need to be approximately here. And then it sends maybe like a sub goal to its finger, which is like, Okay, you can actually apply the pressure, But I'm going even simpler than that. I'm trying to avoid the wear pathway altogether. I'm trying to do this all in the model of the modeling space of the object. The object is the keyboard. The first thing I would start with is my, I have a finger which is located within the model, the keyboard space. And, and now I just have to move it to different parts of the keyboard. I'm trying to, again, I'm, ultimately, have to get the handle of my position, but for starters, I would just say, how do I turn, type, here's a command to type a word, I, know what the sequence of the letters are, How do I pass it down one at a time to the thing that says, okay, here's how I just move in the object space. I don't have to move my hand in any other space. It's it's already on the J key. Now, how do I get it to these other keys? And then, I would start with that. And then later we could add in how do I get my hand at the right position?

even just solving the problem, okay, take the word, break it down into multiple letters. And how do I learn that sequence is pretty, is a good enough challenge for starters.

I have a question about, how a column decides that it's going to do the action. So if you have a hierarchical thing that you want to accomplish and it goes down to a column and your finger says, okay, I'm going to press the M key. Does it have to suppress all the other columns that could have taken that action? Say, you're not allowed to take this action because I'm doing it or is that somewhere in the hierarchy? How do you think about that? I'm thinking about doing this all in one, two columns and then three columns. there isn't a need to suppress. You're either going to use, the first you're going to do it with two columns, or you just have one finger, and there's nobody else who's going to do the action. And, and then you can say, how about I use a second column to do it? and then that's, whether you have to suppress or not, or you're just directing someone else to do it is an interesting question. the answer is, we don't know the answer to that question, but I don't think it's the right first question to ask. I think the first question to ask is, how do I do this with just two columns first? Where I'm just trying to decompose a problem into, into a component. And then, can I learn to do that quickly as opposed to using the model, just do it by rote? And then, once I solve that with two columns, then we can go ask, okay, how do we do, how do we have multiple actuators? And how do we choose which actuator? And how does that, which is your question, Will, you were saying, how do I do, you said, how do I suppress someone, but it more be like, you could also say, how do I can't tell someone to do this and not tell other people.

I have no idea yet how that occurs, but I think it will become obvious over time. I thought a little bit about, I can also try to say something about this and also something about the word pathway a little bit. So I think, so let's say we want to type the letter N on the keyboard and basically, Another way to paraphrase Will's question is, how do I decide I want to use the index finger as opposed to middle finger, thumb, or whatever, and so when I'm first learning to type, so let's say I have ten options, I can press with any of the ten fingers, but through either, through learning, or let's say I saw somebody else type with their index finger on their right, then I might have a little bit more, bias, or higher probability of choosing that action, I will press the, the letter N with my index finger, and then the next time, you have a history of, okay, I have done this action by doing this, I have been, achieved little pressing N by using my index finger, okay? So now you again have a probability, but because you have experience that was successful, you have a higher probability of using that again, or you can explore and do like another finger. But, after a lot of experience, you probably have a lot of evidence or a higher probability that, oh, like I will always use my index finger because that's all. If you've had success once, you'll probably do the same thing again and again. Yeah, this is interesting, that once you've learned to do something some way, you've been doing it your whole life, and someone comes along and shows you a better way of doing it? Yeah. It's like, why did I ever think of that? because, I see It was never an option. I see them talking a lot. My kids come on, and they teach me, Hey, Dad, you're doing this the slow way. why don't you cut the, I'm doing this way. And I'm like, I've always done it this way, and it worked, but then they show me a better way of doing it. I'm like, oh, I should have done that way. How do you know? But you get in this rote. You get in this pattern. This is how I've learned to do it. So you just do it that way over and over again. I think it's natural to do that, right? Why would you explore unless it didn't work? Yeah, unless you're feeling exploratory for whatever reason. But I think that's also an answer. It's like, how can that be fast? Because now, I'll build it and choose an action as opposed to one. About the aware pathway, like, when we're talking about the goal states, the goal is about going from one state of the object to another. that was the proposal I discussed last week, whether that's right or not, we'll see. Yeah, going off with that proposal, I think, let's say the goal is we're tired and we want to get energized. The object that works. So that's the state I want to change, going from tired to energized. And the object that it applies to is us. So I think actually, we're, modeling objects like outside of the agent itself, but I think maybe there's a lot of columns indicating to modeling the agent itself. Yeah, I think when we get to these sort of very high level tasks, like you say, making coffee, it's clear that you have to move your body to different places, or you have to pick things up. And, and at least picking something up is definitely a rare pathway, it's like relative to your body. Yeah. I'm trying to avoid that. The typing example I'm using, it doesn't require that. Okay. and not initially, right? It might require it if I have to get my hand on the keyboard. Okay. But again, it's breaking down the problem into the simplest components and then expanding upon that. So the simplest one I would look for is something that absolutely doesn't require a web pathway. I'm just trying to understand how do I manipulate an object. In the case of the typing example, the goal state would be, literally, just be, I want this word, right? And it turns out it's a series of actions that have to be taken to get that word. Maybe the word's on the screen, or just the word appears, or someone speaks, I don't really care. The goal would be like, get this, get the computer that has that word on the screen, type of thing. And so the goal is, implement this word, and that requires a series of actions on the, of the actuator to do that. But those are all, if, once my finger is located on the J key, then there's no, as far as I can see, there's no where pathway calculations. Just how do I manipulate the object with my hand, the object being the keyboard, to achieve a particular state.

It's going to be a difficult example to do with just two columns, just because of the multimodality property of it, it's hard, it would be very difficult to type that word with only one touch sensor. Why's that?

for one, you can't distinguish the letters using touch, the keys using touch. And then you don't really know, what, if the word actually appeared on the screen. I mean you can do the sequence. We would try to, yeah, making this all up. I'm sitting here making it up. I would try to avoid any of that stuff. I would try to come up with a way of phrasing the problem. That, you don't need to see the result. Somehow the system can know the result, somehow it observes it somehow. I don't know how that is yet. But I would definitely try to avoid, just to get the mechanisms I would try to avoid any of those complexities. Because as soon as we introduce these other things, and the WEAR pathway and so on, it's it's opening up a can of worms. You don't know, it's just really hard to pin down a solution. Yeah, I wouldn't say it requires the WEAR pathway, but It seems like it would require voting between modalities at least, and like basically vision modality telling you the state. But then, why can't we just make up a state for the object that's obvious to the, two columns? can we just change it to pressing a button? And then it's just, maybe, although I want to have different behaviors that are sequences. I like the idea of the fingerprint. Pressing a button, in a Morse code. So you can do yeah, you could do that. That's a different task, but that's not really, it's not really, very much. That's sensorimotor. That's just temporal. Okay. I guess then you still also have audition maybe to hear the tones. No, I don't know. That's right. I think we need to make, we need to make this task abstract enough, real enough you can understand it, but abstract enough that we don't introduce these problems. I think it's really important that the finger moves, that the sensor patch moves in space. That we're not going to be solving the problem correctly and I'll have to learn different high order sequences. To solve the problem. So we're going to use the temporal memory to do that. and, I just, I'm just arguing for my case. I'm going to try to avoid anything else. I'm going to try to solve in two columns, at least get the first understanding done in two columns. You can't solve the whole problem, but then you can branch off from that. I think it's hard enough just to say, okay, what does it mean to tell region 2 you want a word, and who knows what that sequence is, and how is that sequence broken down, and how is the R1 executed? These are all interesting questions. There's a lot to unpack just trying to do something really simple there without moving the hand or looking at the screen or anything like that.

That's my argument. For instead of vision you could substitute it with a linear buffer holding a character where a movement is moving one space in the buffer.

So like that might be like the least amount of vision recognition feature I can think of. Again, it could be a totally artificial way of the columns knowing what's going on.

initially. And don't our fingertips have cameras in them anyway? Like we have vision right on the touch sensor. And we have to worry about that. Our fingers have it. the question is, that's an interesting question. Magic, so the buttons are not equal, right? The buttons have different features and those features could be, we could assume that they're tactically detected. So we have a bunch of different, features at different locations on an object. And, we're trying to, activate, we're trying to press a particular feature, and we have to find out where that feature is. So the J key is a, feature on the keyboard. It's not just a key, it's a J key. I sense the J, assuming like I can tactually touch it and feel it. So take that as a simplifying assumption. Now, basically, I have a, an object with a bunch of different features located at different points on the object. And my goal is to find the particular feature I want right now and move my finger to it. and then I'm going to do it for another feature in sequence. I think it's also, it's, what's really interesting too, I'm just thinking about right now typing, it's we start with our fingers on the home row and the home keys, but as you type, you don't bring them back there every time, right? If I'm, if I type the word jump, I move it up to the U. And then I would move it straight down to the M, and then, and then I move it straight over to the P, if I was checking with one finger. it's not like I'm going back to the home square again. the sequence in which I execute is not completely right. I would have to, that would be another interesting thing to learn, it's the type of word you don't go, from home to A, home to letter. You somehow have to learn how to and so the whole, the word is actually the sequence of moving in a two dimensional direction around the keyboard. that could be all done in one column. Yeah. Yeah. I think we can definitely work around like finding the sensor, finding the key letters and, distinguishing the different keys with the camera finger sensor or something like that, the bigger thing. And again, we can. For sure use an artificial solution for it, but the state of the system, the state that we're trying to influence, so like the word appearing on the screen, is not visualized in the keyboard itself, so the keyboard doesn't tell you which letters you pressed so far and where you are in the sequence, but yeah. It would tell you which letter you're pressing because it has a sensor on it to detect that. Bear in mind, I'm not talking about something practical here. Maybe you guys are all thinking, we're going to build something that does something. I'm not thinking that at all. I'm just trying to think of a toy problem to elucidate mechanisms. I'm willing to say that You could rephrase the goal as ensure all the keys still exist, like the keys for Numenta still exist, and once you're happy that they're all still there, the goal is accomplished. Why would I do that? Why wouldn't I want to have the sequence of them? Oh yeah, the sequence. It's just like I have a But anyway, I've already said it. I think you could have a, think of an abstract model where you have 10 locations, each has a unique feature on them. We call, we'll call those letters of the alphabet, but, and when the sensor goes to that location, it detects that unique feature. So I don't need a visual confirmation. I just, did I get the right input or did I not get the right point? And now the goal is to understand how to go through a sequence of these. Movement in space, to, to accomplish a broader goal of, of a word or sequence. And, and how the system would learn to do that rapidly. And, or it could do it, if it was the new word, it would have to do it one letter at a time.

but if it's a practice word, you can, you don't have to think about it, you, it just automatically plays out. I think it's a very fruitful task, but it's not practical at all. It's just, I'm thinking about mechanisms. I'm not thinking about anything useful. Yeah, no, the only thing I'm pointing out is that, the higher level goal state of having pressed that sequence of letter is not observable in the keyboard, but we could for sure do something artificial like when you press the key, it changes the color of that key or something like that. No, it is observable in the keyboard. I'm saying each key has its unique feature, so the sensor detects whether it got to that feature or not. Oh yeah, it knows when it's there, but it doesn't know if it has already pressed that key before.

What do you mean? I don't, if I have already pressed N U M, and how do I know that I've already pressed these keys? The state of the keyboard doesn't change as I press a key. No, but the state of the temporal memory, my motor behavior sequence is a temporal memory, and I know the state of it, and so I know what the next element I need to do. Yeah. So the agent, the modeling system knows what you've done so far, but there's no way to compare whether you actually achieved your goal. I guess in the higher level, like the learning modules that can detect these, that both knows the concept of this series of unique sensations, and which is also the one that's guiding the overall task. that one's going to get, we could say it only feels it when it presses it, I don't know, it's almost like a depression that comes out or something, but it's going to feel that, and then, and just like any kind of Monty system or whatever, over a series of movements. It'll be like, okay, I detected that feature, I detected that feature. So it will satisfy what it's requesting. It'll know if it's successful, because if it's been learned as a sequence, it knows what the next element should be, and if it isn't the correct next element, it'll know it's wrong. so if you do N U, if it's learned Numenta, and it's a rote sequence, and you do N U M, and it doesn't detect E next, it knows it's not a mistake. so I think it's built into the system that'll know whether it succeeded or not. I don't see a problem with that.

I'm overloading, I'm putting it all on this one little sensor. Just imagine there's ten unique features on an object arranged in some physical arrangement, and, the sensor knows whether it gets to that point or not. It doesn't even have to press it. It just has to get to that location. And that would be the, that would be like, it's like a keypad. It's like just if it followed the right, if it got to the right sequence of elements, it succeeds. in terms of the task, I'm just wondering, it feels we would rather have something where you, it's not like a learned sequence, but more okay, you now need to type this series of letters. you can't plan that out because.

It starts off unlearned, right? It starts off that, like your new typist, you have to use your model, first learn the model of the keyboard, where the different features are, then say, given my current location, how do I have to move to activate a particular function? feature, get to a particular feature. So that can't use temporal memory? Because you've never done that path before? that's it. You're using the model, it's path integration or reverse of path integration. Again, I guess I was just concerned that we were talking so much about re like, doing something we'd done before, that I felt like we'd go down a path of only using, no, It starts out, obviously, nothing learned. And first you have to do it to learn a model of the object. That's pretty simple in this case. It's a set of features in some physical arrangement. Then, you have, then the goal is to, given a particular goal, you have to navigate through one at a time through those different, through a set of those elements, just moving your finger to those elements, in the right order, that is going to be, that's not wrote yet, but if you do it enough times, it will learn to do that automatically. So that would be the, that would be one of the goals of this system. is, you start off slow and methodical, which is even hard enough to imagine how to do that, but then once you've done it enough times, it gets really fast, as long as you as long as you locate the finger in the right position, it just follows the sequence automatically. And again, then we could show it a new word, it doesn't know, And it would have to think about each letter again.

if I gave you some random sequence of letters, it didn't look like any word you knew, you'd have to think one letter at a time. How do I do this letter, then this letter, decompose it. I think all this could be done in two columns. At least for the moment. This, if you're formulating the problem like that, it could be, but maybe it just feels a little bit sad to do it that way, because we're losing, actually manipulating the state of the world. we're not actually changing the state of the keyboard at all, and we're not learning this behavior of, like, whenever it's a button, the state actually changes. I don't think it's sad. I think you just have to realize you're doing it in a simple way that may not look like the way you simply think about it. Perhaps the state, we haven't defined what the state of the object is yet, we don't really know that yet. We're talking about it, but we don't know. So maybe the state of the object is literally, have you gotten it into the position at this location in the sequence? And and meaning you've done the particular right order, and that is the state. It's now in the word Numenta. I can think of it now, maybe that's not a physical state. But we could, I could modify this two point problem to say, as you, I could even modify the problem to say, as you touch the keys, they move around. And depending on where you are in the sequence, you have to go to a different location, right? I think, that, again, I personally have to think about this in the most simplistic form. I'm trying to fit as much as possible in two columns. You might think it's sad. but I don't think it's sad. I think it's the way of getting, making progress. So I'm going to try to do as much as possible like that. And then of course, most people won't understand why that's important. but once you've got the mechanisms, then we should be able to expand it rapidly to do real world things. that's my argument. I also wonder whether it'd be helpful, because I think for me, the complexity, That still feels like it's very there, at least in the, real world imagining of this is like the coordination of the hand and the finger that's attached to it. That's definitely gonna be, non trivial in, if it was actually like a robotic arm or whatever. But I don't know if we say it's like some, almost like a digital space where you just have the four arrows on a game pad or something, where you go up, down, left, on, with a cursor. And so you have to visit locations, yeah, I guess to me, then it's easier to understand how one column can coordinate that. How we're solving robotics, we're not going to get excited about this, but it doesn't matter. These are really hard problems. We have to get to the core of the mechanisms. And I think we will run into dead ends. It wasn't a criticism that it's too simple. It's too simple. It was more just like It was more almost like it wasn't simple enough, like I'm just worried that if we're talking about a finger moving, like inevitably it's going to come back to okay, how does the hand get the finger into the right location and stuff like that? So I'm just wondering if. It's useful to have a motor actuator that's even simpler than that. I think, all I'm saying is that the hand doesn't exist here. The finger, there's like a finger that's anchored in object space, and then the movement is how to move the tip of the finger to the right location. to solve a particular problem. it's a navigation problem. It's not obvious to say, oh, once I have a model of the object, how do I get from this letter to that letter? We know that, grid cells can do that. No one really knows how. there's some speculation about it. So we have to solve that hard problem. We have to solve the decomposition of sequences into, or goals into subtasks. We have to know whether we completed the subtask or not, yeah, there's a lot of hard stuff to solve in this really simple problem, so I just can't imagine tackling more at once. It just seems like until I get the core of this stuff down, everything else, it'll just be like, I think we'll waste time, we'll think about these high level goals and we'll just, it sounds good, but then you try to build something, you just won't know how to do it. that's been my experience. I think it can be done by two people. We don't have to read, by the way. We can take different approaches to this. I'm sorry, what did you say? I'm also, okay, yeah, I'm also trying to suggest keeping it simple. I'm beginning to think that it can be done by two columns. So let's say, I have one finger, no eyes, and first I need to learn, right? So I'm going to just, go through the keyboard. Learn a model of the keyboard. Yeah, learn a model of the keyboard. I can, there's a feature, there's some protrusion, let's say, so I can tell that to N, I can tell that to U, whatever. So I learned it, and then let's say, There's a goal of typing Numenta, so actually what we're learning, so we're learning the keyboard, not, feature at location, so there's N at 0, 0, something, J, U at 0, 1, whatever, like that, and then, and let's start from the easy case, not just putting the hand, on, on it, or like finger on it, but let's say we are at N, and we want to type Numenta, so we break down the goals so that, so now we want to type U, and so the goal is, go to U, and it will have to use some features learned at level 1, like N at 0, 0, and U at, I don't know, 2, 2, and R2 will need to figure out, integrate that information, okay, then, move forward. right to, up to, yeah, and then I think, R2, let's say R1 learns the model of a keyboard. R2 has to know, my first blush would say R2 is telling R1 there's different states it needs to get into. First you have to get to the end state. Then you get to U state, M state, and R2 has to know that R1 has accomplished that somehow. And then it gives the next one, and the next one, and the next one. What will happen as we, as the system gets practiced and practiced that R2 doesn't have to tell R1 to do all those steps. R2 will say, hey, in the context of this word, before I was telling you how to get to all these different points, so maybe there's two things being passed down. One is we're doing the word Numenta now, But you have to do the N, then you have to do the U, then you have to do the M. But after sketch practice, R2 says R1 Numenta and R2, R1 just does it. It just goes, bing and goal accomplished. Yeah. that would be, that's how I'm viewing it. So R1 has the model of the keyboard. I don't think R2 even has to have a model of the keyboard. And it just has model of the word Numenta. Yeah, we, I think goals can also be broken down, infinitely, oh, in the beginning, there might be a lot of step goals, Like that we need to think through, but when we're used to it, there's not as many goals. If we don't have infinite number of layers, so at some point, like R01, we'll need to figure out. But also, just bear in mind that, in the hierarchy, just like in composition, all the hierarchical steps are not represented at the same time. you can just do two levels. You can move those two levels up and down in the stack of hierarchy. So I'm solving this problem now, I'm jumping down, solving this problem, I'm jumping down, it's like a task may have. 20 different sort of complex, I don't know what it would be, but they're not all representative ones. Yeah. anyway, that seems like a big time limit. yeah. What else were we supposed to talk about today? this was the topic, this was the topic, this was the aim. Viviane wants to talk about something, she was offering to review some anatomy, but Oh, I can do it next time. I think we're already over time, Okay. Oh, okay. I'm, so I'm really excited about working on this now. This, to me, today, this meeting was really helpful for me. I don't know about anyone else, but really helpful for me. Just talking through this made it much more clear what my task is and what our task should be. And, so I'm excited about that.