so yeah, let me walk you through this paper. This one is a neuroscience theory paper, so very different from, the other paper in terms of, yeah, results and stuff. So the paper's called hierarchy, or he hierarchy a theory of Long Range Connections for the Sensorimotor Brain.

and to give a brief intro introduction, first of all. The first part of the presentation. Also, the first part of the paper is about, neuroscience, neuroscience evidence, and a review and summary of long range connections in the neocortex. And the second part of this, presentation will be about, what the function of these long range connections might be and what functional requirements they would fulfill when you think of the brain as a, solving sensorimotor tasks. okay. And so to frame, all of this, neuroscience evidence, I think it's useful to just recap the basic structural organization in the neocortex. I think you're all aware of this, but, just as a brief recap, so we have the neocortex, which is basically a thin, sheet that's wrinkled up a bit in our heads. And if you cut through this sheet at any point here, you observe this kind of layered organization. And the different layers contain different types of neurons, different densities of neurons, and can have different response properties. And this picture was first, this was first drawn out by KHA in 1911, and then further classified and analyzed and so on. and basically we find this. Six layered structure, essentially anywhere you cut, depending on where you cut the layers might have, different sizes. but overall, anywhere people classify it into six layers. Sometimes layers are classified into sub layers, like a layer force often split up in the visual cortex, and there's layer five A and layer five B and so on. but they're these, six basic overall layers and then orthogonal to that. So if you look, alongside these layers, like in this direction, you can find these functional units called cortico columns. And, these are not really something you can observe under a microscope. but they're more defined by their, response properties in that all the columns within a cortical column, to the same receptive field. And the call next to it has a different receptive field. It might be overlapping with the one, next to it, but it's a different receptive field. And, if you move about 200 to 600, micrometers along the surface of the cortex, you ha you don't have overlapping receptive fields anymore. You're in a totally different column. And then as a little detail to, you can. Then, decompose a column further into about 5,200 micro columns, which are defined by their response to similar features. So similar oriented edge, for example.

and maybe the most extreme example of this is, the barrel cortex, where basically each whisker of a rat corresponds to one column. and then if you look at different sensory organs like the skin or your retina, the patches can be a bit more overlapping and that's clearly defined. and the first one to, identify the structure, and also propose that the columns, could be the basic unit of computation in the neocortex or the micro columns in this case is Vern Mountcastle. And that's the column hypothesis that, thousand Brains Theory is, strongly based on.

so what do we mean when we talk about long range connections? So when we talk about long range connections here, we are talking about accents that travel outside of a cortical column from which they originate. So every neuron connects to neurons within the column. It originates or has that cell body in, but then some of them send the axon outside of these. The balance of, the cortical column. And that can happen either by the neuron entering the white matter through layer six and then reentering the cortex elsewhere. That's because, information travels faster in the white matter. if you look at this picture here, the gray matter is this kind of structure up here with the layers and then the white matters here. So information would go to, from the neuron down into the white matter, travel very fast along the axon, and then reenter somewhere else in the column. so it's schematically shown as an example. Here we have a pyramidal neuron in layer, two, three, and then it, it sends an axon down all the way down. and then we have a cortical connection. It's just indicated here, which means an, a connection from one area of the cortex to another area of the cortex. So this axon would then travel to some other column, go back up and connect somewhere.

and then alternatively it can travel within the cortex without going into the white matter for, a distance of more than one millimeter. So here is an example of, that shown schematically, where we have a, the red part shows an axonal branching of an layer two, three parametal cell, that can kinda travel across columns.

and yeah, just to note, I'm gonna show some figures from other neuroscience papers in this presentation just to illustrate the concepts. pretty much everything I'm showing in the first part of the presentation is based on a culmination of results from hundreds of neuroscience papers and, people at Menta, particularly Jeff studying them for, about 20 years now. so it's not like this is the only, example of this or only publication, but I'm just trying, I just try to find some illustrative examples to kinda visualize the points, I'm making here. Okay. we group the long range connections in four. Conceptual categories for the purpose of this paper. First, we have the hierarchical, cortical connections, but also the very classical connections that define the cortical hierarchy, as people usually think about it, of like information entering the brain, getting processed, sending further high up in the hierarchy, get getting further processed, getting sent to the next level of the hierarchy, further processing happening all within the neocortex. Then we have, non-hierarchical, cortical connections where we have connections between, different columns within the neocortex. But, as I'll argue in a moment, they are not, can't really be interpreted as hierarchical processing. then we have cortico, thalamic, connections, which, basically every part of neocortex, connects to the thalamus in a very structured way.

and then we have layer five water outputs. And, both of these two categories can be interpreted as hierarchical but also non-hierarchical. And I'll explain why in a moment. there are more long range connections, in the neuro cortex, To the striatum or the claustrum, but, we are omitting those from this review here.

and yeah, also just trying to summarize high level principles. So if you go into the literature, it's never as clear cut and clear to find as we show it here. for every rule there's an exception. some principles vary by species. Some principles vary by sensory modality. there are always some little details, always some conflicting findings, but, this kind of tries to condense it to, high level principles. A lot of them are accepted textbook knowledge. some of them are, less, commonly thought of when you think about long range connections than others.

so yeah, let's start with the, most commonly type of long, thought of long range connection in the neocortex, which are the hy hierarchical, connections. And the general idea is that, information comes from the sensorimotor. It enters the thalamus, from the thalamus. It, It is, it, goes to a relay cell in the thalamus, which relays the information to the neocortex, and there enters in layer four, which is seen as the classical input layer of the column. But also there's some information entering, at the border of layer five and layer six at some information processing happens within the column. and it gets, it act neurons in layer three are activated. And then layer three is often seen as of the classical output layer of the column. And we have these, this connectivity between layer three of a lower region to layer two, layer four of a higher region, as the input to that region. by the way, Niels, feel free to interrupt me if I forget about anything. or add to it. Yeah. and that way it goes, up the hierarchy again in the next region. Information processing happening within the column neurons in layer three activate their long range connections from layer three to layer four in the next higher up region. and then we have the feedback connections, which are shown in purple here, which, originate in the deeper layer. So layer six, and then they go into the lower region where they can Form local connections or have some aberrations down in layer six, or sometimes also layer five, and then the axon ascends all the way up to layer one and spreads pretty broadly, so it can even spread outside of the cortical column to multiple columns in the lower region. when I say region here, this could be for example, V one and V two in the visual cortex. so the figure shows kind of an illustration of one cortical column in a lower region, like V one and one cortical column in a higher region like V two.

and then there are several layers that kind of, send their branches up to layer one where they could be, integrating this feedback information. and this is basically how the classical hierarchy is defined in the development scent paper. essentially the connections between two hierarchically ranged regions are asymmetrical. So region two doesn't really have layer three to layer four connections down to region one. And region one doesn't really have these layer six. Up to layer one, connections to region two, they're asymmetric. and that's how f and Fen back in 1991 kind of made this famous picture of the, hierarchy in, I think the maca monkey sprain.

and then just to show another more experimental image of this idea. so here we have, retrograde labeled neurons in B two that are shown here. So these are neurons in B two. And then, they inserted the DAI in V one and in V four. and you can see that the Dai inserted in V four, which is a higher up, a region that's located higher in the hierarchy than V two. You can see that, these get the, get, inputs from layer two, three of V two, and then V one is the region that's, lower in the hierarchy. And with the retrograde LA labeling, you can see that, those would get input from layer six and for the like upper layer two, three and layer one of, of V two. and then just as an illustrative example of this feedback connection, the purple connection. Here's just one example drawing, of a neuron that, in this case it's just showing the receiving region, where you have the axon coming in down here from the white matter. There's a little branch shooting up in the deeper layer, but, fairly local. the axon keeps ascending up all the way to layer one and then spreads pretty far up here.

alright, so these are the classical hierarchical connections that everyone learns about in the textbooks. then we have, non-hierarchical connections and basically there two points to make here. One is, every cor a lot of cortical columns, even at higher regions in the cortex, receive sensorimotor input, receive, yeah, sensorimotor input. So also in B two you can get direct sensory input. secondly, what's shown here is that we can have these kinda lateral long, long range connections that, connect columns.

Within a modality or between, different modalities. and so if it happens within a modality, it often is observed that it, the connections are between neurons in the same layer. So you can have connections from layer three neurons in mod in this column to layer three neurons in this column. same for layer five B neurons and, layer six cortical connections. And this can happen either within a region, so like different columns within V one connecting laterally to each other, or, going through the, COism to the other side of the brain and basically connecting left and right hemisphere.

and then it can also happen between modalities. So for instance, connections between visual, primary visual cortex and primary auditory or sensory cortex. And there, some papers report connections like this, but predominantly they look a bit more like the feedback connections I just showed. So in the sense that they originate from the deeper layers and then have some more local connectivity in the deeper layers of the receiving column and ascend up to layer one and have a broader spread there.

And just again, to show a couple of visualizations, here's the kind of, local spread across col columns within a region in layer two, three and layer five. here you can see an example of the, layer six cortico cortical cells. So here we have parametal cells in, in layer six that connect to other, cells, mostly in layer six, but in different columns. and then here's an example of connections that go through the, ric callosum where they essentially injected a, dye, over here. And then what this graph shows, is like all of the red dots or red neurons are where they then, visualize these neurons, after injecting the dye over here. So you can see that, you can find a lot of these projections in layer two, three and, mouse macca and human monkey, mouse macca and human. and then a couple of them in layer five and in layer six.

yeah. but notably none in layer four.

oh yeah. Just to, clarify, these are non-hierarchical connections because they can both connect, like first order regions between different modalities, which, wouldn't be thought of as hierarchical connections. They can also connect columns within a modality and, even connect columns between, hemispheres of the brain. So very long range.

yeah. And then secondly, these, input connections going to also higher order regions, again indicate that even higher regions and lower regions can respond in parallel to sensory input. And it doesn't necessarily, the information doesn't necessarily need to propagate from region one to region two to region three, but instead region three can get direct sensory input and directly to inference based on that. Yeah, maybe just consistent with what you were just saying, but, emphasizing that, yeah, and they can be symmetric for those reasons. So go in both directions, basically between regions, which contrasts them to the kind of the defining element of the hierarchical connections, which was that asymmetry, that was originally observed. Yeah. Yeah, that's a good point.

okay, so next, the cor thalamic connections. so there are several, first gonna show this one.

while the cortex is receiving input, always routed through the thalamus, the cortex, also sending back some information to the th and that information comes from layer six B. and it's usually characterized as only modulatory. So it doesn't really cause these cells to fire on its own, but it can modulate, how these cells fire or when they fire. and here is a picture from a nice book from Sherman and ary about the th thalamus that kind of shows this. So we have, input to thalamic relay cells. So this is a first order thalamic nucleus, this, higher order thalamic nucleus. so the input goes onto that relay cell, that is a driving input. it causes the cell to fire and provide input to layer four of the first cortical area, the input layer, if you remember.

and then we can have cells here in layer six. That project back down here to the thalamus. And this is, drawn a little bit lighter because this is the modulatory connection. So it doesn't itself cause the cell to fire, but it modulates its activity. and then what I'm gonna show next on the next slide is, there, but I'll just show it to you 'cause it's already shown. there are also, cells in layer five which connect down to the nu thalamic nucleus with driving input. And this is information that also gets sent down to the mortar centers in lower parts of the brain. And so that's you can think of it as an ference copy of a motor command. And this is actual DR driving input to the cell versus the atory input here from layer six B.

and then the interesting thing is that, the, layer six B cells can send this input both down to the thal thalamic nucleus where they receive their input from, but also up to the next higher order of thalamic nucleus that then sends input to the next higher region. so unless you're at the first order nucleus, most dynamic nuclear actually receive converging input from. Two hierarchically arranged regions. and that's illustrated here as well, where we have, these nicely topographically arranged, neurons, in, in, in cortex. Again, mapping next to each other from two different regions into, onto, points in a thalamus. And yeah, this kind of, converging input onto Islamic nucleus will be important, for the composition object modeling that I'll talk about, later.

so what do these connections mean in a hierarchy? you can argue that they do support a hierarchical interpretation 'cause it does map down to the input region and the next higher up in the hierarchy.

but it's also, yeah, an output that's sent from every, region in the near cortex down back to the thalamus. so it's, not yeah, it's a, parallel process that happens everywhere in the near cortex.

and then lastly, one other connection to the thalamus, and also to lower regions of the brain are the, motor outputs. So layer five A, sends out an axon down to subcortical regions that control, for example, the muscles of your eye or muscles in your body or down to the brainstem.

but, these axons kinda bifurcate and send a branch of them to the higher organ root of, of the thalamus, which then inputs to the next region. That's what I showed in the, earlier picture. But, here's a nice anatomical drawing of this happening.

basically you have, these axons that then split into, at these points that are marked with red arrows, and one part goes, to the spine and another part goes up to the brain to ear cortex. and so yeah, you can, yeah, think of it as an ference copy, like a copy of the motor command that gets then sent up to the next layer of the, cortical hierarchy.

so again, this can be thought of as hierarchical in a way since it, goes from one region to ne next higher up region, but also non-hierarchical because basically every region of the brain has a motor output. Every region of the brain outputs something down to motor related structures, which is not something, not a way that people often think about, information processing in the cortex. Usually people think about visual information entering, going to V one, V two, V four, getting processed more and more, and then eventually recognizing an object and a scene. And then eventually the motor cortex, A separate part of the neocortex is thinking about what to do and then sending motor commands, down to the limbs. but that's really an incomplete picture. actually even B one can send, commands to inform how to move the eyes, for example. So anywhere in the brain we have outputs from layer five down to subcortical areas.

did I miss something else? No. And yeah. Sounds great. And, I really like all the figures you added. I think it's, it's nice grounding of the paper. Yeah, it was fun to dig back in and finding these, okay, cool. So the, conclusion or the argument we make based on this is that, hierarchy is really a bit of a limiting term to use when describing, the functional organization of the neocortex. It's really more of a hierarchy in the sense that there are hierarchical connections and there is hierarchical processing happening, but there are also a lot of non-hierarchical connections and a lot of parallel processing happening. we have these lateral connections between regions. We have motor output from every region in the brain. We have, feedback and feedback forward connections to different thalamic nuclei, and we have direct sensory input to higher regions. so that really suggests a much more complex picture than how people often think about, processing in the brain and also what, deep learning systems suggest that are, often compared to the brain.

all So that's the first part of the presentation, the neuroscience part. Anyone have some questions on that?

Okay. So now the second part is the theory part. While there's lots of anatomical and physiological evidence for these kind of long range connections, there isn't really a comprehensive theory to make sense of all of these connections. And what we're suggesting here is that if you think of the brain as a sensorimotor learning system, there is a unique and very crucial role for each of these long range connections.

and to explain those roles, I'll start with some background. some of this has already been published before as the Thousand Brains Theory. some of it is new, but this is, briefly focused on, just one column, so not long range connections to, to give a bit of a foundation. so basically the sensorimotor sends feature information and movement information to the thalamus and the thalamus then relays this information to the neocortex, to the cortical column. the proposal is that, feature information gets sent up to layer four, the classical input layer, and then the second kind of location of input to neocortex is this border of layer five and layer six, and. The theory suggests that, layer four represents features, and then in layer six we are keeping track of location and orientation. And, there are strong, associate connections between layer four and layer six. And those can be used to learn associations between features and locations. So we can learn which features exist at what relative locations and the movement input can be used to update the internal location representation inside the cortical column.

through a series of movements, we'll activate a bunch of different feature representations and a bunch of different location representations, and those change all the time as we're moving over an object. but then they get pooled into kind of an object representation, which I call here the object id. And that remains constant. So as I'm moving my finger over a coffee mug, for example, the features and locations I'm sensing at any point in time are changing as I move over that object. But the object ID would remain, constant and stable. And this is what would be the output of layer three, and that's what would become the input to layer four in the next higher region.

one thing that, is, new in this picture is this, backward projection from layer six B to the thalamus.

which we propose here is used to inform the thalamus of an orientation transform that it needs to apply to both the features and the locations. and this is new and I'll talk about that in, in a bit more detail, in a moment. But essentially, the idea is that, information from the sensorimotor is in an egocentric format. how am I moving my finger relative to my body, for example? but then representations within the column. So locations here are in an object centric reference frame. So features on the coffee mug are all like locations and features relative to each other in a reference frame. That's just for this coffee mug. And having the separation allows us to really generalize. I can learn about a coffee mug in one room, in one location and orientation, and then I can recognize that same coffee mug in any other location, in any other orientation because the thalamus can transform any movement that's happening in the egocentric format. So relative to the body, it can take that, take the orientation hypothesis from the column and use it to transform, the movement and features into the object centric reference frame. And that's a really powerful idea, for being able to recognize objects in any location orientation, even though they were learned in one particular location and orientation.

okay, that's, the foundation. Any questions on that?

Okay.

I covered this one briefly 'cause, This was actually already, suggested in previous, papers from NOA in the thousand birth theory. So the proposed rule for the lateral connections. So these connections that are between the same layer of two, two cortical columns, those can be used to reach, rapid consensus. So that's something that, we're already using in the, current Monty implementation. Something we call voting, where each cortical column is receiving input from different patches and sensory patches in the world. So the i one part of the eye might be looking at the rim of the cup. Another part of the eye might be looking at the body of the cup, and then you might be touching the handle of the cup with your finger. So each sensorimotor gets different kind of input and each column has learned, potentially different models of objects. For instance, the, model learned by the column connected to the finger wouldn't co contain color information.

but. Whenever they're all sensing the same object, they all have, a particular object representation active in layer three. And that is a pre constant representation as long as the sensors are on that object. And so the lateral connections can be used to quickly reach consensus. So even though each column by itself might not, know for sure yet what it is sensing, this patch that's here on the body of the cup might think it's a cup or a cylinder, not, is not sure about that. The one that's on the rim might think it's a cup or a bowl. and the one on the handle might think it's a cup or scissors. by communicating with each other, they can quickly narrow down what's possible combining each of their, hypotheses. And what's not really shown here, but important to note is that this, would also take, take into account the relative location, of the sensors and the hypothesis, orientation of the objects.

and yeah, for a description of, the implementation of this algorithm, you can see, our paper that, demonstrates Monty's capabilities that Niels just presented.

okay. So now to the first big new proposal in this paper, which is the role of the thalamus in transforming sensory and mortar information from an egocentric format into an object centric format. So whenever information enters thalamus, it will be in an egocentric format. It'll be relative to the body or, some, structure on the body, like to the head or something like that. and that's indicated by these dash lines.

all the information that enters the column will be relative to an object, the object that's currently represented by that column. And in order to do this, we need to inform the thalamus of how to rotate the incoming information to go from egocentric to object centric, format. And, the proposal is that this is done by the layer six B projections to the thalamus. the idea is that, layer six B represents the orientation of the sensorimotor to the object, represented in this column and. This orientation is sent down here and then used to rotate both the incoming movement information and the orientation of the features.

there's another transform that needs to be happening, which is the motor output. The motor output needs to, be in egocentric coordinates, since it doesn't pass through any thalamic nuclear anymore, but directly goes down to the actuators. And so there are, there's connectivity from layer six B to layer five A and, our proposal is that the transform would be happening there. there's some more detail on, why we think that is, possible in, the paper to, and so this really makes sense in the idea that the projection from layer six B is, only modulatory and the input is a driving input, because we have the incoming, feature and movement as the driving input. But then this connection can modulate, how this is passed forward to the neocortex.

and essentially the thalamus would be acting as a multiplexer mapping, one orientation to another orientation depending on which input it receives from layer six b.

Does that, make sense?

Okay.

yeah, it's probably all pretty familiar to all of you, right now because we talked about this so much already.

another thing that's shown this figure is, the different types of movement input that can be used by the neuro cortex to move us through the reference frame of the object. and so we can get movement information either from the retina itself, optic flow, for example. You can watch someone play a video game and without controlling anything, how this person is moving through the virtual world just based on how the patterns are moving on your retina. you can get, ference copies of the actual motor commands, like outputs from the superior cuus or the vestibular system about how your sensors are actually moving. And then also this ference copy of the motor command that's being sent to the next higher region.

okay, now the second big proposal of this paper is the interpretation of hierarchy.

There are many non-hierarchical connections. There are also these hierarchical connections, the both the feed forward and the feedback connections. But like I mentioned, how those are often thought of is this kind of hierarchical processing from the sensorimotor to the thalamus. And then processing, increasingly more complex features. So first, edges and then some more complex features. And then eventually, some representation of objects. And these are some images of, representations in, neural networks, which are often kind compared to, the code processing lately. but how we propose hierarchy is used is to model compositional objects. And when I say compositional objects, I don't mean just complex features being, combined from edges and objects being combined out of complex features, but actual 3D objects, that are made of other 3D objects.

if you remember the first slide, while each column only gets a small patch of input at any one point in time as it moves over objects, The representation of the object is constant and it can therefore model and recognize entire objects that are much bigger than, the receptive field, that it gets as input at any one point in time. And so even columns in V one or V two can represent entire objects that are larger than their receptive field by moving, in the world. and so here's one example of, how compositional structure could be represented. So for instance, as we are attending to different features on this dog, region two has learned a model of a dog. region One is has learned a model of, a dog's tail. So at a certain location in the model of the dog, the tail exists. and then at another location on the dog, the head exists. But then, both region one and region two can have a model of the head of the dog. And through shifting our attention, region two can then attend to the dog, dog's head, while region one represents the eye, which is again at a particular location on the head. It's not just features that are somehow coexisting. It's. Features structured in reference frames. So the relative arrangement of these features is really important as well.

and this kind of composition of structure is both encoded in the feedforward and in the feedback connections.

so I'll show how exactly we proposed that in a moment. one last thing to emphasize again here is that all the regions are receiving sensory and motor input. There's not just a processing of features that are static. Our sensors are moving all the time, and both features and movement are integrated in the same region.

so while it might sound like a small twist to say hierarchical connection, smaller compositional objects is actually quite a different conceptual way of thinking of, hierarchy.

maybe just one last thing to point out is that, pretty much all compositional structure can be represented by very few regions by just shifting your attention. Between different parts of an object, like you don't need hundreds of layers to process things. You can just, attend to one feature and then decompose it into sub features. you would normally not attend to more than two levels in the hierarchy, or you can think about that yourself, as you're looking at the dog. You wouldn't really at the same time decompose it into head and eyes without shifting your attention between them. and so models of the same objects can exist at d in different levels of the hierarchy at the same time, and you can, shift your attention between them, de miss something else. No, I guess I was just thinking, yeah, maybe we don't comment on this that much in the paper, but it also fits well with the purpose of the top down connection because the higher level object is telling the low level object where it should be. So there's like very clear kind of proposal about that. One of the issues with deep learning as a model of the brain is it often doesn't have a clear explanation for this top-down connection because if that top-down connection is doing some kind of computation, then that creates a cyclic graph, which tends to break back propagation, but then it doesn't work as a, as being the means of back propagation because. It involves, biologically impossible assumptions, like symmetric connections, or it just works very poorly compared to the backdrop that actually powers deep learning systems. So yeah, I guess as part of this kind of hierarchy composition, it gives a clear kind of reason for that, very well-defined, L six to L six connection within the broader kind of output in L one.

Yeah, yeah, that's a good point.

okay, so now, how does this actually get implemented in a cortical column? first of all, just getting into a bit more of the complexities of modeling compositional objects, you might first think, okay, it's simple. I have a model of a cup and I have a model of a logo, and now I wanna learn the logo on the cup. And when I learn this, cup with the logo on it. I don't have to relearn a model of the logo, I don't have to relearn a model of the cup. I can simply assign the logo to the existing location, the existing model of the logo, to a location of the existing model of a cup. Super efficient process. That's the promise of learning. Compositional objects, you can combine things very quickly. You don't have to relearn a bunch of stuff you already have learned before. you can assign the logo, to the mug here. and then that's it. Small tweak on it. Logo might be in a different orientation on the mug. Okay. So we associate, a location on the mug with a, particular location and orientation of the logo. so that the kind of connection between the two needs to include, not just the object IDs and relative locations, but also the relative orientation.

now it gets a little more complicated. the logo might be, changing in scale as we go along the surface of the cup, or part of the logo might be shown in a different location in orientation. so for one, we need to include scale. not that big of a deal, but here scale is different in different locations on the, mug and here orientation is different on different locations on the mug. So what we settled on is that this association needs to happen on many locations on the mug. so on a location by location basis, each location on the mark needs to be associated with the location and orientation and scale of the logo. And that happens at many different points here. and this also, helps learn how this, logo that was initially learned in 2D can now actually wrap around this 3D mug. and lastly, there's no kind of pre assumption of which object will be the child object and what will be the parent object. It's not like the logo will always be on the mug. The mug might actually be part of the logo where the logo is the parent object and the mug is a child feature on that object.

so there are all these kind of combinations and initially they seem difficult to, figure out. But, The solution we came up with is that they get associated on a location by location basis, including object id, location and orientation and scale of the child object relative to the parent. so how would this look like in a critical column using these long range connections? so here's an example where we have a series of fixations on this cup with the logo on it. And depending on where we are fixating, the two regions in the cortex are representing, different objects.

note that both of these regions are receiving sensory input. The lower region, like V one receives a smaller, receptive field. The higher region Rece receives input from a larger receptive field, and from the lower region output from layer three. so at fixation one, both regions would be representing the cup fixation. Two. Both regions are, representing the cup, fixation. Three. The lower region would represent the logo. The higher region would represent the cup together. They would learn the logo on the cup. same for fixation four and five verse. Fixation five, the orientation of the logo would be different.

both of these receptive fields are co-located, so they're both like the, both input to region one and region two comes from the same location in space. It's just, a larger receptive field.

so now bear with me. It's, a bit much to take in at first, as we already showed on the kind of first slide. Layer three is a representation of the object, that's, learned in region one. So layer three would be encoding the ID of the logo and layer three connects to layer four of the next higher region. So basically the object ID becomes a feature in the model at the next higher region.

TBP logo now becomes an input to this feature layer, four of region two, and gets associated with locations on the compositional object. note that this input doesn't encode like the whole model. It doesn't encode the structural composition of the logo. It's just an ID of that object.

so this connection alone kind of explains. How we learn at which locations on the mug, the logo exists. Basically whenever we're on the logo on the cup, the logo will be represented in layer three here and sent to layer four of region two. And region two will associate that logo ID with locations on the mug through those. layer four, layer six associative connections.

now region two after having learned the logo on the cup, also wants to inform region one when it should be expecting the logo. So if we're like on fixation three and reaching two, know the TVP mug model. We move to Fixation four, region two should be able to tell region one, to expect to see the logo and where on the logo it should expect to be. So that's what the feedback connection is for. We have both this very local connectivity to the deeper regions, which would communicate a unique location on the logos model. so remember layer six A in codes, the locations in object centric reference frame. So basically region two would tell Region one expect to be at this location on the logo. And then we have this broader connectivity in layer one, which, more broadly inform also neighboring columns about the existing existence of the logo, but not really quite precisely about the location on it.

and then finally, we also need to know the orientation of the logo relative to the cup. And that's what these orange connections are for, or yellow.

region one, or with marked with E, represent the orientation of the sensorimotor to the logo. Region two, layer six P represents the orientation of the sensorimotor to the cup. If we. Combine these two orientations. We get the orientation of the logo relative to the cup at the current location, and that's also the input to, layer four region, two, and can get associated with a specific location on the Cup model.

so that's pretty crucial. We get the relative orientation of the logo to the cup because it's the relative orientation and not just the absolute orientation of the logo.

it needs to be a relative orientation because imagine learning the logo on the mug, the TBP mug model, and now you're tilting the TBP mug. The orientation of the logo is changing and the orientation of the mug is changing, but the relative orientation of the logo to the mug is unchanged. So the input here is still exactly the same and there's no need to update the model or anything. We just need to represent the relative orientation between the logo and the mug. so we can recognize it in any kind of, we can recognize the compositional model in any orientation in the world.

one question here. Sorry. are the, projections between layer six A of region one and two, are these bi-directional or just feedback from region two? So region one, that's just feedback. The location in the feet forward connection is basic. you get that, this is not shown in here, but, the input from the thalamus also includes the movement information to the water of layer, the fife and layer six. And that movement information moves you through the reference frame of the mug up here as the sensorimotor is moving. So that location in the mug's reference frame then gets associated with the logo object ID through those kind of internal associative connections. I'm, just wondering, so it makes this association with the object id, but it doesn't know where on the object it's making this association. Like for example, with the number five on the cup, it doesn't know that this is the word project that is being like this, part of the logo is being assigned here. It just knows that, okay, I know that the logo is being assigned here. So when it goes back from region two to region one, how does it tell it this is the location it should be, on if, yeah, so that's what basically region one learns when it connects, here to the feedback connection.

region two has learned the model of the cup. So if we're at, location five, in the Marks reference frame, we sent this. Location rep representation down to Region one and Region one associates that with a specific location on its logo model. So on the J of the word project. and so that's a very, an association between a specific location on the mug to a specific location on the logo. It's not bi-directional, you're right that Region two does not know where on the logo exactly it is, but it also doesn't need to know because region two doesn't have a full model of the Thousand Brains logo. It only gets the object id, it's a simp more simplified version.

okay, that makes sense. Makes sense.

okay, so there's, I don't know if you noticed, but, we are not communicating the expected orientation from region two two, region one right now in this diagram.

one proposal we have for that is that this can get communicated by the layer six cortical, connections. but we're not certain enough, in that to have included it in this paper. there's also no, showing of how scale gets processed. But the idea is essentially that it's a similar mechanism to orientation in that we calculate a relative scale and associate that relative scale with a location on the compositional object.

yeah. Does someone have some more questions? yeah, I have one kind of question.

so if we go back to the, the first part of this slide where we're talking about the, fixations 1, 2, 3, no, on the, slide You're on, yeah. and fixation one, everyone's seeing a cup in fixation two, everyone's seeing a cup in fixation. Three R one is seeing a logo, but isn't the patch that R two is getting, it's also mostly a logo. So how does it stay with the idea that it's looking at a cup and not decide, oh, I'm looking at a new object now. 'cause all it's seeing is that patch.

Yeah, that's a very good question and I think a kind of a practical question we have with Monty right now as well. So we have not really tested a, concrete mechanism for that yet. I guess one thing is that, this region is receiving a larger, lower resolution, version of the input, They would likely not really see any of the, specific features, be able to perceive specific features of the logo. So might take a bit more for it to, switch its hypothesis.

but yeah, there isn't really that principle of a mechanism for learning it for inference. It's, it's simple. 'cause region two would be representing the compositional object, itself. I don't know any else if you had some more thoughts on it? No. Yeah, I think, like you said, it's, probably to do with the sensory input, but, and, also its sensitivity or, related to that, like just its sensitivity to spatial detail that it's, it's not gonna as quickly pick up on, on things like that.

But yeah, it's a good question and as a thing, we need to practically get working.

It might, actually, region two might from the beginning just represent TBP Cup once it sees that the logo is there, which is not in its default model of the cup. So it might just start saying, okay, this is a new object, I don't know. Really anything about, so would just set the ID to TBP cup the specific cup and then learn that at this location the logo exists. and after learning, kinda this is a, compositional object of, logo and cup and any other questions.

Okay. So yeah, just to summarize, many connections in the neuro cortex are not strictly hierarchical. all the long range connections serve a crucial role when viewing each cortical column as a sensorimotor processing unit, where each column can learn complete models of object objects. Each column receives sensory and motor input. and each column also outputs sensory and motor signals. and columns can work in parallel and hierarchically because of that.

the proposal for the function that these connections, serve is that the hierarchical connections are used to learn compositional objects. So objects composed of other objects, lateral connections are used to establish rapid consensus. Between the hypothesis in different columns and the cortico thalamic connections are used to inform reference frame transforms applied in the thalamus to the incoming features and movements. And then, what's kinda the significance of this paper? so this theory that we pro propose in the papers, provides a comprehensive explanation for the long range connections in the neocortex, or a lot of them. it explains physiological and anatomical findings that previously had no explanation. it's testable and, it's addressed the functional role for the thalamus as a post converter, which is central to all critical computations in a sensorimotor system. You can't really have a sensorimotor system without having something that does this, which we noticed as we build Monty.

and it suggests an alternate way of building artificial intelligence. One we have implemented over the past years and Niels just showed the significant advantages of, such a system that works on these principles.

yeah, it's the hierarchy paper.