Alright, so let me just go through this. This is an idea that's a little simple. It's simple. I haven't worked it all the way through yet, so there might have some errors in it.

but the details are complicated, and I don't want to go through all the details, so I'll do my best. it's not something I stumbled along. I realized that this could be a, an issue with the scale problem, and the scale problem is we're observing an object that's at a different scale than when we learned it, and we seem to be able to do that very rapidly, quickly. It doesn't take any time. It just happens immediately. Seems certainly not effortful, and this is a potential solution to that problem. So it has to do, with grid cells and how they work, and how cells work in the brain. So it's a very neuroscience y solution. Before I go through the neuroscience, maybe I'll just describe the basic idea. in, what we're trying to do, our basic models are we have some location, in a reference frame, and we're pairing it with some observed feature, which could be a curvature or something else. And, when we're correctly on an object, as we update our locations, It points to the correct new feature, and a feature then can narrow down the locations. the idea here is that as you're moving your sensor, or your body or whatever, the thing that's moving, and you're updating your location, it actually sweeps through a series of locations over and over again, in a linear line. So if I'm moving in some direction, or my finger's moving in some direction, it'll sweep through a series of locations along that line of movement about ten times a second. And, you would be able to, match the observed feature early or late, and, then, and still, and it would know that. It would say, yeah, I recognize it, it was in the wrong location, it's a little too further away, or too close to get, too close to me. And then it could adjust its scale in some sense. So it's basically, and this is in the brain, this is going to occur on a theta cycle, which is about anywhere between 4 and 10 hertz. So let's say 10 hertz, every 10 times a second. Essentially, the location signal, location representation will sweep through a series of locations, and, and then along the line of movement, so that, you, again, you could match an input earlier or late, and therefore know that your scale needs to be adjusted. That's a very high level description, and I can explain how it works. if anyone has questions about that. Are you assuming the animal is moving along that arrow? I wasn't talking, I didn't, I wasn't talking about the picture yet. I was just describing the high level view, that you would, you essentially, we think about the upward, we're moving our finger or the animal, it doesn't matter. And, we're updating the grid cells, the location, as we move it. there's doing, there's path integration going on, so as we move it updates, but what actually will happen, it'll sweep through a series of locations along that line, closer and further away, and therefore you could match, The feature, early or late.

and, so if you match it early, then you know that the scale is, this thing is smaller than you observed it. And if you match it late, that means the scale is larger than you observed it.

that was just the overall top, and then I could describe what's going on here in this picture. Is that okay, or do you want to ask me a question? Yeah, no. I do have one question. is that the only way you can get phase precession, is from a difference in scale? That's the only way people have proposed, that I'm aware of. no, no, there's other ways. no, not difference in scale, not difference in scale. I haven't talked about phase precession yet. I haven't even mentioned that yet. I'll get that in a second, Kevin. I was just describing at a very high level view. Because the actual details of how the neurons do this can be very, can be complicated. And, I've struggled with understanding all the different theories about it, and I'm assuming not everyone here knows all that stuff. I'm just trying to give a very high level view. What is the solution? It's gonna end up basically saying, we're gonna, we're gonna sweep along this, we're gonna sweep the location along this over and over again. And we can match earlier or late. So let me just go through some of the details here. So in the upper left hand corner, you see a typical image from a paper about grid cells. Ignore the arrow for the moment. And what you can see here is that these little things, I'll call them fried eggs. These are areas where a grid cell might respond, in a, an environment. this could be an animal moving in an environment, but it could also be our finger moving over an object, right? It's the same thing. just imagine now this animal's moving in an environment, and as it goes along, this is, this represents the response of an individual cell. one cell. would respond in each of these little, highlighted circle areas. And, they're quite large. You see they're not very specific, and so they're color coded by basically on the frequency of firing in this case. they fire more actively in the center of the little fried eggs as opposed to periphery. and the, and, there are two ways, there are two things going on here. There's a lot of theories about this, but all the theories, how grid cells, come about are basically based on the same idea, and that's in the drawing below it. the drawing below it shows two sort of sine waves. The first one is labeled LFP, that stands for local field potential. This is a, something called a theta hertz frequency, between 4 and 10 hertz. This is the frequency you observe. and many, parts of the brain are different interactions. It's like a frequency that's shared for, different modalities, for example. So this would be shared in the hippocampus or the enthorhinal cortex. So all the cells are, that's why it's called a field potential. It's a local, it's a field that's being, all the cells are being subjected to. then individual, the idea that people hypothesize, how do grid cells do this path integration, which by the way they do in the dark, so the path integration isn't relying on any sensory input. The basic idea is that there is a second frequency. and where that frequency originates is a little bit controversial, some people say it's in the dendrite, some people say it's in the second cell, doesn't really matter. There's a second, I'll just label that one, that's the red one, it's called cell, and that, the frequency, that frequency is theta plus a small delta. So it's a little bit faster than theta, but only if this cell is, gonna, it's only if, the animal's moving in a particular direction. All right, so this is a, frequency that says, if you're moving in a particular direction, if you're moving slowly, I'll increase the theta a little bit, if you're moving faster, I'll increase the theta even more. And so now the cell is getting two inputs. It's getting a, the LFP theta, which is a constant, and it's getting this, slightly, faster frequency, which is related to the movement speed along a particular direction. And as you see, what happens is these two sine waves, or these two, Frequencies go in and out of phase, and that's the black line, the third line down, the black line shows the sum of those two frequencies. and the idea here is that as an animal moves, let's say, along the gray arrow above, and it's going through like multiple points where the cell is going to become active, what's happening is that cell is just sitting there, and it's getting these two frequencies, and it slowly goes in and out of phase as the animal moves. So again, that red, sine wave is indicating the animal is moving in some direction at some speed. and if the animal's moving faster, these two cycles will go in and out of phase quicker. And that's as if the animal's moving quicker, across the environment. And if the animal's slower across the environment, they go in and out of phase slower. So this is the general belief how grid cells, become active based on movement and not on sensory input. how path identification occurs, you have these frequencies that are going in and out of phase. Now, there's two things that are going on here. One is, you can see that the at first people say, there's a maximum firing rate of the cell, and that occurs at the peak of the black line there, when the two cycles are in phase. But in reality, that's not a very good reliable indicator that where the cell is. because it's, they make it look like, oh yeah, there's more of those little tick marks in the center and it gets pure on the side, but in reality it doesn't look that clean. but the second thing which is going on, which is very interesting, is you have this thing called phase procession. what it means is that when the cell spikes, when the cell actually emits the spike, it's a different, Points in the phase of the theta frequency. So you can see those little dotted lines coming down from the troughs of the, of the, I guess it's blue sine wave at the top. And, then you can see where that those line up with the, with the black line at the bottom. And where they line up changes over time. That is, Where the, cells actually spike, is moving, from, one part of the theta phase to another part of the theta phase. So if you look at actually when the spikes occur, You can tell where the animal is relative to the, it's, it, to that, that grid cell's ideal response pattern, right? And so as the animal moves towards a point, the grid cell fires, it fires, I think it fires early first, yeah, early first, yeah, early first, and then it gets, right on the trough of the, of the, LFP, the theta cycle, and then it moves beyond that. there's a shifting of the, when the spike actually occurs, as the animal moves towards this, center of its field, and then beyond it. And this phase procession is seen in many cells in the brain. it's seen in grid cells, it's seen in plate cells, it's seen in other cells. This seems to be a very common, phenomenon. And what mostly people say is, oh, that's a good way for the brain to know. Be more precise about where you are. So the grid cell says yes, it's responding over those big, egg like blobs, but if you look at the phase of one, it's responding, it's much more accurate, you can state where the thing is. Okay, any questions about that before I go on? Maybe if you had a question, Kevin, that would be a good one. I, that was good. Or question?

No. I can look at the fried egg, where the center red pieces that's gonna correspond to the middle of, yeah. That corresponds to where my arrow is on the lower deck. Yeah, right, here. Yeah. And then, and so this entire thing you're showing here corresponds to one fried egg. It's not the entire trajectory of it. And what you're saying here is if you look here, this firing is near the beginning of the phase, and when it leaves the fried egg, on the other end, it's on the right hand side.

Just in case that wasn't clear to people. I think, yeah, one question for me, in the middle it shows multiple spikes, but my understanding is within a single cycle, you're not going to see multiple spikes. If you're going to see one spike, it's just across multiple cycles, you're going to see more spikes on average. I didn't know that. I didn't know that. I had the impression that there'll be, several spikes at those peaks. Yeah, there would be several spikes, it's just, my question is, it like during a single cycle? You're actually going to get multiple ones? I think so. But then, I think, then the phase wouldn't be very precise. Because it's, it takes 5, 10 milliseconds to do a spike.

if we're at 10 hertz, that's the maximum sort of a, then you've got 100 milliseconds. Yeah, if you're going to do multiple spikes, that's like a, 30 percent error. I think it's I think it's like two or three spikes, and I don't, they make it look here in that diagram oh yeah, there's clearly more spikes in the middle, but I think in reality it's not like that. I think it's noisy. Yeah, there's a few spikes. if you look at the drawing on the right here, they're showing the same phenomenon, but, I don't know, I don't know. I think, I didn't show a real diagram, like a real recording from cell, but I think if you look at a real recording from a cell, it's not so clean. it's, messy. But the point is that the phase seems to be, the phase procession seems to be pretty accurate, even though the spike count is not. So, the idea is that really, they're saying, the accuracy comes about from the phase procession. And no one has any speculation, as far as I know. How the brain would use that? How would it take advantage of the fact that, oh, it's early or late, on the phase to know something more precise? I'm going to propose something in a second. Okay, so as the animal is moving along that gray arrow in the upper left diagram, the phase is going to keep shifting back and forth as it gets to its preferred, each of the products. Yeah, if we can, I'll just go, oops, I just lost my, I tried to scroll the image over, now I lost it. Let's see if I can get it back.

I'm doing this on my phone, it's not so easy.

I lost the image. You might be able to, wipe the whole screen. Oh, yeah, yeah, there we go. Alright, on the right, I, it just occurred to me, there's something else would be happening. So on the right I show two, our classic model, which is a location layer and a feature layer, right? This is from columns and columns plus. And, and so we're essentially saying, as a model consists of a, a series of locations and the features associated with them. And if the, and if your finger or your eye or your body was moving through space. What you would do is you would see a continuous series of locations and a continuous series of features. if you're moving your finger along the edge of an object. And so this goes back to my, argument recently that you could do this, type of model in a continuous fashion.

what occurs to me is that As you're moving through space, what you really would be doing is on, each data cycle, you'd be cycling through a series of locations further away where you actually are and closer in, because The phase procession thing, remember, we just looked at one cell before, but there's, all these cells are doing this, and so there'll be cells that represent all these locations, and so at any point in time, you'd have, you'd cycle through a series of locations, the ones that are spot on, where you're, aligned with the peak of the phase, the theta, And ones where you're shifted early and shifted late. And as you're moving along, on every theta cycle, you'd be going buh bum, buh bum, buh bum on every, every theta cycle, cycling through a series of points along the line of movement.

and so in some sense it's saying now you've got this feature up in the upper layer and the feature's in there. We're trying to predict this feature. the feature's either there or it's coming in. We're trying to match it up with the location. If the feature is not in the right location, but it's within that sweep, it'll be found. It'll say oh yeah, I found it. There it is. I matched the feature I'm expecting at a location, but my location was either shifted to the left or, shifted earlier, shifted late from what I expected. And Then you would say, yeah, I found it. I found what I was expecting, but it wasn't in the right place. It was shifted. And, and that's the information you need now to, to basically handle scale. and the way scale is handled in situations like this, at least it's speculated to be, and I think this is right, is the way the brain does scale, it just changes the base theta frequency. If you increase it or decrease it, everything scales up. Everything. All the cells that are based on this. Methodology will scale up and scale down, so you could scale up and down movement, you could scale up and down, your, your path integration, motor behaviors, and so on. So now you have basically, you said, okay, you're saying, okay, I'm expecting to find this feature at some peak activity in my, on some grid cells, but I found it on a, on an early or late phase activity of some grid cells, and I don't, I didn't try to work it out, but that's all the information you need to do now adjust the theta cycle. to match what you actually found. If I found that I was early on the cycle, I would have to speed up the theta cycle a little bit, and now I'd be matching it. So the end goal of all this is just to adjust theta, which essentially adjusts the scale, and by, by noticing that I was slightly, some amount off of what I should be, it gives you the information to say move the theta to match this, match what I actually observed. So that's, the entire idea.

I can think of some potential problems with it. But, this is it felt like, this is going to happen whether we wanted it to or not, this didn't require any speculation on my part, this is just what grid cells would do. And, it was, that's why I said I stumbled upon it, because I wasn't trying to solve this particular problem.

Again, I don't think we have to do it this way necessarily, I just, it's just the idea is that you sweep through a series of locations along your line of movement, and you see which one matches better, and when you find the one that matches better, then you have the, then you have the knowledge on how to scale. How to scale the system.

Does it matter how fast you're moving? the faster you move, the, greater the, if on the left, the greater the frequency of the red oscillation.

it does, because if I was a cell, imagine I'm a cell, I'm just going in and out of phase, and every time I'm going in and out of phase here, not phase, I'm going in, I'm either, my red oscillation is matching the blue one or not. And every time it matches the blue one, I fire. And if my red one is going faster, then my inter I will do this, I will cycle through these on and off patterns faster. It's if I'm moving faster, then I will go through my locations faster. So it does matter how fast you're moving. And that's, that has been shown to be the case too, that this, the red oscillation is velocity dependent.

So the, the LFP theta. Isn't that, is that global across, any set of grid cells, or is it, is the adjustments to theta, which you're proposing as a accommodation mechanism, is, can you have more than one theta going on in the brain? Yeah, more than one theta in the brain for certain. I don't know how global it is. Clearly, what's going on in your visual system is different than what's going on in your tactile system, or maybe not. but, my understanding is that it's global to some region, but not the whole brain. That's my understanding about it. But, we could look that up. I, haven't read about that in a long time, so I'm not certain, but that's, what I distilled.

the other question I had when you mentioned cell 1, cell 2, cell 3, If I were to superimpose the Friday diagrams of cell 1, cell 2, cell 3 on top of each other, what would that look like? Are they just displaced just a little bit, or how does, how do those, quote unquote, receptive fields look? In fact, in that diagram, you can look at, there's a little, there's a little highlighted area in the middle, right? I didn't make this diagram. I stole it from someplace. that's basically saying, at some point in movement, so this one second, that means the animal is moving, right? The animal is moving and this is what happened over the second of movement. At that point in, in, the animal is at some location, and you see there's a, first you get a red cell, then you get a green cell, then you get a blue cell. This is the idea that you're cycling through three locations. Very quickly, as the animal moves, and they're, and those separate, they're, those are, they're, basically, they're happening very quickly, of course, you're just separated by some distance in the phase of the theta oscillation. so those are like overlapping eggs, if you will, right? Of course, when we looked at the egg diagram, that's just one cell. There's cells representing every other point on that blue background, so there's all these overlapping eggs. In some sense, lots of them. there's no point in that space that's not represented by grid cells, and they're overlapping quite a bit, actually. Okay, so what I'm seeing is that by, tapping multiple of these cells and assuming they're in some kind of communication with each other, you potentially have a Vernier mechanism that refines the, Phase accuracy, again, the more cells you can harness for that, the phase differences, I think, become more accurate.

maybe I didn't follow that. you know how I got Is that, necessary?

it, is it necessary? I think in, the sense of, right now the, bound of accuracy is on, how, how finely these, cells respective fields are placed. But if you allow them to If some sense interfere with each other, you can probably get a finer resolution out of that. I think something like that occurs separately from this in the retina, where you actually get a finer level of detail that the actual sample frequency would suspect from where the, the retinal receptors are, so I'm just, proposing it as a mechanism that there actually might be a finer level of control if it was necessary by harnessing multiple of these things. Yeah, that's possible. I, don't know. I think I'm just looking at it pretty simplistically. I'm looking, imagine that I'm looking at the red, green, and the blue cells firing succession in that highlighted area. What we're basically, we're just basically what the thing is. That's, I don't know if I need more resolution than that. But basically what's being sent to the upper layer cells, so the feature layer in the upper diagram, it's saying, okay, does this location match your feature, here's a location, is that, matching what feature we're having? And then, here's another location, does that match what feature we're having? Here's another location, does that match feature we're having? And, I don't know if I need finer granularity than that, but maybe it would be helpful. I don't know. I didn't, I wasn't relying on that. I just said, yeah, it should work like this. I'm thinking in the case where if you want to harness this thing for something like curvature or something, and you want to be able to detect multiple curvatures, in parallel, each little group of cell could Why would you want to detect multiple curvatures? I don't, what do you mean by detect multiple curvatures in parallel? I don't know what that means.

Also, I think curvature would be done in a different way. You wouldn't use detailed locations to detect curvature. You'd just get the curvature directly from the skin. you detect curvature in the feature layer. I, I was, so I'm assigning the curvature to the, location, right? Yeah, we're. Okay. Oh, I see. Kevin, you're saying if you wanted to get a final resolution of curvature Now I wasn't even thinking about that at all here. I'm just assuming that you've, got a, you've got a, a representation curvature in the upper layer and, and it says, I know what location I'm supposed to be at. And, yeah, okay. You can imagine how this thing would get synced up pretty easily. Essentially, imagine if I, if the red cell, matched the feature, then I'd say, oh, now, if I just try to synchronize the theta with that new peak, if I just say, okay, let's move the peak of the theta cycle, the LPF, LFP one, To that, to the, where the red cell actually fired, that might be sufficient to set the new theta. Basically, every, moment you can say, I should just try to sync up the theta onto the, when I have a match, I should try to sync the theta up to that point. I just, this is an additional point, I'm not reacting to what you said, Kevin. so I think that's very simple. That's fine. That's fine. I'm just trying to extrapolate on the two, say how, if, Subutai basically saying that you think says that you think curvature is actually something else. I'm trying to think of the, notion of scale, invariance as applied to the problem of curvature. Oh, I see. I wasn't doing that. This is just scale and balance in terms of the reference frame made out of grid cells. if I can get it to scale, I have, the challenge that we were facing is I have a model I learned at some scale. And now I'm observing an object that's at a different scale. And the model doesn't fit anymore, right? The, if I move a certain amount, I'm not going to see the right feature. And therefore, I won't recognize it. And all this says, within a certain amount of variation, this system would be able to quickly detect, yeah, it's right, but it's just off a bit, and now let's adjust it so it's correct. so one question I have, yeah, one question I have, so in order for this to work, cell one, I think, cell one, cell two, and cell three all have to be representing the same location in the object's reference frame, right? It's just slightly, it's at a slightly different scale, right? no, that's not right, they're at slightly different spacing. Cell one, cell two, and cell three are overlapping eggs.

they're basically saying, it's, they're not at different scales, they're not at different scales, they're just they're just different locations. Yeah, okay, so they're different locations in the objects reference frame.

So if you're looking for a feature and the object is smaller or larger, not quite sure how this would actually work, would this actually work. So what we're trying to do, recognition in our models is basically finding Or doing a correct prediction or being synced on a model is basically matching a location and feature at the right locations. And all this is saying is, as you're moving, what would naturally happen is you're in some sense, trying expanded and contracted spaces ten times a second. You say, does any, expanding space, contracting space, expanding space, contracting space, does any of this stuff match? You're not actually expanding and contracting space, you're just essentially, you're trying different locations along the line of movement. No, I get that. In our model, the feature is associated with a particular location in the object's reference frame, and we don't know what the scaling is between the sensor movement and the change in the object's reference frame, right? we do know, we know based on the path integration methods, if the scale didn't change, then it's all set, right? Yeah, but we're trying to determine what the scale, we don't know what the scale is there. Okay. And so the, change that if you move, what, one inch, if you move your finger one inch, the actual change in the object's reference frame could vary depending on the actual scale of the object.

And but in our model, it's the object, object centered, object centric location is associated with features. So there's going to be, so cell, the location represented by cell one would be associated with that feature. Cell two and cell three would not have an association with that feature, because they're different points in the object reference frame. So we're going to find out which are these, which of these series of locations, matches up with the feature. But none of them can. Only, cell one can, regardless of the scale. No, Because cell 2 and cell 3 represent different points in the object reference frame, they're never going to match the feature.

You see what I mean? Because the feature is at a specific location in the object reference frame. but, so what we're basically saying, we don't know our location. We're not certain. What the cycling up through these locations is, we're not really certain where we are. So let's see who matches up. Only one will match up a particular feature. That's what you're saying, I agree. Only one of those cells will match up a particular feature, the other one will match up a different feature, and another one will match up a different feature.

But you didn't see how it would work, so I'm confused by that.

Yeah, I'm trying to think through step by step. So let's say the red cell is associated with the tip of my pen.

but the pen happens to be larger, longer or something. And it's expecting, as I move my finger, it's expecting the tip, it's not going to get the tip.

let's say, that, can we say that instead of the red cell, let's say the green cell is the tip of your finger. Okay, yeah, the green cell is the tip. So if we were on spot on, meaning the model and the thing I'm inferring now are the same scale, then when the green cell gets to its tip. when it's at the, at its center of its egg, it's going to match up to that feature.

now, if, let's say, the pen is longer now, or shorter, what'll happen is, the green cell won't be the one in the middle here anymore. It'll be like, it'll be one of the shifted to the left or shifted to the right, because I'm not at the tip. I'm either before the tip or I'm after the tip. And. And so the green cell would match the tip, but it wouldn't be on, it wouldn't be the center cell now, it would be, it'd be like the red cell or the blue cell. It would be saying, yeah, I got the tip, but I'm offset from where the, there's, a phase shift here, Okay, so we need some mechanism to determine what that offset is to adjust the scale. no, it happens automatically. I, do you, are you following me on that? Yeah, I follow, yeah, I follow that though. at this point, imagine, you were the red cell, and, you, maybe that, at this point, you matched your feature, but it was, but you were offset on the psych, on the, phase. we now know that a shift is required, like a scaling is required. We know that, because, The red was not at the peak. The red was on the edge of its egg. Yeah, but what's the mechanism for that? I don't know, but I, suggested one a moment ago.

you've got the LFP, which is, the black line at the bottom. And now you have, we're actually trying to match up the trough of the LFP, not the peak. The trough is the one here, because there's a few polars in there. and so ideally.

your cell would have been matching up with the trough of the, of the LFP. But now you're not matching up with the trough. on the left here, if you're the red cell, you're matching up more towards the, closer to the opposite, the peak. and now imagine if I said, okay, at this point, what we're going to do is we're just going to force the theta cycle The theta rhythm to bring its trough in line with the cell firing. So I'm gonna, I'm just gonna force the theta cycle to I don't know how I would do this, but it's not, it seems pretty simple idea that you say, okay, you, we should have been lined up, so you line up with me right now. I'm gonna reset your cycle to your frequency to match up with me. And so it's just the fact that the two peaks aren't aligned. The cell is Yeah, no, I get that. I was just wondering what the actual I don't know. I don't know what the actual mechanism is. But it would be the arrow from the feature layer down to the location layer that there would be information there somehow that Yeah, one can imagine one can imagine that maybe, yeah, obviously, it's just speculating. the information is there, right? The information is there very locally. The information is there sufficiently to say, you know what, just line these two things up, try to get them to be in sync. how that happens? I don't know. I think in, this case, in the, interal cortex, I think the theta rhythm is established between the, is it between the reticular formation and the cor? no, I know in the cortex. I don't know what, I don't know enough about it.

I suppose we could look into it, from an engineering point of view, it's not that hard to imagine how to do this, From a bio biochemistry and biophysical point of view, it might be trickier. Jim, Jeff, I have a couple basic questions here. I don't know if I'm the only one who's about two x behind you, but I'm just struggling to keep up here. Can I ask some, I warn I warned you, I said, the biology in this area is really complicated,, I have no problem working through it over a long time, but I, yeah. I'm behind right now, so cell 1, cell 2, cell 3. First question, are these responsive to slight, they're responsive to slightly different locations, but similar locations. they're overlapping eggs, yes. Okay, so these are overlapping eggs. My next question is, do they, so they share this common LFP input. That's a shared input across all cells. Yeah, that's right. Okay, and we're going to just assume for now that those synaptic inputs from that LFP, that's from some other population of neurons. That's not other neighboring grid cells. Is that right? That's right.

Okay. No, the LFP could be in that same population, it's just a global movement. Of all the viruses. Is LFP a traveling wave? Or is it static across all of them? I don't think LFP is coming from grid cells. I don't think people think LFP is coming from grid cells. LFP is whatever they measure, wherever they put the probe to measure. all right. The theta frequency is generally believed to be generated someplace else. we could go look it up. I think there's a theta frequency in the cortex, and I believe it's being generated between thalamus and cortex. That is somehow the interaction with the Yeah, that could be the source of it, but aren't they actually measuring all of the cells in that same region?

they are. Yeah, so all of those cells are going up and down based as a global When they do this, the problem is they're measuring the voltage outside of a cell. Okay. That's why it's local field potential, it's not inside of a cell, and so it is accumulation of a lot of stuff. it's hard. you can't really put your finger on exactly where it's coming from. and so I didn't even try to think about that. yeah, that was gonna be another question is are these LFP inputs to a cell? Does it really look like this? Or is, really a cell should be receiving spikes? So what is the signal? Do we know what the signal to a single one of these cells looks like? so there's a couple of theories about this. If you go look on the left side, where I showed just the red and the green arrow, the green sine waves. Okay.

You know how I'm calling red and blue sine waves? Red and blue, I'm sorry, red and blue, yeah.

there's a couple of theories, there's two theories about where the red cycle's coming from. One is, that, actual individual dendrites, have their own oscillation, and and that they're oscillating, that's the red oscillation, and that there's synapses coming from other cells someplace that are providing the theta oscillation, and that's closer to the soma of the cell body. So you have the blue thing driving the cell body, and you have the red thing coming from a dendrite. That's one theory. And the dendrite itself has its own oscillation, and it's interfering with the, the synapses that are coming from someplace else, which represent the LFP, in this case, but you can think of it as synapses near the soma. So you've got two synaptic inputs, one coming from a, two depolarizations, one coming from a dendrite, and one coming from synapses from someplace else. That's one theory. You follow that one, Ben? Roughly, yes. Yeah, it's confusing. I don't like that one. is it, the other, question is, are just the LFB inputs enough to make the cells fire alone or not? It looks like on the diagram on the left, if it's not synchronized, it's not enough. So every cell has to detect a pattern of inputs coming in to fire, it's not just the global. Otherwise, every grid cell would be firing it all the time. Okay, so we have a subthreshold oscillation going on. Yes. Okay. Yeah. And and one hypothesis is that inputs to the dendrites are responsible for the red oscillation. That's one hypothesis. I don't like that one, but that's, the one I read a paper this morning. They were still proposing that one. That has some real problems to it. Another possibility is there's a set of cells. That are filing, firing, like the red guys, at different phases, and those other cells are providing synapses. In that case, there'd be two sets of synapses on a cell, one coming from a population of cells that represent the red oscillation, and one set of population of reds, the blue oscillation. And they're just synaptic inputs to the cell.

So, I have a question. so the L, the LFP, could either be static in the sense that everyone's getting the same signal, synchronously, or it could be a traveling wave where it moves across. The grid cell, region. there's different models. Huh? It's neither. Neither? No.

How can it be neither? It's just the global average of firing in the cells. In that area, it's not that every cell is getting this exact input, every cell is detecting some other pattern.

This is the global average of the cells firing up, going up and down.

But any individual cell is not getting this signal. I thought, all the grid cells would be getting the blue signal.

Yeah, the blue signal. Yeah, that's what I was saying. That's what I was talking about the LFP, the blue signal.

if you It's not a single signal, it's just a global average of a bunch of cells firing. I don't think if it's a global average and they're phase indiscriminate amongst themselves, then you don't have a mechanism at all. No, they're not phase indiscriminate. They are, in phase. It's just that some, smaller number of cells will fire in the middle and a larger number will fire in the peak.

But it's not like there's a single, a signal coming in that's up and down like that. It's a pattern of cells. It's an SDR of cells. but I think, isn't it true, isn't it true that the LFP is experienced by all the cells in this area?

I think all of the cells in the area, I think all you can say is that the mean Of all of the cells in that area exhibit that cycle. Yeah, but the assumption That's not the same as every single cell getting it. the assumption is that all the grid cells in a grid cell module would be experiencing the same LFP.

I think they're exhibiting the same LFP. Maybe it doesn't make sense to think of all the cells sampling from that LFP. two neurons They're going to have slightly different versions of that blue curve and maybe like distorted versions of it, but maybe on average they're similar. Trying to get the right cartoon image for myself. here's the thing. My understanding of all the grid cell theories assumes that all the cells, all the grid cells in a particular grid cell module are, if you measured outside of them, they would all have the same blue curve. oscillation. It's just a, remember, it's an oscillation in voltage. In fact, if you think about it, a cell fires when it's, a, differential between the inside voltage and the outside voltage, which matters. It's not the absolute voltage, it's the differential. And so just, even just the fact that you have some sort of potential voltage that's oscillating outside, you don't even need to have synapses, it's just, the cells are more likely to fire At the trough of that, or the peak of whatever, I don't have to think about it. Look, I bet you this, maybe Subutai, more about this. I don't know a lot about this LFP, but, it seems, I'm not sure these are essential issues. I think the important thing is, I, maybe we disagree about this. It seems that the, all the grid cells in a module have to be experiencing the same blue oscillation. Yeah, I don't think it's essential. I don't think it's essential at all. All we care about is that the cells are in the space relative to this. the theories I've read about, which make sense to me, which I've absorbed immediately, say, oh yeah, that's got to be right. is that you could speed up and slow down everybody simultaneously by just adjusting this LFP, this global LFP. Yeah, you could scale the entire one. That means everybody has to be experiencing the same LFP. no. how not? Because it's just an ensemble of cells that are sending input into that region. Their firing rates would have to speed up or slow down, but it's not like there's a single scalar value that everyone's receiving. That has the LFP. You see what I mean? Oh, okay. Okay. I think I see what you mean. Is that, a difference that makes a difference,? No. No, I don't think, I think it's purely an implementation detail. I don't think it makes any difference. Okay. What're, I'm just trying to react to what Kevin was saying. Alright. I see. I, okay, I don't think it's really important for today, right? No, it's not. No. Today the idea is really simple idea is that. We don't know the right scale, so as we're moving along and we're predicting the next location, we'll sweep through a series of locations in that direction and see if any of them match. And if one of them matches early or late, then we say that's good enough, and we'll just adjust our scale and keep going. So there's a lot of ways we could do this in software. Yeah. And I certainly wouldn't do this the way they do it in, neurons. This is really good. No, it's software way. Yeah. I, was just thinking this way, right? For example, thinking about a temporal memory of a bunch of locations, can you see the dots, which are, let's say these are possible locations where I could be at this moment, and let's say I, I know the direction, let's say I go this way. Then essentially I, for each of those dots, I, sorry, I just don't see my mouse, so I would have a whole sequence. Of possible values where it could be depending on scale. Yeah. And I see which one matches, my model and one of them will match. Yeah. It, if it's a, if it's the scale version of a model I'm tracking, then one of them will match.

and then, by the way, what if I imagine I had a, an object which had two features that were really close together. And another object that the same two features are further apart. I might get confused, but you have to continue inferring, right? As you're going along, just because you found one feature that's off by a scale, then you're going to keep trying and then you might find the next feature's all right. You can't guarantee that when you find a single feature matching this way that you've, discovered the scale of the object, because it could be another object that just has the same features closer together or further apart. So it's, but I think in the end it would all work out. Yeah. Yeah. I think the tricky thing is that there's a lot of possibilities because I could essentially from any of those start points, I need to check all those possible. Places where the next feature essentially could be. Yeah, but clearly the brain is doing this, right? It has to do it on a 10 hertz cycle. So it's got plenty of time to cycle through a series of locations. The reason I was asking a question was that I was trying to, hypothesize that there's a self timing operation where the thing, where the theta cycle originates from the interactions of cells themselves. And another way of doing it is as a traveling wave, you can imagine there's a traveling wave across the grid cells in the direction of motion. A lot of things become possible. I, don't think it's going to be, I think it's unlikely to be the traveling wave, Kevin. but has anyone measured it and said, that? There are, traveling waves in the brain, but again, thinking about it this way, in the cortex, it's believed that the theta cycle originates in the thalamus, and then the thalamus broadcasts broadly to all different areas of cortex, right? there wouldn't be, that, that's not conducive to doing a traveling wave. That's more like a broadcast signal.

And, I wouldn't make sense propagation delay on doing that. Yeah, but imagine the thalamus is centrally located, and the distance between the thalamus and all areas of B1, for example, is that distance, it, think of it more like uniform as opposed to, it just, if I'm broad, if I'm broadcasting from some central place, I can't really have a traveling wave at the place I'm, broadcasting to. a traveling wave requires Okay, if the radius is all the same, then I agree with you. But even if it's not the radius is all the same, then I agree with you. It might not even reach the same areas, but it wouldn't A traveling wave essentially requires, the wave in a stadium, right? It requires people to wait till the guy before them happens, right? In this case, a traveling wave would say, I'm going to go when my neighbor goes, and then someone says, I'm going to go when you go. But in this case, it wouldn't be that way. It might look like a traveling wave, but it wouldn't be a traveling wave. Okay. because it's being broadcast from someplace else, then it might be just arriving at different time frames. so that's why I said it wouldn't be a traveling wave. It doesn't mean it exactly has to happen everywhere at the same point, but it's not a propagating wave reliant on other people, other norms nearby.

Okay. So I don't, the AR argument is there is from the geometry of the brain, you're saying that it couldn't be a travel or it doesn't need to be a traveling wave because, it's more like propagation delay. It's gonna be the same geometry or more if if the theta cycle is really being generated, let's say in, in the interaction between, the, non reticular formation in the, thalamus and the cortex, that's a sort of a single generator, if you will. And therefore it's if you have a single generator, then it's not a travel knife. Okay. Travel knife says you start at someplace and it sweeps across. There's a lot of those in the brain, but, at least in the, in the retina, those traveling ones.

I don't think you need that here. I think the simplest explanation, you just say, okay, just, assume we have, a theta, and, or we have this, we have a scale that we're shooting for, and we'll try different, we'll sweep through different scales as we go along. If you follow this, it also made me wonder if we could solve some of the other problems, like the problem of orientation. I could sweep through different orientations. Now you guys have an alternate solution. Yeah, yes, it's yeah, it's similar, but yeah, instead of sweeping, yeah, I think it's effectively might be very similar. So sweeping through different orientations is effectively, you try different cortical columns at each of their orientation and this way you narrow it down, you down select and then at some point just Do we have, time? So we can go through that tomorrow. We can do that tomorrow, yeah. Okay. That would be, it would take, we didn't have this detailed mechanism, in fact, I don't think we have a biophysical mechanism yet. I was just curious what the general idea was. Can you, in the next 10 minutes, can you give me a general idea of what you're thinking? Yeah, sure. it might help. I only have 10 minutes. I only have 10 minutes. Yeah, 10 minutes. Okay. I think that's fine. so let me share. I mean, I'm sure it'll take more than 10 minutes. I'm just, maybe you can just give me like something to think about. Yeah, I can give you an overview in 10 minutes. That's fine. All right.

Yeah, so that's essentially the issue. Let's say I have the cup, and I move along a cup with a displacement red arrow, and I don't know what is the orientation of the cup.

a movement, a displacement that I observe near the red arrow could be in the coordinates frame of the cup, near those directions. Yeah, I got it. And how could this be resolved? And here, thinking about the temporal memory, like in the columns plus paper, so we have associations between the sensory layer and the location layer, and we narrow, in each step we narrow down the union of possible locations and the union of possible sensations. Now, the difference between the columns plus papers, we have now a whole set of those modules or cortical columns, and each represents a certain module, It has its own orientation of the curve. So when I now do a displacement Are those multiple grid cell modules? Is that four grid cell modules there? Yeah, each would have its own grid cell. And yeah, let's say this, if this is grid cells, this could be other location code. But if this is a grid cell, it could be the same as the columns plus paper. You have multiple So I'm just saying there's multiple, those four blocks are like four, four separate, path integration modules. Yeah. Okay. Thank you. Yeah, so that would be exactly the same. The only difference is the way it's stacked, from the, from, the top to bottom. So you have three of those, and then each would represent a certain orientation, and with the orientation, essentially, its own transformation of the displacement to a certain direction on that place code. So if it's in that orientation, the director, it would go like this, and if it's that orientation, it would go like that, and so on. So we have basically, Multiple guesses on what the orientation is. Yeah, we have multiple guesses. Multiple guesses. Each, it starts with a guess, and, then essentially, as a group, they narrow down the possibilities, because then, let's say, initially, it might be at all those red locations, then you check, this guy would check, oh, it's the feature at those locations here, where the error is 0. 2. So if I have a, if I have a set of guesses, some are going to be more, more correct than others. And then the correct ones inform the other guys. Yeah, first of all, don't start wrong. Let's say all this, let's say this, let's say the feature I observed wasn't over there and wasn't on this side. So no, this wasn't possible anymore than this would be the only column surviving with activity.

So, the activity would like down select, and you would end up. Just at the end with one of them, and then the other columns that could possibly be reused with a new guess of a location. Oh, so couldn't they inform each other? Yeah, they could inform each other. yeah, no, they would. Once one of them matches, you somehow broadcast it, and they would all then go into the same. if you think about grid cells, They look at multiple grid cell modules in like the enthorhinal cortex. they anchor independently, meaning like any, I go into a new environment, they'll anchor which cells are active and it looks like it's random in some sense. But once you've learned an object, they're always the same. That is, they all anchor together. which would imply that there's a learning there, like they, socially link to each other somehow saying, yeah, okay, my point is that they're not always linked, but when in a learned environment they are linked. So you could just imagine that when one guy says, I'm, working, I'm, it's working for me. My, my orientation is pretty good. Then that could inform the other people right away. They could say, okay, if that's the case, then I know what I should be. Something like that. It wouldn't happen. It would not go in. Yeah. That's good. And then in this way. If you need to refine your location, because you don't want to spend like thousands of columns just to get an accurate direction, you could just have a small number, let's say eight. And then once one guy says, oh, it's in that direction and the other guys can use the same information and on its own have a slightly more refined guess. And in this way you improve the accuracy as you go, while not requiring a lot of columns devoted to figuring out what is the object in orientation. So it sounds like I think what you're saying though, what you're this may be a language issue, but you may be saying something different than what we discussed the other day and said use multiple modules, one for each orientation desk. I don't think we discussed that. I think each row here would be a different orientation desk, right? Yeah, each row would be a different orientation. Yeah, but each row contains multiple modules. Oh, You see what I mean? That's a lot of grid cell modules there.

why do you have, why does it have to be that way, Subutai? Why couldn't each block in a row have its own orientation? or, because I was assuming those are each a grid cell module.

They are, yeah, each one of this is, each of them are their own grid cell module. But I think what we are thinking is this row would have an orientation desk, this row would have another orientation desk, this row would have a third orientation desk. Yeah, that's right. Each layer would have, so we would use multiple columns, not multiple modules. Yeah, I meant modules in our sense of the Monty system. Yeah, that's why I mean there's a language issue here. Modules is a ambiguous term here, so what Jeff was asking is that are each of these modules, and they are, they're each square is a grid cell module. Yeah. You assume that they were in the same, you assume that those four were in the same cortical column, Yes, just like our column plus. Yeah, what if, that wasn't true? This is something that's really puzzling me forever and ever, is okay, the best solution we've ever come up with is having multiple grid cell modules, but it doesn't look like, there's enough to have multiple ones inside a single cortical column. And could there be one grid cell module in each cortical column and still they'd be doing this voting across columns? Yeah, I there's a question, okay, how do you accurately represent location within a column? Do you use single modules or multiple modules? But this, regardless of how you do that, this proposal is, you have multiple guesses going on simultaneously. But they could be multiple, they could be multiple columns, right? Yeah, we have to figure out the exact biophysical interpretation. Are they multiple columns or could it, ideally it would, Somehow we could do it all within one cortical column itself. But, there's a lot of, there's a lot of, and, it could be related to that. of course, it has to work with, okay, I'll just leave it at that. So let's go through this in more detail tomorrow. I think there's, I think you missed a step here on the hypo that might help. of how the movement is translated into these shifts. yeah, that's the same as in the column specimen. So you would learn Yeah, but it wasn't, we didn't state it explicitly. So Jeff, I think for Jeff and others it might be helpful. Okay, that would be helpful. And that's good because I probably have to run here. okay, good. All right, it gives you something to think about. Thanks for doing that. Yeah.