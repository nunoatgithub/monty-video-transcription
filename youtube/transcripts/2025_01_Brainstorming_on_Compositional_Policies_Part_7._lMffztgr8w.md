were you in charge of, I was prepared to talk a bit about behaviors. wasn't there someone else who wanted to say something? Did someone else know? No, we didn't have anything else planned. Yeah. Yeah. so this is, again in the continuing series of get our heads together and bang them against the wall for a while and see if we can figure out what's going on. That's how the research seems to go on this business.

last week, we were, we also talked about behaviors and the way Niels was presenting it was, it's a very different way I think about it. And, and that bothers me because I, I think we all need to be thinking about these things the same way.

I wanted to go back and just go through again how I'm thinking about the problem. and starting with some basic assumptions, And just working through it and making sure we're all on the same page, at least we all understand what we're trying to argue, before we can, say it's right or wrong or anything like that. So I think there's, I still think there's probably a lot of confusion and, lack of understanding of some of the concepts here because they're quite difficult. It takes time, so I feel it's good to go back and review this stuff. Here's Vivian. so unlike, everyone else here who's really good at putting together presentations and making them look really spiffy, I only wrote up some text, not because I'm refusing to write up presentations. It's just I've been extremely busy these few weeks. I have a lot of things going on in my family and, health issues and so on with my kids and so on. I just don't have all the time I want to have. so I just, I'm going to walk through, I have one very simple slide, but mostly just text and I'll walk through it. We just discuss them. I guess I'll, I will share my screen and you're going to look at my word file and that's, I'm, finished apologizing for that. Let's see here. Okay, I'm going to share this one. So hopefully you can all see that.

Yep. Yes. All right. I started off with background assumptions. These are just remind us all some of the things that we've, we assume that I'm viewing this completely from the neuroscience point of view. This is not a Monty presentation. So we have to bear that in mind. I don't think about Monty as much as I think about neuroscience. So that's, my area. Okay. And, and so I started off some background sums, I want to go through them, I, we all should know these already, but if, in case you don't, just speak up, I'll go through them quickly, and and then we'll jump into the object behaviors, which starts at the bottom of the screen here. it's really, I think about all these problems under these sort of images of these columns and the layers and the cells and the neurons and synapses, and so I'm not sure everyone does, I'm pretty sure most people don't, some people might, but it's worth going through it again. so the basic idea is that problems learn models of things in the world. You can see my cursor here, I assume, right?

models, and we associate, basically observed features with locations in space. And when, and we do that through moving. that's how we build up models. Models, part of the models are we have to learn the orientation of the feature independently of the object ID, which is something we didn't know in the beginning, but we, do now. we think the orientation encoded via many columns sets and hypothesis seems to be fit V1 and a few other places, but it's not necessarily 100 percent certain. I've come to believe that all models are compositional, at least that's the way I want to think about them. All models are composed of other child objects, I really want to banish the word feature, or at least understand the feature is more than we typically think of it as. if the feature or the child object comes from a sensor patch, then the child object is very limited. So the way I think about even a column in V1 is basically learning compositional models, but the inputs to it are coming from the sensor, and the sensor Patch has, can only recognize a certain number of things. So there's a limited number of child objects there. And that's just the way I like to think about it. Even B1 is a compositional object. It's an object composed of other things. and of course, if the feature in the child object comes from another column, then it represents a more structured object like the other columns can learn. So the logo on the coffee cup, any individual column, although it's learning, although it's learning a compositional object, It doesn't really know what the inputs represent. It doesn't, a column doesn't know if its input's coming from one place or another, what it means. And so it's just saying, associating some SDR with, the location. But through the back projections, a column can basically say, at my location, it tells a child, you should be observing this. And, these are just learned associations. The parent object doesn't know what. It's, just sending back, we, both, observing the same, these things at this time. of course, locations are defined within a reference frame. we often use the word reference frame to have metric properties. This came up last week when we talked, about the changes in, reference frames. To me, I'm not sure what the technical definition of metric is, but for me metric means that the spacing between the locations is the same in all directions, it's consistent, or I should say the same starting at any point, and, this, of course, this gives us these really nice properties. You can path integrate from any location in any direction and end up knowing where you're going to be. It also means you can calculate the distance and direction between any two points. generally, reference types can't morph. or change without losing their metric properties. Although, as Neil pointed out last week, grid cells do this to a little bit. and it's a mystery, but they don't do it a lot, they just do a little bit. And it's been studied as far as I know, no one understands it. It's not like the total thing is lost, it's just like it gets slightly distorted. In certain situations, so we know that in the brain, reference range is created by grid cells, but it's not just grid cells. Bear in mind, when we talk about grid cells, there's a whole series of other cells that have grid like properties. People talk about grid cells because they're the simplest ones to understand, but there are, actually lots of them that, and people are confused by that, other types of cells. so there's a lot of things not understood about how they work, one being, we've talked about this quite a bit, they appear to be two dimensional, and I have all this evidence why grid cells are two dimensional, but we, would like them to be three dimensional.

okay. And then the same idea, grid cells on themselves, do not represent any unique locations. Grid cells repeat over and over again. That would be true for any neuron, unless you have grandmother cells. So you, it takes multiple grid cell modules. or grid related cells, they don't have to be grid cells themselves, to create unique, SDRs that are unique to the object and the location object. and then it's, well understood that when, an animal recognizes a new environment, the grid cells re anchor, meaning which cell within a grid cell module is active. And if you have enough of these, then you essentially define a new set of locations for the new object. So it's always important to think when we talk about locations in the brain. It's unique to the object, it's not, and yet they still have these nice properties of path integration. Can I ask a question real quick? Yeah. the re anchoring, from what I recall, there's like a, the idea is that it's random, there's like a random initialization for the re anchoring? it's, no, we don't know, it appears to be random from a neuroscience observation point of view. there may be some underlying mechanisms that no one knows about, but, there's no random number generated in the brain, but, so the assumption is that you can treat it as random, which, cell becomes active. do you recall off the top of your head, whether, if I put a rat in environment A, it's got its anchoring, then environment B, new anchoring, then back to environment A, do you recall if the, the familiarity of the environment helps re anchor in the same way? Yeah, obviously, yes, of course. obviously once the animal sees enough of the new environment to know where it is, then the cell is re anchored. It has no other way of knowing Other than through some sort of observations, it could be smell, it could be tactile touch to the whiskers of a rat, it could be things they see, any, set of clues that, that now lets the animal say, oh, I know where I am, that's when the grid cells re anchor. I was just wondering if it would re anchor in the same way. repeated, Absolutely, That's the whole, that's the whole idea. And it's one I'm relying on, we're relying on, essentially that, when you come back to the same environment, in our case, come back to the same object, that the, the grid cells would re anchor exactly the same way, and therefore you're, back in the space. Once you're in, once you're in a particular object space, then all the predictions can make sense. then you know what to expect at every location. so it has to re anchor to the same set of anchoring points for anything in the work. and that's what's observed, if I understood your question correctly. Yeah, that's good. It just, I was just thinking about the random initialization thing and how that would be a problematic, issue. I, I, it, why would it be problematic? if we are, say, doing object recognition, like we extend this out to, the world of object recognition, we think, we definitely would like to be able to return to the same overall space. When we see, when we recognize an object for the second time, however, I guess in the very first use of CODS of, encountering an object for the second or third time, we haven't fully recognized the entire object. if, you haven't recognized it, if you're not certain where you are, then, they haven't re anchored.

I think there's a lot of evidence for rats in environments on this, and my recollection is, when a rat's in an unknown environment, if someone else knows this, correct me, I think it's not random, I think it's, there's like a, I don't know, I had this impression there might be some, background, unknown environment in space, but, yeah, I can't remember what the result is, I just remember there was a, Study I think from the Moser group where they put rats in dark rooms where they couldn't see things so it's like the animals Yeah, I need to remind myself, questions. Do they always anchor the same way? Or was it random? I think it always anchored the same way and, also I think it was also some other interesting little tidbits, which are maybe very misleading. It's like the spacing between the grid cell fine, which was larger, slightly larger. And then when they animal recognize the environment, they tightened up. So it was, like the space becomes looser when they don't know where they are.

Maybe that helps them infer, I don't know. There's a lot of weird stuff that they don't understand about grid cells. But, this, idea, this is really important. that once you recognize an object, once you know where you are, once you know what you're seeing, it's like the aha moment. Oh, I know what this is. That's the moment the grid cells re anchor. And at that point, then all your predictions come true, if I was in a dark room, I couldn't really see things very well. I didn't know what room I'm in. And someone just dropped me in some room by, any one of these rooms that I know, and it's dark and I'm searching around confused. And the moment I said, Oh, I know what this is. This is the bathroom. Then instantly you can visualize the bathroom and you can know where everything is. it's that crystallization of the grid cell modules re anchoring that then defines every other thing in the environment. And so we're, we're, basically saying the same things happening in the column. And yeah, I guess just to close the loop, maybe on Monty. So like in Monty at the moment, we would start with a hypothesis space where we test like multiple ones in parallel until we know which space we're in. And so I guess the question in like biology is. Is there somehow like a multiplexing or like simultaneously encoding of multiple spaces that could be possible until we converge to the true one? Or as I think you were alluding to Jeff, is there some sort of like background generic space that is used to pass and degrade through multiple hypotheses until again we can. I'm not sure. I'm not sure it's passing into multiple hypotheses.

Yeah, I think we don't really know the answer to that question. it's a legitimate question. Brains clearly can do this. We have proposed one possible mechanism, which is the, the union of SDRs is one way of maintaining multiple hypotheses. That works up to a certain number. and, it may be, sufficient, and that may be how the brains do it. but there might be other ways. I don't know. Okay, is it happening with like before the grid cells re anchor? It's not like there's a denser firing of grid cells, is there? No, I'm not. No, it doesn't seem to be that way, but it could be.

again, there's a huge amount of literature on grid cells, and there's a huge number of things that are unknown about how they work, so I, feel if we want to have a more in depth discussion on this, I would have to spend a week reading papers or something. But we do know they exist. We know these other cells that are grid like exist. We do know that they re anchor. it is our hypothesis that, not only, it wasn't our hypothesis, but other people hypothesized, and we adopted it, that multiple, modules, good cell modules, would lead to unique encoding, of space, and that it's almost necessary, because if you didn't do something like that, then you can't even code any space, and I think at this point we have to say there's a lot of things we just don't understand about the details.

okay. Can I go on?

All right. so this last paragraph here basically says, we've, modeled this successfully so far in Monty about how to learn models of static objects. And of course, what we're trying to do now is understand how to model objects when they're not static, when they change. And we've used multiple examples. We used a stapler a lot. I've used a traffic light a bunch. All kinds of objects exhibit behaviors, your computers, your keyboards, tons of, so many things. And when we say they exhibit behaviors, it's the same object, but things are moving, things are changing on that. And we have to be able to learn a model of how Not just the static components of an object, but how it moves, how it contains, and even the simple thing like the staple has many different behaviors. There's the lifting the lid, there's opening up the internals to get access to the staples, there's the little rotating, deflection plate on the bottom. There might be little catches to open the springs and so on. and we have to learn all this, and these are all part of the same model of a state book.

we're trying to extend our column model to, to learn how objects can change over time. And then the thing was, there's a couple of surprising insights we had along the way. One is that pretty much everything about a model can change. I, you could, I could come up with examples of the features move, where the features change orientation, Where the features change scale, where the ID of a feature at a particular location changes. And these can occur in, in, in singular and combinations. And, so I say all, any or all these types of changes could occur at one or more locations. And so pretty much everything about an object can change. They typically don't all change at once. but there seems to be no limit to the type of changes that object can exhibit. And, this led to the idea that, what is an object if everything can change on it, if all the features in, those locations and orientations can change what defines it? And the answer is, two things. One is, from this I deduce, one of the reasons I deduce the fact that the, anchoring of the grid cells for a particular object will not change, even if the object changes. we could, we can prove that and, what was the other thing I was just going to say? You get, oh, also these changes of course occur sequentially through time. if I saw, an, orange sitting in front of me on the table and I walk out of the room and I come back an hour later and there's an apple there, I would make no assumption that the orange turned into an apple. But how, if I was sitting here looking at the orange right in front of me and while I'm looking at it, it turns into an apple. I would say, holy cow, that orange turned into an apple, magic is happening here. so these things, the proximity in space and proximity in time are important for us to realize that this is the, that this is, the same object. And of course, if I just see a small change to an object, if I'm looking at a traffic light and when the light turns to green, I wouldn't think oh, that's a different object because it's almost all the same. But, it is important to recognize that There can be enough changes to objects that sometimes you wouldn't necessarily know they're the same thing. but you, but it really helps that these changes occur while you're observing it. In fact, it's important. and, and they're close in time. All right. So that's basically the sign of the problem space of object behaviors.

and, so we have to extend our models to include that. So here I, something I already talked about, I propose the anchoring of, whoops.

anchoring of, reference frames, defines the object. and if, if the reference frame is, if it re-anchor, then we perceive it as a different object. therefore object behaviors are, change what's associated with one of our locations on an object. So basically it to learn an object behavior is we have this reference saying with features on it, and now we have to say, oh, under certain conditions, the features are different and different locations, and so on. It's important to remember some object exhibit, no behaviors, some exhibit a few and some exhibit many. I just talked about an object completely changing to something different.

I don't go through that.

these changes, is another thing we used to talk about. like the stapler, what is the state of the staplers? Open and close. But staple has many states and they're independent. And this can be true for a lot of objects. So multiple changes can occur independently. Or, they can be causally related. For example, the staple example, I, I said, typically when you raise and blow over the top, it doesn't change the deflection plate on the bottom. But you could build a staple when you raise the top, the deflection plate rotates. That would be perfectly okay. And I could easily learn that. So it just says that there, an object can have multiple different changes that some are causally connected and some are not.

and so we have to be able to accommodate that. These are all things we have to be able to do. often, the behaviors, consist of a sequence, or time series that changes the object. and so that could be along a trajectory in space, so that would be, for example, the lid of the stapler rising and going down. sometimes they can turn it disjoint locations. That is an optic can change here or there. I was thinking about traffic lights and traffic lights. The lights generally go in the same simple order, red, green, yellow, but there's a, there's an old game called Simon. Some of you may remember as a kid's game. Where it has a bunch of yellow colored buttons and the whole task of this is to remember the secrets which those things light up and it's much harder to do that. but things can change randomly, but it's not generally, we'd like to, it's much easier when we see something moving through space continuously.

and then, And then this was the key insight a while back, is that when we learn objects behaviors, we don't forget the rest of the object's model. So I, don't forget anything about the stapler when I've learned that the lid goes up and down. Excuse me for a second here. Okay.

so this, is the proof to me that the reference frame has to remain anchored, because if you change the reference frames, then all learning is lost. So essentially, we have to, within the same reference frame, we have to have an ability to say at any point in time. under different states, what, features are we expecting to see where?

I got confused on this topic, object states versus current state. I was using the word state for two different things, and, I think it's just, I'll just point out my failure on this, I suppose this could go into our, wall of fail, perhaps. and then we use the word state for two different things. One is the different part, different ways an object can behave. So I could say the staple has multiple states, like I say the deflection plate can be in one of two different positions. Those are different states of the deflection plate. But we also use the word state to refer to its current settings, and, which is not part of the object model. So So the object model has to represent how the top can move and how the deflection plate can move in its different positions at different states, but we can also say oh, what's the state of the staple right now? It's open. that's not part of the model. That's a temporary condition that we might want to remember. so I don't have a good answer to this question, but. I was getting confused sometimes because I was using the word state, and for these two different things, and they're really quite different. Maybe some of you, Yeah, that's a good point. We will probably run into this confusion more in the future as well, because in the Monty implementation, we actually call the message class that we used to send information between learning modules, we call it the state. class. So it's like the hypothesized state, the goal state. and so I guess it would be good to think about, how we can distinguish the two in terminology, maybe having the behavioral state and the current state, or I'm not sure what, yeah, that's, I started trying to, oh, maybe I'll just use the words behaviors of an object. and then I didn't want to redo the whole document. I just, so it's something we have to come to grips with and maybe we can define some better language for it. Yeah, like behavioral state and object state. Even that's confusing. It's even confusing and you might say the behavioral, is the behavioral state the current state of it or the things that the object can do? So I like, I was using the word behaviors. I could say the object has certain behaviors. And, that's not a state, that's okay, these are things it can do, where the word state typically refers to a temporary condition. what is the current state? I, I don't, want, I don't think we have to solve it here, I think it needs to be, if someone wants to come up and propose something, that's fine, or maybe I'll do it later. so sometimes I say here, sometimes I refer to these objects behaviors, which is clearer than the object's states. so object behaviors doesn't have that confusion.

this is all about this. What is this paragraph here is essentially says, we have to be conscious of this because it turns out to do anything interesting. That the system has to almost certainly has to remember the current states of an object. It's current configuration. So if I'm going to do, Neal's often talk about making coffee. the coffee maker has different behavioral behaviors it can have. And as I'm making coffee, I have to remember where it was last. what was it was the lid up or down with the coffee in there out, was it on or off with the plug in? I have to remember these things. Even though I turn away to, I take the coffee maker out and put on the counter and I go get the coffee, I have to come back, I have to remember, did I plug it in? did I turn it on? so there, there needs to be a sort of episodic memory to solve. any kind of, be, interesting task. and we haven't, to this date, really dealt with that. In the brain, it's almost certainly this is done in the hippocampal complex, the episodic memory. It almost certainly wouldn't be done in columns themselves, the individual columns in the cortex. It doesn't mean we couldn't do it in the columns in the cortex. in, in, mantra we can do anything we want, but. I just pointed out that, okay, this is something we haven't really dealt with before. and, we will have to deal with it to solve interesting problems. We'll have to have some way of remembering the state of all the objects that we just recently dealt with. So that, we know what to expect. and we know what has to be done next.

Okay. Does that make sense?

I guess just to clarify, how is that different to us remembering the recent locations and orientations of objects? I feel like that's the same class of, it maybe is. Do we do that?

in a sense, but yeah, I guess in the past we talked about that. We can have learning modules that very quickly build up temporary graphs. That's a bit more like the hippocampus. And we talk about it in terms of states, but just in where things are relative to us. It may be exactly the same thing. I thought about that. I was thinking of going back to the dinner setting type of thing and trying to understand that.

that's like a temporary configuration. maybe that I got really confused by it. So I didn't bring it in because I couldn't make sense of it. but it might be the same thing. I don't know. Maybe you can solve it the same way. I don't know.

I went on. I didn't deal with that any further. So the next big thing here is. And this, was like a really big insight when it occurred, and I've talked about it in the last few weeks, that, that I believe that these different behaviors, behavioral states, if you will, of an object have to be learned on a location by location basis. I don't, it is not some, first of all, it's not some global thing. I can't say whether, what's the state of the stapler? I could say what is the position of the stapler top or what is the position right now of this flection plate? but it's not a, it's not a global thing. And, even then, the way to think about it, the right way to think about it is on a location by location basis. This is still a little bit conjecture, but I think it's, I think it's gonna, it's gonna hold.

And it's very similar to how we had the same breakthrough for doing compositional objects. The only way to think about it, it's not oh, it was wrong to say, where is the logo on the cup? That was the wrong way of phrasing the problem. You, the way to phrase the problem for compositional object is at this location on the cup. What is the child's object orientation and scale at this location and another location the child's object location scale could change, or maybe not change, but, it's on a location by location basis and I think that's what we have to think about behaviors of objects on any location, that location can change. what it was from what it was before. Before I would have said there's some feature at some orientation scale, and now I might say there's nothing there, or I might say there's another scale, or a different orientation, or a different feature, or something else, But on a location by location basis, and that seems required to solve a whole bunch of problems.

So to do this, I, propose that, a column has a layer of cells, that represents the current, it has a layer of cells because that's how neurons represent anything, right? A layer of cells, mostly, not completely, but usually, that represent the state of the current location. So as I move through the points in space, this, this other set of cells, would say, okay, what should be under the current, under, right now, what should you observe at that location, because at one moment you might observe A and another moment you might observe B at the same location. That's the definition of a behavior. And so we need some way of telling the, if this is a column like layer four, we have to have some way of telling, the, the, the neurons to predict something else. At this point, I'm going to switch to my one slide. and, I'm gonna share again. I didn't, I shared just that one thing. I'm gonna share everything here.

and then, this is a PowerPoint slide. Hopefully you can see that.

yep. Okay, this is a very crude idea here. typically we talk about layer four as the input for the feature from, a child object feature. layer six is going to be representing a location. And we, and basically our model today is you, basically, you form a unique representation. of the feature at that location in layer four. the idea is that there'd be a, another input to layer four. And I actually, I just picked layer two just because I needed a placeholder. I actually didn't go back and look at what would be a good candidate. So just, this is considered a pure placeholder. I have no idea if it's where it is. and, but the idea there's another set of cells that are representing state. And so the three of these together, combine to tell you what, so at some location, based on the state, you would predict one feature, but based on a different state, you predict a different feature, or no feature, and so this is the thing that would be gating and changing the different behaviors on a, location by location basis. now the mechanism for all this I don't really understand yet, but it's the basic idea. one thing just if you're not aware of it, oops, let's see here, that's just, that's just repeating what I said earlier. This picture here shows a, a, neuron in a dendrite and, and one of the things we see often in, in, real biological neurons is that when a neuron receives inputs from different sources. Like I might receive input from one layer and it also receives input from another layer, or maybe it receives input from the thalamus or something like that. They tend to be segregated on the dendritic branches. That is, they're not all mixed together, they'll be in some sort of order. the first from one source, the red source, and from the green source, and from the blue source. This has been documented in lots of different places, but I'm not sure it's been documented everywhere. but we do know this kind of thing does exist, and this is one way that this could work. For example, You might say, all right, I need to first, if red input may be coming from a state and that just in the blue inputs coming from the feature and the green inputs come from location. I, each of these have to be combined in a certain way that, that gates this whole. I unwrapped it. It could keep it. You're, unmuted, you're talking about something else.

Michael, I'm sorry, Michael. I'm sorry. Cat dilemmas. Sorry, Will. I assumed it was Will. I was trying to do voice recognition.

anyway, there are mechanisms by which this can occur. So this is not a weird thing, in fact, our, hypothesis and theory about how the thalamus does routing is based on this, and there's, it's the same idea, and there's lots of evidence that it occurs in the thalamus, this, is not a crazy idea. I'm just pointing out that it's like, if you're thinking like, oh, these things, this, input could gate the rest of it, and so you have to have the combination of all three of these things to, to get this, this neuron to be at a predicted state. Okay. Is that somewhat clear? I have a quick question about that. Yeah. Wouldn't it be easier biologically to bind a state with a location? If the sources did mix, so they could lie on the same compartment, dendritic compartment. Say it again. I didn't follow. So I'm just thinking about, let's say we've got a dendritic compartment. It's got 20 synapses or something. And we need a certain threshold in order to get that. Neuron to fire. Yeah. Fine. It would seem if you're trying to bind features, locations, or things from different domains together with a neuron, I'm not fighting with nature here. Nature does what nature does, but one would think that it would be better to intermix your signals into, to, so that they mix and dendritic compartments. maybe, I'm not sure why you think that, but let's just tell you why, that might not work. remember for, for these, for example, let's say if the state was the red section there, right? This cell has to recognize the state. It has to say, oh, I know it's, I recognize the state. That means it might, it has to form 15 synapses or 20 synapses, to the, for the, to the, Neurons in layer 2. if I intermix all these things together, then those 20 synapses may get far apart, and they may no longer be in a particular integration zone. That is, the integration zone is like, what, 40 microns wide? You might get 40 synapses in 40 microns. No more. so if I start spreading them out over a longer distance, then the neuron can't actually can no longer recognize the pattern layer two. it's just not possible because they're, it's, they're just spread out too far. And it needs, they need to be within some limited zone for that pattern to be recognized. So regardless of the, Merits of your idea from a theory point of view, and they might be great. I think from a mechanism point of view, it probably wouldn't work. So I guess in this case, Scott, do you mean if it's like an and relationship, like we want this neuron to be active if the feature and the state are there, right? we're just trying to bind together, say location or something like that. Then we want, it's like depending on both of them. Oh, I see. I see. Oh, I see. I misunderstood the question. I misunderstood the question. The way I drew this, thank you Nils, I think you're thinking like, oh, the neuron would fire if A came, the red ones are active, the neurons fire with the green ones are active, the neurons fire with the blue ones are active, so wouldn't we want to bond together?

yeah, I guess you, that's what it looked like when I drew it like this. that's not what I meant. in some sense, remember that the way this actually works is there is a dendritic action potential that has to travel along the dendrite. In this case, from right to left, and that, that action potential which could easily be blocked if the red pattern wasn't there, these are not, just some independently, they're in, order and the order matters. And so some of these could block the other ones. They're not independent. Is that, am I getting at the question then?

I, guess to your proposal, yeah, it seems true that, yeah, if it's learning the association of both the things, that could be learned in one compartment, I think is, was what you were. Is that what you're saying? Yeah. I was just reflecting on the fact that let's say we do want the neuron to behave like a coincidence detector but a coincidence between a particular location and a particular state, in that case, you would prefer to have a single, dendritic compartments. to receive input from both location and state. maybe, but maybe look at it this way. What, if this, neuron would only become, by the way, we're not even actually spiking. We're actually just depolarizing, but we'll take it back. Let's say it's a spike.

that all three of these patterns have to be recognized that the blue has to recognize the green has to be recognized the red has to be recognized. And if they weren't all recognized, the dynamics of a dendrite are such that it appears that if they're not all activated, maybe even in the correct sequence, then nothing gets to the soma or it doesn't, happen. So there is a, there's a, the dendrite, that black bar is not just a summer. it's a complex. Processing element and the action potential on the dendrite has to the dendritic action potential has to travel along this distance and it can be blocked by along the way, I could go back and review it. This is there were several proposed mechanisms for how this worked by other researchers. And it's part and parcel of our Thomas theory.

that entire dendrite sections can be disabled by a particular pattern.

and, go ahead, Vivien. Just sharing one, neuroscience paper talking about this, that I recently read and thought was really nice. This is in the, in thalamocortical neurons, where it shows how, input from different sources like cortex, brain stem, TRN, synapse on different parts of the, dendrite. And then they have this whole. theory around what kind of mechanisms this could enable. This, segregation, like I've shown with the, red, green, and blue, that's seen lots of places.

That this is, this is not speculative. this is. And then the question is, what are the, actual mechanisms that, that Vivian just mentioned? and, how do they do things? there's a lot of complexity there. Some of it's not known. But I, think for the moment we don't have to worry about that here. this may come in, this may be important in the future, this may be some form of generalization, all the things that are recognized by the red are generalized and all the things are, there's, could be other weird stuff going on here. all I wanted to point out that the idea that a neuron could fire or be depolarized based on the confluence of location and state, and then that those two have to be unique, there are mechanisms that would do this. It's not a crazy idea. in fact, it's, it's not, it's almost like a, almost given, there's examples of it.

I don't think we need to worry about too much more than that. But it was a good observation, Bill. You were right. I just didn't explain it completely. Are you okay with it now? Yeah, I didn't want to derail too much. I was just, was Oh, is that Scott? I'm sorry, Scott. I can't I'm not looking at anybody, so I don't see what you're all saying. Oh. Okay. Sorry, Scott. All good.

Where was I here? again, going back to that other image, basically, as the location changes, sometimes the state will change, and I don't really understand that, when it changes and how it changes, but if I have this, if I have the correct state, I've given a state, given a location, it predicts a particular feature or no feature, and a different state at the same location would predict something else. and this is a mechanism for us to allow the model to have different, predictions at, under different states of the, of the object. One thing I was interested in discussing about that was just, cause it, yeah, I definitely agree it makes sense to have the state be location specific, in, some of the representation or whatever for behavior. But like at the moment for the kind of object IDs or the features are also location specific. And the way we do that is, is it's in the lower level column that we'd have a location, an object ID like in L3. Are you talking about you're talking about the, the child object ID? Yeah. Okay. That's being fed up to L4. I'm just wondering. Yeah. Is there a reason you, feel we wouldn't have something similar for state where it's yes, state is location specific, but. The kind of handling of the location specific component is delegated to the lower level column. so that, I'm not following that. Explain it again to me. so go back to this, to this image. Yeah, so that I guess as well as the feature coming in, which is like the, if this is a higher level learning module, that's going to be the object ID from L3 as well as direct sensory input. But then it might also be getting the state of the low level object. I thought about that. I thought about that. should it be passing in the state?

and, I don't think that works.

for example, I can imagine an object that has a lot of behaviors, and the child objects themselves have no Behaviors.

the child objects are just, they don't have any behaviors. They would have no state to pass in, but, but the parent object would be in different, have different states where they're expecting different child objects in different locations. we can come up with some examples of that. But that tells me that, that, that I need to have a local state in the parent column, because it's not something that can be passed up from the child, because the child doesn't have any states. I guess equally, it feels like you can imagine objects that have behaviors that will when they are a child of a new object, they carry over those behaviors. a button can appear in different contexts. And, whatever it's a child of, a button has button like behaviors, and then the high level learning module that's learning like the compositional object needs to learn what effect the button has. On the other child objects in its representation, but it doesn't need to relearn what like a button is, that's carried over from, that's the responsibility of the lower level learning model. So I think maybe if I understood what you're saying, and it may not have, there's two things we're talking about there. How do I associate changes in state on different objects?

if I push one button on an object, maybe another button elsewhere changes. Yeah. Or it, and it gets worse. I could push a button on an OB one object and, completely different object. That's, that I'm not even attending to right now. Changes, I flip the light switch in a room and, a switch in a room and, a door opens to the next room. that kind. and we have, I'm gonna talk about that because we have to learn those things. but I, think that's a separate question than, than, does a child object have to pass its state to the parent.

also, let me, state this, Niels. I can, I already stated it. It's easy to prove that the column has to have its own state. to tell what its model, how its model should change. I can prove that because the child object may not have any states, but the parent object can have behaviors. So there's nothing to pass from a child object. That doesn't mean that your proposal is wrong. It doesn't mean that, that we aren't passing state from a child to a parent at the same time.

maybe it isn't. I haven't really had a need to do that yet. Maybe I will have a need to, but so far I haven't been, I haven't needed to do that. I need to have the state in the column, that I absolutely have to have. And I haven't needed to pass a state from a child yet. But I'm thinking about it right now. Maybe I will. I don't know. Maybe you can come up with some examples. yeah, no worries. I just thought, yeah, it was interesting to talk about since talking about like location specific state. I do think it's, I do think I can very likely prove that it has to be local, but doesn't mean it's only local. We write passives as well, if layer two is, but I, what I will get to in a moment, I do think states are things that have to be associated with across columns, across hierarchy, across modalities, that a change in state in one column could affect changes in state anywhere else in the cortex, in some sense. Thank you.

and those have to be associatively learned.

I'll get to that in a second. so we'll have to leave it as an open question whether state is actually passed in with feature. Yeah, it seems like if you think, basically the state of the child object is like another feature. So if we have the traffic light. The lower level might be just the light bulb of the green light, and that might be in the on or off state, like the light being on or off. And then that is just a feature that goes in, into the parent traffic light, model. And when the traffic light actually changes its state from, stop to go, the feature of the green bulb changes from on to off. but I also have to associate that with the changes to the red bulb and the yellow bulb, and those child objects are not, necessarily, talking to each other, but I would have all the information I need in the traffic light object. yeah, for me to this way I would attack this problem is it was a very this was a very difficult problem we dealt with compositionality. And it took him one time, for us to figure this out that a parent object doesn't know what its child objects are. It just gets some bit pattern. That's all it knows. It's all it needs to know. It doesn't, in fact, it doesn't need to know where on the child object it is. it doesn't need to know the orientation of the child object. maybe it does, but it doesn't need the location of the child object. All it needs is the parent object says, Oh, there's some bit pattern here and, I'm going to now back project to the, person sending me that bit pattern saying, I'm at some location X, Y, Z, you need to associate my location with all the details of your object. So your child object. So it could be that in the traffic light case, it's very similar in the sense that the, child object doesn't have to send the extra information up to the, to the parent object. It just, the parent object projects back and says, oh, in this state, you should have been, in this, I'm in this state in the traffic light, you should have been whatever state you were in the child object state. Yeah. Yeah. Just thinking that like in the traffic light example, the high level model at most entire traffic light doesn't necessarily need to model how like the, each of the lights change on each of the, like how the color changes everywhere, if it's on versus off, but. The high level model is used to coordinate how like the red light is on and then the orange light is on at the same time and then those both turn off and then the green light turns on. all So for it to do that, it didn't have to make, it has to have some sort of concept of state internally. So it knows where it is in that cycle. the order in which they occur. Yeah. Obviously that would be more like a global state, or like that, would be the state for the light as a whole. It would be, but it would be on a location by location basis. It still would be on a location by location basis because you, can't have, you can't have a state of a whole object that we've already determined that. There's no such thing as the state of a whole object. Object has many different things could be changing. Yeah. so that's what I mean, that's what, consistent with everything I'm saying. I'm just saying that basically whether one of the lights is on or off, it's just a feature changing in L4 because. Like the fact that it is on or off is already detected by the lower level learning module. And it's just a changing feature in L4 and how this feature can change and how the SQL, how the lights depend on each other. imagine that we had a traffic, imagine we had a traffic light, what was this completely flat black, there were no, nothing identifying where the lights were, but then the lights would come on and then it would be a red spot. In this black area, and then there'd be a green spot and then there'd be a yellow spot. but there is no other feature. If I, if the light wasn't on at all, there'd be nothing to indicate there were any kind of things there. So essentially, it's hard to say that there's a child object, at the locations where the lights are because there's nothing physically there until, the color changes.

and I then it seems to me the right there, there is no. then you might say, okay, there wasn't a child object, but now there is a child object and the child object is green circle that I guess you could model it that way, but that still, my point was, there'd be no, the child object wouldn't be sending up a state, the child object would be either it's a green circle or it's not a green, it's either there's a green circle or there's no green circle, it wasn't like there was a green light and now it's off, it's just a moment ago there was no green circle here, now there is a green circle here. Okay. yeah, I guess I was just proposing that basically whether the light is on or off, which could be the state of the lower model, can be treated the exact same way as all the other features that come in. there is a great green circle or there's not a green circle, right? There is bright light and there's a dim light. There's a non, I would agree with that. But I guess the question, we're going back to what Niels is asking about whether we're passing state into the, parent column. yeah, so that would be arguing we're doing both. We have the state in L2, like you suggested, and, but we can also receive the state of below a level of a child object. as a feature and interpret it as a feature in L4. Okay, the language gets a little confusing. I'm open to these ideas. I, guess what I'm, going to be adamant about is that there is a local state to the, column in the model. And that state can change on, that state represents the state of the current location and not anything else. and it has to be local. Whether we're also passing in state from a child object, I'm open to that. I think that's, it seems like a possibility, but it gets, but it is confusing to think about exactly what's required. So again, maybe we can leave that as an open question. we could say, in this thing here, we might say, might say something like, how about that?

Will that address our confusion for the moment? Yeah, and basically it wouldn't be treated any differently than the features that are coming in, and it wouldn't be equivalent to the state that's being modeled in L2 or whatever layer. if we're passing a state, if it's a separate variable, I assume it would be handled separately somehow. would it? Or is it? Or is it just the feature and the state are combined? I'm not sure. I would argue it could be treated the same way as other features that are coming in, but. then, it's, so from the columns point of view, it doesn't, you're saying there's not really two things. It's just feature and state. Yeah, the state becomes another feature at that location. Okay. I'm open to all these ideas. I just, I find it a little bit confusing to think about. Maybe, some, clearer examples. will help tease apart, these issues. one thing, one thing that the state has to do, which I'll come to in a second, the state labeled in this picture, it has to associate a link to, other states. It has to associate a link between changing states within this column, like a change in one part of an object would lead to a change in another part of an object. and or it could lead, a change in this object could lead to a change of state in a different part of the world, a different object. and those links have to, those are, sequential associative links that, and that's not the same as voting, right? They're more like a sequence. so it's similar to like how features change based on movement, based on movement or based on anything really is just, we have to, we have the whole trick here, the bottom line of this whole thing is the cause of relate changes in one thing to changes in another thing. that's how we learn to use tools or turn on things or manipulate stuff, right? How do you change one thing? to, create a change, a desired or change, a change somewhere else. and so the state variable, wherever it is, going to be socially linked within its own column. for example, if this was a, traffic light and modeling a traffic light here, imagine that, imagine the, okay, imagine that this is, imagine you're looking at the traffic light through a straw, okay, and you can't see the whole traffic light at once, and you're looking at some benign part of the traffic light, and all of a sudden the light comes on. as we talked about previously, some external action policy detects there's been a change. The column moves to that change and says, Oh, there's a green light here. And it says, the last time I hear there wasn't a green light. So my model says there was no green light on at this location. Now it's green. So it says, okay, something has changed. this is a new state at this location. then the yellow light turns on and the column is once again, redirected to the place where that change occurred. And the same column says, Oh, now at this location. I was just looking at the green light, that I was a state, now we're in this new yellow state at this location. So I can link the, basically the pattern in L2, at one moment represents the, green light came on in one location on the object, and the next moment it represents the yellow light came on at another moment, point in the object, and you can associatively link those two. It says, okay, when the green light was followed by the yellow light, because this column literally went from the location of the green light to the location of the yellow light as they change. And so you could follow through this and the, single column. would learn that this is the sequence that when I see the green light, then it's followed by the yellow light, and it could expect that, and it's followed by the red light, and so on. It could also learn the timing of this, meaning if maybe there's a two second delay in the yellow light or something like that. so you can imagine now this changing in the state variable over time. represents the different object behaviors of a, how an object changes over time, and it can learn that. It gets, and then we could say, oh, maybe when the green light comes on, a bell rings. And, and so there's some other column in the cortex, in the auditory cortex, that is, it's, jumped into oh, I'm listening, the bell just came on, a change occurred. And there would have to be a link between the green light in, in one column and the bell changing in another column. but that would be easy to do. It's just, another association if the connections could be made. so I think this is a way of tying these events together. So there's associations of states within a column and between columns is how we would learn how objects behave over time. Did that follow? Did everyone follow that? Yeah, that was pretty helpful. now I'm going to make it complicated. Let's talk about the stapler top opening. The problem with the stapler top opening, imagine I'm watching through a straw.

there's a lot of things moving. It's not just like the green light. Okay, there's one point where the green, there's a point in space where the green light came on. I'll go to it. But the stapler top is moving. There's multiple things that are moving at once. So imagine You're looking through a straw at the bottom of the stapler, and now the top side is moving, and a detection is made. the column can only jump to one new location, even though there are many locations changing, like all the locations along the stapler top are moving. Which, where does that column go, and how does it learn that all those locations are moving at once?

I don't know the answer to that question yet. Oh, that's introducing a potential problem. I just throw it out because it's okay, I got this. I got the traffic light. That's pretty easy. Pablo's dog. That's pretty easy.

staple top, that's a whole, that's a whole bunch of. Positions changing at once, in the space of this object. I had that question written down, if multiple things change at once, how is it that the column doesn't re anchor and say, oh, this is a completely different thing now? it's, trying not to re anchor. Typically. Typically, you wouldn't re anchor, if something just changes in the world, something you're looking at, you wouldn't think it's a new object. You just think oh, this object I'm looking at is undergoing some transformation. So I'm not worried about that, but I am worried about the issue of like many things happening at once. Imagine, I had a toy and there was a button on the toy and I pressed the button on the toy and then 10 different things on different locations on this toy changed.

you pushed it and then a little window opened up in one place, and you pushed the button at the same time a little wheel spun, and at the same time the light would come on, at the same time a sound would come out. All these things would, or let's keep it all visual, there's different things that are visually changing about this object. Now, when you first experience it, now you're trying to learn this, right? you can't learn all those things at once. you just, it's impossible. You can't attend to all the different changes at once. What you would tend to do is you, do it over and over again, lots of little grandkids now, so if I go see them doing this, they'll push the button and they'll focus on one thing that might be changing, and then a moment later push the button and focus on another thing that might be changing. and so you can't, absorb all these changes at once. The, straw can only look at one thing at a time and, say, okay, how's that change when I push the button? How's it change when I push the button? Push the button, see a change, push the button, see a change, push the button, see a change. And then I'll say, push the button, watch a different change someplace else. And somehow we bring all those two together. I, don't, I think it's going to work.

I think it actually will work, but I have to walk through the mechanisms to see how it would work, but you can't learn it all at once, you'd have to learn it sequentially, once you've learned it, then I push the button and I would have expected, I can have an expectation about any one of those changes that would be occurring. I'd say, if I push this button, I know that over here, this will change and over there, this will change and over there, this will change. but I think you have to learn them sequentially, for additive practice. One thing we've, I'm not saying this is a perfect solution or something, but one thing we've talked about, is like how with hierarchy, if, the, staple top is a child object, it's easier to imagine how that's represented, with a kind of single representation. And I think one thing Vivian, you talked about on Slack at one point was how, you can imagine. If you can vote on a state, or sorry, let's say a ID and pose, and you can do that quickly enough to infer it, that makes it easier to learn a behavior. as in the connection here would be like, as the stapler top opens, because all the columns that are the kind of straw world looking at the stapler are seeing a consistent Pose an orientation of the top. They agree on the pose on the top. So we quickly determine okay, this is the new state. This is the new, or like this is the new pose of the thing. But someone dancing or, this complex toy to your point Yeah. Is gonna be harder because each arm and each leg is gonna be they're basically creating like a totally new And we, we need to break it down and learn that this is like a new. first, okay, how do I move my feet, then how do I move my hands, and how do I move my this and that? But the thing about the stapler top, which is interesting, and it's a compelling idea that, oh, maybe the whole top is like its own child object, and it may well be that way, but it wouldn't start out that way. I can easily imagine an object like the stapler, where I have no idea that it's about to move, or that it even has a seam or a hinge or anything, and so I learn a model of it. And that model does not have, oh, the top part is an independent child. It's just, I have no, there's no evidence that, I can't possibly imagine that. So I've learned this object and, and so there is no child object which says top of stapler or top of box or whatever it is. And now it starts moving. so the first thing that I, just, there is no child that I can say, oh, this whole child is moving. So basically multiple points on the object are changing at once. and, maybe I have to practice. I'll learn that the top is a separate object. And maybe that's the right thing to do, but initially it wouldn't be that case. Initially, I would have an object where that you just imagine it's a rectangular box. There's no seam. I don't think about it. And now all of a sudden the top opens separate from the bottom. So I didn't have a model at the top separate from the rest of the box. There was no visible evidence to that. Now, how do I, what do I do then? Maybe then, maybe what you're suggesting is maybe then when I first see this thing happening, I, maybe I just start focusing on and learning a new model of the, top. That's the first thing I do. So imagine looking through a straw, and I'm looking at the box, and then the box changes, the lid opens up, and then my, straw is redirected to the point where the, lid, somewhere along the lid, it's now partially up. At that point, I say, this is different. but maybe what I would do then is then scan along that lid and say, okay, this is a separate object and I'll form a child and something like that. But it's complicated. It's not so simple. I can't always assume that there's a child object that's changing. I like the idea that I think you wrote in your write up, or maybe I misunderstood it, but basically that's in layer two or wherever the state is being modeled, we can learn associative connections between states. So essentially if I'm detecting, all right, the top of the stapler is in the state, I expect every other point on the top of the stapler to be on a certain state. Like I can. But I have to observe that, right? I can't assume that. I have to observe it.

Yeah. And then yeah. Tying into that would then be that. Yes, we would have to learn that once and it, would be pretty tedious to learn that, but then we should be able to transfer that onto other objects, basically solid lines moving in this kind of stapler way. So we wouldn't have to relearn it every time we have fun with lots of objects. Although I can come up with all kinds of screwy examples that make our life a little bit harder. maybe, so we talked about like making the staple more like a box and you're just lifting the lid of the box. what if the lid of the box was hinged in two on both ends and it lifted up in the middle, like you were two, two second, two pieces opening up?

that's a different thing. I, so I have to learn all these, right? I have to be able to say, okay.

how many and I wouldn't know that, by the way, I wouldn't know that until the imagine your, straw visual system, it could go up and see the right side of the lid going up. And you might say, oh, the whole lid is going up, but it wouldn't be because the left side would be going in a different direction. And so it's it just proves that the system has to observe all these different parts. It has to go around and try to figure out what, what has moved and where it's moving. And the strong example gets really hard because there's multiple things moving at once. And by the time you get to see where the other things they've already changed, you know what I'm saying? It's You can't everything's moving. So if it's just one thing was changing, you could observe it. But since multiple things are changing, it drives you crazy. It's like, where should I go? And how do I observe? And how do I know what happened in between? Anyway, I'm just, I'm riffing on what you said, but mostly I'm saying it's a challenge to understand how like the single column. We'd learn, how could it learn all of the complexities of a complex behavior? The traffic light is a simple behavior. It's easy to understand, but a product, an object that has multiple things moving at once. It's difficult. and, we can't assume that there's already child objects and only the child objects are changing. so somehow the system has to learn this. And you can just imagine looking through a straw and trying to do this. if I was looking at an object and I didn't know it had any behaviors, and then something moves and my straw is redirected up, but I'm only seeing part of it, and then something else is moving, and, I can't see everything that's going on at once. It would be very confusing. I wouldn't be able to figure it out. I'm not sure how it happens.

anyway, I'm almost done here. I know we've got 15 minutes more of time here. Let me go back to my, my, my tech side, if that's okay.

I'm going to stick with the object behaviors I learned by location on location basis. We're open to the idea that, that state could be passed in from a child object as we talked.

I just, I'm going to jump down to this paragraph here. Oh gosh, I needed that.

I just, it's a little fact, if you didn't know this, it's interesting to know. on layer four cells, these are the cells that get the input directly from the retina. Less than 10 percent of the synapses on those cells are actually coming from the retina. So people say, oh yeah, layer 4 is driven by the retina. It's 7 percent of the synapses are coming from the retina. About 40 percent come from L6, which is consistent with L6 being the location, right? And then, but that leaves about 50 percent unaccounted for.

that could be state. just won't pass that on, in case you didn't know that fact. and then this stuff I talked about, just a moment ago. I said behaviors are association of state changes. So when we talk about a behavioral object, we're referring to a set of state changes that are causally linked. Something changes here. It could be one thing, it just changed by itself. An object could one moment be green and the next moment be red. But typically, something happens one place and something happens another place. Especially if it's something that I had to do, something I had to manipulate. so most object behaviors consist of multiple changes to the object. These changes can occur simultaneously at multiple occasions. That, for example, Simultaneously, a multiplication would be like the, the, lid of the stapler going up. or another example is a switch may turn on lights at multiple locations and you'd have to learn each one. again, if you're looking at the world through a straw, you wouldn't be able to see those multiple lights at the same time. You'd have to do them sequentially. and sometimes these changes the current sequence, like the top of the state, but it's a sequence. It doesn't jump around. It just, it goes on and flows in a sequence, and until as a sequence ups, goes up, and then, And then I mentioned here too, if the stapler deflection plate rotated as a stapler top was raised, so there'd be, you'd be raising the staple top, but something else would be changing it elsewhere on the object. and a single column can't learn all this at once. It'd have to, it'd have to learn it through multiple repetitions, of the behavior.

It also feels like another kind of key part of the conditional transition or whatever in the states is, actions and Yeah, I don't know whether that's represented in L5 or whatever somewhere that would probably play in terms of how are we moving through the state space of the state, but it depends on where we're pushing on it or things like that. I've been avoiding that difficult problem for a moment, but you could imagine if it's a button, I can at least say, I don't have to worry yet who pushed the button. I could just say the button went down and the top opened, I'll come back later and say okay, how did the button get pressed, how did the button go down? And of course it's complicated by things like capacitive buttons where they don't move at all, it's such an area and something happens. it's a good, it's a good question, but I think that's an extension of this basic theory, at least I'm hoping it is, Niels, I hope it's, everything I've described so far is consistent and doesn't have to be changed and we can then add on, like, how did the button get pressed? yeah, and that would be the ideal thing. so this is, we were just talking about this, about how we learn these changes in states. and I'll just read through some of these, just read through some of these comments here. I say a column must be able to learn behaviors of objects. It needs to learn which changes occur together and how these changes occur sequentially in time. and the basic method would be learning associations between the SDRs and the state layer.

And a change of state in one location would be associated with a change of state in another location. so that's, that all hangs together really well, I think.

and then I say a state location for location A can be associated with a link to a state, in a state in L2 for location B. Again, if I know that something happened in A, And then layer two would predict a new, another state, that new state would be specifically linked to a different location. So this tells me that states are tied to locations, I, if I know the state of something is changing, I know where it's changing and I can, I could direct my attention to that point. So it's if I, go to that location, I know that what will be there.

I said the learned association, the L2, can be one to one or many to many. This is, this gets back to the idea we were just talking about, the, simple thing could be you push the button and the light comes on, but you lift the stapler, multiple things could be happening at once. And so it could be, many things are associated with changes. Many changes can be happening at the same time. And these changes can be sequenced, or they don't have to be sequenced. I could push a button and instantly everything changes, or I could push a button and there's like an order in which the changes occur.

and then some of those sequences could be learned with or without timed intervals. So a traffic light is a sequence, but the But, but it doesn't, I shouldn't use the traffic light because there are timed intervals there. Oh, these are both trying, these, I think I get the wrong examples here. Anyway, this is garbage today. This is, this, I think, look, I messed up some of my text here, I think.

lemme just look at this one here.

alright. That was repetitive. I think I meant to remove that paragraph.

I talked about this earlier. We talked about single column will automatically learn associations between the states of, that object that's being modeled by that column. but if multiple columns of simultaneously serving the same object, the different locations. So imagine I have multiple columns looking at the stapler now at the same time, multiple columns, multiple patches of the retina, then the long range connections between layer two will associate changes occurring across columns. So I was trying to get at the fact, okay, what if I didn't just have one column? I wasn't just looking through a straw. What if I had multiple columns that were observing different locations on the stapler at once, and they're all observing different, some of them are observing changes and some of them aren't, but the ones that are observing changes would then could link to the other ones that are observing changes at that moment in time. So this is a little complicated, but imagine the, imagine my eye is fixated at one point and, and the lid of the staple is rotating up. there'll be a whole bunch of columns that were observing the stapler top that then don't observe the stapler top. And then a bunch of other columns that weren't observing any part of the stapler that are now observing part of the stapler. And so a whole bunch of columns would be going through state changes simultaneously, but they could all be linked.

they sociably link, so it, the change anywhere could predict a change anywhere else. And this may be the way of dealing with the fact this may be one way of dealing with the, of the fact that, maybe the top of the tape is not a separate child object. I need to learn all these things at once. I, don't know, I just, this is just an observation. What would happen if you had multiple columns observing the, staple at once? That many things would be. Many of these columns would be observing behaviors. and state changes, and they would be linked, and all those links would be make, would all make sense. They would, it, they'd all associate somehow, and I don't really understand it yet, This would work across, yeah. Would this be like voting on states? I don't, it's, voting, but it's, I don't think voting is the right term for it.

I thought about that. I said, is this voting? and I, didn't spend too much time thinking about it. I said, it doesn't feel like, voting is trying to reach a consensus. and these might be both, it's, I don't know, it's, it's a great question Vivian, maybe we should just leave it unanswered. It feels like voting, but it feels like it's doing something more than voting. In my mind, voting was like, okay, we're trying to reach a consensus on a thing. What is this? Is it A or B? This is more voting about what should happen next. Everybody's, all these people saying, yeah, I see what's happening here. And, then let's say, I'm seeing what's happening here and they're, sequenced to it. It's nothing. And by the way, these are all sequential. The time is important here, right? The order in which these things occur is essential. We're voting. It doesn't seem to be essential. so it's, it, there are everyone's voting on what the next thing everyone should see. That would be, then it would be voting. Yeah. Yeah. So it's in a sense like voting that it's associated with long range connections. Yeah. Maybe a bit more of a temporal dimension then when we're voting. it has definitely an order to it, right? The order is essential. Things can happen at the same time or things can happen sequentially, but they can't happen backwards. if B usually follows a, then I don't expect a B.

B might predict the state of A, but it wouldn't predict that A is going to change. I know it's an interesting question. I even asked myself this question at one point. I remember now I said, Hey, could this be all the voting? Could all the voting be done like this? So somehow it seemed like voting. So maybe this is how voting occurs. And, I, got confused. I just was, my brain was getting fried thinking about this now.

And there's, only two more or less points on this page. I've already mentioned that behaviors, you can associate behaviors across modalities. That's easy. It's any layer two cell changes, another layer two cell changes, and you can associate them.

and then the last thing here is I, it wasn't even clear. If I have this state variable, what does it default to, and what does it change to, and does it have meaning, Niels and Rami have been talking about, and how is a new variable chosen when, a change occurs? I, don't have any answers to any of these questions. I, I just was like, oh, I don't really understand this.

It's it's not complete yet.

So I'm done. I'm just saying, I feel really good about this stuff. I feel again, as I've said in the past, I'm making progress on this. So that, that feels great. Clarity is coming in, is showing up, which feels great. Even though there's many things that are still unclear. the only thing that's important to me is it, that it feels like we've nailed down a few concrete items and then we can go on from them and, and much better understanding what's going on. so that's where I am.

I'm done. Nice. Yeah. Hojay, did you have a, yeah, I guess I was. Thinking about the question that Jeff had at the end and also, think of relate back to the question that Vivian asked and in the middle, is state part of features? And I wanted to like, I just thought of another way to think about it. I just want to like, here, I guess on my screen, probably the easiest. so we're, talking about, like features, and then depending on the lower level, we might have a pose color, higher level might have ID, and, of course, they're in some kind of location. Let me just put that as well. Are features consists of pose, color, and ID, or is that what you're saying the features consist of those things or those separate things?

when we talk about features at location, we're talking about all of these in the same location. Okay. So like what you're saying, the word, feature is a, is composed of pose color id, yeah. Let's, think about this as like a, I guess I, I like to think about it as like a dictionary or. Of like things that we are cleanly sensing. and then instead of so if we think about state as like part of, features, and I guess I would add that here, right? this would be, whatever we call, s one state. But then I think another way to think about it is actually let me try to delete this is to think about it as, as like a whole thing is a state of itself. and then this is not exactly clear. So I'm going to go I want to explain a little bit more.

when the learning setting, we're at an object, we don't know what the state is. we don't know what the variable is. So we just. call it at least in program, just call it s one. So and then, this could be part of an object that never changes. Sometimes changes, whatever. and then later, it comes back to the same location. but that this time it notices like a different set of features is there a way to move this? Yeah, I know.

okay, in a new visit, the second visit, we have some features, but now, color is, let's say initial color was, I don't know.

We're at the same location. It's just, we're at the same location. Yes. Cause I'm in the same location box. so now the, this thing has changed to red. So now when you're like, okay, like here, now it came back and now so the feature has changed. So I'm going to say that this is, I'm going to say that this is like another state.

and I'm going to call this state too, and, the location, would store states, and, I think this is in line with the fact that, okay, this, the states are tied to the location, and it's just that, at that particular location, the feature sets, have changed, maybe, I don't know, it could be, like, a location plus, a particular feature set, maybe, yeah, I guess so. Instead of thinking of basically, the conclusion is like instead of thinking of status features, maybe we can think about it this way. And I think this still is aligned with everything. I'm, confused. Is this different than I proposed or I'm a little confused. It's the same. Yeah. no, it's okay. Yeah, it's just, I'm just trying to clarify like where. Where state might be residing, is it part of features or is it like, yeah, it's just a very good question. Is a state associated with a location or is it a state associated with a feature? Is that, what you're asking about? yeah. Yeah. state is definitely, I, agree with you definitely that, or I'm convinced that state is, dependent on the location. and. I guess if this is more programmatically, whether we define state as like part of features and therefore it gets, sent to higher level things or, what, whether we define state, just another way of defining say, implementation terms anyways.

yeah, no, I think it gets to the semantics of like how we refer to state and, maybe also like the point Jeff was raising that it can be a bit confusing how the term quickly gets overloaded. Like Vivian was also, cause this is actually how a state is defined in the code base at the moment. There's this state object. Yeah. Yeah. Yeah. But then, yeah. But then we talked about like behavioral state, like on something like that, or like a behavioral state, I don't know, crushed open, whatever. and yeah, I guess we just need to, we need to somehow find a language that enables us to, Yeah, talk about it in a way that we don't get too confused. Yeah, maybe in code we can just change the state to CMP. I don't know. I, yeah, Yeah, obviously what we actually call things is not essential. It's very helpful to pick good words. but we have, to agree on the principles. What do we mean by it? That's the most important thing.

there's some really good ideas came up here. I think it's worth thinking about further, the child parent relationship and whether, state can be passed in that way, or what does it mean? it's, consistent still to say, oh, there's a state variable on an object location basis, and also maybe that's passed on to the parent. it's not clear, yet to me.

anyway, yeah, I feel like this was at least the most coherent view of modeling object behaviors we had so far at the end of a research meeting. oh, I guess I can feel like it's not saying much, but we're making progress with what I'm saying. I think so too. This is. I've been through this so many times that it starts out this really muddled confusion and then you slowly pick away at it and I recognize this process and it's Oh, this is going to work. We're going to get this. So I feel really good about it. Yeah. A lot of clarity, a lot of clarity came along. I'm going to continue working on this, primarily in the time, anytime I have. maybe, next week I'll have some more things. I'll see. I don't know.

All right. Are we, yeah, I think that's everything.