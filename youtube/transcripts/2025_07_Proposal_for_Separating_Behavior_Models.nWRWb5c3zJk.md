Yeah, the first part is a recap of this pre basic proposal that I made a couple of weeks ago, or general idea that, behavior and morphology columns might be mo models, might be in separate columns and one might also call it going full Monty since no one referenced before.

So that, that's the code name I'm using for it now. because well, yeah, just following Mount Castle's proposal to the end that whatever each column models just depends on the input it, receives.

so very quickly, here's our current model. We have, movement and feature input from the sensorimotor going through the thalamus movement. Input. Input goes in, here, upper layer six, feature input goes into layer four. And then we talked before that, perhaps, or, orientation input goes at in, at the border and kind of activates the minicolumns. And then, features might, cause like very specific activations within the minicolumns. and then we have associative connections between layer four and layer six that learn, which features are at what locations. layer six is the location on the object. And then, a. A is location on the object, b orientation of the object and the orientation of the object can be used to rotate both the incoming movement vector and the incoming orientation feature. over time, those activations get pooled into, something one might call an object id. So which objects are we sensing overall? And that is kinda stable. So as we move over an object, the sensations that come in and that are in layer four and layer six change at every step, but that remains stable as long as we're on the same object. Okay? And then we can also have this kinda feedback input from a higher level column that tells this column which location it should expect to be at, and then this kind of broader context signal to multiple columns, in the lower level, in the hierarchy, in layer one, that, can be connected to layer two to three five A, not a hundred percent sure exactly what each of these get out of this context signal. So far so good. nothing new here. so now what we introduced when we talked about behavior models is, what if there's just a parallel system? we get, changes and directions as input to upper layer three and layer three minicolumns. we got a movement vector as input to layer five B. We have basically two reference frames. One for the behavior model, one for the morphology model. that one also has an orientation which can be used to rotate the input. We also have associative connections in this case, maybe between layer three and layer five B. And those, I'm sorry, did it require doubling up on these things? I thought, it didn't. Yeah, I thought it didn't require a separate movement vector and a separate orientation vector. I thought those were shared.

they need to be separate if we wanna be able to recognize behaviors and morphologies independently of each other in independent orientations. Oh, Yeah.

Sorry. so yeah, then they get pulled into a behavior id. and yeah, that's then the, additional thing would be that there's some kind of time signal, in layer one that we can have neurons in layer three synapse to and kinda temp, have some temporal conditioning on what, changes to expect at which locations. And Do you notice something in this picture? Wow. So you were making double, lines of everything. Yeah. So one, there are doubles of everything and two, there's no interaction between these two things. So blue and green don't really interact at all within this column. But we talked about how they would Right. It wasn't like we, we thought they would, all the interactions so far that we talked about were always between two hierarchically re-arranged. Oh, that's true. We tried to do originally within a column. Yeah. And then we said that's getting hard, so we said that's too hierarchically. Exactly. Yeah. so yeah, for sure. We talked about a lot of different interactions between behavior and morphology models and there need to be some, but the kind of solutions we came up with so far were always two hierarchically arranged regions. And yeah, I guess the only one I can think of that was, but it was a fairly weak one or not like one that's hard to replicate, but just that a behavior can bias an ID recognition and vice versa. So I don't know, recognizing the banana morphology will bias the banana peeling behavior and vice versa. But that's easy to do with voting and stuff like that. So that, I don't think that's okay. Yeah, that would work the same way with voting across columns. I guess the general thing, what Niels just said is an issue. One, I think, is that sometimes behaviors are instantly associated with objects and they're not generally shared. In fact they start off being associated with objects. So sharing behaviors, generalized in other objects is the, yeah. And we did also say that like you can have a behavior at the lower level column and then associate the behavior ID with a location on an object. So saying at this location that object has a certain behavior, but that's, again, hierarchically that behaviors in the lower common.

but yeah, so the general proposal would be to to just separate out the blue and the green, which would allow us to move, everything back into the original layer positioning so we don't have to shift things around a bit to make space for more functionality. and then we could also generalize it a bit and say that this layer one input in the morphology object could be more something like state, like for example, if an object can have multiple morphological states, that could be a conditioning for that.

or it could be like, what's whatever's passed down in the feedback connections. it, it seems to me that time is appropriate for both of these. yeah, maybe not, but so you don't have, you don't have to separate out, you just say time is always there. Yeah. So it could be, I guess what I was getting at is that this could generally be considered as something like context or state and context can be ti time in a sequence, or it can be a behavioral state or an action condition state, or it could be, But there's different, cell populations to project this layer one, so it's not like one thing. Yeah. So time is a kind of a state and, yeah, maybe it would help to show, I guess like a, we almost need to add a separate connection, which is the, what you call it, matrix cells. But, but yeah, but I like that, idea of, because yeah, it fits with kind of what is the, instead of behavior in, the morphological models, they're learning the different key frames that when an object stops moving and those would have these different state variables that, re recover them, yeah.

Yeah. So yeah, in a nutshell, this is the proposal. Instead of having each learning module required to have two reference frames and the, all the machinery. Doubled up just having different learning modules or different co columns that receive different types of input. So they might receive, like features at look or orientations at locations for the morphology model. They would receive changes at locations for the behavior model. And then the reason why I first thought of this was actually because I was thinking about the feature model or like surface model of like basically this kind of 2D map that you can wrap around the surface of an object as like a general feature map, which could receive, features like colors, but then 2D movement vectors along the surface of the object. So there might be other types. This is, a new idea that you're just throwing in here, right? oh, in sense. in sent, no, I showed this, I think some weeks ago.

what I mean is today's topic, you were saying let's take our jack of all trades column and break into the two parts. Yeah. And now you're telling me you're breaking into three parts, which is like. Mostly saying it for context, because that's what's the reason why I thought of the idea, because I was thinking about these surface models, or in the past we talked about there being three types of models, morphology, behavior, and feature models. And the feature models seems to be more like a two dimensional thing that can kinda wrap around an object. And that's, we, started talking about that topic because we were talking about, object deformation. I think in my mind, I was, go ahead J I think we also wanted to learn like a general like class of morphologies that I think that's an idea that Jeff, you presented like again, like a month ago. Yeah. so we wanted to separate out like a, like classes. Yeah. Yeah. So we wanted to separate it out, like the morphology portion from the features that are associated with the morphology and hence what this feature stream, separate thing came out from what I remember. Yeah. And I remember, I think I posted this idea on Slack and then Jeff you said something like, it would be a bit much to expect of a mo of a column to have three reference frames now. To be able to present those three models. So then I thought, yeah, it wouldn't actually have to be in the same column in this case. And then I thought, oh, why does the behavior model even need to be in the same column? I guess I didn't absorb the idea or accept the idea that surface models and morphology models are two things in my mind. They're still, we're trying, I was still trying to assume they were in the same column. and you've gone one step further and Yeah, I'm going, full Monty, yeah. of course this beg the question, the next thing is where are these different modules and how do they relate? And, glad you asked.

so I, yeah, this was all stuff I proposed before, but then last week I did a bit more of a, deep dive into the literature of particularly where's kind of motion process in the visual, stream. And so the very first figure that I found that was what I was looking for was actually this figure, which shows that. With just one, vertical electrode penetration. So basically within the same column, they find both direction selective cells and orientation selective cells of different, sizes of bars and non orientation selective cells. and I was thinking, oh no, I just made all of these slides and animations and this is not working. Because if this was the proposal, I wouldn't assume to find motion selective cells and, orientation selective cells in the same column.

so you would expect, is that the same column? Because it isn't, it doesn't look like a perpendicular projection. yeah, it is. And also look as I dug deeper there, like all these maps of response properties and everything in V one that I could show later. I have a bunch of like misc slides at the end or whatever questions come up. But, basically this was the first thing I saw, but then I read further and within Can you go back? Yeah. Can you go back next just to correct me checking my understanding. Yeah. The problem here is the, little thing box name, level number one. we would expect to see, directional sensitive cells in layer six. For the morphology and the, feature model, right? Yeah. Yeah. It's really this, those are down there. It's really just the upper ones of the problem. Yeah, exactly right. Yeah. Sorry. so yeah, this is expected, you said, I'm just double checking, Mike. yeah. And so I read further in the same paper and saw, okay, this is an interesting thing. the cells, the feedforward projections to mt, which is classically thought of as an area, responsible for motion processing, they actually come from layer four B specifically. They come from layer four B and layer six, but they don't come from layer two three, which is where usually the classical feet forward projections come from. and the layer three outputs from V one go to, V two. And maybe I'll skip this beautiful picture for now. We can get back to that. here's another kind of visualization of that. That's, retrograde labeling of neurons in V one that basically they injected the dye in mt. And then these are the neurons in V one that project to mt, and they're not in layer three. They are mostly in layer four B and some of them in layer six, in upper layer six. And they're about 10 times more in layer four B than in layer six. and most of them, like 80 of them target, excitatory cells in mt.

and also independent of the blobs in V one.

and so here these are just two diagrams from two different papers showing the same thing, the same anatomy, which is this projection from the spiny cell cells in V one going directly to mt. And also in, in layer four, this, the same error here, layer four B going directly to mt, and then for B also projects to V two. But this is a different cell population. Those are mostly parametal cells.

and we can come back to this, those figures for more details in a bit, but maybe just to get to my main. Thought that I had when I saw this was that V one is could be like a relay directly sending motion information to mt to be modeled there because it doesn't seem to be really processed much more in V one. It, doesn't get pooled into a representation in layer two, three and then send forward. instead it goes, it enters from the magnocellular pathway into layer four B alpha goes up to four B, and then gets projected to MT directly. And then there's another pathway to mt, which is also, it's this other population of parametal cells that projects to V two, the thick stripes in V two.

and on the other picture, it would be this arrow here. and then from there, this actually process, there actually exits in layer two three, and then projects to MT and, from Viviane. Yeah. do you have a, guess as to why or, thought as to why the, why you have these extra layers in V one? couldn't the, Magnus Cells project directly to mt? why do they have to go through this? This. So extra layers in V one, why don't they just go right to mt. Yeah. So that's what I was trying to get at Now. So with the kind of second pathway through V two, the physiological studies show that it seems like this input integrates more three dimensional motion information. So actually the disparity between the two eyes, so it takes disparity into account at the point in V two at this point. So maybe V one also does some kind of processing to take depth or some more global information into account to get kind of motion information in world space instead of rational space. that's what I was, I always had that hypothesis, right? I threw that out several times in the past, but it's somehow dealing with the fact you're trying to get to a 3D representation. Yeah, but still it doesn't, exp doesn't tell me why couldn't, that processing could be done? couldn't this whole, everything can be done just by having two separate pathways coming up off the thalamus, like one projects to MT and one projects to B one. I don't think it's important. I just didn't know if you had a thought about the matter and if you Yeah. So yeah, I don't have a clear answer on, why there's this. Here and what would be happening in between those two? Like why does it go through layer four of V one and not directly from the Magnus cell cells to mt? I would guess there's, yeah, my guess would be that there's some kind of local integration of information for getting from retinal space to world space of movement. Because, it seems like that's happening in b2, right? It seems like it is a total mystery to me. So I just thought if you had some insights, that'd be great.

okay. It could also be just a, accident of evolution, somehow. Yeah. Just because there are mammals that don't have this dry eight V one, and they don't have, they're missing something. Yeah. I should mention everything I'm showing here is primates. yeah. but, and then the evolution comes along and says, hey, we're gonna discover something new. It's easier just to change a few cells in existing places than to add a whole nother structure, or, Yeah. It could be just an ac an accent of evolution, so it can't be, but, okay. I'll keep going. Yeah. And I, saw this paper here, which I thought was, meshed well with what I was thinking. I can just read out the marked parts. first of all, just to give some context. What the paper's about. They say some neuron neurons in extra stride area MT are capable of signaling the global motion of complex patterns. Neurons randomly sampled from V one on the other hand, respond only to the motion of individual oriented components. The neurons that project from V one to MT were directionally selective, and like other V one neurons responded only to the motion of components of complex patterns. So this, maybe that's another hint of what is happening in, V one, that it makes sure that the motion is associated with, one object or something like that. and then, yeah, the projection neurons were predominantly special, complex, responsive to a broad range of spatial and temporal frequencies. And then here's the interpretation, that, consistent with the notion that we, one acts as a clearinghouse of basic visual measurements, distributing information appropriately to higher cortical areas for specialized analysis. So that, potentially yeah, we want as a, special region in, that sense in, in that it maybe sorts this information partially it, it might still do modeling there as well, but at least layer four B might be sorting out. Some of the change information just feed forwarded to a column in MT where it then learns the behavior model.

so yeah, this is my interpretation mapped onto this figure. Plus adding some columns here where, purple is the behavior model pathway and blue morphology and feature model pathway. So the pargo cell input goes into layer four C beta, and then it gets pooled up into layer two three. And then depending on whether it's blob or inter blob, it goes to the thin uphill stripes in V two and then from there to V four. And then for the behavior models, there's a magnocellular pathway input that then goes to layer four B, and from there directly into mt.

those cells are highly directly selective. The idea is you're saying MT has the behavioral model, is that right? Yeah. yeah, I'll show that on, yeah, just a second. and at basically this kind of pathway through V two would extract some more three dimensional motion information that then also gets, input to mt.

And there's also feedback, connectivity between MT and V one. And the interesting thing is that connectivity is also a bit atypical in that those feedback connections, they mostly come from layer six and then they mostly terminate in layer six, but also in layer four B, which is not usual for the feedback connections. Some of them terminate in layer one, but only at high eccentricities, which kind of makes sense. If you would think that this is a behavior model, it wouldn't tell you much about an object ID in B one, I would assume.

and so yeah, I thought that was just another interesting thing. and so on a high level, my rough idea was that potentially the ventral stream, could contain the feature and morphology models starting in V one, then V two V four and the dorsal stream to MT would potentially contain behavior models.

and the kind of pathway through V one and V two would be responsible for some motion processing, like incorporating disparity.

there's also some direction select directionally sensitive. Information going to V two and V four, but people have proposed that might be more from motion based shape processing, so like figure ground segmentation or mo detecting motion borders of objects.

and then lastly, this is a bit more vague. It could be that if we do have like feature and morphology models, it could be that morphology models are the inter blobs which are labeled form here, and the pale stripes and feature models could be the blobs, which is why you detect, the two three and people assign color to that. That could be blobs and the thin stripes. But yeah, that's a bit more out there of a proposal. I guess that's that I have a bunch more like just random evidence and fun facts about visual processing. So would you say that the relationship between the three streams, morphology, features, behavior, morphology and features are like horizontally in the same level while the behaviors one on top? I guess I'm trying to understand like how these three, different kinds of alums could be. That's a unit or maybe we don't have to do that.

I guess in Monte I feel like they would be basically the same. It's not like they would have different hierarchical relationships or anything and Okay. Oh, I was thinking of it as that the brain just it separates everything in different ways. So like it clusters different orientation preferences and then direction preferences and ocular dominance columns and all that. It separates all these different properties out. And so it could separate out the behavior models as well and the morphology models and the, feature models in, blobs, but not necessarily making any of them more or less important or, okay. Lower level. Okay. Okay.

and the, or the color blobs, down within one column. as in we're separating out the feature and the morphology, like the morphology being like the inter blob area, but within a column, my understanding was that there's both, which kind of goes back. Yeah. I like the separation idea, but I guess it's just like a devil's advocate for, okay. I think pubs at inter blocks happen one. Call 'em. Yeah.

Yeah, that is definitely, an argument against it. I'm not sure it was the most reasonable thing that currently makes sense for me because those are just in layer two, three. And if you would imagine having a model of the surface of an object and how color and stuff is mapped onto that. Yeah, I would, that, I would expect those to change the activation in layer two three in a consistent way, which might look like. But, or we, in, in implementation we can make them separate, but somehow, like these are more intimately connected in the sense that okay, it must be like laterally, connected.

we, can like strictly follow the biology, like they must be in one or, represent that in a different way, but, meaning the same, would be a very important point Yeah. Right now.

Nice. Yeah. Yeah. Oh, go ahead. That was really nice. Yeah, I was just gonna say, yeah, thanks for the nice overview. yeah, I definitely still think this is interesting. and yeah, it's crazy how complex the connectivity of V one actually is. The, yeah, I was curious, did you have a chance to look much at like how V four and MT are connected and stuff, and like how that might fit with kind of the old ways of what you call it, like how behavior would map, or, kinda like change predictions of a morphology model? like what connections could help with that? yeah. I didn't look at V four. I looked at V two and V one connectivity to mt. Yeah. V two, the forward projections to mt. A layer three to layer three and four. And then the backward projections from MT two V two are from layer three A and mostly layer six to layer one and six. so that's yeah. So as if MT is hierarchically above, yeah. Which I think fits with, I think, yeah, that's why I'd be curious with before, 'cause I think MT is often alongside, but I guess it's a hierarchy so you, you can slice it many ways. I don't know. yeah.

And then V one, it's a bit atypical. So feet forward comes from layer four B and layer six, not from layer two three, and it goes into layer four and six and mt. Then feedback connections come from layer three A and six, same as two V two, and then end in layer four B and six. yeah. And that was the one I guess you were talking about. Yeah. That's really interesting. So I, okay, so I, could you go back a few slides where you had the flow chart of V one going to T or the 3D? Yeah, this one. Yeah, I guess I just don't know the anatomy like very well about how close empty is to the one, but like the, fact that the spiny salads, which in my mind what they look like are basically parametal, but shorter.

and so like the parmal cells without the apical dendrite, yeah, it's, I think they can still have long axons. Oh, okay. So they can still object to, I think the ar the argument was they're exactly the same as parmal cells, minus the apical dendrite, okay. that's the, that's the interpretation I adopted. That was proposed by someone. Okay. Okay. But they can still connect to MTV because I guess a lot of the. I guess I, I thought that's, were mostly for connections within like a lawyer, so No, they have long range projections. Okay. and the other I, this is a minor, question, but I, know somebody did like research into the, third books. I forget the main, the, one that's K, yeah, The commiss. Yeah. Okay. So I'm saying, right? Yeah.

yeah, Do we figure out more about, I just don't remember like what we decided about or find out about it. I, can just look up in Google Docs. I don't think we reach any conclusions. I don't think. Yeah. The only extra image I have on them is, this review study that looked at like over a hundred of studies and that shows this very, this connectivity of coronary cell and put two layer 1, 2, 3. Okay. but yeah, I'm not sure I remember wasn't there some kind of overlap with the matrix cells?

maybe I'm misremembering, but, yeah, that would match with this, I guess maybe. But, yeah, I think one of my favorite things about this still is just, yeah, the idea of simplifying each learning module. Like I think that is really nice 'cause Oh. Yeah, I forgot my, main slide. Oh, okay. Nice. It's not the main slide I guess, but, benefits, it's a relatively simple change. And then the evolutionary argument is environments usually don't have behaviors, so this might have been a capability that near to evolve in the near cortex to model objects. And so it seems like the quote unquote kind pre-processing before getting to MT columns may be reason, a reasonable small addition that doesn't require a whole other set of connections for behavior models within a column, and would make that much easier to just add that capability. Yeah, that's interesting. It reminds me, I think in, the, I think there's some mammals or, maybe it's, marsupials or something that they don't have motor cortex, but they also, they don't have as like fine-grained, kind of dexterity as, for example, primates and, stuff like that. But it, I just feel like it fits with behavior in cortex being a, like a special thing rather than something that's represented everywhere. because, that, comes to mind is everything has bodies, so surely everything needs to be able to model the behaviors of their own body. But I think the point is actually a lot of animals don't, and that's why they have more simplistic, behavioral, models. or, like they, they're may be all model free kind of.

that's interesting. Yeah. Yeah. I can look up again which animals it is that, that, that applies to. but it's, basically some animals that have cortex don't have modal cortex, but it does generally come with a more limited, kind of dexterity in some, I think, have you thought about, how, or then how do we connect motor models with or behavioral models with objects?

Yeah, so what I was thinking was that we could basically use the feedback connections, which go both to V one and V two. I'm not sure. I would have to look up the MT two. I just, just think about it in terms of Monty, for example, let's say we, we are modeling bunch of learning models that are learning behaviors.

those behaviors have to be learned in the context of specific objects and We wanna associate those with those objects, but then we wanna apply 'em to other objects. I just, didn't, instead of a high level block diagram, how would those connections be made? how would, is there topology associated there or not? I guess not.

it's like mechanics. I'm trying to imagine the mechanics of, it might work out fine. I just didn't know if you thought about it. Yeah, I, haven't had the time to think a lot more about how we would apply a behavior to a morphology. Now I think it, it would still be the same mechanism because nothing really changes in the requirements if we separate the behavior and morphology models out there, just physically maybe more apart from each other.

but since we, I think, yeah, since before we assumed to use backward con feedback, connections basically from V two to V one, for example. I would assume the same thing could still be happening from MT to V one.

Yeah. And, just some kind of colocalization in inputs, which kind of fits with the idea that you would learn this behavior at the same time as this morphology, if they were looking at the same thing. it, since they, they der from the same. Map. So I suppose if I see a behavior in a new, it just might work out, it might work out fine. I'm just thinking, Yeah. And MT is also rettino topically organized.

I, have, if we're running outta time, I have a, general proposal just, and it may not, it's consistent with things I've said in the past. yeah. Do you want me to stop sharing? No, it doesn't matter. I can see you all if you wanna stop was useful to keep up. yeah, you might wanna leave it up. Doesn't matter.

there's, Monty is not a brain simulator, right? It's an AI system. It's a, and we, and the trick all along has been to figure out what parts of the brain we need to pay attention to, which parts of the brains we don't need to pay attention to. And in some ways, that is the entire, that's the most difficult exercise for anyone who wants to build a neural computer, is to, have one part. You have to pay attention which parts you don't. And so I think we've been particularly good at that in the past. and there's no spikes here. There's a lot of stuff we're gonna ignore. I think some of these details we're talking about, right on this picture right here are details, which we probably in the end could be inspired by, but really don't have to think about emulating at all. To me, Monty's already progressed enough that we need to. We're moving less and less, relying less and less on the neuroscience and more and more on machine learning ideas. 'cause as long as we don't abandon sensorimotor learning and a, repetitive, common algorithm, we can't go too wrong. though, so I just think we shouldn't spend too much time on these details. So I'm, already saying, okay, you've proposed a major architectural change to Monty, which is to separate out learning modules that are specifically for, behavioral learning behaviors. So that's a great idea. And so I think at some point quickly we should think about, oh, how would we implement that in Monty? And I don't think looking at all these things going on in these layer fours and, these stuff makes a lot of sense. yeah. I do think, okay.

Do you want me to stop? I can stop if you want, but I, may tell you what some of my concerns are. I've always reserved sort of the MT as this. Okay. This is a pretty major thing in the brain. I always felt that it was modeling, egocentric spaces and that, and so we model both behaviors and ob arrangements in egocentric. And now if you are gonna make mt do something else, then I then ask myself, oh, okay, do we still need to model egocentric spaces and, arrangements of things in egocentric spaces? And, if not, Mt. Where, so that's a concern of mine. That's a pretty high level thing. It's more it's neuroscience, but it's also okay. It's, a big idea. Yeah. I guess that ties in a bit with the voting question we discussed earlier that in, at the moment, basically all of the learning modules have access to egocentric location information.

and I guess we could continue to let all of them have that kind of information if we find it practical, but, and at some point it doesn't matter if it's the way the brain's doing it. And I think when, Niels and Viviane started this project, we talked about the essential elements that have to be in Monty. the things are the core principles that we cannot violate. And those include the distributed, learning system, integration of Sensorimotor integration. and as I said a moment ago, there's a lot of variation and that we could around that. and I think you guys have already done an amazing job of doing that. Monte isn't a neural simulator. It does its own things and it has its own ways of doing stuff, which is fine. I think it's great. In fact, it should be that way. So I, guess I'm just pointing out that. This is a major change you're proposing. I think we need to think through the implications for Monty and not worry about too much about the implication, although it may, this is what you're gonna say Viviane, but Yeah. it's actually maybe a simpler Yeah. So the ma, one of the reasons why I like this proposal so much is that it changes behavior models from a major architectural change to a pre minor change. So to add, if we do allow behavior models to be in separate learning modules from morphology models, then the main thing we need is just a different sensorimotor module that outputs changes and directions instead of, orientations and features. and just plug that into the existing learning module. Otherwise, we would have to rewrite our learning modules to have basically two mod, two models at the same time and test both of those at the same time. So it actually makes the change simpler.

So I, agree. So that's the beauty of it.

and then, so anyway. Just to highlight that it's not the only thing that would be needed, but, the biggest change that's necessary in either solution is to give learning modules stability to state condition. Its models. So depending on the coming context, like time or, state, expect different features to different locations and we would need that capability either way. But, that's, the biggest change. And it also feels yeah, a nice feature to have for the morphology models. Like it feels like it gets towards, I don't know, some of this kinda deformation Yeah. Key frame kind of stuff. Yeah. Yeah. And so in like very concrete Monte terms, this would be like key frames or multiple graphs for each object that lead to the same object label. And yeah, the state could also become part of the output of each learning module, like something that infers, and it can inform other learning modules on, on what state to expect. like a state in a behavior model informs which state in morphology to expect and voting can happen on stage to quickly inform. We talked about all this back in January, didn't we? this is stuff we, yeah. I think we can, we were discussing back then. Yeah. So that's not really a change as much as it's still there. Yeah. It's more like an elaboration of this, it is more what Monty needs. Yeah. Because Monty does not Right. This is stuff that's not in Monty right now, but it's not, it. We was, before we even proposed separating out learning modules, a separate, the behavioral models separately, we identified the need for this. So yeah, it is not a new requirement. You're just reminding us that we have, we still have to do this. It's stuff, right? So yeah, I'm just saying, e no matter how we implement behaviors, we need this. And yeah, this is basically, if I were to implement behaviors today in Monty, these would be the three steps I would take. Make a new sensorimotor module, give learning module, stability to state condition, its models. And then third would be to, give a learning module, the ability to, for the behavior to apply movement to another learning modules, movement input, which is the one that's still the most unclear in my head of how it would happen in the neocortex and how it would happen in, Monty, but basically like, how do we apply a behavior to a morphology, this kind of idea of applying movement to the morphology models reference frame. Yeah.

yeah. And yeah, it does, I hope this maybe makes the proposal more concrete for people who are more thinking In terms of Monty, I was mostly going deeper into the literature because I, it was really interesting and also I, wanted to see if. It's a realistic thing to think about that they could be separated physically. Yeah. I think the thing I would look for there is I look for physiological studies of mt. what do they know that MT does? that's the kind of thing I look for. But I, regardless, I know when, we start getting to those TRI eight V one connections, it's just a huge morass of data and it can be very, confusing. and so I, sometimes I worry about everyone on the call through, look at this guy, what the hell are we doing? it's it's so complex. but we don't have to do that, right? It's just our reliance on neuroscience will go down over the years, and pretty rapidly. Yeah. I looked at some MT reviews and studies. you anticipating every one of my questions here? Oh, sorry. You you anticipate every one of my questions, here's fine. No, it was more like I really had a lot of fun getting to read some neuroscience papers again, so I did a lot more of it than I was planning to. Yeah, but you had the slide right here. It's available right? Right here. Okay. Yeah. But I, read this, mt review paper and it had talked about all the connectivity, but it didn't even mention feedback connections. Like it was all just about feedforward processing. but yeah. I think it's hard with the response properties in MT because the experiments are so simplistic, if you like, it's hard to find a paper that would actually detect that it's modeling and object behavior.

So I can only find some general things like orientation tuning and binocular disparity, tuning directional selectivity. Yeah. And yeah, they say, quite complex though. There could be some sort of, studies where they disable MT and an animal doing a high level task and, yeah, see what the deficit is. that's the classic example. We've talked a lot about, you, de deactivate mt. And, now you, the person can recognize an object, but they can't reach for it type of thing. Yeah. I did see, which I was, I, which I always felt like that's indicative of its egocentric space modeling.

Yeah. I'm not sure which. I saw some papers on that, but I think they didn't have nice figures to put on a slide.

but yeah, I think this was the review paper. I one of t's main functions, above and beyond what is done in V one concerns integration and segmentation. MT appears to have built-in mechanisms to deal with this. Oh. Deal with, inappropriate merging of independently moving objects. for example, poncy has a disparity constraint and possibly other constraints to limit integration to a particular depth.

neurons tend to segment motion from its background. MT is involved in the computation of structure. Yeah. It's all oh, here, you apply the anything MT responses and the perception of 3D cylinders, the remarkable integration of direction, speed, and disparity gradients all make a compelling case that MT is processing motion, but doing more than computing the direction of speed and motion. Yeah. That would be behaviors. Yeah. Yeah. And I was just trying to pull up something from Joshua Tenenbaum's group and stuff on, 'cause they do a lot about like intuitive physics and stuff, and they do definitely talk about the dorsal stream being more implicated in that. I think. yeah. I was just thinking this morning before our meeting, I was like, going back to this list of basic topics I presented a few weeks ago and I was thinking like, all right. Let's, tackle something basic, recognize an object that go out and pick it up, and bring it into some pose, some, how do I do that, right? How do we take these ideas and, implement that, that's the, that's the test here in the end. Okay, great. We're modeling behaviors separately from this and that. okay, how do we do something basic with it?

But yeah, what I think is cool is, yeah, like you're proposing Viviane, like if we were gonna implement this in the grand scheme of things, it would be a pretty straightforward thing to add relative to at least some changes you can imagine for behaviors. And so it might not be that long before we can just start testing it and seeing how it works and, And like you can almost imagine, let's say we do revert back at some point to behaviors, meaning every column. I feel like what would be implemented the code for this separate one would probably be how you'd want to encapsulate it, for it to be a component in a learning module anyways. So yeah. If it feels unlikely that we would be wasting time by trying this and seeing how it, how it works, no, it seems like a reasonable assumption to go forward on. Yeah. And actually I was just thinking we could. Start with one and two, while three's not completely figured out yet. Like just testing how, what do we learn if we connect a sensorimotor module? That sense changes to learning module. does it learn a behavior? Can it recognize a behavior? And then also, adding the capability for learning modules to model time or different states generally a useful thing that we will need either way. and then both of those should give us really interesting results and capabilities on their own, even without being able to apply a behavior to a morphology yet.

Yeah. Yeah. Sounds good. Yeah. So can I ask my question? So I've always, from the very, very beginning of my interest in brains, I've always thought about music, right? would this suggest that learning a melody, that the actual melody itself is in the behavioral model and that the, instance of that melody, the key and the instrumentation and specifics are in beha, the morphology model, the feature model?

Yeah. I, guess you could think of the intervals as changes in, frequency, and then that would be a behavior model. But then the specific key it's in, I guess those are features. You're applying to that. You're applying it. So one of the problems I had when we did, the behavioral model back in January at our offsite, I said, wow, this could solve the, this could solve the, the melody problem, which is, recognizing melody in different keys. And, but I couldn't, but it, if when it was in a single column, I couldn't work because I said, a single column generally represents a certain set of frequencies or responds best. And I started reading the literature about brains representation of sound. But the problem was that by having them co-located in the same column, it was hard for me to apply the melody, which is a behavior to a completely different space in, in the feature space, which is the actual key.

it just didn't work. And, how could you, I have to apply this behavior melody to some other part of the cortex, which is representing different frequencies. but now by separating 'em out, I, still have the, I at least have the, I have the, ability to apply a behavior model in, in quote, the behavioral model space to, I should be able to apply to any place else in the morphology model space. Right? And the me, the mechanism for those to communicate should be somehow more flexible enough to accommodate that. I could take this key, this melody and apply it to different keys, which are represented different places in the, auditory cortex. I guess it's a, yeah. It's interesting to think about. Yeah. Yeah. Because we've talked a few times about Yeah, the connection of like displacement to in variance and song recognition stuff. But I agree it's clear with them separate with the melody though. Aren't you just, aren't you recognizing the intervals between the notes and other notes themselves? That's the displacement. Yeah. Yeah. That's the displacement. And and that's the problem, right? Because you, it turns out you can readily, there's a lot of details to that. first of all, you actually do, most people do know the key. They learned their song in, they think they don't, but they do. so when you hear Paul McCartney singing, yest yesterday or the song yesterday, the key actually, if you think you don't, but you can hear that's melody playing any key, and it sounds just as good as any other key. It's like there's, no preference in some sense. It's anyway, there's a, yeah. It is the interval. that's the, trick anyway. I think the behavioral model has the ability to capture the intervals.

Make that more concrete, Yeah, it's basically like the same way, like a feet, like diagonal bars or whatever moving. That's like the movement in the frequency space. Yeah. I can't remember when we talked about in January, it seemed like it was gonna solve that problem. I don't remember how, but somehow, I think part of it was also the matrix cell stuff that you're bringing in and stuff, but yeah, that's the matrix cell is just purely the timing and I think I've had that all along. So anyway, that's great. I, think, it's a pretty major addition to Monty, but not a lot of, not a lot of work, Yeah.

yeah, it'll probably be more work than it looks like on the slide now, but, yeah. I at least have a pretty concrete idea now of how it would get started implementing a behavior in Monty. So I guess in summary in January we came up the general idea of how to model behaviors, but we need, we, we assumed it was gonna happen in the same learning modules as the morphology models, and now we said, oh no, it's really a separate one. And so this is completing the picture or going onto the next stage in the evolution of behaviors that, is that a good summary? Yeah. if you're all on board with this, separating them out, then yeah. Does wanna argue against it.

No, I think it's definitely something to Yeah, I think unless we have a really good reason to reverse it, which we don't, and I think, yeah, the story you've presented is pretty compelling. Like we were like, oh, we need reference frames. And it's oh, we need this transformation, then we need this. It's oh yeah, wait, we've, everything's been doubled. And thing that bother, that's because it's just another learning module. The thing that bothered me is it required a whole nother set of grid cell equivalents that were driven by the same motion vectors, but anchored differently. I was like, yeah, could do it.

that's a lot there. Yeah. I think this is much neater. That's a lot to ask for a column. Yeah. A lot of modules to fit into. We have trouble fitting one set in there, a little and two.

Okay, cool. That's all right. Exciting. I'm happy.