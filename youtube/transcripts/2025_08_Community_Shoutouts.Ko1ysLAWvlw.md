yeah, I'll start with the shout out to the community again, which was a pretty exciting month. this month, I think. it's really getting more substantive, putting together these slides now, which is awesome. so first, some first time posts, just to highlight a few. for example, there were Steven who read one of our RFCs about, doing research while building a stable platform, and, posted some thoughts and, feedback and questions on that. And then there was Spencer who posted a pre RFC request. a basic outline of an idea and running it by us to see if it makes sense. an interesting idea around a phase a learning module was on phase, different phases. and then also Anna introduced herself in the general introductions channel. And great thing was that with our introduction also asked Hey, where's the best place I could help out? and suggested two things that were on our future work roadmap and whether they're still up to date and what would be most helpful. And, I'll have another slide later of where we ended up, And then got several interesting questions. For example, here was a question about, how we even define intelligence. How that compares to how intelligence is, defined in the arc. channel paper, challenge paper, which Jeff answered, yeah, we actually had two posts about using Monty for audio processing, which is pretty interesting. actually I think today there was another, more long form post about a potential way to convert audio into a spatial representation and train Marty on that. So I think it's an interesting direction. Interesting to see that this is something, people are looking into our applications. That, would be interesting. and then, yeah, just another, a small comment on one of our research videos, just referring to an interesting other talk, by a neuroscientist, about, yeah, representation of space. that's, this was on, our research meeting on grid cells and, path integration and yeah, mechanisms of representing space.

we had a, a pretty long form post with some questions about reference frames and Monty and how that works and, the brain as well. And then, Yeah, just some kind of thoughts on our research meeting posts about, for example, this one was on, a meeting about modeling object behaviors. And the idea that Adam proposed was actually using the second order derivative, instead of, velocity acceleration that, that might be interesting features to represent as well for object behaviors. and yeah, so it's, really cool to see, people think about these topics and watching our research meetings and engaging. here was another question by Adam about, a topic we've discussed in our research meetings recently on like, how do you learn something with one sensorimotor that gets during, in one learning module, then it further with a different sensorimotor. how, could that work? and then yeah, generally also got, feedback on suggestions. for instance, feedback on. an RFC that Tristan has drafted about the cortical messaging protocol and generally on, design patterns in Monty. And then also a bit of, feedback on generally the, video formats and chapters and, that sometimes the audio isn't as good. but then also, here's Agent Rev put together, like an AI summary of the subtitles from our videos.

and then yeah, helping others. It was also really great to see, for instance, someone posted about, installation problems of Monty and then several people jumped in and tried to help out, figure out how to set up Monty. and then actually agent Ref, posted a couple of days later a full blown tutorial on how to set up Monty. I can. actually maybe pull that up real quick. 'cause it was, really nice, like a full, step by step, way to install it on Windows, using Windows subsystem for Linux. and yeah, also then replying to follow up questions.

yeah, this literally saved my life after a week of trying to install it with Claude. So thanks a lot, for writing this. and then we also had several, PRS from external people this month. for instance here, Anna, submitted a PR refactoring, that changes the gatherers to properties using the at property. and then, here. Al I think, Lucas is his name. saw an, old to-do or not, but a to-do that I added in the code probably like three years ago, saying there must be an easier way to do this. And he basically just picked this up and implemented an easier way to do this, which is, it, used to be like several nested for loops and he changed it into a single, vector operation. yeah, just really great to someone just seeing it to do in the code, picking up, fixing it and submitting a pr. I think it, it was approved today to be merged and passed all the tests and everything. and then we also have a new contributor on our roadmap, which is Anna I mentioned earlier. She ended up starting work on this item about combining data load and dataset into, environment interface class. so when we first started Monty, we, used traditional machine learning, conventions from PyTorch, or naming, which was data load and dataset and basically using indexing as if we were using the, working with the dataset. But Monty is a sensorimotor system that works in an environment, and so this has been bothering us for a long time that this is confusing people when they come to Monty that we are not working with the dataset yet. Our classes are called data load and dataset. so this refactor will be, really useful, for that. and yeah, she's opened a draft PR already. It's in, in progress right now and I saw today, posted a couple of follow up questions and updates on how it's going. So thanks a lot, Anna, for working on this. And then, we have our first, community work group. Colin had posted, towards the beginning of the month a pretty detailed analysis of, whether it's worth it, accelerating learning modules using GPU operations on Cuda, and implemented several of the main operations in Cuda compared how they kinda speed up compared to CPUs, with different batch sizes and so on. And it looks like there can be significant speed ups. So we had a bit of back and forth on the exact results and, whether we wanna paralyze within learning module or also cross learning modules. And then ended up, Tristan ended up creating a second topic, going into more details of how this can be now turned into first a prototype. and then. a community maintained, repository, for GPU backend for Monte. a lot of detailed plans, and back and forth. And, he also shared this really well organized code repository for it. And here is the first video recording of a meeting of, Tristan and Colin, talking about all this, which will be hopefully our very first kind of community edition video of a work group with someone, from the community working on an important feature of a thousand with a thousand Brains project. So this is, really exciting and really happy to have Colin contribute to this, in such a great way.

then there've also been several people, sharing a thousand Brains project posting about. it all hinges on thousand brains project. If they can't find the way, no one can. someone else posts something. And then, here someone commented on like Monty scoring similar wins. recent example sharing the ultrasound demo. and yeah, Greg posted two more, really nice blog posts that mentioned a thousand Brains Project once, one about catastrophic forgetting and one about, reference frames and using them for navigation and then learning in general. and here mentioning a Thousand Brains Project as one of the promising bio-inspired machine learning approaches. yeah, thanks a lot for to everyone who shares and likes, the project or comments about it and mentions it. And lastly, this was a couple of days ago, I think it doesn't look as balanced anymore, but we reached the 400 stars and at the same time also 200 forks, which is a great, 50 ratio. and yeah, thanks to everyone who's star or forked or repository, super exciting. And yeah, I'm really curious to see, what people are actually doing with the code when they fork it. So if anyone is watching this and wants to share on our discourse forum, please do.