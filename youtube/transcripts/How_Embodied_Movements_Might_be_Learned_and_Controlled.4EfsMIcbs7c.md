all right, let me just, I just have two slides, but they're, they build on top of each other. So we're gonna really pop up a light. First of all, we talked about the cortex interacting with sub-cortical behavior generators. and like the cortex sits on top of the old parts of the brain and tries to control these old parts of the brain. So this is, I'm gonna build up a picture of that right here. So here this little rectangle represents something that's a subcortical behavior generator. It actually, it's orange output here. It drives motor someplace, and he gets some sensory input. Examples of a subcortical behavior general would be the superior colus. This is the ones associated with eye movements, the brainstem that's associated with a lot of the limb movements and walking and things like that. and breathing and things like that. The spinal cord, I don't know what the basal ganglia acids has direct connections to motor neurons. It doesn't really matter, but I put it in there. The point is these are, there's a bunch of brain regions that are not cortex, that actually control neurons that do things, whether it's breathing, moving your limbs, moving neuro rods. So I gave examples of eye movements, walking, breathing reflex or limb limits. These are all sub chordal behavior generators. It's important to maximize that sometimes these, things are fixed. You can think of like a reflux reaction, but they can also learn the general rules they can learn. So when we talk about the cortex interacting with these, we have to, we can't assume that this is some fixed motor system that doesn't change over time. And generally they do, they can still be reflexive, but they changes your body size, changes, your, the trauma injury and so on. Okay. So that's what a subcortical, generated. So like the superior click, this is a great example. It gets input from the eyes, and some other parts of the brain too. And then it generates eye movements. mostly non-model based eye movements, like there'd be, reflexive or to tend to some motion, things like that. Now, the cortex sits on top of that. And so let's just talk about the three properties that really matter here. The, first of all, the cortex projects to these subcortical behavior generators. There's no neurons in the cortex that we know of that project to motor neurons or muscles, you know what I'm saying? I should say muscles. the cortex doesn't control any muscles.

the only thing it could do is it projects to, subcortical behavior generators, which kind of makes sense. and in one way, because, a couple ways actually. One is you don't wanna have two different people trying to control muscle movements. the cortex says, move left and your spinal cord says move right? And what's gonna happen? but it's, also, it's more important to that as it'll become clearer, hopefully. So the idea is that, columns, learning modules, Monty. can only affect behavior by driving these, subcortical behavior generators, which are, much more specific body specific, types of things. We have a general system, this cortical column driving a specific thing and because that spec, because the column doesn't know what that specific thing is, right? A cortical column doesn't know what it's projecting to. It's, a generic learning module, that it has to learn how to drive the sub cortical behavior generator. It has to learn to control it via associative learning connections. So this is not a hardwired thing. It has to figure out how am I supposed to control this thing. So to do that, the column first has to learn a representation of the, of what the thing is doing. You, can't just say, if I'm going to tell the eyes to move, I need to know what, I'm gonna tell, if I'm a column, I want something to happen. I have to know something about the thing that I'm trying to control. I have to know what it does. I don't know if this is clear, but for a generic thing, like a learning module or cortical column to control a specific thing about something below it has to first learn what that specific thing is does so that it can control it. is there any questions about that before I go on?

Don't be shy. Okay. Are you still there? I can't see anything. Yeah, no. Sounds good. Okay. Thank you. Alright, so let's now talk about vision specifically. So what we think is going on in vision is that the ulu moves the eyes that this is, this little arrow is like the feedback from the world. As the eyes move, the input from the center changes and that input comes back up. Into, not only into the superior colus, but into the cortical column. And we've proposed that in this case, there are two inputs from the eyes. There's the mag side of the pathway shown in orange, and the powerful side of the pathway shown in p with a P in green. and the magnet side of the pathway really represents flow patterns on the retina. So the column can observe flow patterns on the retina, which are direct indication of how the eye's moving and it can learn, says okay, it remember a column doesn't know what these cells mean. It has no idea what these inputs mean. It's just, it's a bunch of neurons coming in. It says, okay, there's some changing patterns here. I'm gonna interpret that as some kind of movement and, I'm gonna interpret that kind of movement and then I will, and if I learn what those movements are, then I will know what the subcortical motor generator is doing and I can now control it. If it, if, this thing can move the eyes left, right up and down and I can see that the eyes move left, right up and down, then I can say, oh, I can tell it to do those things.

and so you, it's this feedback loop that allows the column to learn how to control this thing. And I wanna go into details how it does that. So how I think it does that, these principles probably have to apply to Monty as well in, in an embodiment of Monty. Any kind of embodiment of Monty, if we're gonna have a generic learning module, it's, very likely that, and, there's some embodiment that there's gonna be some subcortical behavior generators. This is our model free policies that, that you all been working on, plus others, that the learning module will have to learn to control those. And, and therefore it has to have something like this kind of feedback loop and, this basic process going on. Now I'm gonna talk about how this might be done in the neuroscience, which I will say once again, doesn't mean we have to do this way. I also say that I don't really have a, I'm not a hundred percent certain how it does, the neuroscience does this. I have some pretty important clues and I'll share those clues. but it's still a bit of a mystery. so let's just go into that. So here now is, let me just, how do I hide this? I have this thing on my skin. I wanna hide. There we go. here we show a, column, it's called it B one. And these little dots there represent neurons. And some of these neurons are in minicolumns represented by these vertical arrangements. So here's an observe. An empirical observation goes back many years. The cells in these minicolumns in layer five and six, we're just gonna talk about layer five and six. Right now, they seem to respond to movements of edges in particular directions.

and so that's, just these little blue pictures up here. These are representing the receptive field properties of these cells, like this would be an edge moving in this direction. This would be measuring vertically. This is edge, the same horizontal edge moving down. and so it, as you go across the column, you'll see all the different orientations and all the different directions they can be moving. All the cells, I shouldn't say all the cells, but the cells within the minicolumns seem to respond to that same basic orientation and direction. And the next mini column over represents all the cells, respond to a different orientation, slightly different orientation and direction and so on. in the lower layers of the cortex, these cells all respond best to very long edges, which is what you would want for movement detector. You'd want, you're trying to detect flow across the entire retina. That would be the most important thing to detect for movement of the eye. And we've talked about earlier, a lot about how in the upper layers, the cells have similar response properties, but they're much smaller, receptive fields, which would be more aligned with the object moving in the world. Versus, here it's the eye moving, relative to the world.

does anyone have a question about that so far?

It just makes sense. No, sounds good. Okay. Yeah. All right. So I've always wondered like, why would the cortex have all these cells that respond to the same thing? It's what's the point of that? it's it doesn't make any sense. And if it, I don't have a picture of this, but in the layer four, we propose that, oh, all the cells respond to the same thing outside of context, but within context, a single cell will become active and it forms a unique representation of that item. Something similar I think might be happening down here.

let's see here. Whoops. Why am I not progressing My slides. Oh, here we go. Alright. so my interpretation, this first thing was an empirical observation. My interpretation now is that these minicolumns, these represent a basis set of movement vectors. I've already talked about that. Each one is like how the eye moving relative through the world in reality, if this is learned, and I think it would be learned, it wouldn't be, it doesn't have to be so simple like this. It could be, it's, the different movements could be, into the plane, out of the plane. There could be a bunch of different things that are represented beyond just edges moving in, in horizontal directions.

so we would expect to see minicom, I would expect to see mini comms that don't fit perfectly into this arrangement. And I think there are evidence for that. These are, those are the, these are the classic, these are understand ones anyway, so that's an interpretation that these now represent, movement factors.

but then, a prediction of this theory would be that, the, these many, okay, so now this gets to the part that, Hojae didn't talk about, this oscillatory interference model for how grid cells are generated. And it's really complicated. I can, I'll show you a picture just to show you what it's about, but what it requires, grid cells require, and I'll show you a paper showing this. Grid cells require that these many, that you have a velocity controlled oscillator, meaning there's a cells that are firing at some frequency, and if the animal's moving in a direction, then that frequency increases. Okay? So there's a background frequency, and then you start moving the, move the velocity. These cells would say, oh, this whole column would become active saying, oh, we're moving in this direction. And the faster I move, the faster the oscillation of these cells. That's what velocity controlled oscillator means. I, is it the oscillation or the faster the phase moves through? it's the oscillate, it's the oscillation, which will let me just fill it out next. Okay. So imagine it's going at some, let's say 10 hertz. And now I start moving in a direction, all these cells are now firing at 11 hertz, all of them. And if I go twice as fast at 12 hertz, something like that. But this is also prediction based on theory. I would predict that these cells are all firing at a different phase in that frequency, in that cycle. So they might all be firing at 11 hertz or 10 hertz, but when they actually spike, the individual spikes coming outta the cells would be shifted at different periods of time over that frequency, over the, a period of the 11 hertz or the 10 hertz single. So if it's a 10 herz signal, I have I have a hundred milliseconds. and maybe each of these 10 cells would, peak at different points every 10 milliseconds, something like that. they're all fine with the same frequency, but they're phase shifted.

Yeah, No, that makes sense. Yeah. So one way of conceptualizing is like grid cells for one dimension. if you were just moving in this direction, right? just a grid cell, every, like Imagine the spacing is the entire length of this, this mini column. So the, cell at the top is gonna fire again after you've gone through all the other cells. And gone to the top. If you start moving faster, then each cell is going to fire more frequently. Very, close, but not quite, very close. They're all firing at 11 hertz or 10 hertz. but they were firing different, but only when you're moving, right? Only when you're moving. But they're at different phases. So at the moment, if I just looked at these cells, they wouldn't tell you where you are. It's when you compare them to a background frequency. So let's say there's a background frequency at 10 hertz, and the base frequency of this mini column is 10 hertz. At that, in that case, only one cell would be peaking at the same peak at the background frequency, because the background frequency is going 10 hertz and the cells are faring different points in time throughout that 10 hertz, throughout that a hundred milliseconds, but only one cell would be peaking at the same point in time as the background frequency. But as I speed up the frequency of the firing of the mini column, the, cell that would down peak with the background frequency changes.

and so which cell is in coincident activity peaking at the same time as the background frequency will move up and up this column, or it'll move along here, just like you said, and it'll repeat again at the bottom. And so if I look at which cell is, if I now say I'm gonna only, I'm gonna check my position by, which cell is, peak, it has the same spikes at the same time as the background frequency, then, this becomes like a one dimensional grid cell module.

And you're right, it's only when it's moving, which is, it is a problem, but it is like a one dimensional grid cell module. And I guess even, at a certain level, even without the background, it's still like a one dimensional good cell module, but just where it's operating so fast that it's hard to read out because, you could read out, there's no way to read it out, who's to say, but un unless you had like a coincidence detector that was at any given, like when this one spikes, you're, because of the phase difference, they are gonna spike at different times, right? but the only way to know which is the right ones, you have to compare to the background frequency. If you don't have the background frequency, it's just a bunch of cells that are just spiking and they have different phases. And so what can you tell from that? Not much, but it's only when you have a background frequency, you could say, oh, there's a coincidence between the background frequency and this thing that I know, which is the active one. Which one I'm supposed to, let me show you a picture.

how do I get out here? I'm gonna show you a picture here.

I get this, I get this stupid thing out of my, zoom thing here. Okay. Yeah. We, see that. Okay. This is a paper. This is the paper I mentioned earlier. It's called a hybrid Osto Interference, continuous Attract Network Models for good cell firing. It's from Burgess. Neil Burgess is an expert in all this stuff.

this figure is a, it has all the information we needed in it. Okay, so it took me a long time to understand this figure. These are grid cells, these, black circles down here, okay? These are grid cells, and this is one grid cell. you see my cursor moving around? Open? Yep. Yep. These, I'm gonna tell you, these are the cells in the mini column, okay? And these are the cells in another mini column, and these are the cells in another mini column. This paper does not make that argument at all. This paper make a theoretical argument that you need something like this. But I'm telling you my interpretation, these are the cells in the minicom. These cells in this minicom all respond to movement in a particular direction. These cells in this minicom all respond to a movement in a particular direction. These cells, in this minicom all respond to movement in a particular direction. And, they all fire at different phases, the speeds that all the different phases. So as you're moving here, you go all within a hundred milliseconds or whatever. It's, and they're showing that there, they don't show it here, but there's a background frequency. The, that is also firing. And the red cell is the one, the sp the spike of the cell. That is, that is in coincidence with the background frequency. And these aren cells are close enough that they also are coincident activity, but not as strong. They're close near, they're spiking near each other. Meaning this is spiking just before or just after the background frequency. But this is backing right on the background frequency. So you'll see a bump of activity going on here, actually. and so the input to a grid cell, any particular grid cell will, is derived from this set, right? So a grid cell is not movement direction sensitivity. The grid cell is, is just says I'm in some location. And what Burgess Niels Burgess is arguing is that, this particular grid cell gets inputs from a particular set of red cells here and another grid cell gets a, different set of cells. And so if all these cells were doing something very similar to this, the each one would respire, would, activate just like a classic grid cell does, independent of the direction and, and, have all the properties. We expect this lower cell here is essentially an inhibitory neuron or an interim neurons, a set of them, which are essentially, gar. It's keeping these cells active even when the, in, when the animal's not moving in some sense. And so this is the contin. This represents in the language we mentioned earlier, the continuous attractor network, meaning it's continuously keeping one of these cells active or a group of cells active in the grid cell space. and yet this is the oscillatory interference model, which explains, how grid cells, why they change where they fire and, why when I move this one cell fire, then the next cell fire and the next cell fire. Again, this is a complex picture, but you can just think of these cells as a mini column. and that's all I'm gonna show from this particular, paper, unless there's a question about it. What, exactly is the background frequency? It, there's a, what is it? I always forget which one is, it's called the beta frequency or something like that. It's beta. Yeah. There's this sort of, these, are empirical observations, that there's these frequencies that are continually running in the hippocampal complex and the same in the cortex. and they, I think they're generated by the thalamus, but I'm not sure about that. So there are these observed oscillations of various frequencies that exist in the brain that are pretty well known. And, in the Toronto cortex is, there's beta frequency, I think it's eight hertz or something like that.

This, let me just show you the basic idea of the o atory interference. This is from another paper. I dunno if it's helpful. Just to quickly on that figure, just for clarity sake, like you could have this system in theory set up so that all the V Cs use a rape code. so basically as you move along, let's say the neuron, FI two, it fires, with a high rate and then you move along and it's not until you move far enough along that it fires again. But it's, I suppose it, it is only because you, it is encoded in phase, then you need this background frequency to, decode it. no, you still, I think because it, that makes sense and I think that just helps to understand this, that it's maybe a bit less mysterious than it might seem. Okay. It's basically like you have, you're creating a, grid cell that can path integrate in any direction by having, these six, This alright. This is main the point you made earlier. yeah, in theory you could, in theory you could, like you said earlier, I could have a mini column and as I move which cell is active in the mini column, it indicates your location. Yeah. There's just one cell active and it's just Primary kind of that would, that is correct. That's not going on in the brain. But that's right. It could, that in theory, that's what it's conceptually that's what it's doing. that's just turns out not the way the neurons do it. But yeah, I just mentioning that. 'cause I think that might help to understand this figure. 'cause then it, it is a bit simpler. It's just okay, yeah. They're basically just like 1D grid cell, Sensitive for a particular direction. and the, these different cells around the ring, those are the different phased, phases. For this 1D kind of, it's almost like a min, it's like a 1D grid cell module. And these are all the different phases. but for now, for, it to get to this to work, get this to work, to add one more level of complexity on that, the active cell here, this red cell, whether it's a activity or it's a, it's a spiking cell. It's spiking and not spiking or whether it's in phase or not in phase, this is, has to be anchored. This has to be anchored from an environmental clue that is when you enter a new environment, if I recognize the environment, I have to reset these to the same point as they were before.

you have to re-anchor these one dimensional grid cell modules, in the same way that two dimensional grid cell modules are anchored. I, just mentioned that it's a complexity of the system, but it's not like these, which cell is firing, how do you decide which one to start with? It's it's, so you could pick randomly initially, but then as you learn an environment or in, the case of model, you learn a model of something when you, part of recognizing the model is anchoring the location again. And that means picking which of these cells will be active at any point in time. but you're right. I think I, why am I, you said you tried to make it less complex and I just made it more complex again. Yeah, no, that's okay. and then maybe just to then quickly recap, some like basic physiology like neurons will struggle to integrate. like temporal, codes, unless there's something to basically help them disambiguate that okay, this is the relevant bit. if all of these neurons are spiking at 11 hertz or 10 hertz, whatever, Jeff was saying. Yeah. And a neuron that's receiving that information, like how does it know which of those cells that are all sending a spike every a hundred milliseconds? Which of those is important? And that's where the phase, alignment comes in. If, you look at our paper, why do neurons have thousands of synapses? We described that what neurons do is they have, they act, they, require a bunch of incoming spikes to occur at the same time or very close to the same time. So if they're spread out over a hundred milliseconds, the cell just ignores them. But if they all arrive at the same within a few milliseconds of each other, then it's, oh yeah, that's it. So, that is what I think what you're referring to there, Niels, was this need to, yeah. disambiguate. It's not just, so if you think about how neurons work, but they need this coincidence spikes, then this phase thing makes a lot of sense. if you, say these are just, some spiking rate, they're all spiking at some, at different points. And how do, we differentiate different cells have to anyway, it's so complic, I can't keep it in my head at once, but, but the actual in neurons, the actual timing of the spike arriving is important.

again, I don't think Monte has to do any of this stuff, but I think it's gonna get back to an interesting property that things we do have to do. Alright. It's good point. Anything else you wanna say, Neil or anyone else? Just another question, or, this might be really, I, might be missing something really obvious, but, while we are not moving in one of those directions, how is it maintained where in that, on that ring sequence we could, I don't know. I don't know. Oh, okay. That's a good question. so yeah, I've asked myself that question a lot.

the evidence we have is that these cells stop firing also. They're one directional, so if you go the opposite direction, they don't go backwards, so that's, yeah, I think the implication was the grid cell is all anything downstream cares about maybe. and that's what I guess you were saying. Yeah. Is like the int neurons and stuff helps basically say if I'm not moving this grid cells cell stay active, all the other ones are silent. This one has the machinery stay active. And then, but when I start moving again, but when I start moving again, I have to start up where I left off. And, I may be, moving in a different direction, which case I have a completely different set of rings that are active.

yeah. So I was wondering if it's like a similar mechanism to the inter neurons on the grid cells that could be used there, but I think it's actually a nice thing that the, that there is no like reverse of direction. 'cause that way you don't, they don't need to learn what's the kind of opposing movement to them. But the grid cell, automatically learns that. maybe I, don't know. this is like evolution going out to extremes to figure out how to solve a problem. and, and it's complex solution.

but apparently this is what it did.

by the way, if you're following all this, the, a core column has, minicolumns that, go across all the layers. So the, our cells are organized in a mini common layer four and layer three and layer five and layer six and so on. And I've come to under, I come to this basic idea. Maybe, I should, go back to that. The moment here, you can see this now, that there are these mini, that essentially a mini column within a particular layer is in some sense always doing the same thing. It's, it represents something in part, something generic of which an individual cell represents a specific instance of that. And a mini column on its own is not very unique about all. Just like a, a one of these movement vector cells doesn't tell you where you are in a larger environment. But if I were to look at all the active cells in this area, it would be very unique. And the same thing in layer four. If I look at layer four, it's representing a say an edge orientation. but even if I pick one of the 10 cells in layer four's edge orientation, it's only one in 10 locations. But if I look at multiple minicolumns in, in that thing, it would be, it would be unique. So I think there's this idea of a minicom is essentially this processor that goes from, a set of cells that are not unique to picking one, which is still not unique enough. But then you combine across multiple minicolumns that's unique. Anyway, I don't know if that makes sense, but, okay. Lemme just, I wanna go back to this.

there's a property, there's a property of grid cells in play cells, which is almost a, guarantee that this oscillatory interference system is working. And this is something that's called phase per session. So let me just don't look at the picture yet. Just visualize in your head. Imagine you're looking at a grid cell and an animal's moving. And as it moves to a certain location, in an environment, the grid cell fires, and when it passes it, it stops firing, right? That's what grid cells do. You go into its location, one of its locations, it starts firing, and then it stops firing.

When that fire, it turns out that the, when that fire cell fires relative to the background frequency changes as it moves through the receptive field of the grid cell, it, its phase of firing recessive. Meaning as I'm approaching the area where the grid cells supposed to be active, it fires post the peak of a background frequency. When I'm in the location of the, center of the receptive field, it's firing, coincident with the background frequency. And as I move beyond the receptive field, it require, it requires prior to the background frequency that's called phase procession. And in this diagram, we now look, at this diagram. We can see what they're showing here is this, these little, so when the cell, spikes, at different phases of the background frequency. So what's, basically going on here is there, this is labeled dendrite and soma, but just think of this is this red line here is, the background frequency, think of it that way. And this blue line is the modulated velocity controlled background frequency. And so they're slightly off. if, they were, if the animal's not moving, there'd be the exact same frequency. But since the animal is moving, the blue one is slightly higher frequency than the red one. And if you add them together, you get, a wave like this.

And, what it, this is basically showing, is this point right here. If you can see where my cursor is. This is where they're coincidentally aligned. They're right, perfectly aligned. So the output that, that some of these two spikes, these two frequencies would be maximum. And so this is an area where the cell fires, and then when it goes into this trough, the cell doesn't fire because these things are misaligned.

And, just the physics of it works out that, and this picture tries to show that, the, firing, a as you get closer to this point, these things aren't exactly aligned. So it fires, but they start firing anyway. And so it fires when, the it's not lined up with the peak anymore. It's lined up with a maximum. Is I don't know how to describe it better than that, but it's an explanation. This oscillatory interference, it's an explanation why you see this phase procession, and it's hard to imagine how you can get a phased procession like this if you didn't have this oscillatory interference. So this is like the, clue that told people that I believe it. Once it started that way, people noticed the phase procession, then they said, that must be generated by this oscillatory interference. And that came up with this theory about grid cells and how they operate on oscillatory interference. This particular paper was discussing a different flavor. It was saying that the individual dendrites of a neuron, or like a good cell would be like, would be like the, like the circles of cells we talked about earlier. eachs dendrite would have its own sort of frequency. I don't think it's right, but that's what this paper is showing. But this gives you the sense of where did this oscillatory interference idea come from? It came from this observation of phase procession. That's a pretty much detailed Yeah. Out of your interest, what's your concern with each dendrite having that property? Because it seems like, 'cause yeah, without it, you need a lot of cells just to have one grid cell, and so to have Yeah. Good cell modules, then you need a lot of cells. so it would be nice if that was the case. Yeah. I'm trying to go back to my memory right now. it required that these dendrites have some pretty special properties. it required that individual dendrites were, were like velocity controlled oscillators in particular directions and something like that. I'm trying to remember now, Niels, like I, yeah. My memory is poor on this. that sounds a little bit like the, translation in variance thing you've talked about.

if you move along a certain direction and then you activate certain synapses so that it's, oh, yeah. Maybe, I don't know. I have to go back into it. Yeah. I felt, when it was just described, I felt like, oh man, that seems too hard. I don't think that's right. It was more like they're stretching it here. It's there were, this is less of an observation, oh, we could do it this way. Whereas this picture, someone said, no, they're separate cells. And then I said, oh, yeah, but, and then, and I knew what the cortex looked like, it looks like this. So I said, oh, that's pro, that's evidence that the ring idea was more corrective.

but it, I can't prove it. I said, look, I, don't un, I don't know this for certain. There was a number of things on the dendrite hypothesis that made me feel like that's squirmy, really. But it could be, it could be, I don't know. Let me just finish up here. so we started here. I made this predictions.

so if I'm right then, this, these phase per shifting of these, the different phases of these cells, barring would be something that could be measured in a lab.

and, then, the other thing here, which is really nice about this hypothesis, and it's not, I can't compare it to the dendy hypothesis we just talked about, but this hypothesis in general is in some sense, imagine I have, how many minicolumns do I have in a cortical column? that depends. at a minimum would be a hundred, probably several hundred depending. Now as I'm moving, oh, maybe outta three out of 10 or 30 of these columns are active, right? Because the, because it's like a bump of activity, right? It's this is the most active and the next one over and the next one over a little bit active. So let's say three out of 30, or maybe three out of eight, three outta 10, let's say 30. So if I have a, let's say I have 200 minicolumns, and at that point, 60 are active, right? 'cause there's gonna be re repetitions of these. So I might have 60 as I'm moving in a particular direction, I might have 60 meaning columns that are active, either strongly active or active per year, just pre or prior to it. And and I'm picking one out of, let's say one out of 20 cells or one out of 15 cells to be in phase. So let's say it's, let's even just do one out of 10. It would probably more than that. So I have a one out of 10, but then I can do that by, it's 10 to the 60th. So the number of unique locations I can encode as I'm moving in a particular direction. It would be 10 to the 60th, just in, I'm not understanding your comments from earlier. So I'm sorry if I'm not including that.

and so that's a really big number. I could encode a very large location space if I were looking at the individual cells that are firing. Once I put 'em into a grid cell format, it's not so good anymore. I've lost a lot of this, property I want, a lot of small modules that each one is picking one event, but once I put 'em in, if I put 'em in a grid cell module, it's like I've lost a lot of that information. So one possibility and I just don't, I don't really understand it. One possibility is that nature said, okay, this method I'm showing you here is really the way that location is encoded. Grid cells are required as a stable storage mechanism to say, okay, yeah, when movement stops, somehow remember where you were. And we wanna reignite these same cells again. and so I need some sort of memory to keep track of where I was in this, matrix. But this matrix here that I'm showing you of all these minicolumns fits the build beautifully for a very high dimensional, unique location space, as long as, but I've got some issues with it. So it's not perfect. but it's better than grid cells because grid cell modules, because I don't have enough, I would've to have a whole bunch of grid cell modules, classic grid cell modules in this cortical column to get it to work, to get a unique location. And we don't seem to see that, but. You do see this, and by the way, these cells would appear gritty in some sense, or at least cells that based on 'em, would appear gritty. They'd be like one dimensional. These are like one dimensional grid cells in some sense. And if I consider them in phase, with background frequency, then I would find cells that seem to be one dimensional grid cells. And we see a lot of that. We see a lot of movement sensitive grid grittiness cells in, in the enter cortex. I'm sure we'll see them in, in, in the, in your cortex too. It's not a complete theory. I, it doesn't all make sense, but it's at least the best I am right now. let's keep going here. So the, I wanna now bump back up to Monty. Okay. Or back up to large scale theory. The theory I have is, and if we take vision, the magus cell, the cells from the retina are center surround, receptive fields. If I take those cells and I feed 'em into a spatial pooler, what the spatial pooler says, I'm gonna represent out of, these in n and, n most common patterns. It's like the spatial pooler always outputs, let's say three outta 10 or three out of 50 or something like that. it, it defines a set of, minicolumns that each represent the, a common pattern in its input. And so I would naturally, I believe if I took the mag set of the cells from the retina and I put 'em through a spatial pooler, and I said, okay, I wanna represent these by 200 or a hundred, minicolumns, each one being it, I'll output the spatial pooler. It would learn to represent these kind of things. It would say, oh, a common pattern is a, these things become active when the cells move in this direction and these cells become active when moving in this, that these receptive fields could be learned, from the center round RFS of the Magnus side, the pathway. Clearly the cortex isn't getting any movement in, primates. The cortex does not get movement input from the retina. It only gets these center surrounds, or they're not movement, they're just change detectors. And, but I believe the spatial pooler would turn 'em into these receptive fields. And so this is, these essentially are the cortex is interpretation of how the retina can move. These are, it's basically saying of all the ways the retina can move, I'm gonna represent it with these n minicolumns, each one representing some sort of, basic one dimensional vector.

I believe that the layer five A cells would share that same representation. So the layer five A cells are now encoding, the same basic, interpretation. They're saying, okay, these cells would then represent, a, this cell would layer five A, this would represent activity of an edge going this way, or the retina moving this way and this one retina moving this way, the retina moving this way, or something like motion on the retina. And so I have internally, now I have everything I need. I have a way of forming, of learning how the retina's moving, forming a representation of it. I then can use that representation to form unique locations in space. And I have my output, which I can send back to my, my, pattern generator. oh, I already mentioned this here. One cell in each phase is sufficient in code unique location. So go back to my previous picture here. This would be, this orange line is the layer five A cells saying, okay, you ge subcortical learning generate, you generate some movement of the retina. I have no idea what it is. I, observe that movement through these magnet cellular cells. They come in as just bunch of whole bunch of bits. I don't really know what they are, but I'm gonna run through a spatial pooler. Now I form a representation of a sort of a set of basic movement vectors, one per minicom. And now I can send that back to the SubCal behavior generator. It says, when you're generating the behavior of moving the eyes left, this is my interpretation for it. So I'm telling you, let's, associate my representation with your internal mechanism, which I have no idea what it is. So that way in the future I can tell you to move left or I can tell you to move, right? Because I've now learned how to control you through observation.

That's, the upshot of this whole discussion. This just answers like how the column knows what to communicate to the motor system, but not how it selects which movement to send to the motor system. it, doesn't have the property that knows to get from the location I'm currently at to a different location I wanna get to right? It, layer five doesn't know that layer five is now what we have to introduce next is the allocentric model in the column that can generate behaviors by stringing together these basic movements. Yeah. Okay. That's the whole point of this, right? The point of this is you, first you learn this, how do, how to control the subcortical behavior generator by observation and say, okay, I'm watching you, I'm watching you, I'm watching you. I think I understand what you're doing. I'm, I now have established that I can tell you to do that too. But now I'm gonna, I didn't show, I had a picture over here, but I took it out. Now I'm gonna, I have a, very sophisticated model up here based on my grid cell mechanism, based on my location system, and my model is, I have a model of the world. You don't have that. I have a, the structured model of the world. And now if I wanna achieve something in my structured model, I can stream together a set of basic controls to you to tell you how to implement it. You don't know what's going on. I'm telling you, I'm figuring out what to do and, I'm telling you, move this way, move that way. With vision, it's a little less clear that you know exactly what a V one model would be doing, but if you think about manipulating your fingers or moving your limbs and so on, it makes a lot of sense. I might, if this was a, somatic sensory system, I might be observing reflux behaviors of grasping or, just basically basic movements of the fingers and, the limbs. Here, I learned how to control them and now I can string those together for new purposes based on my model, my learned model of the world. The column would still have to do a reference frame transform on the motor output. Remember I didn't show that here too. I took that picture out. Okay. I should have left it in. if we go back to our paper, we just submitted the manuscript we just submitted about the hierarchy paper. In that we talked about the thalamus does the conversion from oops, from a, egocentric to an allocentric orientation for these two things. And we said that the layer five A cells, since they don't go back through the thalamus, they have to be converted back somehow to an egocentric framework. and if you recall in that paper, the layer five A cells have, are the logical place for the actual happen. They have, this unique physiology, this bursting mode, which is very similar to the bursting in the, in the, thalamic relay cells. So as we speculated in that paper that the thalamus does the orientation conversion on the way up. There's a layer five B cells project to tell the Thomas what to do and layer five B projects to layer five A, layer six B tells it what to do. And layer six B projects to layer five A saying you have tofor also have to perform an orientation, transform. should I bring up that picture from the paper?

I think it's okay. Maybe that would be a dunno if it's not relevant to the main point that you're making. So here we said layer six B was the orientation of this, of the sensorimotor to the object. We passed it down to thalamus to convert the input from the retina from a retinal centric orientation to an object centric orientation. But the same, conversion has to occur in layer five a. So this dash line represents, it's already in egocentric form. And I, say it's already in egocentric form because it doesn't go through the thalamus, it goes right to the motor areas.

and it also then branches up and goes back through the higher thalamus, meaning it has to get converted again. So these are evidences that this is already in a, egocentric format. And then we just briefly mentioned that the layer five A cells have this unique bursting property, which is very similar to the relay cells here. So without further any explanation, we just threw it out there that it's likely that the layer five A cells themselves take this input and do the conversion back to egocentric form, on its way out. So I think that's what you mentioned, isn't it? Vivin? Is that was what you were talking about, right? Yeah.

Yeah. Yeah. No, this is really interesting. And, yeah, in terms of Monty, it's kinda interesting to think about. 'cause obviously we've talked a lot about like goal states and in terms of kind of understanding where that falls into this versus the outputs of columns. it feels like I, if there is still a place for a goal states that's more like column to column communication, right? But something like L six or a version of L six that goes to the apical, DITE and L five or I don't know, something like that. But then it's the l yeah, the L five motor output that you're describing here. It's more what is the, yeah, what is the neural pattern that I can trigger in a subcortical structure that gives me this movement that I want that, that I'm now gonna observe this, in the beginning when I started thinking about this, it was very mysterious to me. How would a, what would be the, what would be a, what would the layer five a cell represent? what what does it encode? And it was not obvious to me initially. And then. Now I feel I have a satisfied explanation. It's encoding a language that is observed the subcortical motor generator, in a language that the subcortical motor generator would understand. And, and it represents movements that occurred, and therefore it is able to control it. and that's also the basis for how we do our, all of our modeling. there's still a lot of things I don't understand about this, but I think this general idea is a good one. I don't know, maybe I shouldn't show this last picture, but I'll just show it to you. This is my last thing I had on here. This, if you look from a top down, cortex, imagine this is a cortical column, and these individual squares are minicolumns. This is, not atypical. These circles represent where the bump of activity would occur in those minicolumns. It's not two, it's not 1D like your, or 2D like you see in this upper picture. It's, did my cursor go, lost my cursor?

that's weird. My cursor's gone. It'll come back in a bit. and so you would actually, and there's a lot of evidence for this. We like the tank picker is another example, but there's lots of evidence for this. What you'd really see is multiple bumps of activity moving around together because the minicolumns repeat themselves within a cortical column. It's not, there's multiple versions of the same thing. even though I may only be representing eight different orientations of movement or 10 different orientations of movements, they repeat. And so this, is what you see actually, if you, could see the activity looking down on cortical column. You'd see these islands of bubbles of activity. And as the animal moves, those, bubbles would shift around. This is, I know this is reminiscent of grid cells, but it's not the same thing at all. Actually. At least it's, but it's, it is a function of the, the inhibition and creating, between cells. Anyway, I just wanna point out that there are multiple copies of the same thing going on in a cortical column. It's not just one copy of, there are multiple cell minicolumns representing the same movement vector. which gives us our, gives us our robustness to uniqueness. Okay. I'm gonna stop here and my curse is back and I'll stop sharing.

nice. Yeah, thanks. That's, yeah, I think some interesting things to think about and yeah. 'cause obviously agree that we wanna move eventually towards learning more this kinda action output. What's the appropriate action and stuff like that. And a lot of that's no, we don't have to, right? we don't, yeah, you could, for example, you could maybe come up with a sensorimotor module that maybe what if we had all cortical columns? I don't like this idea. I said, what if all cortical columns have the same basic motor output representation? Then you send it down to a learning module and the learning module would convert it from the generic form in the cortex to a specific form for the learning module. I don't think that's a good idea. you, another question I had is, what, when don't we talk about concepts like we always talk about, concepts. What is the movement vector and is it still a movement of a sensorimotor or is it a movement of something else? It's tantalizing to think that the mechanism in a cortical column really doesn't know, if it's V one, it doesn't know that those are center surround receptor fields on a, on a retina. It, there's no idea that it just says, these are some bits coming in. I'll form a representation of them. So what would be the equivalent from someplace else? I don't know. I really have no idea. Does, are all concepts rated or, built on vector, spaces that are very much like grid cells and, based on coordinates in the real world, or are they getting some kind of movement input that's from some other part of the brain and, it represents a different space?

That mechanism I described is, did not, it did not require any specific knowledge about what the subcortical motor generator does and represents. And I also ask could that, could it be, and I'll leave you this last slide, could it be that what we labeled as a subcortical motor generator is actually a different region of the cortex? The same mechanism could apply a different region of the cortex should be sending information. I'm a column, I'm getting input. I don't know where it's coming from. Maybe it's the motor output of some other column and I'm gonna try to model it. What does that mean? I don't know, it's possible that some other, somebody, other, some column is just trying to model the behavior of some other column and build a model on top of that. And it may, have nothing to do with physical movement in the world. This is the ideas I talked about, we've talked about before, of concepts.

Yeah. I think it's really interesting to, to try, and, think about movement as these one dimensional movement vectors that then get combined to form space. I was, I didn't really reach a conclusion yet. 'cause I didn't, I was trying to listen to you. I was wondering if the findings that they made with bats, if that could be co explained. If we think about it as one dimensional movement vectors being combined and that's why it loses it, the kind of grittiness in the third dimension because maybe the kind of up and down movements are, not, I don't see why, if I took a, if I took several hundred minicolumns, I don't see why I couldn't represent movements in three dimensions. yeah, You, could drop. But if I did anymore, I, why not? I can think of one answer to that question, but in, but, why wouldn't it, why wouldn't it be gritty in the third dimension in Z? But in the case of bats, maybe the, when they go up and down, it's like a very different kind of movement information that comes in that's maybe much more sparse than what they get as they, maybe, but why, would that be? I don't know.

if they, go down, maybe they, are not moving their wings. So there's a, I don't know. I don't know.

here's a, if you're following all this, here's a, potential solution. What if the Minicolumns really did learn end dimensional movements, right? Whatever they observed. we don't, we do know that in onic parts they can learn one dimensional movements and they can learn two, two dimensional movements. they can perform a grid along a one dimensional track.

we know that they fall apart when they do three dimensions in the rat. Okay? But what if the minicolumns themselves were able to represent any number of dimensions, let's say three dimensions, and they accurately represented that space. But now the problem here is. I, had that, remember I showed the top down view of a column that's two dimensional.

the grid cell array that gets locked in is a physical two dimensional array. It's not a physical three dimensional array. And so I'd have to take my three dimensional representational space in the minicolumns and try to force it into a memory that's two dimensional.

does that make sense? It is if I think so, yeah. if, instead of having blobs moving on a two dimensional surface, if I could have blobs moving into three dimensional space of cells, then it, would probably work. But the cortex isn't three dimensional, it's two dimensional, and it would force itself into a two dimensional array. Why does it, why, couldn't it work in, it's just a bunch of 1D movement vectors. If you have more of those 1D movement vectors, they could be in, in, different dimensions. The problem is not, the, it's not the one dimensional vectors the problem. It's the, I'm sorry, lemme go share my screen again. Which yeah. fits with I guess what you're saying about like the grid cells being more like a storage point for your location, Rather than the core. this image down here on the lower left. Imagine this is, yeah. See why those couldn't correspond to movements in the third dimension as well. They could, they could. all This is not a good, there was this idea that, there there are many places in the brain where the inhibition is spread horizontally, right? So the, continuous attractor network in grid cells. Okay. Just think about the continuous attract network in grid. This is a horizontal span of inhibition. It produces a two dimensional pattern of activity. It looks like this one, a different one, but it looks like this. this. The physical structure of the cortex. If I wanna store a, if grid cells are a storage mechanism for the current location in my space, grid cells are inherently gonna be two dimensional. If they work on inhibition, that's in a two dimensional sheet of cells. and that's what it appears to be. The neocortex is all two dimensional in all of its architecture. So I wouldn't be able to form blobs of activity in three dimensions of the grid of the cortical column. I can only form a two dimensional sheet of blobs of activity. And although the minicolumns themselves, these, guys could represent three dimensions or end dimensions. If I wanna map 'em onto a set of grid cells, and the grid cells require a two dimensional inhibition, na matrix, then I'm gonna force my three dimensional space onto a two dimensional memory. oh, you mean because neighboring minicolumns have similar directions that they encode? that's part of it, but that's not really the issue. The issue is, I, don't know if this is a helpful analogy, but like with CPU design, like part of the issue is they have to design it as a 2D array because as soon as you add a third dimension, there's nowhere for heat to go. So and it's, also very hard Yes. Problem. so all the, like transistors in the center of this 3D grid or like cube would overheat. And it's not, I dunno if that's a helpful visualization based No, that's not, it's not. But, it is more, and here's a better way of doing it in silicon design, it's much, much easier to lay a line down horizontally on the surface of the chip than it is to put a line of a wire that goes vertically on the chip. There. it's like the process by which they make chips is laying down layer upon layer. It's not a three-dimensional manufacturing process. And so there's an inherent advantage to, it is very difficult to make three-dimensional wires in a chip. Okay? It's this the way it is. they can't design chips in 3D. They have to basically design layers and put 'em on top of layers, and they have to connect the layers. So there's a, that's a good analogy here. It just turns out that the neural tissue by evolutionary design is essentially two dimensional. And the way the inhibition works is two dimensional. This might've, this could have worked just fine when animals started, walking on the earth or whatever, right? They two dimensions was good. And so whatever reason, this is how it evolved. And so we have this two dimensional sheet, and therefore you're, these inhibition things are gonna be on the, imagine these are areas of activity that are reinforced by, this, this sort of Mexican hat inhibition, like those local cells reinforce each other and, further away they inhibit each other. So this kind of pattern's very common in neuroscience, but it's inherently two dimension just because of the nature of the, neural tissue. It's not theoretically restricted, but it is in the neural tissue of the brain. It would be restricted. So then it is about the neighborhood relationships of the columns, right? Or, if not, I don't see why you can't just put columns with direct oh. You're right. I'm sorry. You're right. I, you're, actually right. Viviane, I didn't think of it that way. That wasn't the issue to me. The issue I was imagining inhibitory neurons and what they look like.

but Right. this, the, way inhibition works, right? Assumes that columns are neighboring, columns are, are related, and, But I think, I could, imagine having that same property in three dimensions where instead of these being circles, they were, no.

but I, think it's maybe worth pointing out 'cause I, I'm not sure if there's a, an illusion of disagreement or something because like the argument is basically that yeah, the, these minicolumns, VSOs, whatever, it can do end dimensional path integration, which would fit with the fact that animals don't get lost when in moving through 3D space. But just if you happen to look at grid cells for this reason, they only show this really clear grittiness when you look along a two dimensional plane.

And so, like that's the argument, right? And so it would lead to problems representing three dimensional space. It would have, it's, a, it, wouldn't be perfect. And, I'm just saying that it looks like that's the way the brain, I, maybe that's the way the brain doesn't. so to clarify the, are you saying it would be hard to model three dimensional space, in a good way, or it would be hard. I think it would be hard for, biological tissue to heart the model three dimensional space. it wouldn't, all the properties you want wouldn't work very well. So for example, you, might lose path integration in the third dimension. Or, you might, have trouble re-anchoring in the third dimension, something like that. I don't know. but that's with the mechanism that you just proposed with the one dimensional movement, minicolumns, or, that's, that would be the first of all in the grid cell literature. most of it's has nothing to do with three dimensions. Some of it does for bats. Most of it's just hey, it represents the map of a room, right? It's two dimension.

no one, it, no one has proposed how this is done like in, in cortex. And, and, and this specific idea that Minicolumns represent these one dimensional vectors. I showed you that picture of the rings, that's as close as you got, right? People saying, oh, there has to be a bunch of cells that, have these properties. I actually think those, probably the mini column concepts exist in the ENT Toronto cortex, but people haven't looked for it.

so a lot of this is speculative, right? A lot of this is, me interpreting and, making proposals. but my understanding of it would be, I don't, I would see why the spatial pooler mechanism should learn end dimensional spaces. That seems like it would just do that, but that, but then if we're gonna rely on a grid cell-like mechanism to keep track of where you are in dimensional space, the grid cell mechanism wouldn't work very well in three dimensions.

and therefore there'd be some deficits in three dimensions, whether that's path integration or re-anchoring in three dimensions, things like that. I don't know. But like Niels just said, it seems like we don't have deficits path integrating in 3D space. that's not true. That's not clear. We, yeah, we talk a lot about this. One thing I can just quickly share while people are getting back, on this Animals and 2D and stuff. I remember, when looking into this a while back, there was at least, yeah, some evidence that animals to, even animals that move in 3D tend to have a planner ba bias in how they move. So as in if you look at dolphins, this is showing depth of dolphins, where they dive. You see how they like go to 400 to 500 meters and then basically spend hours at that depth and then, or, minutes. And then they go up to get air and then they go back down and then they spend a while. They're not spending loads of time in this kind of like up and down type thing. Of course, that could have other explanations. Like you could imagine that certain animals, like other fish and stuff also tend to survive at certain, depths because of, whatever, light and food is there and stuff. and yeah, I just remember when I was at a conference and there was a presentation about good cells and bats. I think he said the same thing, that they, they basically tended to fly around this room and stuff at like similar heights. They didn't spend, unless they were going somewhere in particular, they didn't spend loads of time going up and down, you can, you can a, little bit of dangerous introspection here. when you're in a room, your head is at some three degree, 3D space location, right? You have a sense of where you're in the room, but it's, not a three, three-dimensional sense. It's not oh, I'm picking my head now six feet off the floor. Now it's four feet off the floor. I you can, you're obviously aware of that, but it's not if I say where you are in the room, your first thought isn't, oh, I'm above the table now. I'm, it's just. you can somehow deduce that. and that's what good cells seem to represent rats. They, also did rats climbing on these, structures, lattice like structures, little tinker to type of thing. And they tried to figure out a rat representing, three dimensional space and I can't remember, but I don't remember the details. But the answer was, didn't look like, it looked like they're somehow hod ponding together some two dimensional representations to make, it work for them. It's like one, it's like here, my house, I go upstairs to my bedroom. I don't have a sense of my three-dimensional location in the house. I just have a location of where I am in the room and yeah, I know I'm upstairs, but it's, I don't have this feeling of oh, I'm floating above the living room. it's I don't know. it's just a little weird. I, it's, that's all purely anecdotal introspection. Not worth much, I think.

I'm sorry. Go ahead, Scott.

you can have a, if you can represent a plane with grid cells, and that means you can represent a plane in that way and that way, and it doesn't really help you with path integration. But, if you do have mini planes like this, if you're in the house or something and you have some other sort of more vertically oriented reference frame plane, it helps you move through the, yeah, through the, levels. it still doesn't mean you can really path integrate in a three-dimensional way, but at least when you want to make vertical movements, you've got some, planer type representation that you can use.

yeah. But it seems very hard to recover path integration fully in three-dimensional space. But I feel like it's, maybe a bit also about the scale. Like your house is a big space to model. That's like even in 2D, moving through a city is difficult to path integrate. You lose it at some point, even in your house, if you think 2D like if I draw a line from the kitchen straight in this vertical direction, where will I be in 10? Where would I be in 10 meters? It would be hard for me to say, but if I have this water bottle, I feel like I have a very three dimensional model of it and I can path integrate very accurately on, on this bottle. Yeah. But then we showed like things like the cube where if you have a cube and you have images on the face of the cube, you don't really represent a good three dimensional model of the cube. And it's hard to features on the cube, the shape of it. I feel like I also have a very thick I don't know, it's like maybe if I think yeah, I don't know. Maybe, just on, oh yeah. Oh, what were you say? I don't know. I'm just thinking, let's think about Monty. What do we, want Monty to do? Yeah. 'cause I mean we, we have 3D working fine in Monty, but I guess you alluded to this like end dimensional, kind of space. And I guess I just wanted to go back to the vs o thing because I've always had this kind of niggling uncertainty about kind of one dimensional path integration stuff. And I feel like even with that model that you were showing Jeff, it's, it seems, maybe I'm missing something, but it seems to me like that problem still exists. I dunno if it's possible to pull up the paper. Which, problem? The, so the six ring VSOs or vco, sorry, dcos. What was the, problem with it? I can explain that by looking at this, but, all right, let me find basically paper. Where was that? One second. Yeah, no worries.

that was in this one here. this, yeah, the second time. This one here. That one? Yeah, that one. Perfect. Thank you. Yeah. So let's say you move, in this direction and then you move in this direction. I, I, oh, I, can't see, you wanna Oh, I, was saying, so let's say you move right for a while. Yeah. And then left. And with these 1D and, for now, let's just yeah. Conceptualize them as 1D kind of grid cells or path integrators, because that's basically what they are.

when you're moving to the right, the five one would be active when you're moving to the left. Five four would be active if you, and, presumably this grid cell that's receiving all these inputs knows where it's meant to be active. Like it knows to reactivate because of, based on which inputs it's getting. Like when it gets either, five two. let's say it's magic. Somehow when you start moving again, it knows which are the correct right cells to be in phased. But, so it makes sense in my head. Let's say, so right now, FI two is active or Got it. It's really unhelpful that they called it. That's like capital fi and lowercase fi, right? oh, yeah. Okay. okay. I'll say, I'll, call it mod module one and Okay. And cell two, so module one. Okay, great. And cell two is red, Okay. Yeah. And then in module four, cell two is also red. If we move the full kind of phase to the right, cell two in, oh, wait, oh, cell, yeah, Cell module. Yeah. If, we move a full kind of phase, to the right, cell two in module one, we'll be active again. And then if we move, Full phase to the left cell. Two in module four will be active again. So that's fine. And then in case what's, happened is like we've moved over the grid cells active, we've moved back and the grid cells active again. wait, let's talk. What it tells you there is you have a completely different neural mechanism representation if you're going left versus going right, You said if you're going left, you have a bunch of these rings that are active and you're going A different set of rings are active. And so the active neural representation is completely different between those two. But, they, once you've completed that movement, in the cases I described, the set of active cells is the same. And so that's what tells this grid cell to become active again.

like that's the path integration that, that you moved away, Right. You moved back and so you know, you're at the same location that grid cells should become activated. So you're saying we didn't get our, we didn't get our high dimensional, uniqueness. No, this is all fine. Like we're getting, it's a question about path integration. So Okay. We're, getting path integration when we do a full phase movement away and then a full phase movement back. The issue I see is what if we move half a phase? Like half of the half the way around the ring? Yeah. So now cell six in module one is active. Yeah. And cell six in module, no, sorry, still cell two is module and active is active in module four. 'cause we haven't moved left at all. I, by the way, I, my understanding is if you're not moving in that direction, these cells stop being active. Yeah. So, if you're moving right, then cell module four is not active at all. Yeah. Okay. Which is it just even, it's a different set of problems. Yeah. That causes problems then if they don't stay active. You have to somehow reactivate 'em correctly.

Yeah, yeah. And, it's, I guess my point is if you just reactivate it based on when it was last active, that doesn't seem sufficient. No, it's not. You'd have to rea, you'd have to somehow know otherwise when you move back left, it's gonna be the wrong cell that's active and that grid cell won't activate as, as far as I know, and I haven't looked at this in maybe four years or so, as far as I know, no one has addressed that question. I don't have any, I've never heard a complete theory of how grid cells come about. That makes sense. Okay.

and mine doesn't, it's proposal I made doesn't completely solve every problem either. you brought up this, you brought up a good one. That's, it's really complicated. How do these cells know which one to become active and how does a grid cell, there's a different representation going left and versus And, by the way, that is actually useful knowing if you're going, one way versus the other. And sometimes grid cells reflect that.

anyway, the point is, okay, that's fine. I just wanted to check. I wasn't misunderstanding something. No, it's not a complete theory. I, it, just, it's so damn compelling to look at those, cells in layer five and six that are large field, edge movement detectors and having all those cells in the minicom represent the same basic receptor field to think oh, that's exactly what's needed. At least in this diagram, the one we're looking at here, that's what's needed. This, I don't think this paper resolved all those issues. Maybe it did. I'd have to go look at it again.

I thought the grid cell kind of has to learn how to path integrate between the different movement vectors. So basically it would activate, it wouldn't just activate with one specific combination of. Of those, phases in different movement columns, but it would activate with a bunch of different combinations, but very specific ones, like that's what this was requires. and one way to think about this is, grid cells anchor based on environmental clues, right? So in, in this case, the environmental clues would have to anchor the individual cells in the rings.

they would have to say, somehow the environmental clues tell me which one of these things to be active. I don't know how that works.

I, we started out today and I made the observation that this is a very complex area and I'm gonna stop sharing this unless you wanna see it still. it's a very complex area. It's not, as far as I know, no one's figured it all out. it's still an area of, as Hojae said, of, I don't know how many people are working on now. 'cause it was so damn hard. I don't know if they got enough rewards on it anymore. but as far as I know, it hasn't really been worked out in any sufficient detail to answer all the questions we have.

but I, again, from Monty's point of view, doesn't matter. Can we can pick up certain ideas from it and try to go with it. Yeah. Yeah. I feel like for me, one of the bigger takeaways in terms of Monty today was just to think more about the sort of the direct output of each column and how we wanna represent that. And, 'cause it's something we've been discussing recently, even last week with you. but also just generally, I feel pretty comfortable with that idea. I feel comfortable that it's a learned representation based on what the actual subcortical motor generator did and and therefore it could control it. Yeah. I guess the question is 'cause broadly maybe there's two options. Like one is it it's a movement or a displacement, and another one is it's more of a target, like a location. that's how we sometimes conceptualize it. And so like until, and, maybe there's a bit of both, especially depending on what's projecting to what and stuff, but like the location makes sense in terms of I'm just gonna tell you what I want. You figure out how to get it. The movement also has its own appeal because it's no, this is actually what you wanna do. but that does get a bit closer to almost like controlling a muscle contraction. the problem, the pro it feels like it, it can put more responsibility on the subcortical structures by just saying, figure out how to get this, there's a, so try to follow this logic, see if I can express it clearly. I always thought oh, okay, there's these two ways you can communicate. You could communicate here's the location you should be at, or, and originally when we started thinking about a Thousand Brains Theory, that's what I thought I said, oh, we have to communicate the, location of this and location of that. But communicating location is really complicated.

and, I, let's not go into the complication yet, but if you communicate a movement vector, it's pretty sim damn simple. Because all I have to say is convert this movement to your orientation and you figure out where you are. Like, I don't know where you are. I'm a, I'm the eye movement. I don't know where I am relative to the coffee cup. how, am I supposed to know that? and I can tell you where I am relative to the head, but. how do I even communicate that in the language you would understand in terms of location? But I can tell you how I'm moving and, that's easy to translate and you can figure out, okay, you don't know where you are either, but I'm telling you how to move and you, infer where you are on the object. you have to both infer where you're on the object and your orientation, but that, was a problem that was solvable and we did solve it. And whereas we try to communicate locations, I don't. it's, I started there and I felt oh, this is impossible. And maybe I just was shortsighted, but it, just felt like this is impossible. And then I realized, oh, it's all about movement vectors that's so simple. It works. let the recipient figure out what the hell it means. So I don't know how the cortex could tell a subcortical system a location, when the models in the cortex don't know locations in the egocentric space and know nothing about it. and the sensorimotor knows nothing about the locations in the allocentric space. I guess that's the conversion we're doing, but Yeah. Yeah. How we're doing it in Monty today, we currently communicate locations as input to Monty, but then we use movements, for recognizing and learning objects. But we communicate the locations because they're necessary for the voting to work. 'cause otherwise the columns don't know where they are relative to each other in the world. it feels, I would, if I were to ask me, I would guess that voting is a mechanism we haven't really discovered yet. maybe it's related to the classroom or something. I don't know? Yeah. And I think we've been saying before that the voting right, how does right now is, probably too complex. or involves too many reference frame transforms for its two, the one we've implemented. Oh, okay. Damn. Too bad. I Okay. You would do it that way. We'll do it that way. It's, yeah, it's not like a problem right now. But yeah, in terms of at least understanding the brain, it, would be nice to find a simpler version. 'cause I think the brain, it's likely that it's simpler than right? I think this idea of communicating movement vectors, was a revelation in my mind that simplified it all and said, oh wow. Of course it has to be that way. yeah, I guess if you have an idea of how voting works with that. Alright, we can bring that up as a separate topic, right? Yeah.

I, I've never really thought about it. we've talked about voting, but we haven't talked about how to know your relative positions to each other. That's the key we're talking about. You start with, with flash inference, you almost have the, assumption is almost like there is no movement. if, someone flashes an object in front of you, right? this is a bag, it's a bag of features unless, Yeah. But that's the thing. But humans, we don't want to do bag of features because No. No. Clearly, we, these are not independent. we've known this for a while that comms need to incorporate their relative positions to each other. When it comes to voting. They have to come to an agreement on a common reference frame. I guess maybe the assumption was always that somehow that reference frame is in the egocentric reference frame and they know where they are there, and then somehow, I don't know, I, some magic it happens up in the cortex. I dunno. Something happens that makes it work.

so you guys have probably implemented this, so you've thought more about it, but I haven't really thought about the neuroscience much on that one. I could, if you want. I can think about it for next week maybe.

I've never read anything about it. there's no. These ideas, many of these ideas, are pretty, yeah, I remember one of the more speculative, but maybe interesting ideas to tug on more was, whether the colostrum could be, 'cause, we, I think when we looked at that in terms of connectivity, we saw lots of connections to and from the same layers that tend to be involved in voting. So like L three and L five. Yeah. And so whether there's any evidence that could be involved in, it seems, like we, we could even approach it from a pure theory point of view. You could just say, okay, here's what we know about cortical comms or learning modules.

just figure out what they have to do and Right. what does that require from, mechanisms to do it? regardless of whether it's a corum or something else. just pure, that's the way we usually work, we need to have a representation location. How could we do it? Oh, maybe grid cells, I was like, okay, we have to do what exactly What does the column really have to do to, solve this voting problem? It's a bit complex because, you it's changing all the time, right? Your fingers are constantly changing positions relative to each other constantly, which is a much harder situation than at least it forced you to think about differently than like the retina.

I could grab this cup, I can grab this, coffee cup, bring my thousand brains cup. I can grab my thousand brains cup, my hands this way or this way. I felt that chip again surprised me. and and they're completely different. The voting is completely different, 'cause their relative positions are completely different every time. Somehow it's, gotta be calculated very quickly.

Yeah, we can think about it.

What has to happen. Yeah. I guess if we did have a, an answer to that, then we could change Monty to just use movement inputs and outputs, instead of All right. how about we, how about, I'll think about it. I'll think about it today and tomorrow and see I come up with something. Please. Other people think about it too. Yeah, it, it might not solve as pressing off an issue as some of the other topics like, modeling object behaviors and stuff, because things work fine with communicating locations right now. okay. yeah. I, that's a good excuse for me to work on it 'cause I'm not doing anything else. Yeah. Maybe one, one topic to inspire brainstorming, that we were talking about the other day was just that, yeah, the, kind of idea Viviane had brought up that, maybe behavior is just in behavior columns or, there's some columns that just get And so those are just behavior and then can, we can get, can we get that to work with the things we want? Like reusing behaviors for different objects and stuff like that. Does it maybe even work better than what we had before?

maybe I wasn't a fan of that idea, so I haven't spent any time thinking about it, but it doesn't mean it's not Right.

Yeah. At least be nice to know a reason of why they need to be in the same column. Because right now there isn't really any good reason. I see why. and it would simplify things a lot and it would make it, it would seem like such a nice solution because that way it's really just every column does the same thing and it just depends on what input it gets, whether it gets well, does every column do the same thing? Does every column have the same motor output? Yeah, I guess it really would. Morphology models need like a temporal dimension in that case. What would they do with the matrix and all that stuff? There could still be like a state conditioning, you know how an object can have different morphological states in a sequence. so you could still say when the object stops moving you learn more morphology again. So that could be the state conditioning for that. But yeah, it's definitely worth thinking through. Yeah, everyone think through it again. I think I said once before, oh, that could be the whole mt aware pathway. Yeah, It's just right now with the current, if you, if we draw our current solution, we are basically drawing the exact same thing two times in the same column. alright, I like it. If I think about it as like the MP ware pathway, then I think it's a good idea. If I think about it like these co-located next to each other, every other column, I don't like it. I don't know why this is my personal bias. and I think part of it would be thinking about what would those long range connections need to be, do as well. 'cause I think that was another thing that we, I mean we also need to solve this even if they're co-located and, like behaviors in every column. But like right now the behavior is trying to apply that movement to offset, the lower level column and, like how that's happening. if that is, happening.

okay, that's, but yeah, but that's, it feels like that's worth explaining 'cause it's, it's something new that we haven't discussed and it's also, yeah, Viviane, like if nothing else, it'll make us more confident that we do need behavior in every column and, double, Yeah. alright, so I'll, retract my objection to the idea. Okay.

and, Oh, sorry. I'm just thinking it's this reminds me of so many things. It seems so damn complicated now, but I think in the end when it's, when we figure all out, it won't be that complicated. It'll be like, okay, it makes sense. but at the moment it still just seems like, how do I keep all these things in my head at once? It's empty colostrum, movements up and down representations of behaviors. Y yeah, that's, what I was thinking when I first thought of putting it in a separate column. It was like, wow, we thought about all of this stuff, all this, like so much, so many things we talked about, but then it might boil down to just having a different sensorimotor module that sends like changes instead of features to the learning module. so yeah. Yeah.

but then, but we do know that even V one columns have, those receptor field properties I talked about with the, the directionally sensitive large cept field cells in layer six and detecting movement and superficial detecting movement. So what are they doing that would still be required for the morphology models? Because you still need the movement input for not the movement in the superficial layers. You mean the movement to L three, layer three that the movement of the object itself. But we can Yeah, double check that. 'cause they, there is classically this idea that MT is more movement sensitive and stuff, so what that's about and stuff. But you would also still, I think you would still need that input to compass. Why would you need, why would I need the objects behavior movement in upper layers in a morphology model? can I suggest we visit this next week? Okay, sure. just 'cause I feel like everyone's probably starting to flag a bit and, but yeah, thanks very much Hojae for the, that nice summary of yeah. Grid cells and then yeah, we can maybe discuss, but Yeah, I think it would still be interesting next week to talk a bit about the re-anchoring stuff you had found, and at least some of those stuff. Also, if someone wants to do a quick, really quick summary of what's known about the cluster that might be useful. I, Yeah, no, I have nothing about it. I can at least pull up the, the same stuff I found before. 'cause it there was a you did. And, yeah, lemme make a note of that. alright. We can, I think it's okay. and then, yeah, otherwise I think thinking about, so yeah, again, if we maybe dedicate like an hour or two grid cells stuff and then otherwise thinking in terms of behavior, this whole, like total separation out of behavior, what, that means if, that makes sense with anatomy and stuff. yeah, I think Viviane you have a clear idea in your head why that makes sense and I do. I don't know how I can, how you can, I think you can do, just share that. I don't know. Yeah, that's a pretty small idea. So I'm, not sure I can, test talk a lot more about it, but I could look a bit more into the literature again and see about the kind of, maybe I'm just trying to understand like how would I have a column that just does behavior and a column that just does morphology? I guess it's not obvious. Yeah, I mean if we did wanna constrain it by neuro physiology measurements, I think it would be useful to just double check. Like, why is it again that everyone says MT is movement and, how much movement is there in V one and stuff. Because I think MT gets input from V one, so there must be movement in V one as as well and stuff. But, obviously the movement has to apply to morphology models, right? So that was part of the thing. By co-locating 'em in a column, you were able to say, oh, I have this behavioral model and now I'm looking at a different, morphology. I can apply the behavior to morphology. Easy peasy. We were doing that using hierarchy, so already using connections between two columns, we did have hierarchy. I thought we were doing that within a column two, didn't we? Or I forgot. I think in the main proposal it was like the higher column would have the behavior model and the lower column of Oh yeah, we, went in that direction, didn't we? we said it might be an option that you could do it within a column, but, I think when we originally had the idea of behavior models, it was all within one column. It was back in February. Yeah. it's gone. I forgot. It was like I had a nickel for every time we swapped from doing one, one column for both versus two columns. If I had a nick of every time I forgot something, man.

yeah. if the reason why we need them in the same column is that we need that to apply behavior to morphology, then that, I think that would be a good outcome too, to just figure that out. I, I think the idea that the wear pathway Mt is doing this as a treating idea and cool. I proposed earlier that, that it's just modeling, it's modeling the space around the body, but that was a, a idea. It wasn't the best idea. So, this is something else to think about. All right. You wanted to end this Niels? Yeah, I think probably a good, stopping point.