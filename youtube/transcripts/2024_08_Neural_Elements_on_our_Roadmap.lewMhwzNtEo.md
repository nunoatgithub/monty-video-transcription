Cool. Thanks. All right. cool. So yeah, some of you have, maybe seen in the, in Slack, I shared this document, that I'd been, working on and also getting feedback from Vivian on, and others now, with trying to encapsulate a bit more of, how we can eventually bring in neural elements into Monty. why would we want to do that? And when we would want to do that. And I guess this was motivated by the feeling that. We talk a lot about, Oh, we should bring in SDRs. We should bring in grid cells and stuff like that. And often there's not clear agreement or disagreement about why we should do that or when we should do that. and so I thought it'd be worth if we actually articulated all those points. and then we could really point to a point and say, okay, this is something we disagree on. This is an unknown, or these are all things that we do agree on.

Yeah, I'll just share my screen. And another thing I could imagine is that once this project is open source, especially HTM community might be like, Oh, how do I integrate? Why are you not doing anything with Numenta's previous work in this project? So this would be to point out, like we're, we've considered it. And for these reasons, we haven't done it yet.

Yeah. And today, yeah, I already touched a little bit on the kind of overall aims of doing this. And then, in the kind of parts of Monty that I'll be focusing on, in this kind of light is the cortical messaging protocol and how we represent the features and then reference frame representations.

and yeah, building on what I was saying earlier, ultimately, we want to we want to be empowered by the fact that it's brain inspired and use that to make it a better system. But of course, we're not trying to simulate brains. and so we want to avoid complexity where possible.

and we also want to make rapid. So those are things that are, that's one kind of tension. And then the other thing is, we want to make rapid progress and often using simpler systems helps with that. it can be useful in the short term, but we also want to be careful that we don't, what's called invest a lot of resources and a lot of kind of, algorithmic development and all this stuff into a particular approach that we're eventually going to abandon later, resulting in, a whole bunch of sunken costs.

so yeah, so this first category, just make sure everyone has like an intuition for it. So this is what we have been using in Monty, really since kind of its inception and still use for certain things. And this is where we have some kind of measure of something, which is Can be represented with just a single number or maybe 2 to 3 numbers. for example, hue saturation, or it might be like the magnitude of principle curvature. And we are the sensor modules in Monty are passing that, as the kind of feature information to the learning modules. And that's what's being stored. And that's what we're matching against when we are performing inference.

overall, this is really nice because it's, it's very intuitive. It's and it's easy to visualize. and debug. You know, exactly, what information assistance receiving and, and it's, I think Tristan made the point that it's also just easier from a pedagogical point of view to conceptualize. Okay, this is what the features that are coming in are. But of course, this, this also means that we're more restricted in, Exactly what these can express and how much kind of they can maybe overlap and relate to one another, become very distinct thing. We should also be saying we know this is not how neurons do this. Yeah, I guess you could imagine maybe you would have a firing rate code that could do Right something like this for some features, but that I got past that imagination decades ago. So You know, that's not true. So I stop let's stop pretending it is. yeah, obviously there are Some places where there's, rate coding, but, but features coming from sensors, that's not how they work. They're always distributed. I just want to point it out. we, agree to do this work because it's easier as engineers and humans. We find it easier, to understand, but the general rule should be, we shouldn't abandon the neuroscience way until we know what we're abandoning. Or at least say we can come back to it later and figure that out, but then you have to be really careful that you don't go too far down the path that's going to be unfruitful. So yeah. Anyway, this is how we agreed to do it up to now. Yeah. Yeah. And that's what this presentation document is about to explicitly spell out. Okay. This is what we're doing for those reasons. And those are alternatives that are closer to biology, but we're not doing them yet for those reasons. We're not doing them everywhere. Cause I think that's one thing that we might do at least to begin with is, a mixture of approaches where, we could take, hue and we could use the hashing algorithm to map that to. SDRs so that, two different hues, the more similar they are, the more overlap they have in their bits, and so forth. But, but, I don't know if it's, there's necessarily that much of a benefit at this point to, doing that. Especially when you're dealing with a sensor, but once you start processing information within the cortex, within the cortical columns, between cortical columns, then this kind of distinction can make a huge difference. so again, it's, it may not be in place. And yeah, so I think what we're leaning towards is, this is a useful way to pass information into the learning modules. but then in terms of how learning modules communicate with one another, we are moving towards. SDRs, which started with, Rami's internship.

I think we should then also use SDRs from the sensor module to the learning module. I think, yeah, eventually it would be nice to be consistent. Yeah. Yeah. Like the, sensor module also uses the CMP, so it should be consistent in the representation.

Fundamental difference between the features like color and curvature and, the features that are like object IDs.

Yeah, and I think there will eventually be advantages when, I don't know, top down learning starts coming in and stuff like that, if we, if everything is in SDR. Yeah.

it's, also, I've learned over and over again, if you take the shortcut, oh, this is how I would do it, and, it's not the way the brain does it, unless you deeply, understand what you're giving up. You're going to end into a dead end and you're just going to regret it later. I've seen that over and over again. I can't emphasize it enough. So I just, I'm always nervous. Every time I see us using real valued numbers, it's okay for now. I always, I'll tell Vivian, I'll say it's okay for now. It's okay for now. It's okay for now, but don't forget, you better be sure before you get up. So I, I'm, it's not like we know we have to use SDRs everywhere. It's more do we know we can't use SDRs everywhere? Okay. that's the way I view it, and if you don't know, you can't say that again. It's not like I know we have to use this. It's more yeah, I know the brain uses SDRs and I'm not sure if we can get rid of them. And until I'm sure I can get rid of them, you don't want to do it. That means I can get rid of them if I know exactly what I'm giving up and I can say, yes, I can solve the same algorithmic problem using real value numbers. And I won't give up anything that's important. Then we can do that. so it's very, this is the whole history of. Neurally inspired machine learning has been, they start off with oh, here's an idea for neuroscience. Let's do that and skip the rest of it because they don't understand it. It never meets the right answer. It never takes to the right place. our, goal in life is to go the opposite direction. You start the neuroscience and say, okay, it'd be a lot easier if we could use real numbers, maybe, but can we? I don't know yet.

I had a question. I'm a little wary of taking this down a rabbit hole, but I'm going to throw it out there. Maybe we can park it.

If you've got multiple coordinating pieces, subsystems, and you have a representation, like SDR, does it change at each step? Input to each layer. Is the, encoding of the SDR different in every place in the network or is there some, there is no system that coordinates it? No, there is no coordination whatsoever. Okay. There's none. Stop thinking about SDRs as some sort of oh, it's like a number. It's not like that at all. Yeah. Okay. I mean that, that makes sense. 'cause what's the mechanism to coordinate it and Right there is no, everything has to be learned. Everything. And the real values then are Breaking that rule a little bit. I don't know if that's true or not, but like you encode hue the same way everywhere in every layer. Yeah. blue is the same number everywhere. Whereas with SDRs blue might be encoded with one SDR in one learning module and another SDR in another learning module. That doesn't mean we couldn't, unlike biology, we can take a quarter of a column that's trained and replicate it. And just make copies of it, convolutional neural network, something like that. And in that case, they might end up, might start off with the same representations.

but, cause, but in biology, that wouldn't be the case. one part of V1 doesn't know anything about the other part of V1 is doing, and you can't, and the neurons are coming and going, they're dying. They're, new ones are appearing. It's these representations are changing all the time. it's a very different sort of system.

I guess my thought was just that like it. Better or worse, it maybe hides a problem, which is that coordination piece or how you deal with different representations in each place. Yeah, I think in general, like for Monty, it wouldn't be that big of an issue. Cause yeah, everything is just learned. You've just store features in the graphs and you just match them when they come in. is this the same feature that I have stored in this graph? So I don't think it would be an issue at that level, but it does make it a lot easier to visualize the system and debug and see what is it actually learning for your own eyes, each layer. Yeah, exactly.

Remember these, numbers don't exist, these aren't numbers, these aren't like some vectors that reside someplace. These are neurons that are firing and not firing. And it's, and the same neurons don't exist someplace else in the cortex or the column. They're just different neurons. There's no possible way that the, there's no table that represents SDRs, very, organic system.

so I, yeah, I have a question again, we can park it. would it be useful, even though we're using real numbers, would it be useful to just. Offset them like just heart like you have a new learning module, just hardcore that every real number is offset by whatever so that we never have a global correlation and we're ensuring that they're learning off of whatever numbers they have. It was still, it's still a misconception of how it works. Tristan. Yeah, nobody looks at these things outside of their local context. There's no. There's no possibility that there can be confusion in that regard.

it's not oh, this range of numbers is for this and this range of numbers is for that or something, it just, I don't know. I just, you just, we have to get the system has to work without some sort of. Table of values. You know what I'm saying? So for what it's worth, for what it's worth, I would say that the system would work exactly the same. It wouldn't be any issue for Monty if we would offset the color values for every learning module. Cause they go in, they never get communicated somewhere else after that. they, we don't vote on features. We vote on the objects that were detected. And that's actually something that we do need to, fix that. Like the voting needs to learn mappings, but yeah. On the feature input side of it, it wouldn't be an issue.

Yeah. So I guess, yeah. One way to say it's basically it's fine for now. I guess it's my, it's good to be mindful of it. But. We might as well, we're for whatever we're using the real value, kind of activations for, or we might as well just, take the benefit that gives, which is, we can just easily visualize it and we know exactly what they correspond to and stuff, but yeah, I guess it's an interesting thing to be aware of.

yeah. And then I've shown here, maybe controversially, just this. we could consider passing in, features that might correspond to texture patches.

and, yeah, and that this could be something where, you don't necessarily learn a detailed model of how, cheetah skin or whatever is on the animal. You just know that it's distributed over it or, tartan or whatever, unless you attend to and specifically learn where, a particular spot is relative to some landmark on the animal and things like that.

but. Anyways, SDRs are, would quite naturally be able to represent essentially textures like this as well, which is something that we definitely can't do with, real valued, or with, this current, setup.

and then, I feel like it's worth just explicitly, addressing the elephant in the room or whatever about kind of real value vectors and just I appreciate you. Yeah. To your point, Jeff, like there's, not good evidence that neurons can do super high fidelity activations like, in, in, what you call it in deep neural networks. But, this does introduce some advantages using these kinds of representations. And then I guess the question Is this something where we're only going to gain benefits by deviating, from biology or to your earlier point is, does this introduce some risks? If we go down this path. Yeah, this, starts to, it is not really possible. First, you can't have minus negative and positive values, right? Don't do that. Endurance have very, limited, possibility for values, real values, they're spiking, as we've talked many times, you don't often don't even have time for a second spike. So you can't really do a spike value. I think the challenge every time I looked at them like this is that. From the neuroscience point of view, if we ever go down to rely on compartmentalized neurons, like the HTM and HTM neuron, and you're basically detecting coincidences of features, then these real value activation values make that whole premise, untenable, I think, you make a change like this, you can say, Oh, this is great. It gives me all this higher fidelity or higher capacity or whatever it is. But then when you look at the whole, how it's going to be used in the system, it doesn't work. at least it doesn't work the way we might need it to work. so you can't look at these things in isolation. You have to look at them in the context of how, who's receiving this information. How is it going to be processed? what, biological features? You mean the power of a neuron to represent, to capture many, different patterns? is really important. And this might, prevent that from happening. So yeah, you gotta be careful of these things. I have one question, a little bit, backtracking for a second, but you're showing that pattern of plaid there. So I get that what Jeff is saying is that, These encodings, call them SDRs or whatever, don't have to be uniform across, any one particular layer. It's, they're learned independently in the, columns. But at some level, there is a recognition that if one cortical column sees a piece of plaid, another one sees a piece of plaid, that there's some notion of continuity there. Which, I'm wondering how you solve that unless you have some sort of alignment of what the representation is or whether two codes are equivalent at some point so that we detect discontinuities in, easily, so unless you have a way of saying I'm seeing the same continuous pattern as it slides across, the various, receptive fields, I'm wondering how you solve that problem of representation unless there is some alignment. Sort of commonality that says, this is the same as this, or this is different than this. Yeah. Okay. I was just gonna say that. Yeah. I feel like that's where like hierarchy is really important that, yeah, it, basically, I think depends on who's receiving the information. And I don't think if, two different systems are receiving two totally different inputs, I don't think it really matters whether the SDRs were the exact same or not. They're not going to know. That, there's some commonality between them, whereas I think generally, you can imagine that it's going to be at some level, something is, it feels like that, Kevin, but it isn't, and, Vivian mentioned the key to this earlier, what columns vote on are object ideas and they, have, they can learn an object using completely different sensory inputs and completely different experiences, but as long as they're modeling the same thing, they agree on, that thing. Now, to the extent, if I'm an expert in plaids, I would see different plaids and recognize them and that becomes the object. So you're voting on the, you're voting on the idea of a particular type of plaid. If you attend to that plaid pattern, but you don't need to share representations, it's imagine I'm touching the coffee cup. And my fingers, the distribution of sensors on my fingers are different. there are skin sensors and there's quite a few of them and they're not equally distributed over your, body. So one part of my skin will be using one set of sensors to learn to coffee cup and another one, a different one, maybe one's sensitive to touch or, to, texture and the other one sensitive to temperature and heat conductivity and so on. None of this, you're not aware of any of this. It doesn't really matter. As long as they're all saying, yeah, we're all touching the coffee cup, that's fine. And then, and they don't need to share what their details are. You don't even know most of these things. You don't know what features you're detecting. I wasn't trying to say that, Jeff. I was trying to say at the next level, whether you're, trying to agree upon these object IDs, if you wish. Remember the voting mechanism is that each column has some guess of what kind of objects it's, but it's not an object ID. What they've learned in the past. They've learned in the past that when sensor 1 is detecting some part of an object and sensor 2 is detecting some part of an object, it doesn't matter. The only thing that matters is that, yeah, we're both touching the same thing. And we're both sensing the same thing, and we can agree that, based on my evidence, I think it's, X, and your evidence, you think it's X, and we can, then we can learn that's an association. we don't have to agree about anything else. We just have to agree that, at the moment, we're both sensing the same object, and we can learn to associate my SDR with your SDR. there is no passing of the SDRs, if you will, there's no agreement upon them. It's just, I have a representation. I'm going to learn to associate with whatever representation you have and the details. There's no other, there's no other knowledge beyond that. It's just here's a pattern you've sent to me. And, it's, I have my own pattern. I'm sending it to you. And let's agree that this is the same thing. Okay. That's, the question, right? Right there. How do you agree? It's the same thing. Because they happen at the same time. They're basically sensing the same object. They, basically just learn, okay, I have some SDR in layer two, three that represents the coffee cup. And whenever that SDR is active in my layer two, three, your layer two, three usually has this set of neurons active, which in that SDR corresponds in this column to the coffee cup ID. So it's just associating whatever SDR is active. The time at the same time when one object is being sensed. Okay, I perceive. Thank you.

Yeah, I had that exact same question. I think I asked Vivian on day one., you don't pass the SDRs around. This is, these concepts are very hard for people to initially get. I just want to point that out and we have to be constantly vigilant because almost anyone coming into this project, for example, will misunderstand these things. there are epiphenomena like, the ability to fill in, when you have a defect in the vision and stuff like that. So there is the sense that also Kevin, I'm going to that is a mistake. That is a misconception that's been passed around for decades. We don't fill in, and people have written about this. What we do is you, don't perceive anything, and then yet if you attend to some spot, then you can predict it will be there. So the classic example is you have a blind spot in your eye and people say, oh, we fill it in. Not true. The blind spot is no different than I'm touching a coffee cup with a couple of fingertips. And I, basically, I'm not touching most of the coffee cup at all. I'm only touching a few spots on it. I don't fill it in. Basically, though, that we have a model of a cup, and if I know, if I move my finger someplace, I know what I will touch. So nobody's filled it in. Everyone just says, Oh, I have, I know what model we're talking about here, even though I'm only sensing a little part of it. I don't want to, I'm not trying to be critical. I just, these are things that took a long time to, to figure out that these, some of these notions that are common out there are not correct. We don't fill things in. We are able to predict what's missing if we go to that spot. Okay. So I'm just trying to look at, what the mechanism. Potentially is if, all I'm trying to do is saying, there's a wallpaper pattern and, I'm predicting basically saying that if there's missing information, you're saying I will still perceive it as a continuous. I don't perceive it as a continuous pattern. I say I have a model of this thing. The model is it's continuing, but at any point in time, I'm only sensing some small parts of it. Nobody else tries to fill in the rest. It's just that the model says it is there. So if I go anywhere and attend to any spot, I will see it if we validate our prediction or model by sensing different parts of it, but nobody's filling in. Nobody's representing what's not being sensed. It's just the model says, Oh, I'm I got the pattern on the wallpaper or I have the coffee cup. I can perceive the coffee cup, even though I'm only touching it with one finger. I've invoked the correct model. But I'm and I fill it in only if I attend to other parts. it's like it seems like it's there because I can go there and it'll be there, but I actually didn't. There's no neurons representing where you weren't where you weren't sensing until you move the sensor to that spot. Then it says, it's there. This is not other people have written about this, but it's not purely our theories. I suggest we keep going because we could, spend a lot of time on this. Yeah. Yeah, no, it's an interesting discussion, but yeah, I'll, yeah, this is just the last one on the kind of representation one, which is, yeah, and this, is definitely What do you call it curveball? Probably not something we will visit. But again, I think it's just worth explicitly bringing up, which is some sort of temporal code in the kind of neural representation. And this is one example of a temporal code you could have. There's lots of ways that time could come in. This is showing that kind of you have neuron ID here on this axis. So you have three pre synaptic neurons and one post synaptic neuron and the same three pre synaptic neurons and another post synaptic neuron. And in this instance, they fire with a particular temporal offset. And in this instance, they fire with a different temporal offset. And, their signals due to these conduction delays arrive at the different neurons, depending on which, sequence they spike in. But yeah, there's, a lot of different, temporal codes you could do other than this. This was just, I thought, a simple one to put in this figure. The, I guess the key point with the temporal code is it allows you to encode an orthogonal, dimension, which, you could imagine might be relevant in encoding something like, if you have like feature ID and then you're encoding its pose, or feature ID and then you're encoding its scale, then the temporal code gives you this flexibility to have kind of something that you can adjust that dimension of the code without distorting it. say the kind of feature ID representation, this idea has been around for a long time and it's my, recollection. I haven't looked at the papers recently. This has always been derived from people who are trying to figure out. How you could use neurons to form, more interesting representations and not people who say, what are the neurons actually doing? there's lots of literature of people saying, oh, look, if we did, if the neurons did this way, we get all this extra information over neurons this way. we're in reality. They're just making it up. now there are conduction delays and there, but the, idea that this idea, which could be right, but I don't have any evidence for it, is that you can individually adjust the, very precise spike timing of, within, milliseconds of an, of a cell. And that is the, that is encoding itself. that's part of what the neurons representing. It's everyone agree that when a neuron fires matters, so they have to fire together, to do anything. But this is much more specific, requires a lot of coordination between these neurons to know when. And, again, this is in the category of machine learning person comes along and says, Or, an engineer says, Hey, this would be really efficient. Let's do this.

That doesn't mean it's biological at all. Yeah. Yeah. Yeah. you can tell my biases here. Yeah. No, Yeah, no, but I'm trying to capture with, I know this is one example I showed, but with temporal code, I'm also trying to capture, for example, spikes relative to a phase, which I think is something you are more amenable to. We know that exists. We do know from biology that type of temporal code actually exists. So if we were going to show an example, I'd rather show an example of that.

Because now we know that exists, we go, oh crap, maybe that's something useful. Let's understand it. So there's an observation, empirical observation, which people don't really understand the information, aspect of it as well. Here's an information aspect that doesn't correspond to biology. so I just. Yeah. Okay. No, I'll, I'll update this. But, but yeah, I guess whether it's this kind or the phase based one, I think it's still similar in that it's basically enabling like another dimension of expressiveness. but yeah, I appreciate there's, there are still lots of differences between them.

yeah, as you can guess, just, or like eyeball just from the amount of green here. The kind of current favorite is, SDRs, and that's therefore, what we're largely going to focus on, going forward, at least according to the current plan, obviously, this is a living, living document, but, yeah, we've discussed keeping, at least in the short term, some of these, real value numerical features and, yeah, we could have, Tristan was suggesting, a parallel version of the system that, maintains these just for people who are first getting familiar with Monty, and learning how to use it. That would be a difficult fork to maintain. Yeah. And it's funny because I was thinking about it in some ways it's more intuitive. Funnily enough, I feel like for a lot of engineers or deep learning people, I feel like this would be maybe equally intuitive in that, they're so used to features being represented as vectors anyways. They might find it actually counterintuitive that it's wait, you're passing in, but then they immediately, but then they immediately jumped to, appoint neurons, no, no active, Plus, high value, high fidelity, values, positive and negative, none of which is right. So I see your point, but they'll, take that leap and then they'll just go off a cliff with it. can I ask a question? yeah. Have we run and what have we, reached the end of what we can do with real value features and numerical representations? I would say we're more reaching a stretching point. So like with, with the work that Rami did, like encoding object similarity, like there is a way we could have done that by passing like some information about kind of these, Evidence matrices and this adjacency matrix of the evidence values like we could have maybe kept that still as real, these kind of numerical features, but I felt Yeah, at that point, it was really starting to stretch what that could reasonably do, in kind of an elegant way. and it also felt because then we're starting to get into the hierarchy of the system. That's also where we expect to start seeing some of the kind of other benefits that the SDRs are going to bring. and it just was like a natural point to, to start exploring that. Okay. Does, using SDRs upset the way, information is stored on a graph in Monty? Or is it a natural transition there? Cause I think like right now you're storing individual features. Yeah. Yeah. So it's quite a natural transition in that, like basically each point in the graph can store whatever features it's coming in. So actually right now we're going to have points in the graph that have both real value, numerical features and SDR features. But yeah, one point to make us, we're only using SDRs for the features and not for the locations on the graph. So like the locations are still real valued numbers. That may be a problem, right? that's the Yeah, that's the next discussion. Okay. But do you mean? Yeah. Yeah. Okay. But anyways, yeah. And then I think, this is only if we really get stuck, that we would, I think, explore this. And similarly, but, the plan is also, of course, we're still continuing brainstorming and all this kind of stuff. And so what I was thinking is we could return to this document in three months as well as whatever discussion happens over the coming weeks. We can return it to this document and say three months time and then update it and we may say at that point. Oh, no, actually, we definitely want to use phase code. Let's think more seriously about when we bring that in. I think this is a really important philosophical issue here, so I'm going to keep harping on. Yeah. yeah. If we wanted to dip problems we can't solve, I wouldn't run away from sparse representation. I'd hunker down on them because we know we have to solve the brain has to solve these problems. yeah. And we should focus on the way the brain solves them before we go say, Oh, it's too hard using SDRs. Let's go do something. The brain doesn't do I guarantee you, you will regret that. I can just promise you it will be a big mistake. you have to like, say, 1st, understand how the brain does it. we talk about locations. It's so important on saying how the brain represents locations and then we can say. Do we have to do it that way, as opposed to saying, we have a problem with representations. I don't know how to do it, but I can solve it with time codes. That's going to be a mistake. I promise you, you're going to, it's just, it's going to lead the project down the wrong path. Yeah. You might go there afterwards, you might say, we figured out how the neurons do this, and we understand it really well, and we prefer to use, some other coding mechanism because it's better for software or hardware or something like that. That's okay. But not because, oh, I'm stuck. Yeah. So yeah, I'd say, yeah, no, that's a good point. Thanks. All right. I'll note that here. I can maybe add something to the document. yeah. So I'd say, with this, it's largely consistent with what Numenta, I think already always had in mind. So maybe this is the less controversial one.

and yeah, over the next six months, as we're focusing on, kind of hierarchy and compositional objects, we'll keep working with SDRs where useful, have some real valued, I'll maybe, I'm more concerned with the language around using real valued vectors.

so yeah, but then the, I think, one that might be a bit more controversial because it's, questions, maybe the, what we a couple of years ago we would do long term is what we would, the reference frame representations, and I guess the short summary is, I think both Vivian and myself feel like there are a lot of advantages of the explicit, coordinate system. beyond just kind of simplicity and visualizations and things like that. and it's harder to see the advantages of the grid cell approach. and so this is something where maybe we'll at least move slower, in going into the kind of more biological ones or maybe even stay here.

yeah. And so I guess, yeah. Again, in the document, I go through all the kind of pros and cons, but I think there's some, sorry, okay, first I'll just talk about the, yeah, so I think everyone's familiar with this, we're explicitly representing these points in the graph in some kind of XYZ coordinate system, and each point in that graph has some information associated with it. Obviously, this is very easy to visualize, and then we have a, in general, these are unconstrained in that we can keep adding points and They can also represent an arbitrarily large or small objects like there's no limits to how big an object a network can learn.

but then Vivian had implemented this, constrained version, which essentially if you imagine you have a voxel, so 3D, boxes, a kind of voxel grid of, 3D space. And that space has two limitations. It has like a limitation in its maximum dimensions. So let's say a given learning module will learn objects no bigger than 10 by 10 centimeters. And then it also has a maximum number of voxels. So essentially the resolution of that space that it's going to model.

and then I don't think it's too important for this, but, then Winners. So they're only like K voxels that can be active for that object. Sorry. Thank you. Yeah. Yeah. So there's also sparsity within that. So it's not every voxel that's being used.

and. yeah, so essentially three constraints. And yeah, there's a kind of algorithm for taking kind of similar observations to this and mapping that into a, it'll still be like a 3D graph, like that. But, or, like the observations are received in a similar way. and it still outputs a 3D graph, but it's a 3D graph that is subject to, the constraints on them. I was describing before.

yeah, feel free. One of the things we believe the neurons are doing, we don't have proof of this, but we believe they're doing is the, they form unique representations of location so that you can take an SDR, which is a SDRs have this, astronomical representational space. And, so when you represent the location and object, it's unique, not just to that location on the object. It's unique to all objects in the universe. these, this, these kind of representations have that ability or not.

Yeah, in the sense that they're stored completely independent. Not stored independent, but, literally, if I use an XYZ coordinate system and I can say, oh, you're at location one, one, one, one, one, one on what object, it doesn't, the location itself doesn't tell you that. But that is specified. So it's like, it is location one, one, one on X objects versus location one, one, one on another object. So theoretically you could have every object, like you could offset the x coordinate by a thousand for one object and the y by a thousand for one object and they would be very far away from each other in three dimensional space and object recognition would still work, like it really doesn't matter where in the space the object is, it just matters that the relative locations within that object are consistent. But you could put we're still working in Euclidean space, so it's not like the locations are represented as SDRs, but you could put them in arbitrary locations in that space, so put them thousands of kilometers apart. That's good. That's good. I still see potential problems, but that's better than otherwise.

the potential problems are things that I don't really have enough data about in neuroscience. And I suspect I don't really understand them yet, but I know there's some things that the neurons might be doing that we don't understand yet, but it would make a difference. But I can't I can talk about what those things are, but I don't have evidence one way or the other. this has to do with the overlapping of SDRs. And, how brains, how the brain resolves the unions, for example, unions, I guess I'm talking about unions are a perfect example where you can simultaneously represent multiple hypotheses with the same set of neurons simultaneously. And that's part of how the brains resolve things. But here, you don't, you'd have to take, make lists of things, but you can't really have, there's no single representation of location that forms a union that you can form a union of. You could say, oh it could be one of these 20 objects and you have a list of them, as opposed to them being inherent in the, representation itself. Okay, I, that's enough, thank you. Yeah, no, that's an interesting point because, I don't know if it's worth discussing a little bit more because I think in general when we talk about a union of locations I feel like that's a form of interference, like that's more of a, I appreciate there's a lot of situations where we want a union. But when we're representing multiple hypotheses that we're testing simultaneously, it feels like the fact that we're cramming all of that into a fixed neural capacity is more like a source of noise. Why? It's, I don't see it that way. I see it as beautiful. It's like an elegant solution to the problem of I don't, see it as noise at all. It's noise only if you have too high a density of representation. If you don't, it's basically the system with sparse representations is just in parallel, processes these things in parallel with no interference. We've shown that mathematically. It's, they don't, it can read them out, but it's just all this stuff like path integration and, there's a separate question about how path integration comes about. that's a detailed mechanism, that how the neurons exactly do that. we know how a single neuron does that, but how you take all that and create grid cells or representations a little tricky.

so maybe that, maybe what you're saying is with this union, we don't really understand that the neural mechanism exactly how grid cells, work, but we don't understand exactly how they work without a union. So I don't see it as noise. we do know that if you have an SDR and you're passing it to another set of cells, unions work well. there's no problem with them. Okay. Yeah. Yeah. And I guess, so one of the things, yeah, I guess that comes up is in terms of grid cells, that, we're not entirely, or to your kind of point, we're not entirely clear how they work for certain things, like how they could update multiple hypotheses, in parallel, in terms of path integration, things like that. Another thing that we've talked a lot about, but, there's not good neuroscience for is like, how is 3d space represented by. grid cells. So we have a lot of And so it's even if we wanted to use grid cells, it's not entirely obvious how we would. I've never said, I've never recommended using grid cells per se. grid cells as a placeholder for sparse representations of location that have the property of, path integration in unions, potential unions. it's just an area where we don't really understand how the neuroscience works. We have some of these attributes that are like, oh, that's amazing. what a clever way the brain came up to solve not having, basically not having numerical values. The brain doesn't have numerical values. It has to solve everything without them. And, so this is wow, what a clever way of doing this. that's how I felt. I think that's how Subutai felt when we first marked this, when we first came across this, oh, crap, this is really brilliant. Biology is smarter than we are, or evolution is smarter than we are. but we don't really understand all the details. So this is an interesting challenge. I think I would put this again in the category. since we don't know how the neuroscience works in this case completely, let's keep using real value, coordinate systems. Don't think that's better than the neuroscience. I would do that with the idea, it's probably not good enough. we'll keep going until it doesn't work. And we'll, maybe we'll learn some more about the neuroscience along the way. but I don't, what I bristle at is, to saying, the neurons don't do a very good job at this. We can do a better job doing in some other ways. no, we just don't understand the neurons yet. And I bet you the way they're doing is better than anything we're going to come up with. But we just don't know it yet. So we have to do something else in the meantime. That's my attitude about it. There is a coordination issue again, here where, and do grid cells solve it? Where, how we represent location needs to be communicated between. It's no different than what we talked about before. There are no, there's no communication or locations and it doesn't need to be.

Yeah, if it helps like every learning module or every column is dealing with object centric coordinates, but if they pass information between them, then that's using like a shared coordinate system. But that would be like body centric or like egocentric. Yeah, voting to work, we need, they need to know their relative location, orientation to each other, the sensors to each other. I don't think we've, never worked out the details of that. Yeah, that's something we still have to figure out, but the object kind of location spaces themselves are independent. Yeah, but still, in order to be able to interpret the voting signals correctly, they need to know, They don't just need to know, I think I'm here on the object. They need to know, okay, if you're here, then I should be over here because the sensors are not at the same location. So it turns out that I used, I was fooled by this early on. That I thought these values had to be communicated elsewhere. take location. I said, I have to, location A here has to be turned into location B over here. But when then I first, then I realized, A, that when information comes into a column, we're not passing locations, we're passing movement vectors, and that's relative to a common reference frame, so that works. And, and as I think Vivian and Neil both said, we, the brain does use other reference frames. So if I want to, I might be moving my hand and, it would go through a common body centered reference frame and then back up again. But the point is, the original question is, do we need to communicate these things as SDRs? And the answer is no, they're, not. That doesn't happen. I've adjusted this to, yeah, be, as you pointed out, we've discussed recently that there was a lot, especially recently that, it's not necessarily grid cells, some form of path integrating neurons is really the key, but that can represent unique locations. And then just again, because it's something that new mentors looked at in the past, I thought it was just worth mentioning, although I don't think it's, a particularly good approach is SDRs for location where we're basically taking X, Y, Z coordinates and using some hashing algorithm to convert that into an SDR. Is this what we did? You're talking about what we did at the anomaly detection and the GPS or the, I think, yeah, I think it was used then, but it was also used by, like for example in, Avi's work, which was like one of the, that was actually like the, I think the first, it was just as I was joining it was like the first attempt to use HTM for Monty Yeah, from I, yeah.

yeah, it's a bit of a funky one, but yeah, so you're asking in that, previous slide where you're updating things, why you marked, hashing algorithms and read, this one. Yeah, on the right hand side.

so as in the. which bit is red? You mean the no path integration or the hashing algorithm is computationally intense? Yeah. So that's a fair point. Maybe this is wrong, but I guess, what I remember from Avi's project, at least, is that was like an extremely, time consuming process was just converting the locations into, these SDRs. Okay. Cause I've been doing some reading on, locality, sensitive hashing, and. It, strikes me is that there is aspects of them that, that kind of line up with what SDRs do, the notion that, if two things, hash, they're basically looking to see whether they're similar and two things hashing, to a similar location takes you into a localized area of quote unquote memory, where, That would offer up candidates to, for further processing. In other words, it's a way of winnowing things down based upon, some hashing algorithm. Now, the normal hashing algorithm doesn't really, is just a compression technique. There's nothing, particularly clever about it. But if you replace that kind of random hashing algorithm with something that is somehow learned rather than just, a random, smashing of bits together. I'm wondering if you're getting closer to something that's more neurological. so are you questioning the fact that it's computationally intensive, Kevin, or that I'm, questioning whether it's intensive, but I'm also, trying to push The notion that you could have some notion of location being an emergent property of some process like this. Okay, I think, so you're really questioning whether that's a red, the redness of that comment there. Yeah. I might just, you just put a question mark. yeah, I added a carrier. Yeah. again, it's, it sounds to me, Kevin, it's Hey, I can think of a clever way of doing this. And it would have these information theoretic, advantages, but, perhaps it has nothing to do with the way neurons work, Or it could. Yeah, it could, everything could, I, I can make neurons do anything, but real neurons don't, real neurons are pretty restricted, it's, yeah, neurons might be using SDRs for locations or might even be likely using SDRs for locations. So I think this is something we should think a bit more on if there's maybe a better solution than what Avi initially implemented. this has been a long time ago, but I remember the same thing that you wrote. Neil said it was very slow and that it didn't path integrate. But maybe there's a better solution and Yeah, but I look at it and I have a much deeper dictionary neurological principles. And so I use that as a constraint. and then it's right. Sometimes I'll say, hey, that's not really possible, or we have no evidence that could work or something like that. I don't have any opinion in this case, Kevin, I just.

I don't know enough about the hashing algorithms you're talking about to know whether, but I did neurons could do this. I'm just warning you morning. Everybody.

We should take approaches like that carefully because we don't know what we're giving up. As I said earlier, but I don't mind doing in the short term. It's fine. let me turn around. what I'm trying to do here is say some of the power of what an SDR does could be looked through as the, as a lens, through the lens of a hashing algorithm, and then you have a whole bunch of maths that give you the ability to analyze what's going on. That's a useful activity. That's useful to help us understand maybe some, possibilities of how SGRs could work. that's what Rami did during his internship here. He worked on things that I don't really think that's actually going to do it. but, it's helpful that what he did to think about, possibilities and new ways of thinking about them. Yeah, it is. it is interesting to think about. Maybe to think about though, in that sense, okay, there's a lot of advantages of, this, explicit code, but let's say we feel like specifically representing each location as an SDR has some inherent value, maybe it's something about unions, like you were saying.

Ultimately we can do path integration and stuff like that in this location space, but maybe as like an intermediary step, it is helpful to convert. The XYZ coordinate into an SDR before further computations are used, or are done. and, Yeah. And so if that's like a learned mapping, which I think is where you're getting that Kevin, like rather than some like random fashion, then maybe that could be quite fast. Yeah. that's, an essence. The thing is, that I'm trying to, I'm trying to get away from the idea that either 2d or 3d is an explicit coordinate system. And there is simply this notion of this is close to this. Which is what, LSH does, but I'm thinking that there's more to it than just simply that they're similar, that there's, similarity in maybe multiple different spaces. a lot of times what they'll do with the, the usages of LSH is they'll do multiple hashes and to get, greater fidelity to how something is close to each other. that's one way, I think, of bringing together, multiple projections to get you to something that maybe has higher dimensional properties. and I can just, I'm trying to relate it back to, all the way back to the neuron where things, the 40, synapses in a group, 20 of which firing, something like that is, to me, there's a deep connection there to, to. To an emergent property of something similar to something else or something, coincident with something else. like I said, I'm just trying to use it as a lens to think of this thing through a prism to think of this thing through rather than, going off to I like that. but I think the summary right now is we're using real values. We're going to continue to use real values for the foreseeable future. and maybe we'll run into some real, I'm throwing this out to make sure I understand this. and that's the plan at the moment. Is that correct? Yeah. I think right now we're not hitting any bottlenecks. We don't have any issues with the real value representation. So it's interesting to figure out more about what the neurons do, but as long as we don't see a real benefit of using a different representation. So from the, until we run into a problem, or we independently discover the benefits, we're going to keep on the same path. Yeah. And then, but I still think there is also that kind of like sunken cost one, which is if we, think we're definitely going to abandon something, then we also want to be careful about how much time we spend, at that point. We don't want to abandon it for. We don't want to abandon it because we think we're going to. We have to abandon it because we know we have a problem, and we know we have the solution to the problem. and we don't have those now. and by the way, if we run into a problem, a real problem, using real value numbers, we're That can help us understand the, how the brain solved it, because then we can say, how would the brain solve that particular problem, and, you can search the literature, we might be able to get an answer to it. again, I'm not sure if you're agreeing with me, Niels, but I, think your recommendation was to stick with this stuff for now, but I think we should continue. I don't think we should abandon anything until we know where to go. We have a problem. Otherwise, we could spend a lot of time. One thing actually that I did, I think, so if you show the overview, it might come up, but the do recommends that we move towards the constrained versions of the graphs, like basically not allowing a learning module to learn a huge object at super high detail. Cause I feel like that's the biological constraint that we want to have. And that will also help us with like compositional objects and representations Basically the lower level learning module shouldn't be able to learn the large compositional scene at super high detail on its own. We want them to learn parts of the object and the higher level learning module learns the compositional object. and I think those kinds of graphs will solve several other issues, like separating an object from background and, things like that, learning general, generic objects.

Yeah. Yeah. No, I think that's a nice point. Yeah. I've got that here.

but yeah, so this is, I think, yeah, I should probably just, take this, maybe, not applicable given our current kind of knowledge, but, could definitely, relevant. And then, yeah, I think this one actually after our discussion just now, I'm a little bit more open to it being relevant in the future.

This one again, SDRs for location non grid. Ah, that's the kind of hashing. Okay. Because it, because that might be a hybrid solution that kind of, we still use something like this, but then we still ultimately represent the locations as, so we basically do path integration in this space, but we do, but we represent. Got it. But can we agree, we're not going to pursue these ideas until we need to? Yes. Okay. Thanks. Okay. Yeah, that's, these are all waiting in the wings. Yeah. Yeah. And, yeah, what I have is other than we just come up with something, or like we realize, to your point, we run into an issue with, I can imagine in the kind of 12 plus months timescale when we started looking more at objects behaviors and abstract spaces and stuff like that. We're especially likely to revisit reference frames maybe and maybe find, maybe we dunno yet. but yeah. But it's unknown problem with a slide like this is, someone says, see you. It's been 12 months, it's time to work on this or something. It's no, it's, we could work on it tomorrow or it could work out it three years from now, depending on Yeah. What we've learned. So it's not a, it's not a roadmap for implementation in this case. This is a go until it's broken and then we'll have to figure out how to fix it. Yeah. So the road map is not a term here. Yeah, I think that's definitely plan here. I think it is. Yeah, it is the plan, but I can maybe write that more explicitly.