Okay, cool. So I hope I didn't over promise, too much message.

I, did make a long list, handwritten with all the requirements and then wrote solutions for all of them down and could check all of them off in my head. But then I made those slides, yesterday and today, and I did notice a couple of holes in it. So there are still, it's not a solution to everything. There are still a couple of, open questions with what I'm proposing and also, not everything I'm, presenting here, stuff that we already agreed on. I'm gonna start with the stuff that we already agreed on, for the most part, and then clearly separate where I'm starting to put together ideas we discussed, but haven't really settled on yet. but I think if we pull in those ideas we previously discussed, they could solve, almost all of the issues, we have or all of the problems we are trying to solve. And the main open questions are around where this would exactly be happening in, neuroanatomy and some more mechanistic questions around, matrix cells and other aspects of it. So that sounds promising because yeah, I guess that's the, in some sense, less important issue. Yeah. Yeah. So hopefully it would address like on the conceptual level most of the, or pretty much all the problems we discussed.

so it is a bit of a dense presentation. I really spend a lot of time trying to make it, digestible.

and yeah, putting everything in reference frames and making it, visually, useful for people to understand where I'm trying to get at. But still, it's partially some kind of complex ideas. just, yeah, feel free to interrupt and ask questions whenever. and yeah, we can discuss everything. yeah, chapter one. I'll start off with just, yeah, there are, four chapters and then epilogue. So chapter one is, the Problem and Constraints. So just going through, yeah, the problem space, which isn't a trivial thing. It's I feel like half of the time, we spend talking about just the problems we're trying to solve and all the different aspects of the problem. So I just try to put together a complete list so then we can check those off in the next chapter, with the solutions to make sure we are actually solving everything. You, you may not remember, but in, in my book I said that, this the way to solve problems defining the problem. If you define the problem sufficiently, the answer presents itself. So I'm agreeing with you. It's if you really got the problem down. Then the answer's obvious. Yeah. Yeah. I was just talking to Will yesterday about how, in the beginning when I started at Memento, it would be like frustrating. You would think, oh, this is, this would work. And then you would come in and be like, no, brains can't do this. this couldn't, like you. Maybe you can do it in a computer. But then, and it, in the beginning be frustrating, but now it's oh, that's great. We have one more constraint to find the optimized solution. Like each of those constraints actually helps us narrow down, yeah. The solution. So hopefully, yeah, this is helpful.

okay. number one, we want to learn a model of object behavior. That's the task we set out to do. So there are tons of objects that move and we want to be able to learn those behaviors. And with that, we want to include any arbitrary change in features and morphology over time. So it could be something moving, it could be something changing. Features, color or brightness could be something moving in like multiple directions. multiple degrees of freedom. It could be multiple objects, moving, dependent on each other. It could be like a compositional object, moving its parts, in a coordinated way. so there are lots of different versions of beha behaviors, and we wanna be able to model all of them with one mechanism. And also we somehow need to be able to observe all the changes such that the model can be learned in a column. So either like following the movement or circadian around, or having like many sensorimotor patches covering the object.

and we talked about, all of those, before as well. And that might, this, I'm not gonna go into too much depth on this one 'cause it might be like a combined solution, of, intelligent policies and voting.

and then second, after we learn the model of a behavior, we wanna be able to use that model to recognize object behaviors. first, we wanna be able to recognize the behavior on an object, on the same object that we learned it on. So we learned, the stapler mo moving up and down and we wanna recognize it again when we see it. But also we wanna be able to recognize the same object behavior on a different object like we learned the stapler. And now we can also recognize that behavior on the whole puncher. and like the extreme example, we talked about before, it's like the walking or dancing banana. It's certainly something you've never seen before, but still you can recognize that the bananas running, and you can imagine a dancing banana without even, ever having seen one. so brains can clearly mix and match these, object and behavior models.

we also wanna be able to apply a behavior to an object at an arbitrary location, orientation, and scale. so we might have learned a hinge behavior and then we can apply that to the la, to a door or a laptop, or any kind of object that has a hinge on it and opens and closes or book.

we also wanna be able to recognize where in the behavioral sequence we are. So if we see a closed stapler or an open stapler or a wide open stapler, we wanna know where in that kinda sequence we are. And we wanna be able to recognize the behavior at different speeds. So we might have learned this kind of speed of stapler, but then we can also recognize it faster or slower, and we wanna be able to do this with single or multiple columns. put a question mark there because it's maybe a bit questionable how well we can do this with a single column.

at least for more complex behaviors, like very simple behaviors, like just pushing down a button and recognizing that with touch, is, should be possible with one column. But, anything more complex and fast moving might require multiple columns.

next big topic. So, those are the first ones that we talked about a lot and that we have a solution for. now I'm going a bit more into additional things that came up lately. so can I just re just comment on the multiple column I idea? Yeah. In my mind, a single column should in theory, be able to do everything, but practically it may not be able to do everything. I just, I don't think we should be thinking like multiple columns are necessary for distributing the, knowledge of the movement or distributing the knowledge of the object. yeah. Yeah. No, I, that's why I'm saying like a simple behavior, like pushing a button and recognizing that from just touch needs to be able to be learned in one column because we are only getting touch input to one column as well. Yeah. But if there's something I just don't want, I don't want anyone to feel like, it doesn't, this doesn't violate the columns hypothesis that columns all do the same thing. It's just that practically you might need many columns to do this. yeah. I'm done. Yeah. Like we could almost phrase it as a magnitude thing that, in terms of the efficiency of learning, there comes a point where a behavior will be so complex that in theory, a single learning module can still learn it, but it would take so long to, to revisit all the parts and stuff that it would just practically be pointless.

but, it's the exact same mechanism. It, just is faster. Yeah. Yeah. And here I'm even just talking about inference. So recognizing it again where it's probably hard if you have like more global movement, like a person walking, if you just have one column and the movement is rather fast, it's hard to see enough changes relative to each other to recognize, again, if it's moving fast, right? Yeah. Point, right? That's maybe something to try with an extra treat is straw vision and those like random dot movement things just given enough time. do we recognize it?

but yeah. Anyway.

okay, so next bigger topic. So learning associations between objects and behaviors. So one, if I'm seeing a static object, like I see the stapler and I've learned the behavior of a stapler before I can, I know that I can push that stapler down. I have an association between this object can move in that way. I learned that and like how is that represented? And then second, also seeing the behavior can bias what object we infer. That's the example we talked about before where we, don't have any features of the object itself. We just see, movement. in fact, if you show a frozen frame, you don't know what it is at all. But if you see it moving, you can, infer that this is probably a person, Then also one object can have multiple behaviors. The stapler, you can like reload the staples so you can change the deflection plates, all this stuff. Apparently there are these really funky staplers where you can rotate the top part so you can staple it at an angle. so yeah, lots of objects have many behaviors.

and then also a behavior can be in an arbitrary location, orientation, and scale on an object. so we already had the kind of opening and closing behavior that can be a different location, rotation, scale on a book or on a door. Here's a mailbox that can also open and close, but also the kind of lever can go up and down, at a different location on that object. And we wanna be able to assign behaviors at any location, orientation, and scale on a, on an object. And then, another larger topic is making predictions about an object at an arbitrary point in the behavior sequence. So basically we have a model of the object, we have a model of the behavior. And then using those two models to predict if I move my sensorimotor from here to here, what am I going to sense here? So that's using the behavior model to make predictions about the morphology at any point in the sequence. and we wanna be able to do that for, object and behavior combination. we know. And then also for a behavior applied to a known object. So a new combination. So we learned the stapler and its behavior, and now we wanna apply that behavior to a book for which we've also learned a morphology, model, but we've never seen a book open and closed. so that, again, we wanna predict if I have my patch here and then move up here, what am I going to sense? and yeah, I just added this note here that, when either one of those two models is not learned yet, no predictions should be possible. So if I've never seen the hinge behavior, I shouldn't be able to predict anything on the book opening. If I've never seen a book before, I will first need to learn a model of the book before I can make predictions about how it'll look when it opens and closes.

And then another constraint we added is that we, don't wanna be learning key frames or like snapshots of the object's morphology, where we have to store how the object looks like at different points in time. because, we already know the object. It's not once the stapler opens a little bit more, I have to explore the whole stapler again and learn a morphology object again. And then once it opens a bit more, I have to explore it again and learn a morphology object again. It's like I know how the top of the stapler looks like. I don't need to relearn it in every, orientation.

and then also if part of the behavioral sequence is occluded, we, are still able to make predictions about what we're gonna see once, it comes out of that occlusion.

and then finally, this one we haven't really talked about yet, but I just thought of it. when I put this together and I think it's, relevant and what I'm proposing also solves it, is that, we wanna be able to use the behavior model to compensate for object movement when we are trying to recognize morphology. So if we are having a, moving car, it's moving, but we can still recognize the car, so we can compensate for the movement of the object when recognizing the object. In the same with like sub components, as the stapler opening and closing, we can still recognize the top of the stapler, and use the kind of behavior model of how the stapler top is moving to compensate. I don't understand. Could you, I don't understand this point. Can you just try again one more time? yeah, basically being able to deal with moving objects when we are trying to, so the whole, object is moving? Yeah. Or, components of the object. Oh. Or components of the object. How does it differ from the, for behavior applied to a known object?

so this is for inference of the object. Now this is like the morphology of the object. Like we're trying to recognize the car or we're trying to recognize the stapler, but the object itself is moving because it has some kind of behavior. okay. So to me, the car driving, that's a funny behavior because the morphology of the car is not changing necessarily at all. It's just changing its location in the world.

yeah. So, this is more like the car is moving in the scene of the world and here the stapler top is moving relative to, the staple. But is the staple example already been taken care of earlier or didn't you already talk about the needs of that, which is, the need to get rid of?

yeah, I guess it, it feels like if we can predict what we will see at a location, given the behavior, then that kind of directly enables us to infer the morphology, if that's already known. Yeah. So this, when it's moving straightforwardly comes out of, this part. So it's not like it's a huge additional problem. It's just, yeah, I don't see it as something different. I guess that's my question.

maybe it is, I just don't understand it. Yeah, I guess I thought of it as different because like when we talk about our larger next, capabilities of Monty, we talk about modeling object behaviors and dealing with a dynamic world. So dealing with a dynamic world where objects might be moving doesn't necessarily require modeling object behaviors. So you just need to compensate for the object movement. And, no, that's interesting. it's it's a couple of things. I take a car like, or, just take something on my, my, my desk right here. I can move my coffee cup in different positions. I don't consider that any kind of behavior. However, a car going through an intersection is, that's the, that's a model of an intersection of which there are things called components called cars, and they follow certain paths and certain behaviors, I don't expect a car to jump over the median or So in that case I could say, oh, it's a behavior of the intersection. Cars are component of the intersection and they have exhibit certain behaviors, but just physically moving something in different positions doesn't seem to be a behavior of anything. does that make any sense? Yeah. No, I, agree with that. I think it's maybe just a linguistic. Yeah. May, maybe one, one way, if I'm understanding kinda what you're saying is it's a special case of behavior where you can imagine we can have a, an object in a behavioral state. So let's say someone says the stapler is open and we can predict like what we'll see as a function of the behavioral state, but then while the object is in the process of moving, there's an additional compensation that's necessary. Is that kind of what you're saying? Yeah. it's not just that there's a behavior, it's the fact that there's actually movement going on that presents an additional challenge. Yeah. Maybe. the slight difference is that in this scenario I'm thinking of here, we haven't actually recognized the object yet. We just recognize the behavior. So we're just, yeah. Okay. Recognizing, so it's more about the initial inference. Okay. Yeah. It's so like we're still trying to rec Oh, the stapler. But then, yeah, then it feels like it's the same mechanism, but then just over the hypothesis base. But isn't that just like the motion capture dots, isn't that the same idea? you, capturing parts of the behavior and that tells you what the, object is?

In the motion capture dots. It's not possible to really recognize the morphology. 'cause there are no clues about morphology. you, you certainly infer the morphology and then you can look for it. it's like you, like I'm, there should be a human there. Or a person. I guess the everything up to now made a hell complete made sense to me. This last point is a little confusing to me. So the question is, do we, is it worth spending more time on or, should we just Yeah, maybe it'll be clear later when you talk about it. Yeah, back to It's not that big of a deal. it'll be like a short last comment in the end. Okay. And it will, let's leave it at that then. Yeah. It's not, if it's not critical to the argument, let's keep going. Yeah. And so then lastly, just to note that in this presentation I'm not going to talk about how actions relate to behavior models. So how we use this behavior model to interact with objects or to know how we can interact with objects. So that's not something, I hope you gotta solve everything. Yeah. I'm, hoping to solve all of these here, but, actions I guess will be the next. I'm joking. These slides are awesome, by the way. Visualization. Oh, thank you. This is like a great presentation for some conversation. Okay. That's just chapter one. Yeah. yeah. does that all make sense? Did I forget about any, problem, or constrained? I. gosh, I can't, I don't know, but it seems pretty good. Okay. We can bring them up later. Just there's something up in there hanging hat on. So, yeah, if someone's watching this video on YouTube later and you haven't seen the solution yet, you can pass the video here and, try and solve the puzzle yourself. Good luck with that.

all right, so chapter two solutions we have so far.

so my plan is to go through each of these points and then check them off. but as a prerequisite, I just wanted to revisit, our current theory or pretty quite confident, stable theory about, modeling and recognizing objects like the morphology model, just as like a baseline, because a lot of the ideas for object behaviors are then based on that and are just slight twists on that. So I think it's good to recap briefly.

I'm, I also, I'm also trying a new visualization look, I, spent like all day yesterday trying to get all the information in some way that doesn't look super confusing.

All right. we have the input from the sensorimotor that goes into first oral nucle of the thalamus. And there, that consists of, some movement information, which, goes into like the border between layer five and six, and informs, the, or updates the location and the objects reference frame. And then we have, feature inputs where we have feature orientations, like oriented bars, for example, and, V one and also, like non orientation dependent features like color or, Temperature or something like that. which go into layer four. And then we learn associative connections between, these features at locations in the object reference frame. And that's really where the model of the object is stored in these connections. and the model of the object is then basically, features at locations relative to each other and over a series of movements, sensing and movement, sensing and moving, we can then, narrow down what we're sensing and, pull this into, representation of an object id, which can then be, communicated laterally to vote on, to narrow down which object we're sensing faster. and also the object ID can be sent, forward through the classical feet forward pathway from layer three to layer four of the next higher cortical region. and just another point to highlight again, is that this location here is unique to the object. So any location SDR that you have here only exists on this specific object. it's not like an X, y, Z coordinate frame that we use for all of the, that's used for all of the objects. It's unique to the objects. So looking at this location already could tell you which object you're sensing. But the movement input and how you move through that objects reference frame is universal. So movement to any objects, reference frame, updates it in the same, structured way.

does that all make sense? Is that clear for everyone? probably. But if there are questions that would be quite important to resolve, no. Okay. I feel like you've just taken 10 years of my life and made it seem like you can do it in one minute. Yeah.

it's definitely something that needs to sink in and it's not, easy to arrive at, but now it looks really elegant and simple, that's nice. I hope that the future slides will look as elegant and simple in the future as Well, that's our goal, right? goal is always in, in hindsight, the theory should be self severe, obvious, oh yeah. How, yeah, how could it not be that way? But I figure out the hard part.

okay. Oh, for, lastly, we also inferring the orientation of the object, which was represented in layer six B. And this orientation can then use, modulatory backward projection to the thalamus to basically, transform the movement and the feature orientations that go as input, into the column so that we are basically transforming, movement and sensed features from the sensors reference frame into the objects reference frame. And that way we can recognize any object at an arbitrary location orientation in the world.

That should be all. is that, I'll just point out, there's, an existing question about the nature of the reference frames and the 2D 3D md, which not being addressed here, but we just put aside because we don't, it doesn't seem to be essential at this moment time. Yeah.

we may have not discussed this before, but is the scale also, do we do we agree that the scale might also be represented in the column and then sent back to the tel is to scale the movements and the features or, yeah, so that's, the idea. Scale is something that we haven't really. decided on where exactly it happens. But the general mechanism should be similar to, like the conceptual mechanism should be like for orientation that we can scale the incoming movement, vector by whatever scale we're detecting the object at, and thereby recognize that at varying scales. Yeah. and we have a working hypothesis about the mechanism for that, right? Which is this, changing frequency of the background frequency. So we don't need to go into it here, but it's, not like we have no idea. And that would occur in the thal. I believe that those, the theta cycle, whatever it is coming from the, thal. Yeah. And I, and then I guess just for context, there would be additional scale in variance from, columns across the hierarchy where columns at higher levels tend to have larger receptive fields and tend to be biased towards recognizing larger, objects. But so that is within a, that's less flexible, so within a column, right? It can given sufficient time a bit like rotation, arbitrarily scale the inputs to recognize it, right? there's an assumption that different columns. Of course, get different inputs and different motor inputs. But within like envision or, touch or something, they'd have inherently different scales of, movement and, feature sizes. And that's inherent, right? It's not really, it's adjustable within a range, but built in, right?

Or a complicated sensorimotor, like vision is, the information that's flowing the, location and the features that, that would be like a cluster of features and a cluster of locations.

I don't what you mean by that, Michael. I just if you're looking at it with your eye, you're gonna see multiple edges, multiple regions of color, right? this is a single column. Okay. And so this is one column sees just one small patch of the retina. And, it's just modeling what it can from the input from that small patch as that small patch move moves. gotcha. Obviously many columns would be observing different parts of the object at the same time, and they would all be doing the same thing, but just the different location, different features. in the retina, the movements tend to be the coordinated because the retina moves as a whole. but if the touch, for example, your fingers and the different skin parts can move independently. So that's the more generic solution is that each column is just oblivious to what the other columns are doing. Each column says, I just see some little patch and I'm moving around, and that's all I know about. And I'll build models and maybe my neighboring columns are doing the same thing, but I don't really know that. All I know is we can vote on what we think we're agreeing to. So a single column is a single feature, single movement vector.

Yeah, I hope that helps. That's a good, thing to point out again, that this input here is just a small patch. It's not like a full image like you think of when you think of computer vision.

and all of this happens through a loop of sensing and moving and sensing and moving.

okay, I'll move on to, actually object behaviors now, for this recap. So now this part about, learning to model a behavior and then recognizing the behavior. Again, that's what we, the idea we had during, last retreat. So you should all be familiar with that as well. But just to show it in this new reference frame. basically, the send we get, Again, input from the sensorimotor. first we have, the movement of the sensorimotor, which is basically the same movement that goes into a parallel modeling part of the column. So I'm showing now shaded light blue is the, modeling stream for, object morphology. And light purple is, object behaviors. And you'll see a lot of parallels between these two. like the object morphology model here, we got a movement, vector input, of how the sensorimotor moves, which updates, the location in the behaviors reference frame. same mechanism, but separate reference frame from the objects reference frame. and then we also get feature input. But in this case, so in the previous, in the object model, we get static features that as input. Now here we only get input when feature change is detected. So when the sensorimotor patch detects some movement or some feature changing or rotating or anything that's actually changing, not something that's static, then the input goes in here into this behavior model. And just like with the object model, we learn associations between locations in the reference frame and changes. And then another thing that's. This thing. Now that's different is that we also have a temporal component to object behaviors. So here the working hypothesis is that, matrix cells in the thalamus could broadcast, ATI global timing signal to this column, which can be picked up by these epical then rights of parametal cells, in layer three. and then the model of the behavior is basically changes at locations, over time. So at each time point in the sequence, we're storing, changes in that behavior reference frame. So in this case of the stapler opening or like the hinge behavior, it would be, the change that's detected as movement of an edge, and like rotation, of that, over a temporal sequence. And then that same as here, this can be pooled into a, behavior ID representation.

and, maybe just to clarify, I think we touched on this, but just, with a stapler in general, any given location is associated with one change, but you could have behaviors where a particular location would be associated with different changes at different points in time. and that would at least in theory be covered here by the apical input. To the L three cell being different. Yeah. So you would predict a different change. Yeah. This stapler could be go closing and it would be the same. Yeah. Or that, but, so yeah, so I don't know if we've gone through and just check the, like the kind of numbers make sense, but at least in theory that seems like it would work. just in terms of how, many potential, predictions you need to, yeah. I don't know. I'm sure it's fine. I, think it, it will, I'm pretty confident the numbers will work out, but, it's good. I, yeah. Think about it.

quick question here. So this pooling that we have, for behavior id, this would be over space and time, This will be pulling, because we have these movements at little patches on, in, in space, and then we're also pooling over time. Yeah. even the morphology model pools over time, right? It's a temporal pool. That's what it is. So it's like you can only sense one piece at a time, therefore you're pooling multiple sensations here. You're pooling, multiple changes over time. so in that sense, they're both temporal, pooled, IDs.

Yeah. Yeah, it's I guess it's temporal from the point of view of the neurons. In the case of the behavioral model, the time is actually a com part of the model. It, only flows one direction and the changes have to occur in that direction. Whereas with the, with the morphology model, the, you could touch the object at different, order. So there's an order, doesn't matter. it's independent of the order.

Okay. And then, yeah, one other thing to highlight here, which is, the key idea that solves all of these problems of mixing and matching objects and behaviors is that one, these are, oops. these are two separate reference frames and those are completely separate models. So this. Behavior model knows nothing about staplers, even though it has been learned by observing the stapler opening. And this stapler model knows nothing about, this hinge behavior. So this beha, this one just models, movement over time, changes over time. whereas this one models, static features at location. So like how, what's the color of the stapler there? What's the sense point normal at that location? What's the curvature sensorimotor at that location? so those are really two independent models, and we can now apply or recognize the same kind of movement sequence of changes on any other object that moves in that, regular path. So if you open a book now or something else like that, you, would still recognize, this behavior even though you've never seen it on that particular object. Does that make sense? Would it be reasonable to say that, the behavior, it doesn't know about the stapler, but it knows about an edge moving because these, movements are arranged in a specific way that mimics an edge? I think it, it, doesn't know, there's no representation of edge. It's a, set of rep, a set of points that each, that you and I could say, oh, that's an edge. but just like the morphology model, Ramy, in the morphology model, there's a set of point normals and features. There's no actual separate representation for edge. It's just a set of features that you and I would look at and say, oh, there's an edge. And I think that's the same with the morphology. The behavioral model is, it's just these independent points in how they're moving and it, and on the staple it looks like an edge, but other object could, it could be a changing circle or a weirdness and, there is no independent representation of edge. I think that's the key point. Yeah. Like maybe if that was to emerge, it would just be through hierarchy and compositionally where if the input was represented as Yeah, exactly. so it's, that's what I mean. So it's like an, a separate object and that therefore it can be represented as an entity. if we had, if the world had, edges as independent objects, so then it would be an object, but it could, it's nothing edge. It's just an object. We've labeled that these set of features are, we're gonna call an edge, but you can have another set of features that's a slight arc or a search that's a curly queue. It doesn't, all the equivalent.

Yeah. In that case, it seems given that the features on an object for any given object are restricted to a certain subset of possible features, could help narrow down. It might help with the quicker association with the behavior itself, because if the behavior itself was also dependent upon the input features that generated the behavior, then that gives us some way to, to build the associative mapping. Would that be accurate? Yeah. Maybe I'll show, the proposal for that associative mapping and you can see if that makes sense. 'cause it doesn't require, any, dependency of these two. I mean it's, yeah, said before, to recognize this behavior, you need to be observing an, an object that has these, possible changes like that is able to move like that. but it's not like this is storing anything about, this object itself or about the features on this object. you've now Go ahead Michael. you've now moved to a set of features, I think from a single feature. No. so this is the behavior of a single feature.

this is, it's like the morphology model there, there's lots of locations in the model that would have here changing features associated with them. Yeah. In theory this would say no one can observe all those at once. Yeah. so this would be like, at this location, we, observe a movement and at this location we observe a movement. And at this location we observe a movement. So these are like. These are in a reference frame. These are relative changes to each other. So this is that's what I try to visualize with these arrows. Yeah. I'm just getting at, but so does the single sensorimotor observe those multiple changes at multiple locations at the same time? No, this is one, only one at the time. This is of the pro, this is one of the problems we had, Michael, in the morphology model, you could take your time to move over the object all the time of the world, discover what the features are, and you do one at a time. In the behavior model, the thing is changing. And if you could, in theory, a single column could sample all the points really quickly and say, okay, at this point it's moving this way, this point's moving this way, this, now let's go to the next step in time. And this point's moving. Yeah. And so the model itself contains all that information, but only a point in time can be sensed by a, a column at once. So you risk like shutter lag where, where you take an image of a, I, don't know if Vivian's gonna solve this problem, but one of the real problem is pointed out that you can't really learn it like this. in theory, the column could in theoretically, but not practically. so that's an issue. And yeah, like I guess related to that, at the retreat, two of the things we talked about was like, yeah, I guess voting can help maybe to some degree, because then you can get a. A quicker sense of, what is the state of the object as a whole. But then also just this observation that like children, when they're learning behaviors, they just do things like over and over again. Like whether it's just pressing a button, they do, or but I, I still argue Oh yeah. Opening the stapler or, yeah. But there has to be, I've argued it, maybe Vivian's gonna come this direction or not, I don't know. But that there needs to be some sort of shared learning that is, if every column has a model like this, they all can't learn it independently. So somehow they have to share their knowledge that I learned this part. You learned that part. Let's combine 'em. I don't know. That's a hypothesis. I don't know if that's true, but it suggests, or I would go like retain state within the column, but I don't know how that fits in the overall picture. Yeah. Anyway, maybe Vivian's gonna solve this problem, so I don't wanna talk to you. Yeah. I think what you're saying, Michael, that's more kind of like voting if I say, we say, whereas, okay, what, I think Jeff's talking about is like almost like weight sharing and CNNs where it's like a column would somehow actually transfer knowledge to another one. so that collectively you could sample multiple points.

Yeah. You can't expect every column to observe every feature on every location, every point in time. It's hard to do, but yeah. I'm not gonna get into that too deep in this presentation of it in the kind of open questions and potential solutions section, but, I Assume that for learning the behavior, we can't really use voting because voting just tells us about the, behavior id. So, that just helps for a quick inference when we see an object behavior. But then for learning, honestly, I think, I mean I'm seeing link all the time repeating a behavior for an hour today. He spent just opening a teapot and closing it and taking the strainer out and putting it back in really an hour. Just doing it over and over again and figuring out every part of the behavior of the teapot. So I, feel like that might just be how it has to be done. And then there are not that many behaviors learn later on in life, but, alright. We'll see. Yeah. Okay. I'm, yeah, it'd be interest, my normal fidgeting repeating a behavior over and over. Yeah. It'd be interesting if there's any quantification in like child development about like how long children spend looking at static objects versus, objects with behaviors because Yeah. I wouldn't be surprised if it's like an order of magnitude difference in how long it can hold their attention. Yeah. I, wouldn't be surprised at, at all. Yeah. but yeah, maybe I'll move on a bit because, there's a yes. Let's do that. Things that we haven't discussed yet. Okay, another thing we wanna be able to do is to recognize the behavior at an arbitrary location, orientation, and scale. And the proposed solution for that is using exactly the same mechanism we're using for recognizing an object at an arbitrary orientation, location, and scale, which is, to transmit this, post hypothesis down to the thalamus and use that to transform the incoming movement vector and, feature inputs into the objects reference frame. so a separate orientation for the behavioral model then? Yes. Pathology model. Okay. Yes. I know we haven't completely agreed on that before, but, I guess that's what I'm I mean in, support of that idea, first of all, it takes very few neurons to represent orientation, unlike location. And, so it, is a small population of cells, that's not an issue. And we do have the different layers in the thalamus, which would suggest perhaps, there's, the, there's these paired layers. Perhaps they're paired in this regard. so we, we can accept that for now, I think. Yeah, it seems, yeah, like you say, it seems like it should be possible to, send another projection down and transform those on those relay. It may look like the same protection. just literally, the anonymous may not see them as separate, they're just. Two cell populations are co-located. So yeah, we don't have to, we don't have to expect to see physically separate projections. Yeah. and it's such, generally just looking at this, it looks so beautiful because it's a, an exact mirroring of this mechanism, of the mechanism we have for object models, now for object behavior. And it gives us all these nice properties that we had for recognizing objects, being able to recognize them in any location, orientation, in the world. And now we can do the same thing with object behaviors, independent of each other. And it, just looks really nice in my, in my mind. and also, yeah, it fits really nicely with so many things, yeah, the movement coming in at the edge between L five and L six, and also the L five being the motor output that, it makes a lot of sense that would be where kind of behaviors are represented. yeah.

okay. And then another requirement we had was to recognize where in the sequence we are and recognizing them at different speeds. So this is one that's not, we haven't, I. Totally settled on, but I think the general mechanism, I'm gonna propose here makes sense. so basically from the matrix cells, we get this timing signal. The matrix cells themselves don't know anything about the behavior model. They don't know which behavior we're recognizing what we're sensing. They're just giving a timing signal, like a metronome. And then here we learn at what click in the me metronome should we, recognize which features at what locations or which changes at what locations. and then when we actually observe, the sequence faster than we have learned it in our model, we are predicting the correct changes at locations, but they appear earlier than expected. So then we need some way to speed up that metronome. So I made that error red because I'm not sure where that signal would come from and how it would go to the matrix cells. But basically we, see correct changes at locations as predicted by the model, but earlier than expected. So somehow we need to tell the matrix cell ma matrix cells to speed up that metronome. And once that's sped up, everything works again. that I don't remember where they're coming from, but that projection back to the matrix cells exists. I talked to a bunch of sciences about it in the past, maybe I taught the past 15, 20 years ago.

so those connections exist. I don't remember the, source, layer. I can double check. I think it came out when I was looking at the colostrum stuff. I think it's from L five, which would fit, potentially. But yeah, I mean in general, like conceptually it's, it's basically like the same like scale and rotation. It's just like here we're scaling time, based on an inferred and again, we might have a bias towards expecting it to happen at a certain pace, but we can recognize it at a unusual pace by scaling it. yeah. And yeah, basically the parametal cells could detect a, that mismatch. So detecting a pattern on the basal dendrites and then which depolarize the cell and, indicate that the next feature should be arriving at this location now. But then, apal, androids don't get that matrix cell timing input at the right time, either, either too early or not at the time they expected it. And then I think Jeff, in a comment, you on the documents you suggested that potentially they could send like a back action potential up the dander, apal, Android. On that expected timing and recognize the difference. but there should definitely be some mechanism in here to recognize, a expected timing difference. There has to be right, there has to be a mechanism. I think the general idea of this matrix cells providing the time signal adjusting is very likely correct. Somebody has to do it. and the actual mechanisms are not as important at this point in time. Exactly. How do the neurons detect the difference and transmit that difference down? Those are gonna be things that maybe no one's even discovered yet. So we don't wanna spend too much time thinking about it because there may be some weirdo property or AOL dendrites that, no one's ever measured. Yeah, we know it has, to exist. So we can just say, go on and say, great. It happens. Yeah. So the conceptual mechanism is pretty simple, but we're not sure how exactly it happens in the anatomy. But yeah, just for the compliment, if the sequence is observed slower, we again, see the correct changes at locations, but later than we expected them. So then we need to tell the matrix cells to slow down the metronome and then everything fits again. it's also kinda interesting because sorry, go ahead, max.

I was, it's a slightly tangent, so Yeah, you go ahead. Okay. just a, I guess a clarifying question. The matrix cells and the metronome are a local clock to this particular behavior, and another behavior column has its own local clock. No, the way the matrix cells work, first of all, they're not specific to any particular behavior. They, as Viviane mentioned earlier, they're a, global clock and they project broadly over, multiple regions within a particular modality. So matrix cells would be set of matrix cells that project broadly over all mutual regions. And another one that predicted broadly overall somatosensory regions. And that makes sense because time is gonna be the same for, you can't have one part of the object running at one time, another part of the object running another time that would be a different behavior. So you want this sort of global signal that tells everybody, Hey everybody, we're speeding up. We're slowing down, we're speeding up, we're slowing down everybody within some multiple regions that are all observing the same objects. Okay. And, then the I'm just getting at, like in electronics, I global clock is a very difficult thing 'cause there's propagation delays as the clock signal moves across distance. so you could take relative measurements, but you couldn't get an absolute time at two different locations and be assured it was the same time. But you gotta remember, and there, there are propagation delays in, in neurons, and, but it doesn't really matter. The, parametal cell that's shown up in, in layer three there, it doesn't know about propagation delays. It just says, Hey, I became active. This is what the clock said. At this point in time, maybe the clock started a little earlier. It doesn't make any difference to that cell. It cell just is, this is what it is, and I don't care how long it took to get to me. This is what it is now. Yeah, okay. As long as you're not, as long as you're not looking to extract the no exact global time, Nope, nope, Then you're fine. What's important is, yeah, and I think in general, the fuzziness of, neurons and stuff, yeah, it's not gonna be a perfect, but it's more just giving them a general, it doesn't matter. It, the delays are in, no one knows about the delays. No one's keeping track. There's nobody saying this is time zero. It's just it's just time has advanced approximately half a second, I'm taking note of it. And if it took a, millisecond to get here. so what? I don't know. Yeah, okay. It doesn't matter.

Yeah, no, I was just gonna comment on actually what ended up coming up in this conversation, which is, yeah, just that it's interesting how here it's kinda global because exactly like you say, Jeff, In general, an object it, follows like a single kind of sequence of time in terms of behavior. Otherwise it's becoming some other type of behavior. Whereas with rotation and scale, like we can have compositional objects where different parts of the child object or different scale and different rotation. So it makes more sense than that. We have that as a right individual column basis. And here too, if we had multiple, behaviors on an object, those behaviors could have different scales of time. So one could And, but we'd we'd have to I guess, shift between them. it would be an a intentional Yeah. Thing. Probably when I first started of this idea of the matrix sales, I was thinking, again, melodies. And within a melody, you basically speed up. You don't just speed up one note, you speed up all the notes, just slow down all the notes. Of course. Yeah. if the drums suddenly, started going really fast and everything else started going really slow or Right. it's all relative positions and timing. So anyway, it was, it doesn't make, this makes sense. It has to be a global signal to all the different columns are participating, all need to know we're all being got up or slowed down together. so anyway, this is a, I think this is a great, we don't have to spend more time on this. This is the hypothesis's almost certainly right to, to the level that you described it. Yeah, and, talking about global signals, we also wanna be able to use multiple columns. So then the last part missing in this picture is, voting. So similar as how this, morphology model can vote on object ID with other columns. The behavior model can vote with, other columns on the behavior id. And then I put state in the sequence here, but in between, 'cause first I thought we could also vote on the state office sequence, but then I thought this information is probably already contained in the, matrix cell signal. I'm not sure, if, that would be something we could al already get from that timing signal. I don't think so. We should spend time on that later, but I don't think so. Yeah. Okay. Then yeah, then maybe we would wanna vote on the state in the sequence as well, or like which point in the sequence we're in.

okay. So that's, up to the point we discussed so far. basically a solution for modeling and object behavior and recognizing object behaviors in a very flexible way. that makes sense to everyone so far. 'cause now I'm gonna go into the more, suggested solution territory.

It's pretty cool to see. It looks like you guys made a lot of progress. Yeah, for sure.

okay, so solutions for the remaining issues. again, I'm gonna do a quick, revisiting of existing theory. So I think, as a prerequisite for understanding these solutions, it's useful to revisit how we think, the brain models and recognize compositional objects.

so again, we have one column that recognizes an object. In this example, it has learned the TBP logo mark, as these, features at different locations relative to each other. And now we introduce a second column, next higher region in the hierarchy.

And this region will get the object ID that was recognized in the lower column as a feature input into layer four. it can also get direct sensory input, through thalamus, which gives it information about, sensorimotor movement. and it could receive direct sensory input, from a larger receptive field than the lower column. And together it can then learn a model of a compositional object. For instance, a cup. So just using this pink and solid blue line, it could already learn a model of a cup, but it would have to pay pretty close attention to these details here. And now using this, connection, it can simply assign, the logo to a location on the cup. And all the details of how the logo looks like is, are stored in this model down here.

is that, clear? yeah. Although the one small technical thing, it's not assigned to a location. The logo is assigned to multiple locations on the cup, right? multiple occasions on logo assigned to multiple locations of the cup, which was required to solve a whole bunch of problems. We don't have to go into it just, but for posterity, it's not assigned to a particular location, right? Yes. So yeah, every location on the cup where the logo exists. In this model, he will store a logo. It will keep getting this input and store it there. So it's not just one point for the logo in this model, but multiple points.

and additionally to storing that the logo exists at these locations on the cup, it'll also need to know, the orientation of the logo relative to the cup. And for this, the proposed mechanism is that, we can take, the orientation in which the logo was detected and the orientation of the cup and calculate the difference of the two. And that difference will then be the feature orientation input, to the higher level column. So yeah, this Delta orientation is basically this orientation here, minus this orientation here. And it, it's the orientation of the logo relative to the cup. that way if the cup rotates, it automatically compensates for which orientation we would expect the logo to have. and we can recognize the cup in any orientation and the logo.

and now we also wanna be able to, I. make predictions. So if we recognize the cup, we wanna be able to make predictions about the logo down here. so we can have these, classical backward projections, from layer six A down, and then all the way back up to layer one. there can make some, synapses over here in layer six A, which can tell the lower level model. It basically says, if I'm here in the cups reference frame, expect to be at this location in the logos reference frame. So it might tell it, oh, you're probably on the center dot right now. which will then tell the lower level, which features to expect. And then also up here, these apical, DDRs from parametal cells in layer three can, get some information about, the high level object that's being detected.

that, what would that information on layer one be used for? I'm not clear about that.

so yeah, the idea would be that this can inform object ID detected down here since that's what's in layer three. there, there's a, the layer one projection, will, it goes beyond the single column. It, goes over many columns. And so you, it's better, like the cup is saying. Hey, multiple columns should be looking at the logo, right? I'm biasing you to look at the logo, but only the columns that's co-align with the, these two columns that are shown here are co-align. And therefore, that geo synapses in layer six A, the purple.in layer six A that says at this point in the cup, you're gonna be at this point in the logo. But, at this point in the cup, I can't tell what other points other columns are gonna be. It's so you can bias the other columns to say you should be looking at a logo, but only one column can you say, this is exactly what you are on the logo. got it, it's helpful. Thank you. And, another question, is it really, telling us or informing what the object IG should be, or, inhibiting unlikely object IDs, because these are inhibitory, neurons, right? With our inhibitory neurons, layer one neurons, these aren't layer one neurons. This is a, an axon from the layer six a cell in the second column. So those are, th that's, those are axons from excitatory cells. And if they form synapses on the apical dendrites as shown, there's a little perial cell in layer three, right? Those would be excitatory synapses.

so, those would be exciting in layer three cells biasing it. There are some cells in layer one, and some of those are inhibitory, but we're not talking about those at all.

okay, so the layer six in region two is not, exciting or, making the, inhibitor in neurons in layer one fire. I, I didn't say that. I just said we're not saying anything about inhibitory neurons in layer one. We have no theory about them. so all that we're saying is that a very well discussed connection is that they make, they make connections. In fact, hardly anyone ever talks about layer one neurons, but there are some, not a lot. There's some, but we're just talking about the very well known connections between the layer six a axons and the layer three apical dendrites. And those are all excitatory.

and we don't have a theory of what the inhibitory neurons are up there doing. And then also since these locations are unique to the respective objects, so this location's unique to the cup and this location's unique to the logo, if there's a connection between those two, this cup will directly inform the logo model itself, about where it will be. That makes sense. Yeah.

Any other questions? We're still in review. I can't wait time. No, we're back in review. I don't wanna run outta time. Okay. Yeah, I'll move on. so lastly, we also wanna inform the lower level column about at what orientation it should expect to see the logo. And for that a proposal, we have is that, that information is basically taking the orientation we stored in the model up here, the orientation of the logo relative to the cup and adding it to the detected rotation of the cup. and then sending it over here. And the idea is that this could be done by layer six cor cortical connections that are observed. and basically communicating, the orientation that should be expected here for the logo by taking the delta orientation stored and the model here, and adding the detected orientation down here.

that's the proposal. That's a more speculative proposal. Yes. But we shouldn't hang our hats on, but it has to be done. And so we should just feel confident that it's done. This could be how it happens. Yeah. Yeah. I think it's a pretty general mechanism. Like I think these calculations would be the best way to do it, but it's yeah. I'm not sure if this, no, I think the speculation is as to what cells are actually doing it Exactly. Where. Yeah, exactly. Specifically the layer six say the layer six. Cortical, connections. There a whole bunch of weird ones like down there and they just fit the bill 'cause they seem to go where we want 'em to go, but, but there's not much beyond that. It's okay. It's a good placeholder. It doesn't, I don't think it impacts really any of our theories. It has to be done and therefore there's gonna be a connection to do it. And so that's just, it's a good placeholder for it. Yeah. It almost, yeah, maybe we should get distracted, but it almost feels like you could also just further transform the thalamic input to the previous column.

bypass it like rather than Yeah. Rather than sharing it with, I don't know if that causes weirdness anyways. Yeah, I don't, yeah, then we would I guess need a to know if there are connections from the like V two to first order thalamic nuclei. Yeah.

Yeah. I don't think we should spend more time on it. Yeah. Okay. I'll move. The function has to occur. We have to do the same for scale. Scale is gonna be relative this, it's gonna happen. We know it happened, so let's just go on.

so yeah. now on the topic of learning associations between objects and behavior, so we wanna be able to see a behavior and bias, which object we detect. one object can have multiple behaviors and behaviors can be in an arbitrary location, orientation, and scale on an object. Does that sound familiar? Yes. It sounds learning compositional objects where the child object, where one object is made up of multiple child objects and child objects can be at arbitrary locations, orientations and scales on the parent object. So why not use the same mechanism to solve this problem?

so the proposal here would be, we have a model of the object, for instance, the stapler at the higher level column, and we have a model of the behavior at the lower level column. And the detected behavior ID essentially becomes a feature on the higher level object at a location and orientation on that object. So same as we assign the logo to the cup. Using this, connection, this feedforward connection, we could assign the hinge behavior to the stapler. and then additionally to, tell it the orientation of the behavior, on the object. We do the same thing. We calculate the relative, orientation of the behavior to the object model down here using these two projections, and then sent that up here as the feature orientation input.

does that make sense? Yeah. the first question that jumps to my mind is the projection of the layer four in this, in region two. Is there, would there be a case where you're projecting both a child morphology object and a child behavioral object at the same time? does that recur? You could, oh, sure. Yeah. You could find instance, say I'm on the top of the stapler here and on the bottom of the stapler as the projection from the, lower level column. if we have segmented the stapler into top and bottom. so that would be the input here for the, as an object a. Yeah. I'm thinking like, what if the logo, had some behavior, the logo can rotate point degrees back and forth or something, but okay. I think it works. So I'm just, I'm just thinking out. Yeah. I think so far in my head, like when we thought through this, how to generalize with this, it makes more sense when the morphology model is the child and the behavior is in the high level column. but, but it, but but we did, we remember we started with that Niels, we started with the idea that, oh, yeah, within a column you could assign the behavior to a different object. No, I'm talking about two different columns. I know. I know. And then, we came across the idea of, oh crap. It could be just like what Viviane just said. There could be a child that could be, these are child objects because you have multiple behaviors per parent object, you could have child objects. And so we, where I was left struggling, maybe Vivian's gonna get to it, we had these two proposals. One is that behaviors could be applied to a, an object within a particular column or as, as hierarchically as shown here. And I'm, yeah, I'm proposing doing it hierarchically here and I'm doing it as behaviors on the object because, usually, as we al also I think talked about before is that the behavior is usually kinda smaller than the object itself or applied to part of the object. So it makes sense that this is on the, at one point, Viviane, you were saying, oh, I, but you love the idea of doing it all in one column and, and, see we're a little hesitant to give up on that. Have you given up on that? If you said, okay, we don't need to do that. Yeah. For this issue of assigning behaviors to objects, I think it's nicest to do it hierarchically because it's exactly the same problem as learning, composition objects. Just, I'm trying to jump ahead. Are you going to abandon any idea that we'd be within a column? I'm okay with that. I'm just trying to understand Yeah. Where you're going ahead. Yeah. And this proposal, there's no right association within the column. I feel that my gut says that's probably the right way to think about it.

okay, good. Okay.

we also wanna be able to see a static object and infer behavior. So we see the stapler standing on the table and infer that it can move up and down. and so for that, again, we have same setup. the stapler model here, behavior model here. we could simply use the feedback connections, where if we have recognized the stapler down here, we, can inform the lower level column, to, sense the, hinge behavior and also to, where to expect to be in that behaviors reference frame. It doesn't tell me where I should be, or it doesn't tell me where I should be in the sequence of the behavior. it tells me definitely like this point on the, stapler has a potential, behavior. Yeah. Usually if the object is static, your, the sequence hasn't really started yet. It's more like you could sense this is a potential behavior of the object.

Okay. And I guess this is something that would also, this would be probably something that would also happen within a column, right? For a familiar object and familiar behavior. The two well. If, you go back to the, constraints, that's the question I just asked a second ago. Yeah. but I think there's multiple things that we could argue about which things can happen within one column and which things can happen across multiple columns and which things might be in both. But specifically biasing the recognition of the behavior based on a morphology. It seems natural that would also happen within a column. you could do it within a column, but I, just didn't see a need for it here because it's already solved with the feedback connections. But what, about the instance where the behavior and the, state, morphology are learned within the same column?

Like here you're showing it across multiple columns 'cause you're generalizing to this is assuming we haven't learned the behavior for the it little bit like stapler. It's, let me, take a stab at that, Neil. It's a little bit like, compositional objects. In compositional objects. We assume that the two columns, meaning the two hierarchically range columns, both can, or actually necessarily learn both sets of objects. like I, the, upper column can learn a mug and the lower column can learn a mug and the upper column can learn a logo in the lower column can learn a mo. Therefore, I can observe a logo on the mug and I can observe a, mug in a logo. that would, a same thing would apply here. We would have, if we took that same idea. We would say these two columns would both learn, the mor might both learn the morphology of the stapler, and they both might both learn the behavior of a stapler. and, and therefore we could say, oh, this is a stapler, which is a hinge. that's a subset of it. yeah, I think the main argument that I, forgot about, is that if we do it within a column, we can't do relative reference frame transforms there. We can't say this behavior should be, in this relative orientation to this object like we can do in the compositional setup. it's like doing composition object within one column where we say the presence of the logo biases the presence of the TVP mug, But we can't tell any, more about which locations it should exist at and which orientation it should exist at. Whereas in this setup we do it hierarchically, we can inform all that. there's a no, I agree with all that and I agree it makes sense to have it across multiple columns. I'm just saying that, have you totally gotten rid of having, because as you just said, Jeff, like you'll learn like potentially both in both columns, but there's not a connection between the two. Like when I Within a column, not within a column. Why wouldn't there be? we went to the same transition with morphology objects. At first I resisted the idea of using hierarchy. I said, look, columns should be able to do everything on its own. That's one of my, things. and then, but then we de this, no, it can't. and, then it's like you have to rely on hierarchy for doing more, for doing composition. It. And it, it doesn't violate the column or hypothesis. It, every column is learning compositional objects. It just doesn't know what the child objects are. That's, the answer to that one. So in the same way here, we started off by thinking, oh, we could learn this all within a single column. They're right there. They're right on top of one another. Isn't that wonderful? we could apply the behavior, learned, in, this column to a new object in the column. but then realizing that the hierarchical solution is more powerful for the reasons Viviane just mentioned. and so the question is why would I introduce it back into a single column? just like we started trying to do morphology in a single column, and I abandoned it with God. We're not trying to do it anymore. and I think the same argument would apply here. It is a little counterintuitive initially, but it's a more impactful, yeah. I think it's worth moving on, I think the point I'm trying to make is, not a particularly important one. It's just this particular question of biasing the recognition of behavior that I, think to a certain degree that could still happen. In addition within a column. But, I don't think it really, it's not a big point. So Vivian's point is that this solution solves all, I think it's gonna solve all those problems. you don't need, yeah. I'm not saying that it's necessary. And then I just think it's some, yeah, it might improve the performance system. You're then you're gonna be introducing problems like, it doesn't work in this situation. It doesn't work in that situation, I had this issue. Yeah. They, I think it's a valid point, Neil, is to say, maybe there's one, one way I look about this is that neurons, they form synapses with anything that makes heavy and sense, right? They're stupid. They don't really know what these, axons are. So it may turn out within a column if these axons are passing their other neurons, that they'll make connections that we don't really need them to do, but they might, they don't hurt. so that may actually happen, I think, but we should follow the logic of first, the whole theory of how can be done hierarchically then come back later and say, is did they miss anything? Is there anything we need that they didn't do yet?

and I think that would be the, I think that's what Vivian's recommended. Yeah. No, that sounds good.

okay, lemme move on. to last, points, I guess just, for curious. Viewers who saw this kind of.here and were confused why that's there too. It's just Which dot here. Oh, that one right here. The feedback projection. It's just for completeness because this is still the morphology model. So this feedback connection as we've shown it before, also biases locations in the child objects reference frame. So here, like you touched on earlier, Jeff, this column might actually also get, feedforward input of the object ID of the child object. So like the top of the stapler. And then the same feedback connection that biases, or that informs the behavior that exists at this location can also, inform the child object access at this location. can I make a, an observation? It's really a question. Yes. Because, I was doing this, chart of all the possible ways this could work and one of the things that're suggesting is that there isn't asymmetry here in the sense that the feedback connection is only coming from the full morphology model. There's no feedback from the behavioral model. And I think that's, are you I think that's right, but I don't know if you agree with that. that is a, the higher mythology model can predict behaviors and predict components. but the higher, there is no sort of hierarchical behavioral model. Is that correct?

yes, I think so. let me come back to that in a bit. I think I, hang on, I thought about it yesterday and I think I came up with a, purpose for a feedback connection from the hair order behavior model, but, that would be like a projection from if that was in layer five B, then it would be a projection from layer five B back, like the purple. Oh, I think I will show it in a, okay. A future slide. I couldn't come up with a reason for that. I couldn't come up with a reason why a behavior model had to project backwards. Okay. Yeah, it'll actually come up, next. I think so, yeah. Alright, so I'll get back to it in a moment.

oh yeah. And then also, we can use the same kind of cortical, layer six cc connection to inform the orientation at which the behavior should be observed.

quick question. Yes. Does this solution help us, break up the objects? so the way I see it, we've learned, so in region one, we've learned the movements or the behavior. Yeah. On the, I'll also get to that in a moment. okay. all to come. okay.

this was the chapter about, or the part about learning associations between objects and behavior. And basically the proposed solution is to use hierarchy for that and use the same mechanism we use for composition models. now the next topic, is this big one that, that we struggled on the past weeks, is how do we make predictors about an object at an arbitrary point in the behavior sequence, without learning key frames. and I'll first look at it for an object and behavior combination that we know. So we learned the stapler opening and closing, for example.

so now here you notice I'm showing the different combination. In the last slide I showed the morphology model up here and the behavior model down here. Now we're actually recognizing, the morphology model of, the sub component here, the stapler top, and the behavior of the stapler opening over here.

I just, yeah, this is irrelevant, just, as FYI, this high level model would have then the model of the complete stapler where the top is, a feature on the stapler.

and Let me think through this again. Did I explain it correctly?

ah, yes. Okay. So what would be a behavior at this higher level? so one thing that can happen is we have the orientation of the child object and the, or orientation of the parent object. So the stapler top and the stapler. And normally that's a fixed thing and that relative orientation becomes the input to layer four, minicolumns. But if we have a moving object that can actually be changing. So suddenly this relative orientation is changing. so now this will become the input to the behavior model. So now exactly same. what becomes the input to the behavior model? What is that, the change in pose of the child object relative to the parent? Is it a change or is it just the current, orientation? No, it would be the change because the behavior model only gets changes as input. So it doesn't get input if there's nothing changing. So if, we just have a stapler sitting there, we calculate the relative orientation of the top to the stapler and that becomes the input to layer four to the morphology model. We assign the stapler top two. To the full stapler model here. but if the stapler top now changes its orientation because the stapler is opening, whatever we are calculating here, suddenly changing and that change in pose of the child object will then be sent to the behavior model.

Yeah, I think that makes sense. Yeah. This pulls in my thinking about it. I'm trying to think oh, it's, there's orientation represented by Minicolumns. And so would these be minicolumns or would these be features of the, these would be, would these be features of the behavioral model? I think is, yeah. So how I imagine it is that it's basically the same mechanism as we use at the lower level for the behavior where we detect changes by like temporal offset of, on off, cells in the thalamus, being activated here we have temporal offset of relative orientations, changing and that, kind of encodes an orientation change that then activates minicolumns here.

So same as here, we would detect a rotating bar or moving bar here we would detect, this relative orientation changing.

I'll have to think about it.

yeah, so that's for me, it answered a couple of questions first, what is even the input to behavior at a higher level? Because it only receives changes, not features. so the behavior ID is a static feature at this point. So that needs to go into the morphology model. It can't go into the behavior model. but this kind of answers this, that if now the, pose of the child object is changing, that suddenly becomes an input to the behavior model. but that's only the, or that's only the orientation of the features changing, right? Yes. but the other things could happen just in, it's not just the orientation. It could be appearing or disappearing or just changing in any way. Yeah. So that's, that would be other kinds of changes. So for example, I don't think I show it in this, graph, but, if for example, the object ID changes or the behavior ID changes, then that would also become input to the behavior model. if I have a, red light that changes to green or that's not too complex, but if you, have an app on your phone and you press it and the icon changes, then it's a new icon id, that has changed when you pressed it. And then that change would be an input. Here, the goal of this exercise right now we're trying to predict what the, the morphology of the object will be based on its current behavioral state. Is that right? Yes. So this is a preamble to that. So basically Oh, okay. 'cause I said I don't think you've solved that yet. No, I didn't. Oh, okay. This is just defining, what is stored in this behavior model and basically the idea is that the behavior model stores changes of the child objects, location and orientation. so basically, here now in this behavior model, in the higher level, we store that the top of the stapler is changing its orientation over time. And we can then, for one, we can use a back projection, which tell, which tells where we expect to be in the child's reference frame. so which features to expect. And then we can have again this, layer six cc projection, which tells, which updates the expected orientation of the child object. So basically up here, we store the changes in the pose of the child object, which is the behavior model now. And now we can project these changes over here and, through the sequence of behaviors, update the expected orientation of the, of the stapler top. Then all the predictions about morphology, about which features to expect are made down here using this learned model of the stapler top. We don't have to do anything, we just adjust at which orientation we expect it to be, using this feedback projection and that transforms the incoming movement vector and the incoming feature vector and lets us make predictions. Yeah, I mean, I think that makes a lot of sense. I think that's fits with intuition of how this would work. And yeah, let's go. I hadn't my assumption that somehow this would work, but I think you're putting some meat on it. yeah, I think it's promising, there's one big issue with it that I haven't mentioned yet, but, yeah.

the, the main big issue is that this only works for orientation changes of the child object. It doesn't work for location changes. and I think the, fundamental issue there is that nowhere do we ever communicate, the location of the object relative to the se sensorimotor or the body. hang on, what do you mean by location change? Yeah, let me think of an example.

I guess it just seems like we can have object behaviors where sub components are changing their location and not their orientation.

it's interesting.

Yeah. Would that be more like a location by location basis? Like you have to break it up and then those are gonna be different associations?

yeah, it would help if we had a specific example, but just, yeah, I guess if we, if you think of a part as a compositional object and the lid goes up and down and it's not a perfect example because, you can take the stapler, take the staple instead of having a hinge, let's say the whole thing at the top, just extend it up and then extend it down. Say might, yeah, it's still connected somehow. it's like your pot, but instead of hinging it's moving. Yeah. and it's not clue me right up front.

why that's fine, isn't it? Because so the movement in, or, like the behavior in the high level column tells us that, okay, after this behavioral state will be at a new location, but, it's kinda like what we were talking about last time. Like it. As long as there's a way that location is common in the higher level column, it's still going to predict the, right location in the lower level model and therefore predict the right morphology. I think the tricky thing is yeah, understanding, understanding how behaviors in the higher level column, like actually represent, changes loca in location.

it, we can change, we can bias the location in the objects reference frame that we want to expect, but we can't really communicate that the object is in a completely new location. Now, relative to the sensorimotor again, or No, it's too much for me to absorb right now, so I, it's not clear to me it doesn't work. Yeah, we might, we can leave it at this end, say that it's, maybe we can make it work for location as well. I think it's a nice solution for making it work for orientation changes and I think it's a nice solution to make predictions about object morphology, basically making all the morphological predictions using this morphology model and the behavior model basically just rotates that expectations. again, I'm not sure why it just has to be rotating. you're saying, it's not clear to me that it won't work for the locations as well.

Yeah, maybe I'm not thinking hard enough about it, but, maybe, with, like a ex draw brainstorming session. I think we would, we have to figure out exactly how it fails or, I, it's not obvious to me. I, can't absorb, what you've presented today is great. it's flushing out details of one of the ideas we've had, And now putting a lot of meat on it. And so that feels great. It feels oh, this is great. I love this. but I haven't internalized what the implications are yet of that. It's hard for me to internalize all that in one, Yeah. 20 minute presentation of this particular idea. so I'm just saying I'm not able to personally, I'm not able to say, oh, it works or it doesn't work. Oh, I see the problem. I don't see the problem more oh, I have to spend some time working through this to understand it better. Yeah. Maybe I'll, just wrap up the last slides 'cause we're already a bit over time. And then, I can, share the presentation, with the slides on what I think are open issues and then, we can talk about those more in the next meeting after it settled a bit. That sounds good. Yeah.

so yeah, basically I put a grayish check mark here because I think it's, it solves it. except, for location changes, but maybe it can do that too, and I'm just not thinking of it. and then the next, problem to solve would be, to make predictions for our behavior applied to a known object, but a new combination. So we've never seen that behavior on this particular object before.

so for instance, we have a book, down here and we've never seen the book opening, so we wanna, we are detecting this kind of opening behavior and we wanna make predictions of how the book will look, when it's, opening.

and so we can use the same mechanism, of sending down and changing the expected orientation of the book. but we would have to apply this temporary mask that we talked about before where. Since we haven't learned a like composition object of the book yet, we haven't, recognized that like this part of the book can move, independent of the other part. We basically wanna make predictions about the book orient, changing orientation, but only for part of the book. and that kind of where this attention mask is applied could be informed by which parts are moving. So basically we only wanna make predictions about the par parts of the book that are moving. and that could be the heuristic for that. I'm not sure how that would work on a neural level or which kind of connection would need for. we had, this has to happen for the stapler too, right? yeah. Before we have learned the sub-component. this is the idea that how do we determine that the top of the stapler is a separate object? yeah, exactly. And the, and the assumption has to be that the lower column has already learned the complete stapler or the complete book, and now we're just going to math off part of it while it's moving. Exactly. And then, yeah, over time this mask could be used to then learn a composition object. So learn that this is a sub component on the higher level book object and help us, it seems like we learn this very quickly. So this isn't a slow learning process. Yeah. Okay. Yeah. Observation. Yes, you could, this could be wounded. One or two exposures and you go, yeah, I get it. Yeah.

that's a, but yeah, so this would be the proposal, for applying behavior to a new object that we haven't segmented yet. I think it's a nice mechanism, but, I also a few things that still would need to be worked through maybe, oh yeah. But, yeah, it would at least solve the general problem.

Yeah. No, I think, it definitely feels like it's along the right track. I think the, or yeah, maybe we'll get to this, but yeah, I think it's the location representation in the higher column, in the behavioral reference frame. I think the nature of that is key because by definition that's changing. If the beha, if we're going through behavioral space, so are we, how do we then maintain an association, with the, morphological model in the lower reference frame? you mean this location is changing? Yeah. Moving the sensorimotor, but then wouldn't this one move as well? Yeah, exactly.

I think it would, so work was regarding the same, so we moved to a new location, let's say we Cade, so we expect a, like with the open thing that now it's gonna be somewhere else. Yeah. We haven't, made an association. that's why I feel like there's almost like an association between the behavioral model and the morphological model in the higher column, and then between the two morphological columns, because that's at least fixed. I think, and so that's, I think that's why you need the morphologies to be similar. Like you, you can't really expect, you can't really apply like a, I don't know, a like you can take a clam like morphology and apply the hinge behavior, but you can't apply it to a box unless there's suddenly a seam in it. Yeah. maybe I'm missing something you're saying. I guess something to also point out is that notice here, I haven't drawn the feedback connections in this example. So there's no association between this location, no reference frame to this location in the reference frame. 'cause we can't know about this at this point, in this scenario because we've never seen the book with the, hinge behavior. so, we can't really have this kind of location association learned either between two columns or within the column. 'cause it's like a novel combination. I don't know if that maybe I when we learn it with, because, and I guess that's the other thing, is it maybe fits better with the anatomy that it would be an association from the, again, the morphology model and the higher level column, which you just like when you learn a composition object, like you see a logo for the first time on a new object, you look at it, you attend to it, you can learn that connection immediately. But then that enables you to generalize to, when the model causes the object to deform.

that's at least how I was thinking of it, that it's, like it is a learned association. but it would be in the L six to L six connection between the two columns. Yeah.

So you say, there would be like L six between the two morpho morphological models. Yeah. And then it's like the, because the behavior's familiar in the higher level column, it's, it then, can map you map from a behavioral point of space to a point of morphology space in the, where it's familiar and that tells you what is the corresponding morph pointed morphology space in the lower level one. And then you're predicting a, what you'd see after moving in that space. And what problem would that solve? This is for applying the, behavior to a novel object. Okay. But the way, why wouldn't this mechanism be sufficient?

I guess it's just in terms of how you actually predict, like maybe you're right, maybe for orientation this is sufficient, but, I guess yeah, for predicting other kind of changes. That can happen in the lower level one other than it just rotating.

Yeah. So yeah, if it's a solution to it, changing location, then yeah, definitely. I'm not sure I understand completely yet. Maybe we can draw it out sometimes. Yeah. I'm not, I don't think it makes total sense in my head. Like it's definitely just a rough, like a feeling, but yeah, it would, be worth working through properly. yeah. But no, I think you're right. I think maybe with orientation it's sufficient just to have this, transformation. Yeah. Yeah. That's what I like about this mechanism so much is that it's it's really simple. It really just takes the storage orientation change here and sends it's over here and applies it to the, orientation of Yeah. Objects reference frame and then that takes care of all the predictions we wanna make about morphology. Yeah. It reminds me about something I think you talked about at the retreat, which was like, what if the behavior is like predicting a transformation, the change then almost subtracting that in the thalamus or something like that. But here it's more column to column. Yeah.

yeah. Lemme maybe get to the last yeah. Sorry. I'm gonna see open issues. Okay. All right. just briefly, if a part of a behavior sequence is occluded, that's no issue because we have learned the behavior model and that sequence is just getting played through the matrix cells. We're not pausing it as we go through the occluded part. So we keep making predictions even when the book is partially occluded and, we are just at the correct point in the sequence once it comes out of occlusion again. So we make the correct predictions, basically that metronome keeps on ticking even if there's like a black bar here.

and then lastly, compensating for object movement when recognizing morphology is also no issue because Yeah. what we talked about at the beginning that it's a sub-issue of the previous problem.

because this behavior rotates the expected orientation of the sub object that automat automatically takes care of, properly transforming the movement vector, and incoming features so we can still recognize it even if it's moving.

so that's that chapter four remaining issues. You all still have a few minutes to go through them? Yes, I do. Okay.

so this one is the main one that I see, or it's two sub-bullets. Host the child object, location change, communicated to region two. So we have a way of communicating that the orient relative orientation of the child to the parent is changing. We, we use this kind of c relative orientation calculation and communicate that change up here. But what if the relative location of the child to the parent object is changing? I don't have a good answer for this right now. one random idea I had would, I could use the layer six a projection. I, still don't understand this problem well enough. And even with the staple top, it doesn't seem the staple top doesn't in a compositional idea. It's not at some, it's not one location there either. the parts of the staple top are moving relative to the other parts. the orientation, remember we apply the, we apply this at a, point by point loca, on the point by point. So I guess I'm still, I'm not even, I don't, I'm not see this as a separate problem or maybe you haven't solved it in the early one. I'm confused by this. So basically I'm thinking of the scenario where we have a child object that moves relative to the parent object.

Have a pen and we press the back of the pen and the tip comes out. And so that movement of the child object relative to the parent, I don't know where this information would come from. We, can detect relative, or I'm saying the staple top is the same thing. The staple top is, it's really not just an orientation change, it's the location of parts of that staple top removing. It's not just, it's not just the, there isn't an entire thing that's orientation. Yeah, I guess one way of maybe phrasing it is if it was literally just the orientation you would, the top would pivot on a point in the middle. Yeah. I'm not solving the stapler completely either. yeah. But, maybe just, I clarify. So everyone's talking about the same thing, like that's just one way of conceptualizing. I think it's even worse than that, Neil. It's not that it would rotate in the middle, it's just that we only define rotation at a point by point location. Remember that we remember the logo on the cup that took a a, bend. so that's the way it works.

there, there isn't, I don't think it solves it. I don't think you've solved it for the stapler top either. yeah. Either I agree. Yeah. It's not solved for the stapler part either top either. So I'm just stating the problem that I don't know where changes in location of the child object relative to the parent would be detected and where it would be communicated. Alright. It's a good opening. I think it's, I think there's some more filling in here we have to do on this. Yeah. yeah, I guess just two, two possible options I put in here was like layer six a projection. 'cause there, there's a reference frame there. it's not great because I don't think it projects to the higher level of thalamic region, I'm not sure. And then another option could be layer five A because that one is already, in the global reference frame, like relative to the body. So it would be much easier to calculate the relative orient, relative location change. But it's also not great because here we wanna share the goal state and not the current location of the object. those are just the two I could think of. I'm not a fan of either one, but, yeah, open issue I guess. and then related to that, how can region two communicate the child, the expected child object location, back to region one? Isn't that the same problem in some ways? Yeah, it's basically the same problem. just the backwards connection if I'm, yeah, if I know the behavior, how do I tell it to expect the child object at this location? So could be like a similar way of projecting the change that's stored in the model down here somewhere. And then we can communicate the expected location of the child object over here. but yeah, again, this is quite vague idea and I don't really know. Yeah, again, this is where it feels like the L six. The normal feedback connection could be a natural if like L five can tell that reference frame, what is the particular, like L five in the column two, if that reference frame can tell the morphological reference frame where it should be, then then that could Yeah, guess the issue with the feedback connection I see is that, that is, in the objects reference room, which is specific to the object. So if we've never seen that object behavior combination, we can't possibly have that, those connections in the backward projection. whereas here, I guess I drew this in black because I meant that this is relative to the body, so in a common reference frame, and then we can transform it into the objects reference frame so that way we could tell the location of an arbitrary child object, relative to the body.

but yeah. Yeah. Okay. we're assuming that we know the morphology and we know the behavior, we just haven't seen them together. Yeah. Okay. Yeah, so I think it could be done with like quick binding of those things, but yeah, that's, yeah. Sure. Yeah, definitely. Wanna think more about this and talk more about this one. And then another one is just how the attention mask would be applied. To, to region one before the object is segmented. I think the idea of the attention mask is nice, but I'm just not very sure about what mechanism could be used for that on a neural basis.

and yeah, I can use this heuristic of applying it to any part of the object that is moving. have to think through if that actually works for any example we can think of.

it seems by the way, it seems a solution to that. There's a, it a general problem. It's what if I have an object that it's moving relative to me and I still can reference, recognize the object. So the stapler as the car is moving as you suggested, or the stapler slotting across my desk or whatever.

if you, understand how we do that, how we still infer that morphology of the stapler even as changing its location, then essentially I think you'll solve the problem of how do you break out the moving top? It's, it seems to be the same problem. I, guess I, I'm just speaking out loud about how, thinking out loud about how I think you could solve that.

I feel like the first one is more an instance of the last problem I stated of still recognizing object morphology, even though it's moving. but there, there wouldn't Yeah. Need to be a mask applied to it necessarily. obviously, once you, it's not a mask, it's more like. An object is moving. I'm going to my, I have to, make sure that my reference frame and everything is anchored to that moving object. It's, so it's positioned relative to my body and its orientation to my body is changing, but I want to maintain the same model. But in the case, this case, the model only applies to part of the object, because only part of the object's moving relative to my body. yeah. Yeah. Maybe one relevant thing, I think this was a comment from you at the retreat, Jeff, but it was although there's a, maybe some, there's almost a question of how much a mask there really is, because you still see it as the object. if the TA stop at the top of the stapler is moving, you don't, I guess you can talk about the top of the stapler, but in some sense you just say the stapler is moving. Like that part? no. I, just, it feels the, the opposite. I feel once the top of the stapler starts moving, once the top of the stapler starts moving, that's the only thing I'm focused on. I could come back and say, oh, is the rest of the stapler there? Yeah, there it is. And that would it, but I guess the point is like, it's still a stapler, so it's like maybe we don't even need to mask that. Like maybe the, like the masking it's useful conceptually, but it's, it doesn't actually need to happen for kind of the system to work well at. I dunno, at this point we're saying it's a separate part of the stapler. or I, wanna make sure we get through all of your, oh, your. Yeah, so those are the big remaining issues I had that need a lot more kind of thinking and could break some of these ideas. And then I just have a couple of remaining uncertainties that are more like going back into a literature to read and, just that those are, to point out what I'm not so sure about. So one is this kind of child object orientation change and how it can be, whether it can actually be communicated by these layer six cor cortical connections similar to how we propose it for other compositional objects. I think in both instances, this is the, like the least certain part, even in the compositional object I, idea. So just I'm not a hundred percent sure if this is the best way to communicate this, in the layers. and then yeah, whether changes are actually represented in L three because at least from a lot of papers, it seems like direction sensitive cells are in V one at least, are usually found in layer four C alpha, which is the main target of the magnocellular pathway.

yeah, maybe a brief comment on that. I wonder if, like maybe a simple solution to this is maybe that's the direct input in the column, but then that's processed into L three and then that's why you see movements, sensitive cells with, narrow receptor fields in L three, even though the Magnus cellular input is in say, L four, C alpha. just to bear in mind, if you don't remember this, there are people who have argued that the labeling of these extra layers are incorrect, that the different layers four are actually different layer threes. So just, some arbitrary decision to, to call 'em layer four. Yeah, I guess I'm just finding out that like this exact layer assignment, at least I'm not a hundred percent sure on and, yeah, whether layer three is the best one and yeah, I think this kind of, whether they're direction sensitive cells, earlier in LGN or even retinal gangone cells dependent on species as well. if, I remember that you don't really see them as, first of all, there are directional sensitive cells in the retina, but they're not transmitting, they're not gang the cells, they're the internal cells. and it's believed they do other the functions. but I think we assume that there, that information is not transmitted. yeah. Yeah. I guess just that on a general note that Yeah, I think the mechanisms I presented here are, pretty nice and general, especially for the behavior model, but like the exact assignment to layers, right? At least I'm not so sure about yet, with the behavior model part.

and then. Another one I didn't talk about is how do we recognize change if the sensorimotor is following the object. So smooth pursuit where we have movement input but no feature change. That's something you also brought up before Jeff. and yeah, basically how does this change information get into layer three or be compensated in the thalamus and how, would that mechanism work?

and then this question we touched on earlier, how can columns share knowledge so they don't all have to observe every change in the behavior to learn it? don't have a great answer to it yet, besides you do have to observe every change and repeat it many times.

and another one is whether this is not for inference of behaviors, whether voting on behavior ID poses sufficient for past behavior inference, or if we need to have some stronger mechanism, actually communicating movements between neighboring columns that are being detected. 'cause yeah, behaviors are just, can happen quite quickly. And then if you're just voting on their id, you're not sharing a lot of information between columns, to detect the behavior.

but maybe it is sufficient.

And then, yeah, do we vote on the point that we are in, the sequence? So where in the sequence are we, or can this be communicated by resetting matrix cells? and telling it we're at the start of the sequence now, and from there the clock starts.

and yeah, just generally how timing is implemented by matrix cells, how they're modulated for the speed adjustments. how do we indicate the start of sequence or recognize it in the middle?

yeah, those are all things to ponder, I guess Apple. Ask them, oh no. Oh, we more the complicated world of the new cortex. yesterday I spent all day just putting all the connections into one diagram so then I could build the slides and just remove the connections that were not relevant for the point I'm making. And yeah, this is how it looked like. I guess the solution is not as simple as it might seem. Yeah. That's pretty funny.

nice. Yeah, that was a great presentation. Can I, can I just try to make it the most crudest summary I can? it was great. I love it. I love the diagrams. It's, very helpful. The first thing is there's really two, just a couple of the things you're proposing. One is, we talked about this earlier. We really should be focusing on behaviors in a hierarchy and not think anything about what's going on in a particular column between the behavior models and the morphology model. Just focus on the idea that there they are parent-child relationships. That was one. And that's alar. That's a great clarification. that was oh, thank goodness you did that. I think that's great. The second one is, I think was surprising to me was that you now basically the behavioral model ID was become a feature of the morphology model that was being projected to layer four. That was a big insight, that, I don't think we, we discussed before. It may be obvious in hindsight, I don't know. But so that was really cool. And then the third thing is just, okay, given those two assumptions, and you assume that the same mechanisms are in, assume the same mechanisms are in place for both the morphology model and the, behavioral model, which we said before, but stated explicitly, then walk through all the issues. And so most of your presentation was just walking through all the issues. What happens if you make those assumptions? which is great. I, I got lost towards the end there. I couldn't follow everything. I'm sure I'm not the only one. maybe I am, I'm still older, but, oh, I got lost too many times. Okay. So making the slides, to me that was a huge, those two things. Eliminating thinking about within a column is just gets me to focus on hierarchy. Assuming that they're the same mechanisms everywhere, which we've said, but we never explicitly spelled it all out. And the same mechanism between the two types of models and then third, tying together in some, like one, the morphology model projects a layer four, the behavioral model project layer for the morphology model. That was like, oh, that's how you tie together and now you can tie together with the backers. So given all those things, I think this was an, a great start in a lot of great stuff in there. And so now the, it, now it's just a matter of working out these details, right? It's, and that can't be done in one first session like this, so at least not for me. but it's a huge clarification in my mind, just like simplifying the problem to eliminate things we don't wanna have to think about. and yeah, I think it was, yeah, pretty nice how, we can, that's why I added these two kind of preliminary sections about the existing theory because for the first chunk of problems, we could take the existing theory about object models, and then for the second chunk of problems, learning associations and making predictions about morphology, we could use the theory about compositional objects, right? I think that's my favorite part about this proposed solution that it so nicely with what we already have. So if the past is a prediction of the future, I think it'll take several rounds of discussions to work out all the details here. but I think it's a, I think it's the right path. So then the details are just a matter of, turning the crank and working at it. and, thinking through the problems a little more concretely, like the issue of the moving of the staple top versus the changing the orientation. I really got me confused what the hell's going on there?

but I think, I bet you this is, we'll be able to solve all those issues with this clarification of the thoughts here. That's my, yeah, I think if you're, I anyone says observations. That was my observations. I don't want to shut down conversation. No. Yeah. if you are on board with the general ideas of using hierarchy for some of these issues, then, our remaining problems, I feel like at least become much smaller and more concrete. but but we, I it, I'm not trying to take anything away from it. that wasn't an idea we had, we just hadn't fully embraced it yet. It's oh wow. It's, it's gonna be hierarchy like this. We already knew that behaviors had to be, you had to have multiple behavior models per morphology model. So it has to be hierarchical in that regard. yeah. Yeah. I think it's, just stating it and putting in a picture like, oh shoot, why? Of course, it has to be that way.

Why was I struggling on this? Yeah. And I, think for me, another kind of takeaway or interesting one was just this kind of like orient relative orientation and. Yeah. What we can do with that. 'cause again, it's something that I think you were Yeah. Was talked about briefly, but just again, as you said Jeff, like putting in for a figure, really thinking through it. just stating helpful, just leave names, some possibilities stating this is the way it's gonna be and then just walking through the consequences. that's sometimes, half, half the solution, just stop talking about this other stuff. Just focus on this one. yeah. And then, we can keep going back to our, as you said, Viviane, go back to our existing solutions for hierarchy and say, okay, how do they make this work? assume they're happening here too, right? What's gonna happen? I'm still confused. Yeah. And I feel that in general, it's just really satisfying that it can feel insurmountable sometimes these problems, but just how this kind of a kneeling process just can slowly chip away at it, Because yeah, if you think about where we were six months ago or something, it is definitely a huge progress. that's why I made my comment earlier about when with just re reviewing the morphology model, I was like, oh, that was 10 years of my life. Because that was so hard. We didn't understand any of that stuff. It was just so damn hard to figure that out. And now I was like, now this seems easier. It was like, oh yeah, we're just doing variations on a theme. It's it's still hard, but it seems easier in some ways. I'm gonna think about this. This is great. I know if anyone else wants to talk about it, but yeah, thanks Viviane. Sorry, not being so long and No, the diagrams are great too. All those little animations and everything, it's all really, very, cool. Yeah, it took me like an hour to write all the notes, but then two days to put it into slides. 'cause it's just so hard to communicate these ideas. Like it, it's all in my head. But then to put it into a way that I can tell it to someone else and not be totally confusing.

Yeah. those are nice diagrams. A nice new format.

and work for you. It worked for me, okay. I'm gonna go back to the hierarchy paper.