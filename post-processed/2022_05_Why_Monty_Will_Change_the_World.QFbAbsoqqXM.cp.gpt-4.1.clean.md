I'm going to start with a series of statements. The first one is not too controversial. Many people agree that machine intelligence will transform the 21st century, similar to how computing transformed the 20th century. If you think about the impact of computers from the beginning to the end of the 20th century, it changed everything: communications, entertainment, transportation, science, literature, arts—every aspect of society in ways no one anticipated. People in the 1940s and 1950s couldn't have known what was coming. The same transformation will happen in this century with machine intelligence, affecting every aspect of society globally, perhaps even more profoundly.

Many people believe this, and I'm very confident in it. The second statement may be a little surprising: we don't believe that deep learning, the current AI technology, will be the foundation of this transition. It's popular today, but there are many reasons to think it won't drive the future. I'll explain more in a moment, and we're not the only ones who feel this way. I'll share some quotes. So, what technology will drive this change? We think we've figured it out: sensorimotor learning. This technology combines inputs from sensors or sensory systems with movement to learn models of the world. Humans learn by moving through the world—moving our arms, fingers, bodies, and eyes. This is integral to how we learn; we are not static entities. The human brain is essentially a learning system, so there's no question about that. Our bet is that this will be the method for building AI in the sensorimotor domain. Meta is building the first developer platform based on sensorimotor learning, and we are leading in this area. This is the opportunity we have.

Here are some quotes. Francois, a well-known machine intelligence expert at Google, says you cannot achieve general intelligence simply by scaling up today's deep learning techniques. Jeff Hinton, one of the inventors of deep learning, says, "My view is throw it all away and start again," referring to his own creation. Jan and other famous AI researchers echo similar sentiments.

Getting closer to our work, what's missing is the principle that allows machines to learn how the world works by observation, interaction, and moving through the world. This is the biggest obstacle to progress in AI. De Hasis, founder and CEO of DeepMind (part of Google), also said we need to study the human brain because it's the only proof we have for general intelligence. DeepMind has a team of neuroscientists working on this. I've spoken to De Hasis; they have a different approach, but you never want to count them out—they're working on it too. Jeff Bezos, though not an AI scientist, points out that business leaders also recognize humans do something fundamentally different from current machine learning and intelligence approaches. The implication is that we probably need to do something different.

So, what is sensorimotor learning? Here are two cartoon diagrams contrasting deep learning and sensorimotor learning. On the left is deep learning, which consists of a series of layers of artificial neurons—sometimes a hundred layers or more, though here just a few are shown. They're highly interconnected. The way you train the system is by presenting a pattern of input at one end of the network and a desired output at the other. You use a method called backpropagation, which adjusts all the weights (the blue lines), and you repeat this process until the system learns the matching between input and output.

On the right, you have deep sensorimotor learning. You have an input, typically from a sensorimotor source, and a second input called motor, which represents how the sensorimotor is moving. Imagine your finger sensing something and moving, or your eyes sensing something at a point in the world and moving. Internally, the sensory learning system has a concept of location in a reference frame, so the observation occurs at a specific point in space, and you pair that point with the actual observation. Most learning happens in the pairing between the observation layer and the reference frame location. Sensorimotor systems learn models of the world and where things are relative to other things. The idea of space is critical to how this works, and this capability is not inherent in deep learning systems.

Let's talk about training these systems. If you take a classic image classifier, you present a picture and say, "That's a car." Then you present another picture and say, "That's also a car," repeating this process maybe a hundred thousand times across different categories. Each time, you adjust the weights minimally, trying to get the system to recognize new images as cars. On the sensorimotor side, you wouldn't show a picture of a car; instead, you'd look at a car and your eyes would attend to different parts sequentially. You might first look at the tire or wheel, noting its location in the car's reference frame. Then you move your eyes to the door handle, and the motor signal updates the internal reference frame. You continue moving your eyes to different points, pairing each location with the observation, such as the headlamp. In this way, you build a model of the car and its components relative to each other. This is a very different way of learning compared to deep learning.

Deep learning has strengths and downsides. On the plus side, it can theoretically learn any input-output mapping and improve incrementally with more training data. However, it's brittle because you can't train on infinite data, and there are points where it fails miserably. Changing a few pixels on a car image might cause the system to misclassify it as something else, like a blue bear. This lack of generalization is well documented; the system doesn't understand what it's looking at and has no structure. It can't recognize new objects with similar features or adapt to changes without retraining from scratch. Deep learning requires unsustainable amounts of data, training time, and energy, leading to large models that are expensive to run and have significant environmental impact. These systems also struggle with continuous learning.

Sensorimotor systems have opposite strengths. They're much more robust due to the structured way data is stored, allowing for model comparison and generalization. You can see that different objects have similar components and relationships, and infer similar functions. These systems require much less training data and are more energy efficient. Training is fast, and you can learn continuously, adding and changing things without issue. The models are actionable, enabling planning and reasoning, such as determining the actions needed to achieve a result. The downside is that sensorimotor learning isn't always best for point problems, like playing the game of Go, where deep learning excels and has surpassed human performance. For narrow domains with no general knowledge required, deep learning is best. Sensorimotor learning is best for general problems that require knowledge and understanding of the world, which is what's missing in today's AI.

One slide on neuroscience: this approach is based on years of studying the brain. The neocortex, the organ of intelligence, is a sheet of material composed of columns. There are over a hundred thousand columns in the human brain.These are about the size of a grain of rice. They don't actually look like this, but you can visualize them this way. All the different parts of your cortex have this structure. It's surprising—even in vision, they all have a complex architecture with the same prototypical layers, cell types, and connections. The big mystery is: what do these columns do, and how does this lead to intelligence? One of our major discoveries is that each column in the neocortex is a complete sensory learning system.

If you have questions, just stop.

Going back to the picture I showed before, there's a reference frame and an input. We see this in every cortical column, and we propose that there's a layer of cells in every cortical column that's a reference frame—grid cells. At the time, we made this prediction.

The second discovery relates to how these columns collaborate with each other. There are long-range connections in the neocortex, shown here with horizontal green arrows. This is where the models collaborate; this is how they communicate. Simply put, they're trying to reach a consensus on what they're seeing and where it is in the world. Each column has its own modeling system, receives its own input, and yet together they can reach a general consensus. This is the basic architecture of the neocortex, and it's the architecture we'll use in our Monty system. This has been documented in a series of neuroscience papers. Richard Dawkins heard about the theory and said it was brilliant. He wrote a nice foreword to my book. Bill Gates took my book from last year and listed it as one of the top five books he recommends—the only non-fiction book he recommended. I was pretty thrilled by that.

Let's talk about Monty. Monty is a codename based on the name of a scientist called Vernon. That's where we got it. I think of it as a development platform for sensorimotor AI. How would you build AI systems? The basic idea is that these systems are built using two types of modules in varying combinations.

The first module we've already seen; we call this a learning module. It's more complicated than this, but basically, you take an input, you have a motor component, which is how the sensorimotor is moving, and you build structured models through movement of a sensorimotor. These can be very flexible. They can model different things—objects like a soda can, a computer, a mouse, or a chair. They can model environments like rooms and outdoor spaces. In your brain, these learning modules also model your body, with some dedicated to modeling space around your body. Pretty much anything with structure—this is how the brain can learn things like math, history, language, and even physical structure in the world. If you use the reference frame correctly, you can learn any structured knowledge base. This is not a speculative idea; we know brains do this, and if we're right about learning this...

The second type of module is called a sensorimotor module, which differs from what you might expect from sensors. There are two outputs from the sensorimotor module: what it senses (the output) and how it moves. It communicates both the sensory data and the movement information. This aligns well with learning modules, which process both what is sensed and how the sensorimotor system moves. Learning modules can work with any modality, including biological ones like vision, touch, hearing, echolocation in bats, or even radar and ultrasound. As long as the output is compatible, the system functions.

Sensorimotor modules are not like cameras; they detect features at specific locations in 3D space, one at a time. When you observe the world, your eyes attend to different points in space, and you know their positions and orientations. This spatial awareness starts at the beginning of the system, with locations in space being sensed. The sensorimotor module senses both what is sensed and how it moves, and the learning module maps this onto a reference frame. Because all sensorimotor modules share an understanding of space, they are largely interchangeable. This is why the cortex can process touch and vision similarly. For example, when my finger touches something, my brain knows its location and movement, just as my eyes report where they are sensing and how they are moving. This allows the brain to intermix modalities, treating them similarly in some respects.

Another important aspect is that the motor signal is bidirectional. Learning modules can output a motor signal indicating desired movement, and sensorimotor modules can receive this signal. For instance, I might explore an object with my finger to learn how it feels, but once I have a model of the object, I can direct my finger to a specific location, such as pressing the power button on my phone. The learning module knows where the button is and instructs the sensorimotor system to move accordingly. The entire system is inherently robotic from the start, and in the future, AI and robotics will converge, with model learning achieving both goals.

Many applications can scale in multiple dimensions. For example, you could have one learning module and one sensorimotor module, which can be quite useful. Typically, you might have more modules. You can scale by adding different modalities, such as touch and vision or lidar and vision, each with its own learning module. The voting layer allows these modalities to collaborate, informing each other and making the system more robust. If a vision system is impaired in the dark, another modality can supplement it, leading to faster inference as multiple modalities resolve the situation simultaneously.

Expansion can occur horizontally by adding more modalities, more sensorimotor modules of the same modality, and more models. For example, having four touch sensors (fingers) allows for quicker learning and manipulation. On the vision side, more sensors provide greater acuity. This horizontal expansion increases capability. You can also expand vertically by stacking models hierarchically, representing deeper knowledge and insights. Humans are believed to have a four-level visual system, while mice have a one-level system. Mice can perform sophisticated vision tasks, such as identifying and manipulating food, with just one level. Higher animals and humans have larger cortices, enabling deeper insights across domains.

This is the general high-level plan for how the system works. The good news is that we can start small; even small systems can be powerful if the architecture supports expansion. To build human-level brains, we may need to implement all these features in silicon, which may not be possible in software alone.

I have one last slide, which outlines a strategy for moving forward. There is an opportunity to establish a leadership position, a key goal for startups and technologists.

Most people don't understand what to do next. We have a multiyear head start on this. People will catch up to us eventually, but right now we're ahead. We have the opportunity to define the field, the terminology, and what this technology is good for. That is a tremendous opportunity. We're not trying to fight our way into an existing field; we want to create new territory here.

It's important to focus on developer platforms from the start. You can have the best technology, but if someone else comes along later and makes it easier to use, you lose. There are many examples of this in technology. It's not enough to have the best technology; you also have to make it so that nobody can just outrun you by making it easier. We have to focus on that from the start.

In addition to the technology, I think we need to pick one, maybe two application areas to begin with. We can start very small. These don't have to be flashy applications; they just have to show some conversional value, meaning someone says, "I want to use this, I'm willing to pay for it," and it has to demonstrate the principles of sensorimotor AI and the Monty platform.

Whenever you create a new platform, I've observed that there's always a whole bunch of people who want to rush to it and see what it can do. You just have to get it going, and they will come, but it's got to be easy and it's got to work.

Whether that's self-driving cars, vision systems, robotics, multisensory security—I don't really know yet. We haven't chosen what these application areas are to focus on. There are lots of partnering opportunities, which is great for a platform. People who make sensors might want to modify those sensors to be compatible with Monty and to be location aware. There's an opportunity to partner with them. There's an opportunity to partner with people building new types of learning models that work on different variations of the technology or are pre-learned or have certain biases. There are opportunities to work with silicon vendors to implement this. We already have conversations on other parts of our work. There are opportunities to work with systems integrators who can help less capable end developers, and of course, end developers themselves.

In summary, we have the opportunity here to create and shepherd one of the most important technologies of the 21st century. I think it's exciting. It's something we have to be very thoughtful about because it's going to have a big impact. We have to think carefully about how we handle that, but it's a tremendous opportunity. We have a lot of technical issues we still have to resolve, but I think everything I've just told you here is pretty clear, and that's how we're going forward. That's it.