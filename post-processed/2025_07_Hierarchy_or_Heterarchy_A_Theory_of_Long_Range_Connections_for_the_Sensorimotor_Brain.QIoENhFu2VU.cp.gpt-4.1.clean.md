Let me walk you through this paper. This is a neuroscience theory paper, very different from the other paper in terms of results. The paper is called "Hierarchy or Heterarchy: A Theory of Long-Range Connections for the Sensorimotor Brain."

To give a brief introduction, the first part of the presentation—and the paper—is about neuroscience evidence, specifically a review and summary of long-range connections in the neocortex. The second part of the presentation will discuss the function of these long-range connections and what functional requirements they might fulfill when considering the brain as solving sensorimotor tasks.

To frame all this neuroscience evidence, it's useful to recap the basic structural organization in the neocortex. You're likely aware of this, but as a brief recap: the neocortex is a thin sheet that's wrinkled up in our heads. If you cut through this sheet at any point, you observe a layered organization. The different layers contain different types of neurons, different densities, and can have different response properties. This was first drawn by KHA in 1911 and further classified and analyzed over time. We find this six-layered structure essentially anywhere you cut; depending on where you cut, the layers might have different sizes, but overall, people classify it into six layers. Sometimes layers are classified into sublayers, like layer four is often split up in the visual cortex, and there's layer 5A and layer 5B, and so on. But there are these six basic overall layers, and orthogonal to that, if you look alongside these layers, you find functional units called cortical columns. These are not something you can observe under a microscope, but are defined by their response properties: all the cells within a cortical column respond to the same receptive field, and the column next to it has a different receptive field. It might be overlapping with the one next to it, but it's a different receptive field. If you move about 200 to 600 micrometers along the surface of the cortex, you no longer have overlapping receptive fields; you're in a totally different column. As a detail, you can further decompose a column into about 5,200 microcolumns, defined by their response to similar features, such as similarly oriented edges.

The most extreme example of this is the barrel cortex, where each whisker of a rat corresponds to one column. In other sensory organs like the skin or retina, the patches can be more overlapping and less clearly defined. The first to identify this structure and propose that columns—or microcolumns—could be the basic unit of computation in the neocortex was Vern Mountcastle. This is the column hypothesis that the Thousand Brains Theory is strongly based on.

When we talk about long-range connections, we mean axons that travel outside of the cortical column from which they originate. Every neuron connects to neurons within the column where its cell body is, but some send their axon outside the boundaries of the cortical column. This can happen either by the neuron entering the white matter through layer six and then reentering the cortex elsewhere, as information travels faster in the white matter. In the diagram, the gray matter is the structure with the layers, and the white matter is below. Information would go from the neuron down into the white matter, travel quickly along the axon, and then reenter somewhere else in the cortex. For example, a pyramidal neuron in layer 2/3 sends an axon all the way down, and then there's a cortical connection—meaning a connection from one area of the cortex to another. The axon would travel to another column, go back up, and connect somewhere else.

Alternatively, it can travel within the cortex without entering the white matter for a distance of more than one millimeter. For example, the red part in a schematic shows axonal branching of a layer 2/3 pyramidal cell that can travel across columns.

I'll show some figures from other neuroscience papers in this presentation to illustrate these concepts. Everything in the first part of the presentation is based on a culmination of results from hundreds of neuroscience papers, with people at Numenta, particularly Jeff, studying them for about 20 years. This is not the only example or publication, but I've tried to find illustrative examples to visualize the points I'm making.

We group long-range connections into four conceptual categories for this paper. First, we have hierarchical cortical connections, the classical connections that define the cortical hierarchy: information enters the brain, gets processed, is sent further up in the hierarchy, and further processing happens within the neocortex. Second, we have non-hierarchical cortical connections, which are connections between different columns within the neocortex, but as I'll argue, they can't really be interpreted as hierarchical processing. Third, we have corticothalamic connections; every part of the neocortex connects to the thalamus in a very structured way.

Finally, we have layer five motor outputs. Both of these last two categories can be interpreted as hierarchical or non-hierarchical, and I'll explain why. There are more long-range connections in the neocortex, such as to the striatum or the claustrum, but we are omitting those from this review.

Also, we are trying to summarize high-level principles. If you go into the literature, it's never as clear-cut as we show here. For every rule, there's an exception. Some principles vary by species, and some by sensory modality. There are always details and conflicting findings, but this tries to condense things to high-level principles. Many are accepted textbook knowledge, while some are less commonly considered when thinking about long-range connections.

Let's start with the most commonly thought-of long-range connection in the neocortex: hierarchical connections. The general idea is that information comes from the sensorimotor system, enters the thalamus, and goes to a relay cell in the thalamus, which relays the information to the neocortex. There, it enters in layer four, the classical input layer of the column. Some information also enters at the border of layer five and layer six, where additional processing happens within the column, activating neurons in layer three. Layer three is often seen as the classical output layer of the column. There is connectivity between layer three of a lower region to layer two or layer four of a higher region, serving as input to that region. Niels, feel free to interrupt me if I forget anything or want to add to it. In this way, information goes up the hierarchy in the next region. Processing happens within the column, neurons in layer three activate, and their long-range connections go from layer three to layer four in the next higher region.

Then we have feedback connections, shown in purple here, which originate in the deeper layers, such as layer six. They go into the lower region, where they can form local connections or have some branches in layer six or sometimes layer five. The axon then ascends all the way up to layer one and spreads broadly, even outside the cortical column to multiple columns in the lower region. When I say region, this could be, for example, V1 and V2 in the visual cortex. The figure shows an illustration of one cortical column in a lower region like V1 and one in a higher region like V2.

Several layers send their branches up to layer one, where they can integrate this feedback information. This is how the classical hierarchy is defined in the Development Scent paper. The connections between two hierarchically arranged regions are asymmetrical. Region two doesn't have layer three to layer four connections down to region one, and region one doesn't have these layer six up to layer one connections to region two—they're asymmetric. This is how Felleman and Van Essen, back in 1991, made the famous picture of the hierarchy in the macaque monkey's brain.

To show another experimental image of this idea: here we have retrograde-labeled neurons in V2. These are neurons in V2, and dye was inserted in V1 and V4. The dye inserted in V4, a region higher in the hierarchy than V2, shows inputs from layer two and three of V2. V1, lower in the hierarchy, with retrograde labeling, shows input from layer six and upper layer two, three, and layer one of V2. As an illustrative example of this feedback connection—the purple connection—here's a drawing of a neuron showing the receiving region, with the axon coming in from the white matter, a branch in the deeper layer, and the axon ascending all the way to layer one and spreading far.

These are the classical hierarchical connections taught in textbooks. Next, we have non-hierarchical connections. There are two main points here. First, many cortical columns, even at higher regions in the cortex, receive sensorimotor input. For example, in V2, you can get direct sensory input. Second, we can have lateral long-range connections that connect columns within a modality or between different modalities. If it happens within a modality, the connections are often between neurons in the same layer, such as layer three neurons in one column connecting to layer three neurons in another, or layer five B neurons and layer six cortical connections. This can happen within a region, like different columns within V1 connecting laterally, or through the corpus callosum to the other side of the brain, connecting the left and right hemispheres.

It can also happen between modalities, such as connections between primary visual cortex and primary auditory or sensory cortex. Some papers report connections like this, but predominantly they resemble the feedback connections described earlier: originating from deeper layers, with local connectivity in the deeper layers of the receiving column, ascending to layer one, and spreading broadly there.

To show some visualizations: here is the local spread across columns within a region in layer two, three, and layer five. Here is an example of layer six cortico-cortical cells—pyramidal cells in layer six connecting to other cells, mostly in layer six but in different columns. Another example shows connections through the corpus callosum, where dye was injected, and the red neurons indicate where projections were found after injection. Many projections are found in layer two, three, and in mouse, macaque, and human, with a few in layer five and layer six.

Notably, there are none in layer four.

These are non-hierarchical connections because they can connect first-order regions between different modalities, which wouldn't be considered hierarchical. They can also connect columns within a modality and even connect columns between hemispheres of the brain, so they are very long-range.

These input connections going to higher-order regions indicate that higher and lower regions can respond in parallel to sensory input. Information doesn't necessarily need to propagate from region one to region two to region three; instead, region three can get direct sensory input and make inferences based on that. They can be symmetric, going in both directions between regions, which contrasts with the defining element of hierarchical connections—namely, their asymmetry.

Next, the cortico-thalamic connections. There are several, and I'll first show this one.

While the cortex is receiving input always routed through the thalamus, the cortex also sends back some information to the thalamus from layer 6B. This is usually characterized as only modulatory; it doesn't cause these cells to fire on its own, but it can modulate how or when these cells fire. Here is a picture from a book by Sherman and Guillery about the thalamus that shows this. We have input to thalamic relay cells—a first-order thalamic nucleus and a higher-order thalamic nucleus. The input goes onto the relay cell as a driving input, causing the cell to fire and provide input to layer four of the first cortical area, the input layer.

Cells in layer six project back down to the thalamus. This is drawn lighter because it's a modulatory connection; it doesn't itself cause the cell to fire but modulates its activity. There are also cells in layer five that connect down to the thalamic nucleus with driving input. This information also gets sent down to the motor centers in lower parts of the brain. You can think of it as an efference copy of a motor command. This is actual driving input to the cell, versus the modulatory input from layer 6B.

Interestingly, layer 6B cells can send input both down to the thalamic nucleus where they receive their input from and up to the next higher-order thalamic nucleus, which then sends input to the next higher region. Unless you're at the first-order nucleus, most thalamic nuclei actually receive converging input from two hierarchically arranged regions. This is illustrated here, with topographically arranged neurons in cortex mapping next to each other from two different regions onto points in the thalamus. This converging input onto a thalamic nucleus will be important for the compositional object modeling I'll discuss later.

What do these connections mean in a hierarchy? You can argue that they support a hierarchical interpretation because they map down to the input region and the next higher region in the hierarchy.

But it's also an output sent from every region in the neocortex back to the thalamus. It's a parallel process that happens everywhere in the neocortex.

Lastly, another connection to the thalamus and to lower regions of the brain are the motor outputs. Layer 5A sends an axon down to subcortical regions that control, for example, the muscles of your eye, your body, or down to the brainstem.

These axons bifurcate and send a branch to the higher-order root of the thalamus, which then inputs to the next region. That's what I showed in the earlier picture. Here's an anatomical drawing of this happening.

These axons split at points marked with red arrows; one part goes to the spine and another part goes up to the brain or cortex. You can think of it as an efference copy—a copy of the motor command that gets sent up to the next layer of the cortical hierarchy.

This can be thought of as hierarchical since it goes from one region to the next higher region, but also non-hierarchical because every region of the brain has a motor output. Every region outputs something down to motor-related structures, which is not how people often think about information processing in the cortex. Usually, people think about visual information entering, going to V1, V2, V4, getting processed more and more, eventually recognizing an object and a scene, and then the motor cortex—a separate part of the neocortex—decides what to do and sends motor commands down to the limbs. But that's really an incomplete picture. Even V1 can send commands to inform how to move the eyes, for example. Anywhere in the brain, we have outputs from layer five down to subcortical areas.

Did I miss something else? No. I really like all the figures you added. It's a nice grounding of the paper. It was fun to dig back in and find these.

The conclusion or argument we make is that "hierarchy" is a limiting term when describing the functional organization of the neocortex. There are hierarchical connections and processing, but also many non-hierarchical connections and a lot of parallel processing. We have lateral connections between regions, motor output from every region, feedback and feedforward connections to different thalamic nuclei, and direct sensory input to higher regions. This suggests a much more complex picture than how people often think about processing in the brain and what deep learning systems suggest when compared to the brain.

That's the first part of the presentation, the neuroscience part. Anyone have questions on that?

Now, the second part is the theory. While there is a lot of anatomical and physiological evidence for these kinds of long-range connections, there isn't a comprehensive theory to make sense of all of them. We suggest that if you think of the brain as a sensorimotor learning system, each of these long-range connections has a unique and crucial role.

To explain those roles, I'll start with some background. Some of this has already been published as the Thousand Brains Theory, and some of it is new. This focuses briefly on just one column, not long-range connections, to provide a foundation. The sensorimotor system sends feature and movement information to the thalamus, which then relays this information to the neocortex, specifically to the cortical column. The proposal is that feature information is sent up to layer four, the classical input layer, and the second kind of input to neocortex is at the border of layer five and layer six. The theory suggests that layer four represents features, and in layer six we keep track of location and orientation. There are strong associative connections between layer four and layer six, which can be used to learn associations between features and locations. We can learn which features exist at what relative locations, and the movement input can be used to update the internal location representation inside the cortical column.

Through a series of movements, we activate different feature and location representations, which change as we move over an object. These get pooled into an object representation, called the object ID, which remains constant. As I move my finger over a coffee mug, the features and locations I sense change, but the object ID remains constant and stable. This is the output of layer three and becomes the input to layer four in the next higher region.

A new aspect in this picture is the backward projection from layer six B to the thalamus. We propose that this is used to inform the thalamus of an orientation transform it needs to apply to both features and locations. This is new, and I'll discuss it in more detail in a moment. Essentially, information from the sensorimotor system is in an egocentric format—how I move my finger relative to my body, for example. Representations within the column, however, are in an object-centric reference frame. Features on the coffee mug are locations and features relative to each other in a reference frame specific to the mug. This separation allows for generalization: I can learn about a coffee mug in one room, in one location and orientation, and then recognize that same mug in any other location or orientation because the thalamus can transform any movement happening in the egocentric format. It can take the orientation hypothesis from the column and use it to transform movement and features into the object-centric reference frame. This is a powerful idea for recognizing objects in any location or orientation, even if they were learned in a particular one.

That's the foundation. Any questions on that?

I covered this briefly because it was already suggested in previous papers from NOA in the Thousand Brains Theory. The proposed rule for the lateral connections—connections between the same layer of two cortical columns—is that they can be used to reach rapid consensus. We're already using this in the current Monty implementation, something we call voting, where each cortical column receives input from different sensory patches in the world. For example, one part of the eye might be looking at the rim of the cup, another at the body, and you might be touching the handle with your finger. Each sensorimotor system gets different input, and each column may have learned different models of objects. For instance, the model learned by the column connected to the finger wouldn't contain color information.

Whenever they're all sensing the same object, they all have a particular object representation active in layer three. That is a constant representation as long as the sensors are on that object. The lateral connections can be used to quickly reach consensus. Even though each column by itself might not know for sure what it is sensing—one patch might think it's a cup or a cylinder, another might think it's a cup or a bowl, and another might think it's a cup or scissors—by communicating, they can quickly narrow down what's possible by combining their hypotheses. This also takes into account the relative location of the sensors and the hypothesized orientation of the objects.

For a description of the implementation of this algorithm, see our paper that demonstrates Monty's capabilities, which Niels just presented.

Now to the first big new proposal in this paper: the role of the thalamus in transforming sensory and motor information from an egocentric format into an object-centric format. Whenever information enters the thalamus, it is in an egocentric format—relative to the body or some structure on the body, like the head. That's indicated by these dashed lines.

All the information that enters the column will be relative to the object currently represented by that column. To do this, we need to inform the thalamus how to rotate the incoming information from egocentric to object-centric format. The proposal is that this is done by the layer six B projections to the thalamus. The idea is that layer six B represents the orientation of the sensorimotor system to the object represented in this column. This orientation is sent down and used to rotate both the incoming movement information and the orientation of the features.

There is another transform that needs to happen, which is the motor output. The motor output needs to be in egocentric coordinates, since it doesn't pass through any thalamic nucleus anymore, but goes directly down to the actuators. There is connectivity from layer six B to layer five A, and our proposal is that the transform would happen there. There is more detail on why we think that is possible in the paper. This makes sense in the idea that the projection from layer six B is only modulatory and the input is a driving input, because we have the incoming feature and movement as the driving input. This connection can modulate how this is passed forward to the neocortex.

Essentially, the thalamus would act as a multiplexer, mapping one orientation to another depending on which input it receives from layer six B.

Another thing shown in this figure is the different types of movement input that can be used by the neocortex to move us through the reference frame of the object. We can get movement information either from the retina itself—optic flow, for example. You can watch someone play a video game and, without controlling anything, see how this person is moving through the virtual world just based on how the patterns are moving on your retina. You can get efference copies of the actual motor commands, like outputs from the superior colliculus or the vestibular system about how your sensors are actually moving. There is also this efference copy of the motor command that's being sent to the next higher region.

The second big proposal of this paper is the interpretation of hierarchy.

There are many non-hierarchical connections. There are also hierarchical connections, both feedforward and feedback. Often, these are thought of as hierarchical processing from the sensorimotor system to the thalamus, then processing increasingly more complex features—first edges, then more complex features, and eventually some representation of objects. These are some images of representations in neural networks, which are often compared to the code processing lately. However, we propose hierarchy is used to model compositional objects. When I say compositional objects, I don't mean just complex features combined from edges and objects combined out of complex features, but actual 3D objects made of other 3D objects.

If you remember the first slide, while each column only gets a small patch of input at any one point in time as it moves over objects, the representation of the object is constant and can therefore model and recognize entire objects that are much bigger than the receptive field it gets as input at any one point in time. Even columns in V1 or V2 can represent entire objects that are larger than their receptive field by moving in the world. Here is one example of how compositional structure could be represented: as we attend to different features on this dog, region two has learned a model of a dog, and region one has learned a model of a dog's tail. At a certain location in the model of the dog, the tail exists, and at another location, the head exists. Both region one and region two can have a model of the head of the dog. Through shifting our attention, region two can then attend to the dog's head, while region one represents the eye, which is at a particular location on the head. It's not just features that are coexisting; it's features structured in reference frames. The relative arrangement of these features is really important as well.

This kind of composition of structure is encoded in both the feedforward and feedback connections.

One last thing to emphasize here is that all the regions are receiving sensory and motor input. There is not just a processing of static features. Our sensors are moving all the time, and both features and movement are integrated in the same region.

While it might sound like a small twist to say hierarchical connection, modeling smaller compositional objects is actually quite a different conceptual way of thinking about hierarchy.

Pretty much all compositional structure can be represented by very few regions by just shifting your attention between different parts of an object. You don't need hundreds of layers to process things. You can attend to one feature and then decompose it into subfeatures. You would normally not attend to more than two levels in the hierarchy. As you're looking at the dog, you wouldn't decompose it into head and eyes at the same time without shifting your attention between them. Models of the same objects can exist at different levels of the hierarchy at the same time, and you can shift your attention between them.

This also fits well with the purpose of the top-down connection, because the higher-level object is telling the low-level object where it should be. There is a clear proposal about that. One of the issues with deep learning as a model of the brain is that it often doesn't have a clear explanation for this top-down connection. If that top-down connection is doing some kind of computation, it creates a cyclic graph, which tends to break backpropagation. It doesn't work as the means of backpropagation because it involves biologically impossible assumptions, like symmetric connections, or it just works poorly compared to the backprop that powers deep learning systems. As part of this kind of hierarchy composition, it gives a clear reason for the well-defined L6 to L6 connection within the broader output in L1.

Now, how does this actually get implemented in a cortical column? First, getting into more of the complexities of modeling compositional objects, you might think it's simple: I have a model of a cup and a model of a logo, and now I want to learn the logo on the cup. When I learn this cup with the logo on it, I don't have to relearn the model of the logo or the cup. I can simply assign the existing model of the logo to a location on the existing model of the cup. This is a super efficient process. That's the promise of learning compositional objects—you can combine things very quickly without relearning what you've already learned. You can assign the logo to the mug, and that's it. There might be a small tweak, like the logo being in a different orientation on the mug. So, we associate a location on the mug with a particular location and orientation of the logo. The connection between the two needs to include not just the object IDs and relative locations, but also the relative orientation.

It gets a little more complicated. The logo might change in scale as it goes along the surface of the cup, or part of the logo might appear in a different location or orientation. We need to include scale. Here, scale is different in different locations on the mug, and orientation is different in different locations as well. We settled on the idea that this association needs to happen at many locations on the mug. On a location-by-location basis, each location on the mug needs to be associated with the location, orientation, and scale of the logo. This happens at many different points. This also helps learn how a logo initially learned in 2D can now wrap around a 3D mug. Lastly, there's no pre-assumption of which object is the child and which is the parent. The logo won't always be on the mug; the mug might actually be part of the logo, where the logo is the parent object and the mug is a child feature.

There are all these combinations, and initially they seem difficult to figure out. The solution we came up with is that they get associated on a location-by-location basis, including object ID, location, orientation, and scale of the child object relative to the parent.

How would this look in a cortical column using these long-range connections? Here's an example: we have a series of fixations on this cup with the logo on it. Depending on where we are fixating, the two regions in the cortex represent different objects.

Both of these regions receive sensory input. The lower region, like V1, receives a smaller receptive field. The higher region receives input from a larger receptive field and from the lower region's output from layer three. At fixation one, both regions represent the cup. At fixation two, both regions represent the cup. At fixation three, the lower region represents the logo, and the higher region represents the cup. Together, they learn the logo on the cup. The same applies for fixations four and five; at fixation five, the orientation of the logo is different.

Both receptive fields are co-located, so both input to region one and region two come from the same location in space, just with a larger receptive field.

Layer three is a representation of the object learned in region one. Layer three encodes the ID of the logo and connects to layer four of the next higher region. The object ID becomes a feature in the model at the next higher region.

The TBP logo now becomes an input to the feature layer, layer four of region two, and gets associated with locations on the compositional object. This input doesn't encode the whole model or the structural composition of the logo—it's just an ID of that object.

This connection alone explains how we learn at which locations on the mug the logo exists. Whenever we're on the logo on the cup, the logo is represented in layer three and sent to layer four of region two. Region two associates that logo ID with locations on the mug through those layer four to layer six associative connections.

After learning the logo on the cup, region two also wants to inform region one when it should expect the logo. If we're on fixation three and region two knows the TBP mug model, when we move to fixation four, region two should be able to tell region one to expect to see the logo and where on the logo it should expect to be. That's what the feedback connection is for. We have very local connectivity to the deeper regions, which communicate a unique location on the logo's model. Layer six A encodes the locations in an object-centric reference frame. Region two tells region one to expect to be at this location on the logo. There's also broader connectivity in layer one, which more broadly informs neighboring columns about the existence of the logo, but not precisely about its location.

Finally, we also need to know the orientation of the logo relative to the cup. That's what these orange or yellow connections are for.

Region one, marked with E, represents the orientation of the sensorimotor to the logo. Region two, layer six P, represents the orientation of the sensorimotor to the cup. If we combine these two orientations, we get the orientation of the logo relative to the cup at the current location, and that's also the input to layer four of region two, which can get associated with a specific location on the cup model.

It's crucial to get the relative orientation of the logo to the cup, because it's the relative orientation—not just the absolute orientation of the logo—that matters.

It needs to be a relative orientation because, imagine learning the logo on the mug—the TBP mug model—and now you're tilting the TBP mug. The orientation of the logo is changing and the orientation of the mug is changing, but the relative orientation of the logo to the mug is unchanged. The input here is still exactly the same, and there's no need to update the model. We just need to represent the relative orientation between the logo and the mug, so we can recognize the compositional model in any orientation in the world.

One question: are the projections between layer 6A of region one and two bi-directional, or just feedback from region two? For region one, that's just feedback. The location in the feedforward connection is basic. This isn't shown here, but the input from the thalamus also includes movement information to the border of layer five and layer six. That movement information moves you through the reference frame of the mug as the sensorimotor system is moving. The location in the mug's reference frame then gets associated with the logo object ID through internal associative connections. I'm wondering, it makes this association with the object ID, but it doesn't know where on the object it's making this association. For example, with the number five on the cup, it doesn't know that this is the word "project"—that this part of the logo is being assigned here. It just knows that the logo is being assigned here. So when it goes back from region two to region one, how does it tell region one the location it should be on? That's what region one learns when it connects to the feedback connection.

Region two has learned the model of the cup. If we're at location five in the mug's reference frame, we send this location representation down to region one, and region one associates that with a specific location on its logo model, such as the "J" of the word "project." That's an association between a specific location on the mug and a specific location on the logo. It's not bi-directional. Region two does not know where on the logo exactly it is, but it doesn't need to know because region two doesn't have a full model of the Thousand Brains logo. It only gets the object ID; it's a more simplified version.

That makes sense.

We are not communicating the expected orientation from region two to region one in this diagram. One proposal is that this can be communicated by the layer six cortical connections, but we're not certain enough to have included it in this paper. There's also no depiction of how scale gets processed, but the idea is that it's a similar mechanism to orientation: we calculate a relative scale and associate that relative scale with a location on the compositional object.

Does someone have more questions? I have one.

If we go back to the first part of this slide, where we're talking about fixations 1, 2, 3—on the slide you're on—in fixation one, everyone's seeing a cup; in fixation two, everyone's seeing a cup; in fixation three, region one is seeing a logo, but isn't the patch that region two is getting also mostly a logo? How does it stay with the idea that it's looking at a cup and not decide it's looking at a new object, since all it's seeing is that patch?

That's a very good and practical question we have with Monty right now. We have not really tested a concrete mechanism for that yet. One thing is that this region is receiving a larger, lower-resolution version of the input. They would likely not see any specific features or be able to perceive specific features of the logo, so it might take more for it to switch its hypothesis.

There isn't a principled mechanism for learning it for inference. It's simple because region two would be representing the compositional object itself. I don't know if anyone else has thoughts on it. I think, as you said, it's probably to do with the sensory input and its sensitivity to spatial detail—it's not going to quickly pick up on things like that.

It's a good question and something we need to get working.

Region two might, from the beginning, just represent "TBP Cup" once it sees that the logo is there, which is not in its default model of the cup. It might just start saying, "This is a new object, I don't know anything about," so it would set the ID to "TBP Cup," the specific cup, and then learn that at this location the logo exists. After learning, this becomes a compositional object of logo and cup. Any other questions?

Just to summarize, many connections in the neocortex are not strictly hierarchical. All the long-range connections serve a crucial role when viewing each cortical column as a sensorimotor processing unit, where each column can learn complete models of objects. Each column receives sensory and motor input and also outputs sensory and motor signals. Columns can work in parallel and hierarchically because of that.

The proposal for the function these connections serve is that hierarchical connections are used to learn compositional objects—objects composed of other objects. Lateral connections are used to establish rapid consensus between hypotheses in different columns, and the cortico-thalamic connections are used to inform reference frame transforms applied in the thalamus to the incoming features and movements. The significance of this paper is that the theory we propose provides a comprehensive explanation for many long-range connections in the neocortex. It explains physiological and anatomical findings that previously had no explanation. It's testable and addresses the functional role for the thalamus as a pose converter, which is central to all critical computations in a sensorimotor system. You can't have a sensorimotor system without something that does this, which we noticed as we built Monty.

It suggests an alternate way of building artificial intelligence, one we have implemented over the past years, and Niels just showed the significant advantages of such a system that works on these principles.

It's the hierarchy paper.